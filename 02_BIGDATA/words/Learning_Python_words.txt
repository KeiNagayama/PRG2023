learning
python
fourth
edition
learning
python
mark
lutz
beijing
cambridge
farnham
k√∂ln
sebastopol
taipei
tokyo
learning
python
fourth
edition
by
mark
lutz
copyright
mark
lutz
all
rights
reserved
printed
in
the
united
states
of
america
published
by
o
reilly
media
inc
gravenstein
highway
north
sebastopol
ca
o
reilly
books
may
be
purchased
for
educational
business
or
sales
promotional
use
online
editions
are
also
available
for
most
titles
http
my
safaribooksonline
com
for
more
information
contact
our
corporate
institutional
sales
department
or
corporate
oreilly
com
editor
julie
steele
production
editor
sumita
mukherji
copyeditor
rachel
head
production
services
newgen
north
america
indexer
john
bickelhaupt
cover
designer
karen
montgomery
interior
designer
david
futato
illustrator
robert
romano
printing
history
march
december
october
september
first
edition
second
edition
third
edition
fourth
edition
nutshell
handbook
the
nutshell
handbook
logo
and
the
o
reilly
logo
are
registered
trademarks
of
o
reilly
media
inc
learning
python
the
image
of
a
wood
rat
and
related
trade
dress
are
trademarks
of
o
reilly
media
inc
many
of
the
designations
used
by
manufacturers
and
sellers
to
distinguish
their
products
are
claimed
as
trademarks
where
those
designations
appear
in
this
book
and
o
reilly
media
inc
was
aware
of
a
trademark
claim
the
designations
have
been
printed
in
caps
or
initial
caps
while
every
precaution
has
been
taken
in
the
preparation
of
this
book
the
publisher
and
author
assume
no
responsibility
for
errors
or
omissions
or
for
damages
resulting
from
the
use
of
the
information
contained
herein
isbn
m
to
vera
you
are
my
life
table
of
contents
preface
xxxi
part
i
getting
started
a
python
q
a
session
why
do
people
use
python
software
quality
developer
productivity
is
python
a
scripting
language
ok
but
what
s
the
downside
who
uses
python
today
what
can
i
do
with
python
systems
programming
guis
internet
scripting
component
integration
database
programming
rapid
prototyping
numeric
and
scientific
programming
gaming
images
serial
ports
xml
robots
and
more
how
is
python
supported
what
are
python
s
technical
strengths
it
s
object
oriented
it
s
free
it
s
portable
it
s
powerful
it
s
mixable
it
s
easy
to
use
it
s
easy
to
learn
it
s
named
after
monty
python
how
does
python
stack
up
to
language
x
vii
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
how
python
runs
programs
introducing
the
python
interpreter
program
execution
the
programmer
s
view
python
s
view
execution
model
variations
python
implementation
alternatives
execution
optimization
tools
frozen
binaries
other
execution
options
future
possibilities
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
how
you
run
programs
the
interactive
prompt
running
code
interactively
why
the
interactive
prompt
using
the
interactive
prompt
system
command
lines
and
files
a
first
script
running
files
with
command
lines
using
command
lines
and
files
unix
executable
scripts
clicking
file
icons
clicking
icons
on
windows
the
input
trick
other
icon
click
limitations
module
imports
and
reloads
the
grander
module
story
attributes
import
and
reload
usage
notes
using
exec
to
run
module
files
the
idle
user
interface
idle
basics
using
idle
advanced
idle
tools
other
ides
other
launch
options
viii
table
of
contents
embedding
calls
frozen
binary
executables
text
editor
launch
options
still
other
launch
options
future
possibilities
which
option
should
i
use
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
test
your
knowledge
part
i
exercises
part
ii
types
and
operations
introducing
python
object
types
why
use
built
in
types
python
s
core
data
types
numbers
strings
sequence
operations
immutability
type
specific
methods
getting
help
other
ways
to
code
strings
pattern
matching
lists
sequence
operations
type
specific
operations
bounds
checking
nesting
comprehensions
dictionaries
mapping
operations
nesting
revisited
sorting
keys
for
loops
iteration
and
optimization
missing
keys
if
tests
tuples
why
tuples
files
other
file
like
tools
other
core
types
how
to
break
your
code
s
flexibility
table
of
contents
ix
user
defined
classes
and
everything
else
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
numeric
types
numeric
type
basics
numeric
literals
built
in
numeric
tools
python
expression
operators
numbers
in
action
variables
and
basic
expressions
numeric
display
formats
comparisons
normal
and
chained
division
classic
floor
and
true
integer
precision
complex
numbers
hexadecimal
octal
and
binary
notation
bitwise
operations
other
built
in
numeric
tools
other
numeric
types
decimal
type
fraction
type
sets
booleans
numeric
extensions
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
the
dynamic
typing
interlude
the
case
of
the
missing
declaration
statements
variables
objects
and
references
types
live
with
objects
not
variables
objects
are
garbage
collected
shared
references
shared
references
and
in
place
changes
shared
references
and
equality
dynamic
typing
is
everywhere
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
x
table
of
contents
strings
string
literals
single
and
double
quoted
strings
are
the
same
escape
sequences
represent
special
bytes
raw
strings
suppress
escapes
triple
quotes
code
multiline
block
strings
strings
in
action
basic
operations
indexing
and
slicing
string
conversion
tools
changing
strings
string
methods
string
method
examples
changing
strings
string
method
examples
parsing
text
other
common
string
methods
in
action
the
original
string
module
gone
in
string
formatting
expressions
advanced
string
formatting
expressions
dictionary
based
string
formatting
expressions
string
formatting
method
calls
the
basics
adding
keys
attributes
and
offsets
adding
specific
formatting
comparison
to
the
formatting
expression
why
the
new
format
method
general
type
categories
types
share
operation
sets
by
categories
mutable
types
can
be
changed
in
place
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
lists
and
dictionaries
lists
lists
in
action
basic
list
operations
list
iteration
and
comprehensions
indexing
slicing
and
matrixes
changing
lists
in
place
dictionaries
dictionaries
in
action
basic
dictionary
operations
changing
dictionaries
in
place
table
of
contents
xi
more
dictionary
methods
a
languages
table
dictionary
usage
notes
other
ways
to
make
dictionaries
dictionary
changes
in
python
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
tuples
files
and
everything
else
tuples
tuples
in
action
why
lists
and
tuples
files
opening
files
using
files
files
in
action
other
file
tools
type
categories
revisited
object
flexibility
references
versus
copies
comparisons
equality
and
truth
python
dictionary
comparisons
the
meaning
of
true
and
false
in
python
python
s
type
hierarchies
type
objects
other
types
in
python
built
in
type
gotchas
assignment
creates
references
not
copies
repetition
adds
one
level
deep
beware
of
cyclic
data
structures
immutable
types
can
t
be
changed
in
place
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
test
your
knowledge
part
ii
exercises
part
iii
statements
and
syntax
introducing
python
statements
python
program
structure
revisited
python
s
statements
xii
table
of
contents
a
tale
of
two
ifs
what
python
adds
what
python
removes
why
indentation
syntax
a
few
special
cases
a
quick
example
interactive
loops
a
simple
interactive
loop
doing
math
on
user
inputs
handling
errors
by
testing
inputs
handling
errors
with
try
statements
nesting
code
three
levels
deep
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
assignments
expressions
and
prints
assignment
statements
assignment
statement
forms
sequence
assignments
extended
sequence
unpacking
in
python
multiple
target
assignments
augmented
assignments
variable
name
rules
expression
statements
expression
statements
and
in
place
changes
print
operations
the
python
print
function
the
python
print
statement
print
stream
redirection
version
neutral
printing
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
if
tests
and
syntax
rules
if
statements
general
format
basic
examples
multiway
branching
python
syntax
rules
block
delimiters
indentation
rules
statement
delimiters
lines
and
continuations
a
few
special
cases
table
of
contents
xiii
truth
tests
the
if
else
ternary
expression
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
while
and
for
loops
while
loops
general
format
examples
break
continue
pass
and
the
loop
else
general
loop
format
pass
continue
break
loop
else
for
loops
general
format
examples
loop
coding
techniques
counter
loops
while
and
range
nonexhaustive
traversals
range
and
slices
changing
lists
range
parallel
traversals
zip
and
map
generating
both
offsets
and
items
enumerate
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
iterations
and
comprehensions
part
iterators
a
first
look
the
iteration
protocol
file
iterators
manual
iteration
iter
and
next
other
built
in
type
iterators
list
comprehensions
a
first
look
list
comprehension
basics
using
list
comprehensions
on
files
extended
list
comprehension
syntax
other
iteration
contexts
new
iterables
in
python
the
range
iterator
the
map
zip
and
filter
iterators
multiple
versus
single
iterators
xiv
table
of
contents
dictionary
view
iterators
other
iterator
topics
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
the
documentation
interlude
python
documentation
sources
comments
the
dir
function
docstrings
doc
pydoc
the
help
function
pydoc
html
reports
the
standard
manual
set
web
resources
published
books
common
coding
gotchas
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
test
your
knowledge
part
iii
exercises
part
iv
functions
function
basics
why
use
functions
coding
functions
def
statements
def
executes
at
runtime
a
first
example
definitions
and
calls
definition
calls
polymorphism
in
python
a
second
example
intersecting
sequences
definition
calls
polymorphism
revisited
local
variables
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
table
of
contents
xv
scopes
python
scope
basics
scope
rules
name
resolution
the
legb
rule
scope
example
the
built
in
scope
the
global
statement
minimize
global
variables
minimize
cross
file
changes
other
ways
to
access
globals
scopes
and
nested
functions
nested
scope
details
nested
scope
examples
the
nonlocal
statement
nonlocal
basics
nonlocal
in
action
why
nonlocal
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
arguments
argument
passing
basics
arguments
and
shared
references
avoiding
mutable
argument
changes
simulating
output
parameters
special
argument
matching
modes
the
basics
matching
syntax
the
gritty
details
keyword
and
default
examples
arbitrary
arguments
examples
python
keyword
only
arguments
the
min
wakeup
call
full
credit
bonus
points
the
punch
line
generalized
set
functions
emulating
the
python
print
function
using
keyword
only
arguments
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
xvi
table
of
contents
advanced
function
topics
function
design
concepts
recursive
functions
summation
with
recursion
coding
alternatives
loop
statements
versus
recursion
handling
arbitrary
structures
function
objects
attributes
and
annotations
indirect
function
calls
function
introspection
function
attributes
function
annotations
in
anonymous
functions
lambda
lambda
basics
why
use
lambda
how
not
to
obfuscate
your
python
code
nested
lambdas
and
scopes
mapping
functions
over
sequences
map
functional
programming
tools
filter
and
reduce
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
iterations
and
comprehensions
part
list
comprehensions
revisited
functional
tools
list
comprehensions
versus
map
adding
tests
and
nested
loops
filter
list
comprehensions
and
matrixes
comprehending
list
comprehensions
iterators
revisited
generators
generator
functions
yield
versus
return
generator
expressions
iterators
meet
comprehensions
generator
functions
versus
generator
expressions
generators
are
single
iterator
objects
emulating
zip
and
map
with
iteration
tools
value
generation
in
built
in
types
and
classes
comprehension
syntax
summary
comprehending
set
and
dictionary
comprehensions
extended
comprehension
syntax
for
sets
and
dictionaries
timing
iteration
alternatives
timing
module
timing
script
timing
results
table
of
contents
xvii
timing
module
alternatives
other
suggestions
function
gotchas
local
names
are
detected
statically
defaults
and
mutable
objects
functions
without
returns
enclosing
scope
loop
variables
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
test
your
knowledge
part
iv
exercises
part
v
modules
modules
the
big
picture
why
use
modules
python
program
architecture
how
to
structure
a
program
imports
and
attributes
standard
library
modules
how
imports
work
find
it
compile
it
maybe
run
it
the
module
search
path
configuring
the
search
path
search
path
variations
the
sys
path
list
module
file
selection
advanced
module
selection
concepts
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
module
coding
basics
module
creation
module
usage
the
import
statement
the
from
statement
the
from
statement
imports
happen
only
once
import
and
from
are
assignments
xviii
table
of
contents
cross
file
name
changes
import
and
from
equivalence
potential
pitfalls
of
the
from
statement
module
namespaces
files
generate
namespaces
attribute
name
qualification
imports
versus
scopes
namespace
nesting
reloading
modules
reload
basics
reload
example
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
module
packages
package
import
basics
packages
and
search
path
settings
package
init
py
files
package
import
example
from
versus
import
with
packages
why
use
package
imports
a
tale
of
three
systems
package
relative
imports
changes
in
python
relative
import
basics
why
relative
imports
the
scope
of
relative
imports
module
lookup
rules
summary
relative
imports
in
action
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
advanced
module
topics
data
hiding
in
modules
minimizing
from
damage
x
and
all
enabling
future
language
features
mixed
usage
modes
name
and
main
unit
tests
with
name
using
command
line
arguments
with
name
changing
the
module
search
path
the
as
extension
for
import
and
from
table
of
contents
xix
modules
are
objects
metaprograms
importing
modules
by
name
string
transitive
module
reloads
module
design
concepts
module
gotchas
statement
order
matters
in
top
level
code
from
copies
names
but
doesn
t
link
from
can
obscure
the
meaning
of
variables
reload
may
not
impact
from
imports
reload
from
and
interactive
testing
recursive
from
imports
may
not
work
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
test
your
knowledge
part
v
exercises
part
vi
classes
and
oop
oop
the
big
picture
why
use
classes
oop
from
feet
attribute
inheritance
search
classes
and
instances
class
method
calls
coding
class
trees
oop
is
about
code
reuse
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
class
coding
basics
classes
generate
multiple
instance
objects
class
objects
provide
default
behavior
instance
objects
are
concrete
items
a
first
example
classes
are
customized
by
inheritance
a
second
example
classes
are
attributes
in
modules
classes
can
intercept
python
operators
a
third
example
why
use
operator
overloading
the
world
s
simplest
python
class
xx
table
of
contents
classes
versus
dictionaries
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
a
more
realistic
example
step
making
instances
coding
constructors
testing
as
you
go
using
code
two
ways
step
adding
behavior
methods
coding
methods
step
operator
overloading
providing
print
displays
step
customizing
behavior
by
subclassing
coding
subclasses
augmenting
methods
the
bad
way
augmenting
methods
the
good
way
polymorphism
in
action
inherit
customize
and
extend
oop
the
big
idea
step
customizing
constructors
too
oop
is
simpler
than
you
may
think
other
ways
to
combine
classes
step
using
introspection
tools
special
class
attributes
a
generic
display
tool
instance
versus
class
attributes
name
considerations
in
tool
classes
our
classes
final
form
step
final
storing
objects
in
a
database
pickles
and
shelves
storing
objects
on
a
shelve
database
exploring
shelves
interactively
updating
objects
on
a
shelve
future
directions
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
class
coding
details
the
class
statement
general
form
table
of
contents
xxi
example
methods
method
example
calling
superclass
constructors
other
method
call
possibilities
inheritance
attribute
tree
construction
specializing
inherited
methods
class
interface
techniques
abstract
superclasses
python
and
abstract
superclasses
namespaces
the
whole
story
simple
names
global
unless
assigned
attribute
names
object
namespaces
the
zen
of
python
namespaces
assignments
classify
names
namespace
dictionaries
namespace
links
documentation
strings
revisited
classes
versus
modules
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
operator
overloading
the
basics
constructors
and
expressions
init
and
sub
common
operator
overloading
methods
indexing
and
slicing
getitem
and
setitem
intercepting
slices
index
iteration
getitem
iterator
objects
iter
and
next
user
defined
iterators
multiple
iterators
on
one
object
membership
contains
iter
and
getitem
attribute
reference
getattr
and
setattr
other
attribute
management
tools
emulating
privacy
for
instance
attributes
part
string
representation
repr
and
str
right
side
and
in
place
addition
radd
and
iadd
in
place
addition
call
expressions
call
function
interfaces
and
callback
based
code
comparisons
lt
gt
and
others
xxii
table
of
contents
the
cmp
method
removed
in
boolean
tests
bool
and
len
object
destruction
del
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
designing
with
classes
python
and
oop
overloading
by
call
signatures
or
not
oop
and
inheritance
is
a
relationships
oop
and
composition
has
a
relationships
stream
processors
revisited
oop
and
delegation
wrapper
objects
pseudoprivate
class
attributes
name
mangling
overview
why
use
pseudoprivate
attributes
methods
are
objects
bound
or
unbound
unbound
methods
are
functions
in
bound
methods
and
other
callable
objects
multiple
inheritance
mix
in
classes
coding
mix
in
display
classes
classes
are
objects
generic
object
factories
why
factories
other
design
related
topics
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
advanced
class
topics
extending
built
in
types
extending
types
by
embedding
extending
types
by
subclassing
the
new
style
class
model
new
style
class
changes
type
model
changes
diamond
inheritance
change
new
style
class
extensions
instance
slots
class
properties
getattribute
and
descriptors
metaclasses
static
and
class
methods
table
of
contents
xxiii
why
the
special
methods
static
methods
in
and
static
method
alternatives
using
static
and
class
methods
counting
instances
with
static
methods
counting
instances
with
class
methods
decorators
and
metaclasses
part
function
decorator
basics
a
first
function
decorator
example
class
decorators
and
metaclasses
for
more
details
class
gotchas
changing
class
attributes
can
have
side
effects
changing
mutable
class
attributes
can
have
side
effects
too
multiple
inheritance
order
matters
methods
classes
and
nested
scopes
delegation
based
classes
in
getattr
and
built
ins
overwrapping
itis
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
test
your
knowledge
part
vi
exercises
part
vii
exceptions
and
tools
exception
basics
why
use
exceptions
exception
roles
exceptions
the
short
story
default
exception
handler
catching
exceptions
raising
exceptions
user
defined
exceptions
termination
actions
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
exception
coding
details
the
try
except
else
statement
try
statement
clauses
the
try
else
clause
xxiv
table
of
contents
example
default
behavior
example
catching
built
in
exceptions
the
try
finally
statement
example
coding
termination
actions
with
try
finally
unified
try
except
finally
unified
try
statement
syntax
combining
finally
and
except
by
nesting
unified
try
example
the
raise
statement
propagating
exceptions
with
raise
python
exception
chaining
raise
from
the
assert
statement
example
trapping
constraints
but
not
errors
with
as
context
managers
basic
usage
the
context
management
protocol
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
exception
objects
exceptions
back
to
the
future
string
exceptions
are
right
out
class
based
exceptions
coding
exceptions
classes
why
exception
hierarchies
built
in
exception
classes
built
in
exception
categories
default
printing
and
state
custom
print
displays
custom
data
and
behavior
providing
exception
details
providing
exception
methods
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
designing
with
exceptions
nesting
exception
handlers
example
control
flow
nesting
example
syntactic
nesting
exception
idioms
exceptions
aren
t
always
errors
table
of
contents
xxv
functions
can
signal
conditions
with
raise
closing
files
and
server
connections
debugging
with
outer
try
statements
running
in
process
tests
more
on
sys
exc
info
exception
design
tips
and
gotchas
what
should
be
wrapped
catching
too
much
avoid
empty
except
and
exception
catching
too
little
use
class
based
categories
core
language
summary
the
python
toolset
development
tools
for
larger
projects
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
test
your
knowledge
part
vii
exercises
part
viii
advanced
topics
unicode
and
byte
strings
string
changes
in
string
basics
character
encoding
schemes
python
s
string
types
text
and
binary
files
python
strings
in
action
literals
and
basic
properties
conversions
coding
unicode
strings
coding
ascii
text
coding
non
ascii
text
encoding
and
decoding
non
ascii
text
other
unicode
coding
techniques
converting
encodings
coding
unicode
strings
in
python
source
file
character
set
encoding
declarations
using
bytes
objects
method
calls
sequence
operations
other
ways
to
make
bytes
objects
mixing
string
types
using
and
bytearray
objects
xxvi
table
of
contents
using
text
and
binary
files
text
file
basics
text
and
binary
modes
in
type
and
content
mismatches
using
unicode
files
reading
and
writing
unicode
in
handling
the
bom
in
unicode
files
in
other
string
tool
changes
in
the
re
pattern
matching
module
the
struct
binary
data
module
the
pickle
object
serialization
module
xml
parsing
tools
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
managed
attributes
why
manage
attributes
inserting
code
to
run
on
attribute
access
properties
the
basics
a
first
example
computed
attributes
coding
properties
with
decorators
descriptors
the
basics
a
first
example
computed
attributes
using
state
information
in
descriptors
how
properties
and
descriptors
relate
getattr
and
getattribute
the
basics
a
first
example
computed
attributes
getattr
and
getattribute
compared
management
techniques
compared
intercepting
built
in
operation
attributes
delegation
based
managers
revisited
example
attribute
validations
using
properties
to
validate
using
descriptors
to
validate
using
getattr
to
validate
table
of
contents
xxvii
using
getattribute
to
validate
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
decorators
what
s
a
decorator
managing
calls
and
instances
managing
functions
and
classes
using
and
defining
decorators
why
decorators
the
basics
function
decorators
class
decorators
decorator
nesting
decorator
arguments
decorators
manage
functions
and
classes
too
coding
function
decorators
tracing
calls
state
information
retention
options
class
blunders
i
decorating
class
methods
timing
calls
adding
decorator
arguments
coding
class
decorators
singleton
classes
tracing
object
interfaces
class
blunders
ii
retaining
multiple
instances
decorators
versus
manager
functions
why
decorators
revisited
managing
functions
and
classes
directly
example
private
and
public
attributes
implementing
private
attributes
implementation
details
i
generalizing
for
public
declarations
too
implementation
details
ii
open
issues
python
isn
t
about
control
example
validating
function
arguments
the
goal
a
basic
range
testing
decorator
for
positional
arguments
generalizing
for
keywords
and
defaults
too
implementation
details
open
issues
xxviii
table
of
contents
decorator
arguments
versus
function
annotations
other
applications
type
testing
if
you
insist
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
metaclasses
to
metaclass
or
not
to
metaclass
increasing
levels
of
magic
the
downside
of
helper
functions
metaclasses
versus
class
decorators
round
the
metaclass
model
classes
are
instances
of
type
metaclasses
are
subclasses
of
type
class
statement
protocol
declaring
metaclasses
coding
metaclasses
a
basic
metaclass
customizing
construction
and
initialization
other
metaclass
coding
techniques
instances
versus
inheritance
example
adding
methods
to
classes
manual
augmentation
metaclass
based
augmentation
metaclasses
versus
class
decorators
round
example
applying
decorators
to
methods
tracing
with
decoration
manually
tracing
with
metaclasses
and
decorators
applying
any
decorator
to
methods
metaclasses
versus
class
decorators
round
chapter
summary
test
your
knowledge
quiz
test
your
knowledge
answers
part
ix
appendixes
a
installation
and
configuration
b
solutions
to
end
of
part
exercises
index
table
of
contents
xxix
preface
this
book
provides
an
introduction
to
the
python
programming
language
python
is
a
popular
open
source
programming
language
used
for
both
standalone
programs
and
scripting
applications
in
a
wide
variety
of
domains
it
is
free
portable
powerful
and
remarkably
easy
and
fun
to
use
programmers
from
every
corner
of
the
software
industry
have
found
python
s
focus
on
developer
productivity
and
software
quality
to
be
a
strategic
advantage
in
projects
both
large
and
small
whether
you
are
new
to
programming
or
are
a
professional
developer
this
book
s
goal
is
to
bring
you
quickly
up
to
speed
on
the
fundamentals
of
the
core
python
language
after
reading
this
book
you
will
know
enough
about
python
to
apply
it
in
whatever
application
domains
you
choose
to
explore
by
design
this
book
is
a
tutorial
that
focuses
on
the
core
python
language
itself
rather
than
specific
applications
of
it
as
such
it
s
intended
to
serve
as
the
first
in
a
two
volume
set
learning
python
this
book
teaches
python
itself
programming
python
among
others
shows
what
you
can
do
with
python
after
you
ve
learned
it
that
is
applications
focused
books
such
as
programming
python
pick
up
where
this
book
leaves
off
exploring
python
s
role
in
common
domains
such
as
the
web
graphical
user
interfaces
guis
and
databases
in
addition
the
book
python
pocket
reference
provides
additional
reference
materials
not
included
here
and
it
is
designed
to
supplement
this
book
because
of
this
book
s
foundations
focus
though
it
is
able
to
present
python
fundamentals
with
more
depth
than
many
programmers
see
when
first
learning
the
language
and
because
it
s
based
upon
a
three
day
python
training
class
with
quizzes
and
exercises
throughout
this
book
serves
as
a
self
paced
introduction
to
the
language
xxxi
about
this
fourth
edition
this
fourth
edition
of
this
book
has
changed
in
three
ways
this
edition
covers
both
python
and
python
it
emphasizes
but
notes
differences
in
includes
a
set
of
new
chapters
mainly
targeted
at
advanced
core
language
topics
reorganizes
some
existing
material
and
expands
it
with
new
examples
for
clarity
as
i
write
this
edition
in
python
comes
in
two
flavors
version
is
an
emerging
and
incompatible
mutation
of
the
language
and
retains
backward
compatibility
with
the
vast
body
of
existing
python
code
although
python
is
viewed
as
the
future
of
python
python
is
still
widely
used
and
will
be
supported
in
parallel
with
python
for
years
to
come
while
is
largely
the
same
language
it
runs
almost
no
code
written
for
prior
releases
the
mutation
of
print
from
statement
to
function
alone
aesthetically
sound
as
it
may
be
breaks
nearly
every
python
program
ever
written
this
split
presents
a
bit
of
a
dilemma
for
both
programmers
and
book
authors
while
it
would
be
easier
for
a
book
to
pretend
that
python
never
existed
and
cover
only
this
would
not
address
the
needs
of
the
large
python
user
base
that
exists
today
a
vast
amount
of
existing
code
was
written
for
python
and
it
won
t
be
going
away
any
time
soon
and
while
newcomers
to
the
language
can
focus
on
python
anyone
who
must
use
code
written
in
the
past
needs
to
keep
one
foot
in
the
python
world
today
since
it
may
be
years
before
all
third
party
libraries
and
extensions
are
ported
to
python
this
fork
might
not
be
entirely
temporary
coverage
for
both
and
to
address
this
dichotomy
and
to
meet
the
needs
of
all
potential
readers
this
edition
of
this
book
has
been
updated
to
cover
both
python
and
python
and
later
releases
in
the
x
and
x
lines
it
s
intended
for
programmers
using
python
programmers
using
python
and
programmers
stuck
somewhere
between
the
two
that
is
you
can
use
this
book
to
learn
either
python
line
although
the
focus
here
is
on
primarily
differences
and
tools
are
also
noted
along
the
way
for
programmers
using
older
code
while
the
two
versions
are
largely
the
same
they
diverge
in
some
important
ways
and
i
ll
point
these
out
along
the
way
for
instance
i
ll
use
print
calls
in
most
examples
but
will
describe
the
print
statement
too
so
you
can
make
sense
of
earlier
code
i
ll
also
freely
introduce
new
features
such
as
the
nonlocal
statement
in
and
the
string
format
method
in
and
and
will
point
out
when
such
extensions
are
not
present
in
older
pythons
if
you
are
learning
python
for
the
first
time
and
don
t
need
to
use
any
legacy
code
i
encourage
you
to
begin
with
python
it
cleans
up
some
longstanding
warts
in
the
language
while
retaining
all
the
original
core
ideas
and
adding
some
nice
new
tools
xxxii
preface
many
popular
python
libraries
and
tools
will
likely
be
available
for
python
by
the
time
you
read
these
words
especially
given
the
file
i
o
performance
improvements
expected
in
the
upcoming
release
if
you
are
using
a
system
based
on
python
x
however
you
ll
find
that
this
book
addresses
your
concerns
too
and
will
help
you
migrate
to
in
the
future
by
proxy
this
edition
addresses
other
python
version
and
releases
as
well
though
some
older
version
x
code
may
not
be
able
to
run
all
the
examples
here
although
class
decorators
are
available
in
both
python
and
for
example
you
cannot
use
them
in
an
older
python
x
that
did
not
yet
have
this
feature
see
tables
p
and
p
later
in
this
preface
for
summaries
of
and
changes
shortly
before
going
to
press
this
book
was
also
augmented
with
notes
about
prominent
extensions
in
the
upcoming
python
release
comma
separators
and
automatic
field
numbering
in
string
format
method
calls
multiple
context
manager
syntax
in
with
statements
new
methods
for
numbers
and
so
on
because
python
was
targeted
primarily
at
optimization
this
book
applies
directly
to
this
new
release
as
well
in
fact
because
python
supersedes
and
because
the
latest
python
is
usually
the
best
python
to
fetch
and
use
anyhow
in
this
book
the
term
python
generally
refers
to
the
language
variations
introduced
by
python
but
that
are
present
in
the
entire
x
line
new
chapters
although
the
main
purpose
of
this
edition
is
to
update
the
examples
and
material
from
the
preceding
edition
for
and
i
ve
also
added
five
new
chapters
to
address
new
topics
and
add
context
chapter
is
a
new
class
tutorial
using
a
more
realistic
example
to
explore
the
basics
of
python
object
oriented
programming
oop
chapter
provides
details
on
unicode
and
byte
strings
and
outlines
string
and
file
differences
between
and
chapter
collects
managed
attribute
tools
such
as
properties
and
provides
new
coverage
of
descriptors
chapter
presents
function
and
class
decorators
and
works
through
comprehensive
examples
chapter
covers
metaclasses
and
compares
and
contrasts
them
with
decorators
the
first
of
these
chapters
provides
a
gradual
step
by
step
tutorial
for
using
classes
and
oop
in
python
it
s
based
upon
a
live
demonstration
i
have
been
using
in
recent
years
in
the
training
classes
i
teach
but
has
been
honed
here
for
use
in
a
book
the
chapter
is
designed
to
show
oop
in
a
more
realistic
context
than
earlier
examples
and
to
preface
xxxiii
illustrate
how
class
concepts
come
together
into
larger
working
programs
i
hope
it
works
as
well
here
as
it
has
in
live
classes
the
last
four
of
these
new
chapters
are
collected
in
a
new
final
part
of
the
book
advanced
topics
although
these
are
technically
core
language
topics
not
every
python
programmer
needs
to
delve
into
the
details
of
unicode
text
or
metaclasses
because
of
this
these
four
chapters
have
been
separated
out
into
this
new
part
and
are
officially
optional
reading
the
details
of
unicode
and
binary
data
strings
for
example
have
been
moved
to
this
final
part
because
most
programmers
use
simple
ascii
strings
and
don
t
need
to
know
about
these
topics
similarly
decorators
and
metaclasses
are
specialist
topics
that
are
usually
of
more
interest
to
api
builders
than
application
programmers
if
you
do
use
such
tools
though
or
use
code
that
does
these
new
advanced
topic
chapters
should
help
you
master
the
basics
in
addition
these
chapters
examples
include
case
studies
that
tie
core
language
concepts
together
and
they
are
more
substantial
than
those
in
most
of
the
rest
of
the
book
because
this
new
part
is
optional
reading
it
has
end
of
chapter
quizzes
but
no
end
of
part
exercises
changes
to
existing
material
in
addition
some
material
from
the
prior
edition
has
been
reorganized
or
supplemented
with
new
examples
multiple
inheritance
for
instance
gets
a
new
case
study
example
that
lists
class
trees
in
chapter
new
examples
for
generators
that
manually
implement
map
and
zip
are
provided
in
chapter
static
and
class
methods
are
illustrated
by
new
code
in
chapter
package
relative
imports
are
captured
in
action
in
chapter
and
the
contains
bool
and
index
operator
overloading
methods
are
illustrated
by
example
now
as
well
in
chapter
along
with
the
new
overloading
protocols
for
slicing
and
comparison
this
edition
also
incorporates
some
reorganization
for
clarity
for
instance
to
accommodate
new
material
and
topics
and
to
avoid
chapter
topic
overload
five
prior
chapters
have
been
split
into
two
each
here
the
result
is
new
standalone
chapters
on
operator
overloading
scopes
and
arguments
exception
statement
details
and
comprehension
and
iteration
topics
some
reordering
has
been
done
within
the
existing
chapters
as
well
to
improve
topic
flow
this
edition
also
tries
to
minimize
forward
references
with
some
reordering
though
python
s
changes
make
this
impossible
in
some
cases
to
understand
printing
and
the
string
format
method
you
now
must
know
keyword
arguments
for
functions
to
understand
dictionary
key
lists
and
key
tests
you
must
now
know
iteration
to
use
exec
to
run
code
you
need
to
be
able
to
use
file
objects
and
so
on
a
linear
reading
still
probably
makes
the
most
sense
but
some
topics
may
require
nonlinear
jumps
and
random
lookups
all
told
there
have
been
hundreds
of
changes
in
this
edition
the
next
section
s
tables
alone
document
additions
and
changes
in
python
in
fact
it
s
fair
to
say
that
this
xxxiv
preface
edition
is
somewhat
more
advanced
because
python
is
somewhat
more
advanced
as
for
python
itself
though
you
re
probably
better
off
discovering
most
of
this
book
s
changes
for
yourself
rather
than
reading
about
them
further
in
this
preface
specific
language
extensions
in
and
in
general
python
is
a
cleaner
language
but
it
is
also
in
some
ways
a
more
sophisticated
language
in
fact
some
of
its
changes
seem
to
assume
you
must
already
know
python
in
order
to
learn
python
the
prior
section
outlined
some
of
the
more
prominent
circular
knowledge
dependencies
in
as
a
random
example
the
rationale
for
wrapping
dictionary
views
in
a
list
call
is
incredibly
subtle
and
requires
substantial
foreknowledge
besides
teaching
python
fundamentals
this
book
serves
to
help
bridge
this
knowledge
gap
table
p
lists
the
most
prominent
new
language
features
covered
in
this
edition
along
with
the
primary
chapters
in
which
they
appear
table
p
extensions
in
python
and
extension
covered
in
chapter
s
the
print
function
in
the
nonlocal
x
y
statement
in
the
str
format
method
in
and
string
types
in
str
for
unicode
text
bytes
for
binary
data
text
and
binary
file
distinctions
in
class
decorators
in
and
private
age
new
iterators
in
range
map
zip
dictionary
views
in
d
keys
d
values
d
items
division
operators
in
remainders
and
set
literals
in
a
b
c
set
comprehensions
in
x
for
x
in
seq
dictionary
comprehensions
in
x
x
for
x
in
seq
binary
digit
string
support
in
and
b
bin
i
the
fraction
number
type
in
and
fraction
function
annotations
in
def
f
a
b
str
int
keyword
only
arguments
in
def
f
a
b
c
d
extended
sequence
unpacking
in
a
b
seq
relative
import
syntax
for
packages
enabled
in
from
context
managers
enabled
in
and
with
as
exception
syntax
changes
in
raise
except
as
superclass
preface
xxxv
extension
covered
in
chapter
s
exception
chaining
in
raise
e
from
e
reserved
word
changes
in
and
new
style
class
cutover
in
property
decorators
in
and
property
descriptor
use
in
and
metaclass
use
in
and
abstract
base
classes
support
in
and
specific
language
removals
in
in
addition
to
extensions
a
number
of
language
tools
have
been
removed
in
in
an
effort
to
clean
up
its
design
table
p
summarizes
the
changes
that
impact
this
book
covered
in
various
chapters
of
this
edition
many
of
the
removals
listed
in
table
p
have
direct
replacements
some
of
which
are
also
available
in
to
support
future
migration
to
table
p
removals
in
python
that
impact
this
book
removed
replacement
covered
in
chapter
s
reload
m
imp
reload
m
or
exec
apply
f
ps
ks
f
ps
ks
x
repr
x
x
y
x
y
long
int
l
d
has
key
k
k
in
d
or
d
get
key
none
raw
input
input
old
input
eval
input
xrange
range
file
open
and
io
module
classes
x
next
x
next
called
by
next
x
x
getslice
x
getitem
passed
a
slice
object
x
setslice
x
setitem
passed
a
slice
object
reduce
functools
reduce
or
loop
code
execfile
filename
exec
open
filename
read
exec
open
filename
exec
open
filename
read
o
print
x
y
print
x
y
xxxvi
preface
removed
replacement
covered
in
chapter
s
print
f
x
y
print
x
y
file
f
print
x
y
print
x
y
end
u
ccc
ccc
bbb
for
byte
strings
b
bbb
raise
e
v
raise
e
v
except
e
x
except
e
as
x
def
f
a
b
def
f
x
a
b
x
file
xreadlines
for
line
in
file
or
x
iter
file
d
keys
etc
as
lists
list
d
keys
dictionary
views
map
range
etc
as
lists
list
map
list
range
built
ins
map
none
zip
or
manual
code
to
pad
results
x
d
keys
x
sort
sorted
d
or
list
d
keys
cmp
x
y
x
y
x
y
x
cmp
y
lt
gt
eq
etc
x
nonzero
x
bool
x
hex
x
oct
x
index
sort
comparison
functions
use
key
transform
or
reverse
true
dictionary
compare
sorted
d
items
or
loop
code
types
listtype
list
types
is
for
nonbuilt
in
names
only
metaclass
m
class
c
metaclass
m
builtin
builtins
renamed
tkinter
tkinter
renamed
sys
exc
type
exc
value
sys
exc
info
function
func
code
function
code
getattr
run
by
built
ins
redefine
x
methods
in
wrapper
classes
t
tt
command
line
switches
inconsistent
tabs
spaces
use
is
always
an
error
from
within
a
function
may
only
appear
at
the
top
level
of
a
file
import
mod
in
same
package
from
import
mod
package
relative
form
class
myexception
class
myexception
exception
exceptions
module
built
in
scope
library
manual
thread
queue
modules
thread
queue
both
renamed
anydbm
module
dbm
renamed
cpickle
module
pickle
renamed
used
automatically
os
popen
subprocess
popen
os
popen
retained
string
based
exceptions
class
based
exceptions
also
required
in
preface
xxxvii
removed
replacement
covered
in
chapter
s
string
module
functions
string
object
methods
unbound
methods
functions
staticmethod
to
call
via
instance
mixed
type
comparisons
sorts
nonnumeric
mixed
type
comparisons
are
errors
there
are
additional
changes
in
python
that
are
not
listed
in
this
table
simply
because
they
don
t
affect
this
book
changes
in
the
standard
library
for
instance
might
have
a
larger
impact
on
applications
focused
books
like
programming
python
than
they
do
here
although
most
standard
library
functionality
is
still
present
python
takes
further
liberties
with
renaming
modules
grouping
them
into
packages
and
so
on
for
a
more
comprehensive
list
of
changes
in
see
the
what
s
new
in
python
document
in
python
s
standard
manual
set
if
you
are
migrating
from
python
x
to
python
x
be
sure
to
also
see
the
to
automatic
code
conversion
script
that
is
available
with
python
it
can
t
translate
everything
but
it
does
a
reasonable
job
of
converting
the
majority
of
x
code
to
run
under
x
as
i
write
this
a
new
to
back
conversion
project
is
also
underway
to
translate
python
x
code
to
run
in
x
environments
either
tool
may
prove
useful
if
you
must
maintain
code
for
both
python
lines
see
the
web
for
details
because
this
fourth
edition
is
mostly
a
fairly
straightforward
update
for
with
a
handful
of
new
chapters
and
because
it
s
only
been
two
years
since
the
prior
edition
was
published
the
rest
of
this
preface
is
taken
from
the
prior
edition
with
only
minor
updating
about
the
third
edition
in
the
four
years
between
the
publication
of
the
second
and
third
editions
of
this
book
there
were
substantial
changes
in
python
itself
and
in
the
topics
i
presented
in
python
training
sessions
the
third
edition
reflected
these
changes
and
also
incorporated
a
handful
of
structural
changes
the
third
edition
s
python
language
changes
on
the
language
front
the
third
edition
was
thoroughly
updated
to
reflect
python
and
all
changes
to
the
language
since
the
publication
of
the
second
edition
in
late
the
second
edition
was
based
largely
on
python
with
some
features
grafted
on
at
the
end
of
the
project
in
addition
discussions
of
anticipated
changes
in
the
upcoming
python
release
were
incorporated
where
appropriate
here
are
some
of
the
major
language
topics
for
which
new
or
expanded
coverage
was
provided
chapter
numbers
here
have
been
updated
to
reflect
the
fourth
edition
xxxviii
preface
the
new
b
if
a
else
c
conditional
expression
chapter
with
as
context
managers
chapter
try
except
finally
unification
chapter
relative
import
syntax
chapter
generator
expressions
chapter
new
generator
function
features
chapter
function
decorators
chapter
the
set
object
type
chapter
new
built
in
functions
sorted
sum
any
all
enumerate
chapters
and
the
decimal
fixed
precision
object
type
chapter
files
list
comprehensions
and
iterators
chapters
and
new
development
tools
eclipse
distutils
unittest
and
doctest
idle
enhancements
shedskin
and
so
on
chapters
and
smaller
language
changes
for
instance
the
widespread
use
of
true
and
false
the
new
sys
exc
info
for
fetching
exception
details
and
the
demise
of
string
based
exceptions
string
methods
and
the
apply
and
reduce
built
ins
are
discussed
throughout
the
book
the
third
edition
also
expanded
coverage
of
some
of
the
features
that
were
new
in
the
second
edition
including
three
limit
slices
and
the
arbitrary
arguments
call
syntax
that
subsumed
apply
the
third
edition
s
python
training
changes
besides
such
language
changes
the
third
edition
was
augmented
with
new
topics
and
examples
presented
in
my
python
training
sessions
changes
included
chapter
numbers
again
updated
to
reflect
those
in
the
fourth
edition
a
new
chapter
introducing
built
in
types
chapter
a
new
chapter
introducing
statement
syntax
chapter
a
new
full
chapter
on
dynamic
typing
with
enhanced
coverage
chapter
an
expanded
oop
introduction
chapter
new
examples
for
files
scopes
statement
nesting
classes
exceptions
and
more
many
additions
and
changes
were
made
with
python
beginners
in
mind
and
some
topics
were
moved
to
appear
at
the
places
where
they
proved
simplest
to
digest
in
training
classes
list
comprehensions
and
iterators
for
example
now
make
their
initial
appearance
in
conjunction
with
the
for
loop
statement
instead
of
later
with
functional
tools
preface
xxxix
coverage
of
many
original
core
language
topics
also
was
substantially
expanded
in
the
third
edition
with
new
discussions
and
examples
added
because
this
text
has
become
something
of
a
de
facto
standard
resource
for
learning
the
core
python
language
the
presentation
was
made
more
complete
and
augmented
with
new
use
cases
throughout
in
addition
a
new
set
of
python
tips
and
tricks
gleaned
from
years
of
teaching
classes
and
years
of
using
python
for
real
work
was
incorporated
and
the
exercises
were
updated
and
expanded
to
reflect
current
python
best
practices
new
language
features
and
common
beginners
mistakes
witnessed
firsthand
in
classes
overall
the
core
language
coverage
was
expanded
the
third
edition
s
structural
changes
because
the
material
was
more
complete
it
was
split
into
bite
sized
chunks
the
core
language
material
was
organized
into
many
multichapter
parts
to
make
it
easier
to
tackle
types
and
statements
for
instance
are
now
two
top
level
parts
with
one
chapter
for
each
major
type
and
statement
topic
exercises
and
gotchas
common
mistakes
were
also
moved
from
chapter
ends
to
part
ends
appearing
at
the
end
of
the
last
chapter
in
each
part
in
the
third
edition
i
also
augmented
the
end
of
part
exercises
with
end
of
chapter
summaries
and
end
of
chapter
quizzes
to
help
you
review
chapters
as
you
complete
them
each
chapter
concludes
with
a
set
of
questions
to
help
you
review
and
test
your
understanding
of
the
chapter
s
material
unlike
the
end
of
part
exercises
whose
solutions
are
presented
in
appendix
b
the
solutions
to
the
end
of
chapter
quizzes
appear
immediately
after
the
questions
i
encourage
you
to
look
at
the
solutions
even
if
you
re
sure
you
ve
answered
the
questions
correctly
because
the
answers
are
a
sort
of
review
in
themselves
despite
all
the
new
topics
the
book
is
still
oriented
toward
python
newcomers
and
is
designed
to
be
a
first
python
text
for
programmers
because
it
is
largely
based
on
timetested
training
experience
and
materials
it
can
still
serve
as
a
self
paced
introductory
python
class
the
third
edition
s
scope
changes
as
of
its
third
edition
this
book
is
intended
as
a
tutorial
on
the
core
python
language
and
nothing
else
it
s
about
learning
the
language
in
an
in
depth
fashion
before
applying
it
in
application
level
programming
the
presentation
here
is
bottom
up
and
gradual
but
it
provides
a
complete
look
at
the
entire
language
in
isolation
from
its
application
roles
for
some
learning
python
involves
spending
an
hour
or
two
going
through
a
tutorial
on
the
web
this
works
for
already
advanced
programmers
up
to
a
point
python
is
after
all
relatively
simple
in
comparison
to
other
languages
the
problem
with
this
fasttrack
approach
is
that
its
practitioners
eventually
stumble
onto
unusual
cases
and
get
xl
preface
stuck
variables
change
out
from
under
them
mutable
default
arguments
mutate
inexplicably
and
so
on
the
goal
here
is
instead
to
provide
a
solid
grounding
in
python
fundamentals
so
that
even
the
unusual
cases
will
make
sense
when
they
crop
up
this
scope
is
deliberate
by
restricting
our
gaze
to
language
fundamentals
we
can
investigate
them
here
in
more
satisfying
depth
other
texts
described
ahead
pick
up
where
this
book
leaves
off
and
provide
a
more
complete
look
at
application
level
topics
and
additional
reference
materials
the
purpose
of
the
book
you
are
reading
now
is
solely
to
teach
python
itself
so
that
you
can
apply
it
to
whatever
domain
you
happen
to
work
in
about
this
book
this
section
underscores
some
important
points
about
this
book
in
general
regardless
of
its
edition
number
no
book
addresses
every
possible
audience
so
it
s
important
to
understand
a
book
s
goals
up
front
this
book
s
prerequisites
there
are
no
absolute
prerequisites
to
speak
of
really
both
true
beginners
and
crusty
programming
veterans
have
used
this
book
successfully
if
you
are
motivated
to
learn
python
this
text
will
probably
work
for
you
in
general
though
i
have
found
that
any
exposure
to
programming
or
scripting
before
this
book
can
be
helpful
even
if
not
required
for
every
reader
this
book
is
designed
to
be
an
introductory
level
python
text
for
programmers
it
may
not
be
an
ideal
text
for
someone
who
has
never
touched
a
computer
before
for
instance
we
re
not
going
to
spend
any
time
exploring
what
a
computer
is
but
i
haven
t
made
many
assumptions
about
your
programming
background
or
education
on
the
other
hand
i
won
t
insult
readers
by
assuming
they
are
dummies
either
whatever
that
means
it
s
easy
to
do
useful
things
in
python
and
this
book
will
show
you
how
the
text
occasionally
contrasts
python
with
languages
such
as
c
c
java
and
pascal
but
you
can
safely
ignore
these
comparisons
if
you
haven
t
used
such
languages
in
the
past
this
book
s
scope
and
other
books
although
this
book
covers
all
the
essentials
of
the
python
language
i
ve
kept
its
scope
narrow
in
the
interests
of
speed
and
size
to
keep
things
simple
this
book
focuses
on
core
concepts
uses
small
and
self
contained
examples
to
illustrate
points
and
and
by
programmers
i
mean
anyone
who
has
written
a
single
line
of
code
in
any
programming
or
scripting
language
in
the
past
if
this
doesn
t
include
you
you
will
probably
find
this
book
useful
anyhow
but
be
aware
that
it
will
spend
more
time
teaching
python
than
programming
fundamentals
preface
xli
sometimes
omits
the
small
details
that
are
readily
available
in
reference
manuals
because
of
that
this
book
is
probably
best
described
as
an
introduction
and
a
steppingstone
to
more
advanced
and
complete
texts
for
example
we
won
t
talk
much
about
python
c
integration
a
complex
topic
that
is
nevertheless
central
to
many
python
based
systems
we
also
won
t
talk
much
about
python
s
history
or
development
processes
and
popular
python
applications
such
as
guis
system
tools
and
network
scripting
get
only
a
short
glance
if
they
are
mentioned
at
all
naturally
this
scope
misses
some
of
the
big
picture
by
and
large
python
is
about
raising
the
quality
bar
a
few
notches
in
the
scripting
world
some
of
its
ideas
require
more
context
than
can
be
provided
here
and
i
d
be
remiss
if
i
didn
t
recommend
further
study
after
you
finish
this
book
i
hope
that
most
readers
of
this
book
will
eventually
go
on
to
gain
a
more
complete
understanding
of
applicationlevel
programming
from
other
texts
because
of
its
beginner
s
focus
learning
python
is
designed
to
be
naturally
complemented
by
o
reilly
s
other
python
books
for
instance
programming
python
another
book
i
authored
provides
larger
and
more
complete
examples
along
with
tutorials
on
application
programming
techniques
and
was
explicitly
designed
to
be
a
follow
up
text
to
the
one
you
are
reading
now
roughly
the
current
editions
of
learning
python
and
programming
python
reflect
the
two
halves
of
their
author
s
training
materials
the
core
language
and
application
programming
in
addition
o
reilly
s
python
pocket
reference
serves
as
a
quick
reference
supplement
for
looking
up
some
of
the
finer
details
skipped
here
other
follow
up
books
can
also
provide
references
additional
examples
or
details
about
using
python
in
specific
domains
such
as
the
web
and
guis
for
instance
o
reilly
s
python
in
a
nutshell
and
sams
s
python
essential
reference
serve
as
useful
references
and
o
reilly
s
python
cookbook
offers
a
library
of
self
contained
examples
for
people
already
familiar
with
application
programming
techniques
because
reading
books
is
such
a
subjective
experience
i
encourage
you
to
browse
on
your
own
to
find
advanced
texts
that
suit
your
needs
regardless
of
which
books
you
choose
though
keep
in
mind
that
the
rest
of
the
python
story
requires
studying
examples
that
are
more
realistic
than
there
is
space
for
here
having
said
that
i
think
you
ll
find
this
book
to
be
a
good
first
text
on
python
despite
its
limited
scope
and
perhaps
because
of
it
you
ll
learn
everything
you
need
to
get
started
writing
useful
standalone
python
programs
and
scripts
by
the
time
you
ve
finished
this
book
you
will
have
learned
not
only
the
language
itself
but
also
how
to
apply
it
well
to
your
day
to
day
tasks
and
you
ll
be
equipped
to
tackle
more
advanced
topics
and
examples
as
they
come
your
way
xlii
preface
this
book
s
style
and
structure
this
book
is
based
on
training
materials
developed
for
a
three
day
hands
on
python
course
you
ll
find
quizzes
at
the
end
of
each
chapter
and
exercises
at
the
end
of
the
last
chapter
of
each
part
solutions
to
chapter
quizzes
appear
in
the
chapters
themselves
and
solutions
to
part
exercises
show
up
in
appendix
b
the
quizzes
are
designed
to
review
material
while
the
exercises
are
designed
to
get
you
coding
right
away
and
are
usually
one
of
the
highlights
of
the
course
i
strongly
recommend
working
through
the
quizzes
and
exercises
along
the
way
not
only
to
gain
python
programming
experience
but
also
because
some
of
the
exercises
raise
issues
not
covered
elsewhere
in
the
book
the
solutions
in
the
chapters
and
in
appendix
b
should
help
you
if
you
get
stuck
and
you
are
encouraged
to
peek
at
the
answers
as
much
and
as
often
as
you
like
the
overall
structure
of
this
book
is
also
derived
from
class
materials
because
this
text
is
designed
to
introduce
language
basics
quickly
i
ve
organized
the
presentation
by
major
language
features
not
examples
we
ll
take
a
bottom
up
approach
here
from
built
in
object
types
to
statements
to
program
units
and
so
on
each
chapter
is
fairly
self
contained
but
later
chapters
draw
upon
ideas
introduced
in
earlier
ones
e
g
by
the
time
we
get
to
classes
i
ll
assume
you
know
how
to
write
functions
so
a
linear
reading
makes
the
most
sense
for
most
readers
in
general
terms
this
book
presents
the
python
language
in
a
linear
fashion
it
is
organized
with
one
part
per
major
language
feature
types
functions
and
so
forth
and
most
of
the
examples
are
small
and
self
contained
some
might
also
call
the
examples
in
this
text
artificial
but
they
illustrate
the
points
it
aims
to
make
more
specifically
here
is
what
you
will
find
part
i
getting
started
we
begin
with
a
general
overview
of
python
that
answers
commonly
asked
initial
questions
why
people
use
the
language
what
it
s
useful
for
and
so
on
the
first
chapter
introduces
the
major
ideas
underlying
the
technology
to
give
you
some
background
context
then
the
technical
material
of
the
book
begins
as
we
explore
the
ways
that
both
we
and
python
run
programs
the
goal
of
this
part
of
the
book
is
to
give
you
just
enough
information
to
be
able
to
follow
along
with
later
examples
and
exercises
part
ii
types
and
operations
next
we
begin
our
tour
of
the
python
language
studying
python
s
major
built
in
object
types
in
depth
numbers
lists
dictionaries
and
so
on
you
can
get
a
lot
done
in
python
with
these
tools
alone
this
is
the
most
substantial
part
of
the
book
because
we
lay
groundwork
here
for
later
chapters
we
ll
also
look
at
dynamic
typing
and
its
references
keys
to
using
python
well
in
this
part
preface
xliii
part
iii
statements
and
syntax
the
next
part
moves
on
to
introduce
python
s
statements
the
code
you
type
to
create
and
process
objects
in
python
it
also
presents
python
s
general
syntax
model
although
this
part
focuses
on
syntax
it
also
introduces
some
related
tools
such
as
the
pydoc
system
and
explores
coding
alternatives
part
iv
functions
this
part
begins
our
look
at
python
s
higher
level
program
structure
tools
functions
turn
out
to
be
a
simple
way
to
package
code
for
reuse
and
avoid
code
redundancy
in
this
part
we
will
explore
python
s
scoping
rules
argument
passing
techniques
and
more
part
v
modules
python
modules
let
you
organize
statements
and
functions
into
larger
components
and
this
part
illustrates
how
to
create
use
and
reload
modules
we
ll
also
look
at
some
more
advanced
topics
here
such
as
module
packages
module
reloading
and
the
name
variable
part
vi
classes
and
oop
here
we
explore
python
s
object
oriented
programming
tool
the
class
an
optional
but
powerful
way
to
structure
code
for
customization
and
reuse
as
you
ll
see
classes
mostly
reuse
ideas
we
will
have
covered
by
this
point
in
the
book
and
oop
in
python
is
mostly
about
looking
up
names
in
linked
objects
as
you
ll
also
see
oop
is
optional
in
python
but
it
can
shave
development
time
substantially
especially
for
long
term
strategic
project
development
part
vii
exceptions
and
tools
we
conclude
the
language
fundamentals
coverage
in
this
text
with
a
look
at
python
s
exception
handling
model
and
statements
plus
a
brief
overview
of
development
tools
that
will
become
more
useful
when
you
start
writing
larger
programs
debugging
and
testing
tools
for
instance
although
exceptions
are
a
fairly
lightweight
tool
this
part
appears
after
the
discussion
of
classes
because
exceptions
should
now
all
be
classes
part
viii
advanced
topics
new
in
the
fourth
edition
in
the
final
part
we
explore
some
advanced
topics
here
we
study
unicode
and
byte
strings
managed
attribute
tools
like
properties
and
descriptors
function
and
class
decorators
and
metaclasses
these
chapters
are
all
optional
reading
because
not
all
programmers
need
to
understand
the
subjects
they
address
on
the
other
hand
readers
who
must
process
internationalized
text
or
binary
data
or
are
responsible
for
developing
apis
for
other
programmers
to
use
should
find
something
of
interest
in
this
part
part
ix
appendixes
the
book
wraps
up
with
a
pair
of
appendixes
that
give
platform
specific
tips
for
using
python
on
various
computers
appendix
a
and
provide
solutions
to
the
endof
part
exercises
appendix
b
solutions
to
end
of
chapter
quizzes
appear
in
the
chapters
themselves
xliv
preface
note
that
the
index
and
table
of
contents
can
be
used
to
hunt
for
details
but
there
are
no
reference
appendixes
in
this
book
this
book
is
a
tutorial
not
a
reference
as
mentioned
earlier
you
can
consult
python
pocket
reference
as
well
as
other
books
and
the
free
python
reference
manuals
maintained
at
http
www
python
org
for
syntax
and
built
in
tool
details
book
updates
improvements
happen
and
so
do
mis
h
h
h
typos
updates
supplements
and
corrections
for
this
book
will
be
maintained
or
referenced
on
the
web
at
one
of
the
following
sites
http
www
oreilly
com
catalog
o
reilly
s
web
page
for
the
book
http
www
rmi
net
lutz
the
author
s
site
http
www
rmi
net
lutz
about
lp
html
the
author
s
web
page
for
the
book
the
last
of
these
three
urls
points
to
a
web
page
for
this
book
where
i
will
post
updates
but
be
sure
to
search
the
web
if
this
link
becomes
invalid
if
i
could
become
more
clairvoyant
i
would
but
the
web
changes
faster
than
printed
books
about
the
programs
in
this
book
this
fourth
edition
of
this
book
and
all
the
program
examples
in
it
is
based
on
python
version
in
addition
most
of
its
examples
run
under
python
as
described
in
the
text
and
notes
for
python
readers
are
mixed
in
along
the
way
because
this
text
focuses
on
the
core
language
however
you
can
be
fairly
sure
that
most
of
what
it
has
to
say
won
t
change
very
much
in
future
releases
of
python
most
of
this
book
applies
to
earlier
python
versions
too
except
when
it
does
not
naturally
if
you
try
using
extensions
added
after
the
release
you
ve
got
all
bets
are
off
as
a
rule
of
thumb
the
latest
python
is
the
best
python
because
this
book
focuses
on
the
core
language
most
of
it
also
applies
to
jython
the
java
based
python
language
implementation
as
well
as
other
python
implementations
described
in
chapter
source
code
for
the
book
s
examples
as
well
as
exercise
solutions
can
be
fetched
from
the
book
s
website
at
http
www
oreilly
com
catalog
so
how
do
you
run
the
examples
we
ll
study
startup
details
in
chapter
so
please
stay
tuned
for
information
on
this
front
using
code
examples
this
book
is
here
to
help
you
get
your
job
done
in
general
you
may
use
the
code
in
this
book
in
your
programs
and
documentation
you
do
not
need
to
contact
us
for
permission
unless
you
re
reproducing
a
significant
portion
of
the
code
for
example
preface
xlv
writing
a
program
that
uses
several
chunks
of
code
from
this
book
does
not
require
permission
selling
or
distributing
a
cd
rom
of
examples
from
o
reilly
books
does
require
permission
answering
a
question
by
citing
this
book
and
quoting
example
code
does
not
require
permission
incorporating
a
significant
amount
of
example
code
from
this
book
into
your
product
s
documentation
does
require
permission
we
appreciate
but
do
not
require
attribution
an
attribution
usually
includes
the
title
author
publisher
and
isbn
for
example
learning
python
fourth
edition
by
mark
lutz
copyright
mark
lutz
if
you
feel
your
use
of
code
examples
falls
outside
fair
use
or
the
permission
given
above
feel
free
to
contact
us
at
permissions
oreilly
com
font
conventions
this
book
uses
the
following
typographical
conventions
italic
used
for
email
addresses
urls
filenames
pathnames
and
emphasizing
new
terms
when
they
are
first
introduced
constant
width
used
for
the
contents
of
files
and
the
output
from
commands
and
to
designate
modules
methods
statements
and
commands
constant
width
bold
used
in
code
sections
to
show
commands
or
text
that
would
be
typed
by
the
user
and
occasionally
to
highlight
portions
of
code
constant
width
italic
used
for
replaceables
and
some
comments
in
code
sections
constant
width
indicates
a
syntactic
unit
that
should
be
replaced
with
real
code
indicates
a
tip
suggestion
or
general
note
relating
to
the
nearby
text
indicates
a
warning
or
caution
relating
to
the
nearby
text
xlvi
preface
notes
specific
to
this
book
in
this
book
s
examples
the
character
at
the
start
of
a
system
command
line
stands
for
the
system
s
prompt
whatever
that
may
be
on
your
machine
e
g
c
python
in
a
dos
window
don
t
type
the
character
or
the
system
prompt
it
sometimes
stands
for
yourself
similarly
in
interpreter
interaction
listings
do
not
type
the
and
characters
shown
at
the
start
of
lines
these
are
prompts
that
python
displays
type
just
the
text
after
these
prompts
to
help
you
remember
this
user
inputs
are
shown
in
bold
font
in
this
book
also
you
normally
don
t
need
to
type
text
that
starts
with
a
in
listings
as
you
ll
learn
these
are
comments
not
executable
code
safari
books
online
safari
books
online
is
an
on
demand
digital
library
that
lets
you
easily
search
over
technology
and
creative
reference
books
and
videos
to
find
the
answers
you
need
quickly
with
a
subscription
you
can
read
any
page
and
watch
any
video
from
our
library
online
read
books
on
your
cell
phone
and
mobile
devices
access
new
titles
before
they
are
available
for
print
and
get
exclusive
access
to
manuscripts
in
development
and
post
feedback
for
the
authors
copy
and
paste
code
samples
organize
your
favorites
download
chapters
bookmark
key
sections
create
notes
print
out
pages
and
benefit
from
tons
of
other
time
saving
features
o
reilly
media
has
uploaded
this
book
to
the
safari
books
online
service
to
have
full
digital
access
to
this
book
and
others
on
similar
topics
from
o
reilly
and
other
publishers
sign
up
for
free
at
http
my
safaribooksonline
com
how
to
contact
us
please
address
comments
and
questions
concerning
this
book
to
the
publisher
o
reilly
media
inc
gravenstein
highway
north
sebastopol
ca
in
the
united
states
or
canada
international
or
local
fax
we
will
also
maintain
a
web
page
for
this
book
where
we
list
errata
examples
and
any
additional
information
you
can
access
this
page
at
http
www
oreilly
com
catalog
preface
xlvii
to
comment
or
ask
technical
questions
about
this
book
send
email
to
bookquestions
oreilly
com
for
more
information
about
our
books
conferences
resource
centers
and
the
o
reilly
network
see
our
website
at
http
www
oreilly
com
for
book
updates
be
sure
to
also
see
the
other
links
mentioned
earlier
in
this
preface
acknowledgments
as
i
write
this
fourth
edition
of
this
book
in
i
can
t
help
but
be
in
a
sort
of
mission
accomplished
state
of
mind
i
have
now
been
using
and
promoting
python
for
years
and
have
been
teaching
it
for
years
despite
the
passage
of
time
and
events
i
am
still
constantly
amazed
at
how
successful
python
has
been
over
the
years
it
has
grown
in
ways
that
most
of
us
could
not
possibly
have
imagined
in
so
at
the
risk
of
sounding
like
a
hopelessly
self
absorbed
author
you
ll
have
to
pardon
a
few
words
of
reminiscing
congratulations
and
thanks
here
it
s
been
the
proverbial
long
and
winding
road
looking
back
today
when
i
first
discovered
python
in
i
had
no
idea
what
an
impact
it
would
have
on
the
next
years
of
my
life
two
years
after
writing
the
first
edition
of
programming
python
in
i
began
traveling
around
the
country
and
the
world
teaching
python
to
beginners
and
experts
since
finishing
the
first
edition
of
learning
python
in
i
ve
been
an
independent
python
trainer
and
writer
thanks
largely
to
python
s
exponential
growth
in
popularity
as
i
write
these
words
in
mid
i
have
written
python
books
editions
of
i
have
also
been
teaching
python
for
more
than
a
decade
have
taught
some
python
training
sessions
in
the
u
s
europe
canada
and
mexico
and
have
met
over
students
along
the
way
besides
racking
up
frequent
flyer
miles
these
classes
helped
me
refine
this
text
as
well
as
my
other
python
books
over
the
years
teaching
honed
the
books
and
vice
versa
in
fact
the
book
you
re
reading
is
derived
almost
entirely
from
my
classes
because
of
this
i
d
like
to
thank
all
the
students
who
have
participated
in
my
courses
during
the
last
years
along
with
changes
in
python
itself
your
feedback
played
a
huge
role
in
shaping
this
text
there
s
nothing
quite
as
instructive
as
watching
students
repeat
the
same
beginner
s
mistakes
this
edition
owes
its
changes
primarily
to
classes
held
after
though
every
class
held
since
has
in
some
way
helped
refine
this
book
i
d
especially
like
to
single
out
clients
who
hosted
classes
in
dublin
mexico
city
barcelona
london
edmonton
and
puerto
rico
better
perks
would
be
hard
to
imagine
i
d
also
like
to
express
my
gratitude
to
everyone
who
played
a
part
in
producing
this
book
to
the
editors
who
worked
on
this
project
julie
steele
on
this
edition
tatiana
xlviii
preface
apandi
on
the
prior
edition
and
many
others
on
earlier
editions
to
doug
hellmann
and
jesse
noller
for
taking
part
in
the
technical
review
of
this
book
and
to
o
reilly
for
giving
me
a
chance
to
work
on
those
book
projects
it
s
been
net
fun
and
only
feels
a
little
like
the
movie
groundhog
day
i
want
to
thank
my
original
coauthor
david
ascher
as
well
for
his
work
on
the
first
two
editions
of
this
book
david
contributed
the
outer
layers
part
in
prior
editions
which
we
unfortunately
had
to
trim
to
make
room
for
new
core
language
materials
in
the
third
edition
to
compensate
i
added
a
handful
of
more
advanced
programs
as
a
self
study
final
exercise
in
the
third
edition
and
added
both
new
advanced
examples
and
a
new
complete
part
for
advanced
topics
in
the
fourth
edition
also
see
the
prior
notes
in
this
preface
about
follow
up
application
level
texts
you
may
want
to
consult
once
you
ve
learned
the
fundamentals
here
for
creating
such
an
enjoyable
and
useful
language
i
owe
additional
thanks
to
guido
van
rossum
and
the
rest
of
the
python
community
like
most
open
source
systems
python
is
the
product
of
many
heroic
efforts
after
years
of
programming
python
i
still
find
it
to
be
seriously
fun
it
s
been
my
privilege
to
watch
python
grow
from
a
new
kid
on
the
scripting
languages
block
to
a
widely
used
tool
deployed
in
some
fashion
by
almost
every
organization
writing
software
that
has
been
an
exciting
endeavor
to
be
a
part
of
and
i
d
like
to
thank
and
congratulate
the
entire
python
community
for
a
job
well
done
i
also
want
to
thank
my
original
editor
at
o
reilly
the
late
frank
willison
this
book
was
largely
frank
s
idea
and
it
reflects
the
contagious
vision
he
had
in
looking
back
frank
had
a
profound
impact
on
both
my
own
career
and
that
of
python
itself
it
is
not
an
exaggeration
to
say
that
frank
was
responsible
for
much
of
the
fun
and
success
of
python
when
it
was
new
we
still
miss
him
finally
a
few
personal
notes
of
thanks
to
oqo
for
the
best
toys
so
far
while
they
lasted
to
the
late
carl
sagan
for
inspiring
an
year
old
kid
from
wisconsin
to
my
mom
for
courage
and
to
all
the
large
corporations
i
ve
come
across
over
the
years
for
reminding
me
how
lucky
i
have
been
to
be
self
employed
for
the
last
decade
to
my
children
mike
sammy
and
roxy
for
whatever
futures
you
will
choose
to
make
you
were
children
when
i
began
with
python
and
you
seem
to
have
somehow
grown
up
along
the
way
i
m
proud
of
you
life
may
compel
us
down
paths
all
our
own
but
there
will
always
be
a
path
home
and
most
of
all
to
vera
my
best
friend
my
girlfriend
and
my
wife
the
best
day
of
my
life
was
the
day
i
finally
found
you
i
don
t
know
what
the
next
years
hold
but
i
do
know
that
i
want
to
spend
all
of
them
holding
you
mark
lutz
sarasota
florida
july
preface
xlix
part
i
getting
started
chapter
a
python
q
a
session
if
you
ve
bought
this
book
you
may
already
know
what
python
is
and
why
it
s
an
important
tool
to
learn
if
you
don
t
you
probably
won
t
be
sold
on
python
until
you
ve
learned
the
language
by
reading
the
rest
of
this
book
and
have
done
a
project
or
two
but
before
we
jump
into
details
the
first
few
pages
of
this
book
will
briefly
introduce
some
of
the
main
reasons
behind
python
s
popularity
to
begin
sculpting
a
definition
of
python
this
chapter
takes
the
form
of
a
question
and
answer
session
which
poses
some
of
the
most
common
questions
asked
by
beginners
why
do
people
use
python
because
there
are
many
programming
languages
available
today
this
is
the
usual
first
question
of
newcomers
given
that
there
are
roughly
million
python
users
out
there
at
the
moment
there
really
is
no
way
to
answer
this
question
with
complete
accuracy
the
choice
of
development
tools
is
sometimes
based
on
unique
constraints
or
personal
preference
but
after
teaching
python
to
roughly
groups
and
over
students
during
the
last
years
some
common
themes
have
emerged
the
primary
factors
cited
by
python
users
seem
to
be
these
software
quality
for
many
python
s
focus
on
readability
coherence
and
software
quality
in
general
sets
it
apart
from
other
tools
in
the
scripting
world
python
code
is
designed
to
be
readable
and
hence
reusable
and
maintainable
much
more
so
than
traditional
scripting
languages
the
uniformity
of
python
code
makes
it
easy
to
understand
even
if
you
did
not
write
it
in
addition
python
has
deep
support
for
more
advanced
software
reuse
mechanisms
such
as
object
oriented
programming
oop
developer
productivity
python
boosts
developer
productivity
many
times
beyond
compiled
or
statically
typed
languages
such
as
c
c
and
java
python
code
is
typically
one
third
to
one
fifth
the
size
of
equivalent
c
or
java
code
that
means
there
is
less
to
type
less
to
debug
and
less
to
maintain
after
the
fact
python
programs
also
run
immediately
without
the
lengthy
compile
and
link
steps
required
by
some
other
tools
further
boosting
programmer
speed
program
portability
most
python
programs
run
unchanged
on
all
major
computer
platforms
porting
python
code
between
linux
and
windows
for
example
is
usually
just
a
matter
of
copying
a
script
s
code
between
machines
moreover
python
offers
multiple
options
for
coding
portable
graphical
user
interfaces
database
access
programs
webbased
systems
and
more
even
operating
system
interfaces
including
program
launches
and
directory
processing
are
as
portable
in
python
as
they
can
possibly
be
support
libraries
python
comes
with
a
large
collection
of
prebuilt
and
portable
functionality
known
as
the
standard
library
this
library
supports
an
array
of
application
level
programming
tasks
from
text
pattern
matching
to
network
scripting
in
addition
python
can
be
extended
with
both
homegrown
libraries
and
a
vast
collection
of
third
party
application
support
software
python
s
third
party
domain
offers
tools
for
website
construction
numeric
programming
serial
port
access
game
development
and
much
more
the
numpy
extension
for
instance
has
been
described
as
a
free
and
more
powerful
equivalent
to
the
matlab
numeric
programming
system
component
integration
python
scripts
can
easily
communicate
with
other
parts
of
an
application
using
a
variety
of
integration
mechanisms
such
integrations
allow
python
to
be
used
as
a
product
customization
and
extension
tool
today
python
code
can
invoke
c
and
c
libraries
can
be
called
from
c
and
c
programs
can
integrate
with
java
and
net
components
can
communicate
over
frameworks
such
as
com
can
interface
with
devices
over
serial
ports
and
can
interact
over
networks
with
interfaces
like
soap
xml
rpc
and
corba
it
is
not
a
standalone
tool
enjoyment
because
of
python
s
ease
of
use
and
built
in
toolset
it
can
make
the
act
of
programming
more
pleasure
than
chore
although
this
may
be
an
intangible
benefit
its
effect
on
productivity
is
an
important
asset
of
these
factors
the
first
two
quality
and
productivity
are
probably
the
most
compelling
benefits
to
most
python
users
software
quality
by
design
python
implements
a
deliberately
simple
and
readable
syntax
and
a
highly
coherent
programming
model
as
a
slogan
at
a
recent
python
conference
attests
the
net
result
is
that
python
seems
to
fit
your
brain
that
is
features
of
the
language
interact
in
consistent
and
limited
ways
and
follow
naturally
from
a
small
set
of
core
chapter
a
python
q
a
session
concepts
this
makes
the
language
easier
to
learn
understand
and
remember
in
practice
python
programmers
do
not
need
to
constantly
refer
to
manuals
when
reading
or
writing
code
it
s
a
consistently
designed
system
that
many
find
yields
surprisingly
regular
looking
code
by
philosophy
python
adopts
a
somewhat
minimalist
approach
this
means
that
although
there
are
usually
multiple
ways
to
accomplish
a
coding
task
there
is
usually
just
one
obvious
way
a
few
less
obvious
alternatives
and
a
small
set
of
coherent
interactions
everywhere
in
the
language
moreover
python
doesn
t
make
arbitrary
decisions
for
you
when
interactions
are
ambiguous
explicit
intervention
is
preferred
over
magic
in
the
python
way
of
thinking
explicit
is
better
than
implicit
and
simple
is
better
than
complex
beyond
such
design
themes
python
includes
tools
such
as
modules
and
oop
that
naturally
promote
code
reusability
and
because
python
is
focused
on
quality
so
too
naturally
are
python
programmers
developer
productivity
during
the
great
internet
boom
of
the
mid
to
late
s
it
was
difficult
to
find
enough
programmers
to
implement
software
projects
developers
were
asked
to
implement
systems
as
fast
as
the
internet
evolved
today
in
an
era
of
layoffs
and
economic
recession
the
picture
has
shifted
programming
staffs
are
often
now
asked
to
accomplish
the
same
tasks
with
even
fewer
people
in
both
of
these
scenarios
python
has
shined
as
a
tool
that
allows
programmers
to
get
more
done
with
less
effort
it
is
deliberately
optimized
for
speed
of
development
its
simple
syntax
dynamic
typing
lack
of
compile
steps
and
built
in
toolset
allow
programmers
to
develop
programs
in
a
fraction
of
the
time
needed
when
using
some
other
tools
the
net
effect
is
that
python
typically
boosts
developer
productivity
many
times
beyond
the
levels
supported
by
traditional
languages
that
s
good
news
in
both
boom
and
bust
times
and
everywhere
the
software
industry
goes
in
between
is
python
a
scripting
language
python
is
a
general
purpose
programming
language
that
is
often
applied
in
scripting
roles
it
is
commonly
defined
as
an
object
oriented
scripting
language
a
definition
that
blends
support
for
oop
with
an
overall
orientation
toward
scripting
roles
in
fact
people
often
use
the
word
script
instead
of
program
to
describe
a
python
code
file
in
this
book
the
terms
script
and
program
are
used
interchangeably
with
a
slight
for
a
more
complete
look
at
the
python
philosophy
type
the
command
import
this
at
any
python
interactive
prompt
you
ll
see
how
in
chapter
this
invokes
an
easter
egg
hidden
in
python
a
collection
of
design
principles
underlying
python
the
acronym
eibti
is
now
fashionable
jargon
for
the
explicit
is
better
than
implicit
rule
is
python
a
scripting
language
preference
for
script
to
describe
a
simpler
top
level
file
and
program
to
refer
to
a
more
sophisticated
multifile
application
because
the
term
scripting
language
has
so
many
different
meanings
to
different
observers
some
would
prefer
that
it
not
be
applied
to
python
at
all
in
fact
people
tend
to
make
three
very
different
associations
some
of
which
are
more
useful
than
others
when
they
hear
python
labeled
as
such
shell
tools
sometimes
when
people
hear
python
described
as
a
scripting
language
they
think
it
means
that
python
is
a
tool
for
coding
operating
system
oriented
scripts
such
programs
are
often
launched
from
console
command
lines
and
perform
tasks
such
as
processing
text
files
and
launching
other
programs
python
programs
can
and
do
serve
such
roles
but
this
is
just
one
of
dozens
of
common
python
application
domains
it
is
not
just
a
better
shell
script
language
control
language
to
others
scripting
refers
to
a
glue
layer
used
to
control
and
direct
i
e
script
other
application
components
python
programs
are
indeed
often
deployed
in
the
context
of
larger
applications
for
instance
to
test
hardware
devices
python
programs
may
call
out
to
components
that
give
low
level
access
to
a
device
similarly
programs
may
run
bits
of
python
code
at
strategic
points
to
support
end
user
product
customization
without
the
need
to
ship
and
recompile
the
entire
system
s
source
code
python
s
simplicity
makes
it
a
naturally
flexible
control
tool
technically
though
this
is
also
just
a
common
python
role
many
perhaps
most
python
programmers
code
standalone
scripts
without
ever
using
or
knowing
about
any
integrated
components
it
is
not
just
a
control
language
ease
of
use
probably
the
best
way
to
think
of
the
term
scripting
language
is
that
it
refers
to
a
simple
language
used
for
quickly
coding
tasks
this
is
especially
true
when
the
term
is
applied
to
python
which
allows
much
faster
program
development
than
compiled
languages
like
c
its
rapid
development
cycle
fosters
an
exploratory
incremental
mode
of
programming
that
has
to
be
experienced
to
be
appreciated
don
t
be
fooled
though
python
is
not
just
for
simple
tasks
rather
it
makes
tasks
simple
by
its
ease
of
use
and
flexibility
python
has
a
simple
feature
set
but
it
allows
programs
to
scale
up
in
sophistication
as
needed
because
of
that
it
is
commonly
used
for
quick
tactical
tasks
and
longer
term
strategic
development
so
is
python
a
scripting
language
or
not
it
depends
on
whom
you
ask
in
general
the
term
scripting
is
probably
best
used
to
describe
the
rapid
and
flexible
mode
of
development
that
python
supports
rather
than
a
particular
application
domain
chapter
a
python
q
a
session
ok
but
what
s
the
downside
after
using
it
for
years
and
teaching
it
for
the
only
downside
to
python
i
ve
found
is
that
as
currently
implemented
its
execution
speed
may
not
always
be
as
fast
as
that
of
compiled
languages
such
as
c
and
c
we
ll
talk
about
implementation
concepts
in
detail
later
in
this
book
in
short
the
standard
implementations
of
python
today
compile
i
e
translate
source
code
statements
to
an
intermediate
format
known
as
byte
code
and
then
interpret
the
byte
code
byte
code
provides
portability
as
it
is
a
platform
independent
format
however
because
python
is
not
compiled
all
the
way
down
to
binary
machine
code
e
g
instructions
for
an
intel
chip
some
programs
will
run
more
slowly
in
python
than
in
a
fully
compiled
language
like
c
whether
you
will
ever
care
about
the
execution
speed
difference
depends
on
what
kinds
of
programs
you
write
python
has
been
optimized
numerous
times
and
python
code
runs
fast
enough
by
itself
in
most
application
domains
furthermore
whenever
you
do
something
real
in
a
python
script
like
processing
a
file
or
constructing
a
graphical
user
interface
gui
your
program
will
actually
run
at
c
speed
since
such
tasks
are
immediately
dispatched
to
compiled
c
code
inside
the
python
interpreter
more
fundamentally
python
s
speed
of
development
gain
is
often
far
more
important
than
any
speed
of
execution
loss
especially
given
modern
computer
speeds
even
at
today
s
cpu
speeds
though
there
still
are
some
domains
that
do
require
optimal
execution
speeds
numeric
programming
and
animation
for
example
often
need
at
least
their
core
number
crunching
components
to
run
at
c
speed
or
better
if
you
work
in
such
a
domain
you
can
still
use
python
simply
split
off
the
parts
of
the
application
that
require
optimal
speed
into
compiled
extensions
and
link
those
into
your
system
for
use
in
python
scripts
we
won
t
talk
about
extensions
much
in
this
text
but
this
is
really
just
an
instance
of
the
python
as
control
language
role
we
discussed
earlier
a
prime
example
of
this
dual
language
strategy
is
the
numpy
numeric
programming
extension
for
python
by
combining
compiled
and
optimized
numeric
extension
libraries
with
the
python
language
numpy
turns
python
into
a
numeric
programming
tool
that
is
efficient
and
easy
to
use
you
may
never
need
to
code
such
extensions
in
your
own
python
work
but
they
provide
a
powerful
optimization
mechanism
if
you
ever
do
who
uses
python
today
at
this
writing
the
best
estimate
anyone
can
seem
to
make
of
the
size
of
the
python
user
base
is
that
there
are
roughly
million
python
users
around
the
world
today
plus
or
minus
a
few
this
estimate
is
based
on
various
statistics
like
download
rates
and
developer
surveys
because
python
is
open
source
a
more
exact
count
is
difficult
there
are
no
license
registrations
to
tally
moreover
python
is
automatically
included
who
uses
python
today
with
linux
distributions
macintosh
computers
and
some
products
and
hardware
further
clouding
the
user
base
picture
in
general
though
python
enjoys
a
large
user
base
and
a
very
active
developer
community
because
python
has
been
around
for
some
years
and
has
been
widely
used
it
is
also
very
stable
and
robust
besides
being
employed
by
individual
users
python
is
also
being
applied
in
real
revenue
generating
products
by
real
companies
for
instance
google
makes
extensive
use
of
python
in
its
web
search
systems
and
employs
python
s
creator
the
youtube
video
sharing
service
is
largely
written
in
python
the
popular
bittorrent
peer
to
peer
file
sharing
system
is
a
python
program
google
s
popular
app
engine
web
development
framework
uses
python
as
its
application
language
eve
online
a
massively
multiplayer
online
game
mmog
makes
extensive
use
of
python
maya
a
powerful
integrated
d
modeling
and
animation
system
provides
a
python
scripting
api
intel
cisco
hewlett
packard
seagate
qualcomm
and
ibm
use
python
for
hardware
testing
industrial
light
magic
pixar
and
others
use
python
in
the
production
of
animated
movies
jpmorgan
chase
ubs
getco
and
citadel
apply
python
for
financial
market
forecasting
nasa
los
alamos
fermilab
jpl
and
others
use
python
for
scientific
programming
tasks
irobot
uses
python
to
develop
commercial
robotic
devices
esri
uses
python
as
an
end
user
customization
tool
for
its
popular
gis
mapping
products
the
nsa
uses
python
for
cryptography
and
intelligence
analysis
the
ironport
email
server
product
uses
more
than
million
lines
of
python
code
to
do
its
job
the
one
laptop
per
child
olpc
project
builds
its
user
interface
and
activity
model
in
python
and
so
on
probably
the
only
common
thread
amongst
the
companies
using
python
today
is
that
python
is
used
all
over
the
map
in
terms
of
application
domains
its
general
purpose
nature
makes
it
applicable
to
almost
all
fields
not
just
one
in
fact
it
s
safe
to
say
that
virtually
every
substantial
organization
writing
software
is
using
python
whether
for
short
term
tactical
tasks
such
as
testing
and
administration
or
for
longterm
strategic
product
development
python
has
proven
to
work
well
in
both
modes
chapter
a
python
q
a
session
for
more
details
on
companies
using
python
today
see
python
s
website
at
http
www
python
org
what
can
i
do
with
python
in
addition
to
being
a
well
designed
programming
language
python
is
useful
for
accomplishing
real
world
tasks
the
sorts
of
things
developers
do
day
in
and
day
out
it
s
commonly
used
in
a
variety
of
domains
as
a
tool
for
scripting
other
components
and
implementing
standalone
programs
in
fact
as
a
general
purpose
language
python
s
roles
are
virtually
unlimited
you
can
use
it
for
everything
from
website
development
and
gaming
to
robotics
and
spacecraft
control
however
the
most
common
python
roles
currently
seem
to
fall
into
a
few
broad
categories
the
next
few
sections
describe
some
of
python
s
most
common
applications
today
as
well
as
tools
used
in
each
domain
we
won
t
be
able
to
explore
the
tools
mentioned
here
in
any
depth
if
you
are
interested
in
any
of
these
topics
see
the
python
website
or
other
resources
for
more
details
systems
programming
python
s
built
in
interfaces
to
operating
system
services
make
it
ideal
for
writing
portable
maintainable
system
administration
tools
and
utilities
sometimes
called
shell
tools
python
programs
can
search
files
and
directory
trees
launch
other
programs
do
parallel
processing
with
processes
and
threads
and
so
on
python
s
standard
library
comes
with
posix
bindings
and
support
for
all
the
usual
os
tools
environment
variables
files
sockets
pipes
processes
multiple
threads
regular
expression
pattern
matching
command
line
arguments
standard
stream
interfaces
shell
command
launchers
filename
expansion
and
more
in
addition
the
bulk
of
python
s
system
interfaces
are
designed
to
be
portable
for
example
a
script
that
copies
directory
trees
typically
runs
unchanged
on
all
major
python
platforms
the
stackless
python
system
used
by
eve
online
also
offers
advanced
solutions
to
multiprocessing
requirements
guis
python
s
simplicity
and
rapid
turnaround
also
make
it
a
good
match
for
graphical
user
interface
programming
python
comes
with
a
standard
object
oriented
interface
to
the
tk
gui
api
called
tkinter
tkinter
in
that
allows
python
programs
to
implement
portable
guis
with
a
native
look
and
feel
python
tkinter
guis
run
unchanged
on
microsoft
windows
x
windows
on
unix
and
linux
and
the
mac
os
both
classic
and
os
x
a
free
extension
package
pmw
adds
advanced
widgets
to
the
tkinter
toolkit
in
addition
the
wxpython
gui
api
based
on
a
c
library
offers
an
alternative
toolkit
for
constructing
portable
guis
in
python
what
can
i
do
with
python
higher
level
toolkits
such
as
pythoncard
and
dabo
are
built
on
top
of
base
apis
such
as
wxpython
and
tkinter
with
the
proper
library
you
can
also
use
gui
support
in
other
toolkits
in
python
such
as
qt
with
pyqt
gtk
with
pygtk
mfc
with
pywin
net
with
ironpython
and
swing
with
jython
the
java
version
of
python
described
in
chapter
or
jpype
for
applications
that
run
in
web
browsers
or
have
simple
interface
requirements
both
jython
and
python
web
frameworks
and
serverside
cgi
scripts
described
in
the
next
section
provide
additional
user
interface
options
internet
scripting
python
comes
with
standard
internet
modules
that
allow
python
programs
to
perform
a
wide
variety
of
networking
tasks
in
client
and
server
modes
scripts
can
communicate
over
sockets
extract
form
information
sent
to
server
side
cgi
scripts
transfer
files
by
ftp
parse
generate
and
analyze
xml
files
send
receive
compose
and
parse
email
fetch
web
pages
by
urls
parse
the
html
and
xml
of
fetched
web
pages
communicate
over
xml
rpc
soap
and
telnet
and
more
python
s
libraries
make
these
tasks
remarkably
simple
in
addition
a
large
collection
of
third
party
tools
are
available
on
the
web
for
doing
internet
programming
in
python
for
instance
the
htmlgen
system
generates
html
files
from
python
class
based
descriptions
the
mod
python
package
runs
python
efficiently
within
the
apache
web
server
and
supports
server
side
templating
with
its
python
server
pages
and
the
jython
system
provides
for
seamless
python
java
integration
and
supports
coding
of
server
side
applets
that
run
on
clients
in
addition
full
blown
web
development
framework
packages
for
python
such
as
django
turbogears
web
py
pylons
zope
and
webware
support
quick
construction
of
full
featured
and
production
quality
websites
with
python
many
of
these
include
features
such
as
object
relational
mappers
a
model
view
controller
architecture
server
side
scripting
and
templating
and
ajax
support
to
provide
complete
and
enterprise
level
web
development
solutions
component
integration
we
discussed
the
component
integration
role
earlier
when
describing
python
as
a
control
language
python
s
ability
to
be
extended
by
and
embedded
in
c
and
c
systems
makes
it
useful
as
a
flexible
glue
language
for
scripting
the
behavior
of
other
systems
and
components
for
instance
integrating
a
c
library
into
python
enables
python
to
test
and
launch
the
library
s
components
and
embedding
python
in
a
product
enables
onsite
customizations
to
be
coded
without
having
to
recompile
the
entire
product
or
ship
its
source
code
at
all
chapter
a
python
q
a
session
tools
such
as
the
swig
and
sip
code
generators
can
automate
much
of
the
work
needed
to
link
compiled
components
into
python
for
use
in
scripts
and
the
cython
system
allows
coders
to
mix
python
and
c
like
code
larger
frameworks
such
as
python
s
com
support
on
windows
the
jython
java
based
implementation
the
ironpython
net
based
implementation
and
various
corba
toolkits
for
python
provide
alternative
ways
to
script
components
on
windows
for
example
python
scripts
can
use
frameworks
to
script
word
and
excel
database
programming
for
traditional
database
demands
there
are
python
interfaces
to
all
commonly
used
relational
database
systems
sybase
oracle
informix
odbc
mysql
postgresql
sqlite
and
more
the
python
world
has
also
defined
a
portable
database
api
for
accessing
sql
database
systems
from
python
scripts
which
looks
the
same
on
a
variety
of
underlying
database
systems
for
instance
because
the
vendor
interfaces
implement
the
portable
api
a
script
written
to
work
with
the
free
mysql
system
will
work
largely
unchanged
on
other
systems
such
as
oracle
all
you
have
to
do
is
replace
the
underlying
vendor
interface
python
s
standard
pickle
module
provides
a
simple
object
persistence
system
it
allows
programs
to
easily
save
and
restore
entire
python
objects
to
files
and
file
like
objects
on
the
web
you
ll
also
find
a
third
party
open
source
system
named
zodb
that
provides
a
complete
object
oriented
database
system
for
python
scripts
and
others
such
as
sqlobject
and
sqlalchemy
that
map
relational
tables
onto
python
s
class
model
furthermore
as
of
python
the
in
process
sqlite
embedded
sql
database
engine
is
a
standard
part
of
python
itself
rapid
prototyping
to
python
programs
components
written
in
python
and
c
look
the
same
because
of
this
it
s
possible
to
prototype
systems
in
python
initially
and
then
move
selected
components
to
a
compiled
language
such
as
c
or
c
for
delivery
unlike
some
prototyping
tools
python
doesn
t
require
a
complete
rewrite
once
the
prototype
has
solidified
parts
of
the
system
that
don
t
require
the
efficiency
of
a
language
such
as
c
can
remain
coded
in
python
for
ease
of
maintenance
and
use
numeric
and
scientific
programming
the
numpy
numeric
programming
extension
for
python
mentioned
earlier
includes
such
advanced
tools
as
an
array
object
interfaces
to
standard
mathematical
libraries
and
much
more
by
integrating
python
with
numeric
routines
coded
in
a
compiled
language
for
speed
numpy
turns
python
into
a
sophisticated
yet
easy
to
use
numeric
programming
tool
that
can
often
replace
existing
code
written
in
traditional
compiled
languages
such
as
fortran
or
c
additional
numeric
tools
for
python
support
what
can
i
do
with
python
animation
d
visualization
parallel
processing
and
so
on
the
popular
scipy
and
scientificpython
extensions
for
example
provide
additional
libraries
of
scientific
programming
tools
and
use
numpy
code
gaming
images
serial
ports
xml
robots
and
more
python
is
commonly
applied
in
more
domains
than
can
be
mentioned
here
for
example
you
can
do
game
programming
and
multimedia
in
python
with
the
pygame
system
serial
port
communication
on
windows
linux
and
more
with
the
pyserial
extension
image
processing
with
pil
pyopengl
blender
maya
and
others
robot
control
programming
with
the
pyro
toolkit
xml
parsing
with
the
xml
library
package
the
xmlrpclib
module
and
third
party
extensions
artificial
intelligence
programming
with
neural
network
simulators
and
expert
system
shells
natural
language
analysis
with
the
nltk
package
you
can
even
play
solitaire
with
the
pysol
program
you
ll
find
support
for
many
such
fields
at
the
pypi
websites
and
via
web
searches
search
google
or
http
www
python
org
for
links
many
of
these
specific
domains
are
largely
just
instances
of
python
s
component
integration
role
in
action
again
adding
it
as
a
frontend
to
libraries
of
components
written
in
a
compiled
language
such
as
c
makes
python
useful
for
scripting
in
a
wide
variety
of
domains
as
a
general
purpose
language
that
supports
integration
python
is
widely
applicable
how
is
python
supported
as
a
popular
open
source
system
python
enjoys
a
large
and
active
development
community
that
responds
to
issues
and
develops
enhancements
with
a
speed
that
many
commercial
software
developers
would
find
remarkable
if
not
downright
shocking
python
developers
coordinate
work
online
with
a
source
control
system
changes
follow
a
formal
pep
python
enhancement
proposal
protocol
and
must
be
accompanied
by
extensions
to
python
s
extensive
regression
testing
system
in
fact
modifying
python
today
is
roughly
as
involved
as
changing
commercial
software
a
far
cry
from
python
s
early
days
when
an
email
to
its
creator
would
suffice
but
a
good
thing
given
its
current
large
user
base
chapter
a
python
q
a
session
the
psf
python
software
foundation
a
formal
nonprofit
group
organizes
conferences
and
deals
with
intellectual
property
issues
numerous
python
conferences
are
held
around
the
world
o
reilly
s
oscon
and
the
psf
s
pycon
are
the
largest
the
former
of
these
addresses
multiple
open
source
projects
and
the
latter
is
a
python
only
event
that
has
experienced
strong
growth
in
recent
years
attendance
at
pycon
nearly
doubled
from
the
prior
year
growing
from
attendees
in
to
over
in
this
was
on
the
heels
of
a
attendance
increase
in
from
in
pycon
had
attendees
a
slight
decrease
from
but
a
still
very
strong
showing
during
a
global
recession
what
are
python
s
technical
strengths
naturally
this
is
a
developer
s
question
if
you
don
t
already
have
a
programming
background
the
language
in
the
next
few
sections
may
be
a
bit
baffling
don
t
worry
we
ll
explore
all
of
these
terms
in
more
detail
as
we
proceed
through
this
book
for
developers
though
here
is
a
quick
introduction
to
some
of
python
s
top
technical
features
it
s
object
oriented
python
is
an
object
oriented
language
from
the
ground
up
its
class
model
supports
advanced
notions
such
as
polymorphism
operator
overloading
and
multiple
inheritance
yet
in
the
context
of
python
s
simple
syntax
and
typing
oop
is
remarkably
easy
to
apply
in
fact
if
you
don
t
understand
these
terms
you
ll
find
they
are
much
easier
to
learn
with
python
than
with
just
about
any
other
oop
language
available
besides
serving
as
a
powerful
code
structuring
and
reuse
device
python
s
oop
nature
makes
it
ideal
as
a
scripting
tool
for
object
oriented
systems
languages
such
as
c
and
java
for
example
with
the
appropriate
glue
code
python
programs
can
subclass
specialize
classes
implemented
in
c
java
and
c
of
equal
significance
oop
is
an
option
in
python
you
can
go
far
without
having
to
become
an
object
guru
all
at
once
much
like
c
python
supports
both
procedural
and
object
oriented
programming
modes
its
object
oriented
tools
can
be
applied
if
and
when
constraints
allow
this
is
especially
useful
in
tactical
development
modes
which
preclude
design
phases
it
s
free
python
is
completely
free
to
use
and
distribute
as
with
other
open
source
software
such
as
tcl
perl
linux
and
apache
you
can
fetch
the
entire
python
system
s
source
code
for
free
on
the
internet
there
are
no
restrictions
on
copying
it
embedding
it
in
your
systems
or
shipping
it
with
your
products
in
fact
you
can
even
sell
python
s
source
code
if
you
are
so
inclined
what
are
python
s
technical
strengths
but
don
t
get
the
wrong
idea
free
doesn
t
mean
unsupported
on
the
contrary
the
python
online
community
responds
to
user
queries
with
a
speed
that
most
commercial
software
help
desks
would
do
well
to
try
to
emulate
moreover
because
python
comes
with
complete
source
code
it
empowers
developers
leading
to
the
creation
of
a
large
team
of
implementation
experts
although
studying
or
changing
a
programming
language
s
implementation
isn
t
everyone
s
idea
of
fun
it
s
comforting
to
know
that
you
can
do
so
if
you
need
to
you
re
not
dependent
on
the
whims
of
a
commercial
vendor
the
ultimate
documentation
source
is
at
your
disposal
as
mentioned
earlier
python
development
is
performed
by
a
community
that
largely
coordinates
its
efforts
over
the
internet
it
consists
of
python
s
creator
guido
van
rossum
the
officially
anointed
benevolent
dictator
for
life
bdfl
of
python
plus
a
supporting
cast
of
thousands
language
changes
must
follow
a
formal
enhancement
procedure
and
be
scrutinized
by
both
other
developers
and
the
bdfl
happily
this
tends
to
make
python
more
conservative
with
changes
than
some
other
languages
it
s
portable
the
standard
implementation
of
python
is
written
in
portable
ansi
c
and
it
compiles
and
runs
on
virtually
every
major
platform
currently
in
use
for
example
python
programs
run
today
on
everything
from
pdas
to
supercomputers
as
a
partial
list
python
is
available
on
linux
and
unix
systems
microsoft
windows
and
dos
all
modern
flavors
mac
os
both
os
x
and
classic
beos
os
vms
and
qnx
real
time
systems
such
as
vxworks
cray
supercomputers
and
ibm
mainframes
pdas
running
palm
os
pocketpc
and
linux
cell
phones
running
symbian
os
and
windows
mobile
gaming
consoles
and
ipods
and
more
like
the
language
interpreter
itself
the
standard
library
modules
that
ship
with
python
are
implemented
to
be
as
portable
across
platform
boundaries
as
possible
further
python
programs
are
automatically
compiled
to
portable
byte
code
which
runs
the
same
on
any
platform
with
a
compatible
version
of
python
installed
more
on
this
in
the
next
chapter
chapter
a
python
q
a
session
what
that
means
is
that
python
programs
using
the
core
language
and
standard
libraries
run
the
same
on
linux
windows
and
most
other
systems
with
a
python
interpreter
most
python
ports
also
contain
platform
specific
extensions
e
g
com
support
on
windows
but
the
core
python
language
and
libraries
work
the
same
everywhere
as
mentioned
earlier
python
also
includes
an
interface
to
the
tk
gui
toolkit
called
tkinter
tkinter
in
which
allows
python
programs
to
implement
full
featured
graphical
user
interfaces
that
run
on
all
major
gui
platforms
without
program
changes
it
s
powerful
from
a
features
perspective
python
is
something
of
a
hybrid
its
toolset
places
it
between
traditional
scripting
languages
such
as
tcl
scheme
and
perl
and
systems
development
languages
such
as
c
c
and
java
python
provides
all
the
simplicity
and
ease
of
use
of
a
scripting
language
along
with
more
advanced
software
engineering
tools
typically
found
in
compiled
languages
unlike
some
scripting
languages
this
combination
makes
python
useful
for
large
scale
development
projects
as
a
preview
here
are
some
of
the
main
things
you
ll
find
in
python
s
toolbox
dynamic
typing
python
keeps
track
of
the
kinds
of
objects
your
program
uses
when
it
runs
it
doesn
t
require
complicated
type
and
size
declarations
in
your
code
in
fact
as
you
ll
see
in
chapter
there
is
no
such
thing
as
a
type
or
variable
declaration
anywhere
in
python
because
python
code
does
not
constrain
data
types
it
is
also
usually
automatically
applicable
to
a
whole
range
of
objects
automatic
memory
management
python
automatically
allocates
objects
and
reclaims
garbage
collects
them
when
they
are
no
longer
used
and
most
can
grow
and
shrink
on
demand
as
you
ll
learn
python
keeps
track
of
low
level
memory
details
so
you
don
t
have
to
programming
in
the
large
support
for
building
larger
systems
python
includes
tools
such
as
modules
classes
and
exceptions
these
tools
allow
you
to
organize
systems
into
components
use
oop
to
reuse
and
customize
code
and
handle
events
and
errors
gracefully
built
in
object
types
python
provides
commonly
used
data
structures
such
as
lists
dictionaries
and
strings
as
intrinsic
parts
of
the
language
as
you
ll
see
they
re
both
flexible
and
easy
to
use
for
instance
built
in
objects
can
grow
and
shrink
on
demand
can
be
arbitrarily
nested
to
represent
complex
information
and
more
built
in
tools
to
process
all
those
object
types
python
comes
with
powerful
and
standard
operations
including
concatenation
joining
collections
slicing
extracting
sections
sorting
mapping
and
more
what
are
python
s
technical
strengths
library
utilities
for
more
specific
tasks
python
also
comes
with
a
large
collection
of
precoded
library
tools
that
support
everything
from
regular
expression
matching
to
networking
once
you
learn
the
language
itself
python
s
library
tools
are
where
much
of
the
application
level
action
occurs
third
party
utilities
because
python
is
open
source
developers
are
encouraged
to
contribute
precoded
tools
that
support
tasks
beyond
those
supported
by
its
built
ins
on
the
web
you
ll
find
free
support
for
com
imaging
corba
orbs
xml
database
access
and
much
more
despite
the
array
of
tools
in
python
it
retains
a
remarkably
simple
syntax
and
design
the
result
is
a
powerful
programming
tool
with
all
the
usability
of
a
scripting
language
it
s
mixable
python
programs
can
easily
be
glued
to
components
written
in
other
languages
in
a
variety
of
ways
for
example
python
s
c
api
lets
c
programs
call
and
be
called
by
python
programs
flexibly
that
means
you
can
add
functionality
to
the
python
system
as
needed
and
use
python
programs
within
other
environments
or
systems
mixing
python
with
libraries
coded
in
languages
such
as
c
or
c
for
instance
makes
it
an
easy
to
use
frontend
language
and
customization
tool
as
mentioned
earlier
this
also
makes
python
good
at
rapid
prototyping
systems
may
be
implemented
in
python
first
to
leverage
its
speed
of
development
and
later
moved
to
c
for
delivery
one
piece
at
a
time
according
to
performance
demands
it
s
easy
to
use
to
run
a
python
program
you
simply
type
it
and
run
it
there
are
no
intermediate
compile
and
link
steps
like
there
are
for
languages
such
as
c
or
c
python
executes
programs
immediately
which
makes
for
an
interactive
programming
experience
and
rapid
turnaround
after
program
changes
in
many
cases
you
can
witness
the
effect
of
a
program
change
as
fast
as
you
can
type
it
of
course
development
cycle
turnaround
is
only
one
aspect
of
python
s
ease
of
use
it
also
provides
a
deliberately
simple
syntax
and
powerful
built
in
tools
in
fact
some
have
gone
so
far
as
to
call
python
executable
pseudocode
because
it
eliminates
much
of
the
complexity
in
other
tools
python
programs
are
simpler
smaller
and
more
flexible
than
equivalent
programs
in
languages
like
c
c
and
java
chapter
a
python
q
a
session
it
s
easy
to
learn
this
brings
us
to
a
key
point
of
this
book
compared
to
other
programming
languages
the
core
python
language
is
remarkably
easy
to
learn
in
fact
you
can
expect
to
be
coding
significant
python
programs
in
a
matter
of
days
or
perhaps
in
just
hours
if
you
re
already
an
experienced
programmer
that
s
good
news
for
professional
developers
seeking
to
learn
the
language
to
use
on
the
job
as
well
as
for
end
users
of
systems
that
expose
a
python
layer
for
customization
or
control
today
many
systems
rely
on
the
fact
that
end
users
can
quickly
learn
enough
python
to
tailor
their
python
customizations
code
onsite
with
little
or
no
support
although
python
does
have
advanced
programming
tools
its
core
language
will
still
seem
simple
to
beginners
and
gurus
alike
it
s
named
after
monty
python
ok
this
isn
t
quite
a
technical
strength
but
it
does
seem
to
be
a
surprisingly
well
kept
secret
that
i
wish
to
expose
up
front
despite
all
the
reptile
icons
in
the
python
world
the
truth
is
that
python
creator
guido
van
rossum
named
it
after
the
bbc
comedy
series
monty
python
s
flying
circus
he
is
a
big
fan
of
monty
python
as
are
many
software
developers
indeed
there
seems
to
almost
be
a
symmetry
between
the
two
fields
this
legacy
inevitably
adds
a
humorous
quality
to
python
code
examples
for
instance
the
traditional
foo
and
bar
for
generic
variable
names
become
spam
and
eggs
in
the
python
world
the
occasional
brian
ni
and
shrubbery
likewise
owe
their
appearances
to
this
namesake
it
even
impacts
the
python
community
at
large
talks
at
python
conferences
are
regularly
billed
as
the
spanish
inquisition
all
of
this
is
of
course
very
funny
if
you
are
familiar
with
the
show
but
less
so
otherwise
you
don
t
need
to
be
familiar
with
the
series
to
make
sense
of
examples
that
borrow
references
to
monty
python
including
many
you
will
see
in
this
book
but
at
least
you
now
know
their
root
how
does
python
stack
up
to
language
x
finally
to
place
it
in
the
context
of
what
you
may
already
know
people
sometimes
compare
python
to
languages
such
as
perl
tcl
and
java
we
talked
about
performance
earlier
so
here
we
ll
focus
on
functionality
while
other
languages
are
also
useful
tools
to
know
and
use
many
people
find
that
python
how
does
python
stack
up
to
language
x
is
more
powerful
than
tcl
python
s
support
for
programming
in
the
large
makes
it
applicable
to
the
development
of
larger
systems
has
a
cleaner
syntax
and
simpler
design
than
perl
which
makes
it
more
readable
and
maintainable
and
helps
reduce
program
bugs
is
simpler
and
easier
to
use
than
java
python
is
a
scripting
language
but
java
inherits
much
of
the
complexity
and
syntax
of
systems
languages
such
as
c
is
simpler
and
easier
to
use
than
c
but
it
doesn
t
often
compete
with
c
as
a
scripting
language
python
typically
serves
different
roles
is
both
more
powerful
and
more
cross
platform
than
visual
basic
its
open
source
nature
also
means
it
is
not
controlled
by
a
single
company
is
more
readable
and
general
purpose
than
php
python
is
sometimes
used
to
construct
websites
but
it
s
also
widely
used
in
nearly
every
other
computer
domain
from
robotics
to
movie
animation
is
more
mature
and
has
a
more
readable
syntax
than
ruby
unlike
ruby
and
java
oop
is
an
option
in
python
python
does
not
impose
oop
on
users
or
projects
to
which
it
may
not
apply
has
the
dynamic
flavor
of
languages
like
smalltalk
and
lisp
but
also
has
a
simple
traditional
syntax
accessible
to
developers
as
well
as
end
users
of
customizable
systems
especially
for
programs
that
do
more
than
scan
text
files
and
that
might
have
to
be
read
in
the
future
by
others
or
by
you
many
people
find
that
python
fits
the
bill
better
than
any
other
scripting
or
programming
language
available
today
furthermore
unless
your
application
requires
peak
performance
python
is
often
a
viable
alternative
to
systems
development
languages
such
as
c
c
and
java
python
code
will
be
much
less
difficult
to
write
debug
and
maintain
of
course
your
author
has
been
a
card
carrying
python
evangelist
since
so
take
these
comments
as
you
may
they
do
however
reflect
the
common
experience
of
many
developers
who
have
taken
time
to
explore
what
python
has
to
offer
chapter
summary
and
that
concludes
the
hype
portion
of
this
book
in
this
chapter
we
ve
explored
some
of
the
reasons
that
people
pick
python
for
their
programming
tasks
we
ve
also
seen
how
it
is
applied
and
looked
at
a
representative
sample
of
who
is
using
it
today
my
goal
is
to
teach
python
though
not
to
sell
it
the
best
way
to
judge
a
language
is
to
see
it
in
action
so
the
rest
of
this
book
focuses
entirely
on
the
language
details
we
ve
glossed
over
here
the
next
two
chapters
begin
our
technical
introduction
to
the
language
in
them
we
ll
explore
ways
to
run
python
programs
peek
at
python
s
byte
code
execution
model
and
introduce
the
basics
of
module
files
for
saving
code
the
goal
will
be
to
give
you
chapter
a
python
q
a
session
just
enough
information
to
run
the
examples
and
exercises
in
the
rest
of
the
book
you
won
t
really
start
programming
per
se
until
chapter
but
make
sure
you
have
a
handle
on
the
startup
details
before
moving
on
test
your
knowledge
quiz
in
this
edition
of
the
book
we
will
be
closing
each
chapter
with
a
quick
pop
quiz
about
the
material
presented
therein
to
help
you
review
the
key
concepts
the
answers
for
these
quizzes
appear
immediately
after
the
questions
and
you
are
encouraged
to
read
the
answers
once
you
ve
taken
a
crack
at
the
questions
yourself
in
addition
to
these
end
of
chapter
quizzes
you
ll
find
lab
exercises
at
the
end
of
each
part
of
the
book
designed
to
help
you
start
coding
python
on
your
own
for
now
here
s
your
first
test
good
luck
what
are
the
six
main
reasons
that
people
choose
to
use
python
name
four
notable
companies
or
organizations
using
python
today
why
might
you
not
want
to
use
python
in
an
application
what
can
you
do
with
python
what
s
the
significance
of
the
python
import
this
statement
why
does
spam
show
up
in
so
many
python
examples
in
books
and
on
the
web
what
is
your
favorite
color
test
your
knowledge
answers
how
did
you
do
here
are
the
answers
i
came
up
with
though
there
may
be
multiple
solutions
to
some
quiz
questions
again
even
if
you
re
sure
you
got
a
question
right
i
encourage
you
to
look
at
these
answers
for
additional
context
see
the
chapter
s
text
for
more
details
if
any
of
these
responses
don
t
make
sense
to
you
software
quality
developer
productivity
program
portability
support
libraries
component
integration
and
simple
enjoyment
of
these
the
quality
and
productivity
themes
seem
to
be
the
main
reasons
that
people
choose
to
use
python
google
industrial
light
magic
eve
online
jet
propulsion
labs
maya
esri
and
many
more
almost
every
organization
doing
software
development
uses
python
in
some
fashion
whether
for
long
term
strategic
product
development
or
for
short
term
tactical
tasks
such
as
testing
and
system
administration
python
s
downside
is
performance
it
won
t
run
as
quickly
as
fully
compiled
languages
like
c
and
c
on
the
other
hand
it
s
quick
enough
for
most
applications
and
typical
python
code
runs
at
close
to
c
speed
anyhow
because
it
invokes
test
your
knowledge
answers
linked
in
c
code
in
the
interpreter
if
speed
is
critical
compiled
extensions
are
available
for
number
crunching
parts
of
an
application
you
can
use
python
for
nearly
anything
you
can
do
with
a
computer
from
website
development
and
gaming
to
robotics
and
spacecraft
control
import
this
triggers
an
easter
egg
inside
python
that
displays
some
of
the
design
philosophies
underlying
the
language
you
ll
learn
how
to
run
this
statement
in
the
next
chapter
spam
is
a
reference
from
a
famous
monty
python
skit
in
which
people
trying
to
order
food
in
a
cafeteria
are
drowned
out
by
a
chorus
of
vikings
singing
about
spam
oh
and
it
s
also
a
common
variable
name
in
python
scripts
blue
no
yellow
python
is
engineering
not
art
when
python
first
emerged
on
the
software
scene
in
the
early
s
it
spawned
what
is
now
something
of
a
classic
conflict
between
its
proponents
and
those
of
another
popular
scripting
language
perl
personally
i
think
the
debate
is
tired
and
unwarranted
today
developers
are
smart
enough
to
draw
their
own
conclusions
still
this
is
one
of
the
most
common
topics
i
m
asked
about
on
the
training
road
so
it
seems
fitting
to
say
a
few
words
about
it
here
the
short
story
is
this
you
can
do
everything
in
python
that
you
can
in
perl
but
you
can
read
your
code
after
you
do
it
that
s
it
their
domains
largely
overlap
but
python
is
more
focused
on
producing
readable
code
for
many
the
enhanced
readability
of
python
translates
to
better
code
reusability
and
maintainability
making
python
a
better
choice
for
programs
that
will
not
be
written
once
and
thrown
away
perl
code
is
easy
to
write
but
difficult
to
read
given
that
most
software
has
a
lifespan
much
longer
than
its
initial
creation
many
see
python
as
a
more
effective
tool
the
somewhat
longer
story
reflects
the
backgrounds
of
the
designers
of
the
two
languages
and
underscores
some
of
the
main
reasons
people
choose
to
use
python
python
s
creator
is
a
mathematician
by
training
as
such
he
produced
a
language
with
a
high
degree
of
uniformity
its
syntax
and
toolset
are
remarkably
coherent
moreover
like
math
python
s
design
is
orthogonal
most
of
the
language
follows
from
a
small
set
of
core
concepts
for
instance
once
one
grasps
python
s
flavor
of
polymorphism
the
rest
is
largely
just
details
by
contrast
the
creator
of
the
perl
language
is
a
linguist
and
its
design
reflects
this
heritage
there
are
many
ways
to
accomplish
the
same
tasks
in
perl
and
language
constructs
interact
in
context
sensitive
and
sometimes
quite
subtle
ways
much
like
natural
language
as
the
well
known
perl
motto
states
there
s
more
than
one
way
to
do
it
given
this
design
both
the
perl
language
and
its
user
community
have
historically
encouraged
freedom
of
expression
when
writing
code
one
person
s
perl
code
can
be
radically
different
from
another
s
in
fact
writing
unique
tricky
code
is
often
a
source
of
pride
among
perl
users
chapter
a
python
q
a
session
but
as
anyone
who
has
done
any
substantial
code
maintenance
should
be
able
to
attest
freedom
of
expression
is
great
for
art
but
lousy
for
engineering
in
engineering
we
need
a
minimal
feature
set
and
predictability
in
engineering
freedom
of
expression
can
lead
to
maintenance
nightmares
as
more
than
one
perl
user
has
confided
to
me
the
result
of
too
much
freedom
is
often
code
that
is
much
easier
to
rewrite
from
scratch
than
to
modify
consider
this
when
people
create
a
painting
or
a
sculpture
they
do
so
for
themselves
for
purely
aesthetic
purposes
the
possibility
of
someone
else
having
to
change
that
painting
or
sculpture
later
does
not
enter
into
it
this
is
a
critical
difference
between
art
and
engineering
when
people
write
software
they
are
not
writing
it
for
themselves
in
fact
they
are
not
even
writing
primarily
for
the
computer
rather
good
programmers
know
that
code
is
written
for
the
next
human
being
who
has
to
read
it
in
order
to
maintain
or
reuse
it
if
that
person
cannot
understand
the
code
it
s
all
but
useless
in
a
realistic
development
scenario
this
is
where
many
people
find
that
python
most
clearly
differentiates
itself
from
scripting
languages
like
perl
because
python
s
syntax
model
almost
forces
users
to
write
readable
code
python
programs
lend
themselves
more
directly
to
the
full
software
development
cycle
and
because
python
emphasizes
ideas
such
as
limited
interactions
code
uniformity
and
regularity
and
feature
consistency
it
more
directly
fosters
code
that
can
be
used
long
after
it
is
first
written
in
the
long
run
python
s
focus
on
code
quality
in
itself
boosts
programmer
productivity
as
well
as
programmer
satisfaction
python
programmers
can
be
creative
too
of
course
and
as
we
ll
see
the
language
does
offer
multiple
solutions
for
some
tasks
at
its
core
though
python
encourages
good
engineering
in
ways
that
other
scripting
languages
often
do
not
at
least
that
s
the
common
consensus
among
many
people
who
have
adopted
python
you
should
always
judge
such
claims
for
yourself
of
course
by
learning
what
python
has
to
offer
to
help
you
get
started
let
s
move
on
to
the
next
chapter
test
your
knowledge
answers
chapter
how
python
runs
programs
this
chapter
and
the
next
take
a
quick
look
at
program
execution
how
you
launch
code
and
how
python
runs
it
in
this
chapter
we
ll
study
the
python
interpreter
chapter
will
then
show
you
how
to
get
your
own
programs
up
and
running
startup
details
are
inherently
platform
specific
and
some
of
the
material
in
these
two
chapters
may
not
apply
to
the
platform
you
work
on
so
you
should
feel
free
to
skip
parts
not
relevant
to
your
intended
use
likewise
more
advanced
readers
who
have
used
similar
tools
in
the
past
and
prefer
to
get
to
the
meat
of
the
language
quickly
may
want
to
file
some
of
this
chapter
away
as
for
future
reference
for
the
rest
of
you
let
s
learn
how
to
run
some
code
introducing
the
python
interpreter
so
far
i
ve
mostly
been
talking
about
python
as
a
programming
language
but
as
currently
implemented
it
s
also
a
software
package
called
an
interpreter
an
interpreter
is
a
kind
of
program
that
executes
other
programs
when
you
write
a
python
program
the
python
interpreter
reads
your
program
and
carries
out
the
instructions
it
contains
in
effect
the
interpreter
is
a
layer
of
software
logic
between
your
code
and
the
computer
hardware
on
your
machine
when
the
python
package
is
installed
on
your
machine
it
generates
a
number
of
components
minimally
an
interpreter
and
a
support
library
depending
on
how
you
use
it
the
python
interpreter
may
take
the
form
of
an
executable
program
or
a
set
of
libraries
linked
into
another
program
depending
on
which
flavor
of
python
you
run
the
interpreter
itself
may
be
implemented
as
a
c
program
a
set
of
java
classes
or
something
else
whatever
form
it
takes
the
python
code
you
write
must
always
be
run
by
this
interpreter
and
to
enable
that
you
must
install
a
python
interpreter
on
your
computer
python
installation
details
vary
by
platform
and
are
covered
in
more
depth
in
appendix
a
in
short
windows
users
fetch
and
run
a
self
installing
executable
file
that
puts
python
on
their
machines
simply
double
click
and
say
yes
or
next
at
all
prompts
linux
and
mac
os
x
users
probably
already
have
a
usable
python
preinstalled
on
their
computers
it
s
a
standard
component
on
these
platforms
today
some
linux
and
mac
os
x
users
and
most
unix
users
compile
python
from
its
full
source
code
distribution
package
linux
users
can
also
find
rpm
files
and
mac
os
x
users
can
find
various
macspecific
installation
packages
other
platforms
have
installation
techniques
relevant
to
those
platforms
for
instance
python
is
available
on
cell
phones
game
consoles
and
ipods
but
installation
details
vary
widely
python
itself
may
be
fetched
from
the
downloads
page
on
the
website
http
www
python
org
it
may
also
be
found
through
various
other
distribution
channels
keep
in
mind
that
you
should
always
check
to
see
whether
python
is
already
present
before
installing
it
if
you
re
working
on
windows
you
ll
usually
find
python
in
the
start
menu
as
captured
in
figure
these
menu
options
are
discussed
in
the
next
chapter
on
unix
and
linux
python
probably
lives
in
your
usr
directory
tree
because
installation
details
are
so
platform
specific
we
ll
finesse
the
rest
of
this
story
here
for
more
details
on
the
installation
process
consult
appendix
a
for
the
purposes
of
this
chapter
and
the
next
i
ll
assume
that
you
ve
got
python
ready
to
go
program
execution
what
it
means
to
write
and
run
a
python
script
depends
on
whether
you
look
at
these
tasks
as
a
programmer
or
as
a
python
interpreter
both
views
offer
important
perspectives
on
python
programming
the
programmer
s
view
in
its
simplest
form
a
python
program
is
just
a
text
file
containing
python
statements
for
example
the
following
file
named
script
py
is
one
of
the
simplest
python
scripts
i
could
dream
up
but
it
passes
for
a
fully
functional
python
program
print
hello
world
print
this
file
contains
two
python
print
statements
which
simply
print
a
string
the
text
in
quotes
and
a
numeric
expression
result
to
the
power
to
the
output
stream
don
t
worry
about
the
syntax
of
this
code
yet
for
this
chapter
we
re
interested
only
in
getting
it
to
run
i
ll
explain
the
print
statement
and
why
you
can
raise
to
the
power
in
python
without
overflowing
in
the
next
parts
of
this
book
chapter
how
python
runs
programs
figure
when
installed
on
windows
this
is
how
python
shows
up
in
your
start
button
menu
this
can
vary
a
bit
from
release
to
release
but
idle
starts
a
development
gui
and
python
starts
a
simple
interactive
session
also
here
are
the
standard
manuals
and
the
pydoc
documentation
engine
module
docs
you
can
create
such
a
file
of
statements
with
any
text
editor
you
like
by
convention
python
program
files
are
given
names
that
end
in
py
technically
this
naming
scheme
is
required
only
for
files
that
are
imported
as
shown
later
in
this
book
but
most
python
files
have
py
names
for
consistency
after
you
ve
typed
these
statements
into
a
text
file
you
must
tell
python
to
execute
the
file
which
simply
means
to
run
all
the
statements
in
the
file
from
top
to
bottom
one
after
another
as
you
ll
see
in
the
next
chapter
you
can
launch
python
program
files
program
execution
by
shell
command
lines
by
clicking
their
icons
from
within
ides
and
with
other
standard
techniques
if
all
goes
well
when
you
execute
the
file
you
ll
see
the
results
of
the
two
print
statements
show
up
somewhere
on
your
computer
by
default
usually
in
the
same
window
you
were
in
when
you
ran
the
program
hello
world
for
example
here
s
what
happened
when
i
ran
this
script
from
a
dos
command
line
on
a
windows
laptop
typically
called
a
command
prompt
window
found
in
the
accessories
program
menu
to
make
sure
it
didn
t
have
any
silly
typos
c
temp
python
script
py
hello
world
we
ve
just
run
a
python
script
that
prints
a
string
and
a
number
we
probably
won
t
win
any
programming
awards
with
this
code
but
it
s
enough
to
capture
the
basics
of
program
execution
python
s
view
the
brief
description
in
the
prior
section
is
fairly
standard
for
scripting
languages
and
it
s
usually
all
that
most
python
programmers
need
to
know
you
type
code
into
text
files
and
you
run
those
files
through
the
interpreter
under
the
hood
though
a
bit
more
happens
when
you
tell
python
to
go
although
knowledge
of
python
internals
is
not
strictly
required
for
python
programming
a
basic
understanding
of
the
runtime
structure
of
python
can
help
you
grasp
the
bigger
picture
of
program
execution
when
you
instruct
python
to
run
your
script
there
are
a
few
steps
that
python
carries
out
before
your
code
actually
starts
crunching
away
specifically
it
s
first
compiled
to
something
called
byte
code
and
then
routed
to
something
called
a
virtual
machine
byte
code
compilation
internally
and
almost
completely
hidden
from
you
when
you
execute
a
program
python
first
compiles
your
source
code
the
statements
in
your
file
into
a
format
known
as
byte
code
compilation
is
simply
a
translation
step
and
byte
code
is
a
lower
level
platform
independent
representation
of
your
source
code
roughly
python
translates
each
of
your
source
statements
into
a
group
of
byte
code
instructions
by
decomposing
them
into
individual
steps
this
byte
code
translation
is
performed
to
speed
execution
byte
code
can
be
run
much
more
quickly
than
the
original
source
code
statements
in
your
text
file
you
ll
notice
that
the
prior
paragraph
said
that
this
is
almost
completely
hidden
from
you
if
the
python
process
has
write
access
on
your
machine
it
will
store
the
byte
code
of
your
programs
in
files
that
end
with
a
pyc
extension
pyc
means
compiled
py
source
you
will
see
these
files
show
up
on
your
computer
after
you
ve
run
a
few
chapter
how
python
runs
programs
programs
alongside
the
corresponding
source
code
files
that
is
in
the
same
directories
python
saves
byte
code
like
this
as
a
startup
speed
optimization
the
next
time
you
run
your
program
python
will
load
the
pyc
files
and
skip
the
compilation
step
as
long
as
you
haven
t
changed
your
source
code
since
the
byte
code
was
last
saved
python
automatically
checks
the
timestamps
of
source
and
byte
code
files
to
know
when
it
must
recompile
if
you
resave
your
source
code
byte
code
is
automatically
re
created
the
next
time
your
program
is
run
if
python
cannot
write
the
byte
code
files
to
your
machine
your
program
still
works
the
byte
code
is
generated
in
memory
and
simply
discarded
on
program
exit
however
because
pyc
files
speed
startup
time
you
ll
want
to
make
sure
they
are
written
for
larger
programs
byte
code
files
are
also
one
way
to
ship
python
programs
python
is
happy
to
run
a
program
if
all
it
can
find
are
pyc
files
even
if
the
original
py
source
files
are
absent
see
frozen
binaries
on
page
for
another
shipping
option
the
python
virtual
machine
pvm
once
your
program
has
been
compiled
to
byte
code
or
the
byte
code
has
been
loaded
from
existing
pyc
files
it
is
shipped
off
for
execution
to
something
generally
known
as
the
python
virtual
machine
pvm
for
the
more
acronym
inclined
among
you
the
pvm
sounds
more
impressive
than
it
is
really
it
s
not
a
separate
program
and
it
need
not
be
installed
by
itself
in
fact
the
pvm
is
just
a
big
loop
that
iterates
through
your
byte
code
instructions
one
by
one
to
carry
out
their
operations
the
pvm
is
the
runtime
engine
of
python
it
s
always
present
as
part
of
the
python
system
and
it
s
the
component
that
truly
runs
your
scripts
technically
it
s
just
the
last
step
of
what
is
called
the
python
interpreter
figure
illustrates
the
runtime
structure
described
here
keep
in
mind
that
all
of
this
complexity
is
deliberately
hidden
from
python
programmers
byte
code
compilation
is
automatic
and
the
pvm
is
just
part
of
the
python
system
that
you
have
installed
on
your
machine
again
programmers
simply
code
and
run
files
of
statements
performance
implications
readers
with
a
background
in
fully
compiled
languages
such
as
c
and
c
might
notice
a
few
differences
in
the
python
model
for
one
thing
there
is
usually
no
build
or
make
step
in
python
work
code
runs
immediately
after
it
is
written
for
another
python
byte
code
is
not
binary
machine
code
e
g
instructions
for
an
intel
chip
byte
code
is
a
python
specific
representation
and
strictly
speaking
byte
code
is
saved
only
for
files
that
are
imported
not
for
the
top
level
file
of
a
program
we
ll
explore
imports
in
chapter
and
again
in
part
v
byte
code
is
also
never
saved
for
code
typed
at
the
interactive
prompt
which
is
described
in
chapter
program
execution
figure
python
s
traditional
runtime
execution
model
source
code
you
type
is
translated
to
byte
code
which
is
then
run
by
the
python
virtual
machine
your
code
is
automatically
compiled
but
then
it
is
interpreted
this
is
why
some
python
code
may
not
run
as
fast
as
c
or
c
code
as
described
in
chapter
the
pvm
loop
not
the
cpu
chip
still
must
interpret
the
byte
code
and
byte
code
instructions
require
more
work
than
cpu
instructions
on
the
other
hand
unlike
in
classic
interpreters
there
is
still
an
internal
compile
step
python
does
not
need
to
reanalyze
and
reparse
each
source
statement
repeatedly
the
net
effect
is
that
pure
python
code
runs
at
speeds
somewhere
between
those
of
a
traditional
compiled
language
and
a
traditional
interpreted
language
see
chapter
for
more
on
python
performance
tradeoffs
development
implications
another
ramification
of
python
s
execution
model
is
that
there
is
really
no
distinction
between
the
development
and
execution
environments
that
is
the
systems
that
compile
and
execute
your
source
code
are
really
one
and
the
same
this
similarity
may
have
a
bit
more
significance
to
readers
with
a
background
in
traditional
compiled
languages
but
in
python
the
compiler
is
always
present
at
runtime
and
is
part
of
the
system
that
runs
programs
this
makes
for
a
much
more
rapid
development
cycle
there
is
no
need
to
precompile
and
link
before
execution
may
begin
simply
type
and
run
the
code
this
also
adds
a
much
more
dynamic
flavor
to
the
language
it
is
possible
and
often
very
convenient
for
python
programs
to
construct
and
execute
other
python
programs
at
runtime
the
eval
and
exec
built
ins
for
instance
accept
and
run
strings
containing
python
program
code
this
structure
is
also
why
python
lends
itself
to
product
customization
because
python
code
can
be
changed
on
the
fly
users
can
modify
the
python
parts
of
a
system
onsite
without
needing
to
have
or
compile
the
entire
system
s
code
at
a
more
fundamental
level
keep
in
mind
that
all
we
really
have
in
python
is
runtime
there
is
no
initial
compile
time
phase
at
all
and
everything
happens
as
the
program
is
running
this
even
includes
operations
such
as
the
creation
of
functions
and
classes
and
the
linkage
of
modules
such
events
occur
before
execution
in
more
static
languages
but
happen
as
programs
execute
in
python
as
we
ll
see
the
net
effect
makes
for
a
much
more
dynamic
programming
experience
than
that
to
which
some
readers
may
be
accustomed
chapter
how
python
runs
programs
execution
model
variations
before
moving
on
i
should
point
out
that
the
internal
execution
flow
described
in
the
prior
section
reflects
the
standard
implementation
of
python
today
but
is
not
really
a
requirement
of
the
python
language
itself
because
of
that
the
execution
model
is
prone
to
changing
with
time
in
fact
there
are
already
a
few
systems
that
modify
the
picture
in
figure
somewhat
let
s
take
a
few
moments
to
explore
the
most
prominent
of
these
variations
python
implementation
alternatives
really
as
this
book
is
being
written
there
are
three
primary
implementations
of
the
python
language
cpython
jython
and
ironpython
along
with
a
handful
of
secondary
implementations
such
as
stackless
python
in
brief
cpython
is
the
standard
implementation
all
the
others
have
very
specific
purposes
and
roles
all
implement
the
same
python
language
but
execute
programs
in
different
ways
cpython
the
original
and
standard
implementation
of
python
is
usually
called
cpython
when
you
want
to
contrast
it
with
the
other
two
its
name
comes
from
the
fact
that
it
is
coded
in
portable
ansi
c
language
code
this
is
the
python
that
you
fetch
from
http
www
python
org
get
with
the
activepython
distribution
and
have
automatically
on
most
linux
and
mac
os
x
machines
if
you
ve
found
a
preinstalled
version
of
python
on
your
machine
it
s
probably
cpython
unless
your
company
is
using
python
in
very
specialized
ways
unless
you
want
to
script
java
or
net
applications
with
python
you
probably
want
to
use
the
standard
cpython
system
because
it
is
the
reference
implementation
of
the
language
it
tends
to
run
the
fastest
be
the
most
complete
and
be
more
robust
than
the
alternative
systems
figure
reflects
cpython
s
runtime
architecture
jython
the
jython
system
originally
known
as
jpython
is
an
alternative
implementation
of
the
python
language
targeted
for
integration
with
the
java
programming
language
jython
consists
of
java
classes
that
compile
python
source
code
to
java
byte
code
and
then
route
the
resulting
byte
code
to
the
java
virtual
machine
jvm
programmers
still
code
python
statements
in
py
text
files
as
usual
the
jython
system
essentially
just
replaces
the
rightmost
two
bubbles
in
figure
with
java
based
equivalents
jython
s
goal
is
to
allow
python
code
to
script
java
applications
much
as
cpython
allows
python
to
script
c
and
c
components
its
integration
with
java
is
remarkably
seamless
because
python
code
is
translated
to
java
byte
code
it
looks
and
feels
like
a
true
java
program
at
runtime
jython
scripts
can
serve
as
web
applets
and
servlets
build
java
based
guis
and
so
on
moreover
jython
includes
integration
support
that
allows
execution
model
variations
python
code
to
import
and
use
java
classes
as
though
they
were
coded
in
python
because
jython
is
slower
and
less
robust
than
cpython
though
it
is
usually
seen
as
a
tool
of
interest
primarily
to
java
developers
looking
for
a
scripting
language
to
be
a
frontend
to
java
code
ironpython
a
third
implementation
of
python
and
newer
than
both
cpython
and
jython
ironpython
is
designed
to
allow
python
programs
to
integrate
with
applications
coded
to
work
with
microsoft
s
net
framework
for
windows
as
well
as
the
mono
open
source
equivalent
for
linux
net
and
its
c
programming
language
runtime
system
are
designed
to
be
a
language
neutral
object
communication
layer
in
the
spirit
of
microsoft
s
earlier
com
model
ironpython
allows
python
programs
to
act
as
both
client
and
server
components
accessible
from
other
net
languages
by
implementation
ironpython
is
very
much
like
jython
and
in
fact
was
developed
by
the
same
creator
it
replaces
the
last
two
bubbles
in
figure
with
equivalents
for
execution
in
the
net
environment
also
like
jython
ironpython
has
a
special
focus
it
is
primarily
of
interest
to
developers
integrating
python
with
net
components
because
it
is
being
developed
by
microsoft
though
ironpython
might
also
be
able
to
leverage
some
important
optimization
tools
for
better
performance
ironpython
s
scope
is
still
evolving
as
i
write
this
for
more
details
consult
the
python
online
resources
or
search
the
web
execution
optimization
tools
cpython
jython
and
ironpython
all
implement
the
python
language
in
similar
ways
by
compiling
source
code
to
byte
code
and
executing
the
byte
code
on
an
appropriate
virtual
machine
still
other
systems
including
the
psyco
just
in
time
compiler
and
the
shedskin
c
translator
instead
attempt
to
optimize
the
basic
execution
model
these
systems
are
not
required
knowledge
at
this
point
in
your
python
career
but
a
quick
look
at
their
place
in
the
execution
model
might
help
demystify
the
model
in
general
the
psyco
just
in
time
compiler
the
psyco
system
is
not
another
python
implementation
but
rather
a
component
that
extends
the
byte
code
execution
model
to
make
programs
run
faster
in
terms
of
figure
psyco
is
an
enhancement
to
the
pvm
that
collects
and
uses
type
information
while
the
program
runs
to
translate
portions
of
the
program
s
byte
code
all
the
way
down
to
real
binary
machine
code
for
faster
execution
psyco
accomplishes
this
jython
and
ironpython
are
completely
independent
implementations
of
python
that
compile
python
source
for
different
runtime
architectures
it
is
also
possible
to
access
java
and
net
software
from
standard
cpython
programs
jpype
and
python
for
net
systems
for
example
allow
cpython
code
to
call
out
to
java
and
net
components
chapter
how
python
runs
programs
translation
without
requiring
changes
to
the
code
or
a
separate
compilation
step
during
development
roughly
while
your
program
runs
psyco
collects
information
about
the
kinds
of
objects
being
passed
around
that
information
can
be
used
to
generate
highly
efficient
machine
code
tailored
for
those
object
types
once
generated
the
machine
code
then
replaces
the
corresponding
part
of
the
original
byte
code
to
speed
your
program
s
overall
execution
the
net
effect
is
that
with
psyco
your
program
becomes
much
quicker
over
time
and
as
it
is
running
in
ideal
cases
some
python
code
may
become
as
fast
as
compiled
c
code
under
psyco
because
this
translation
from
byte
code
happens
at
program
runtime
psyco
is
generally
known
as
a
just
in
time
jit
compiler
psyco
is
actually
a
bit
different
from
the
jit
compilers
some
readers
may
have
seen
for
the
java
language
though
really
psyco
is
a
specializing
jit
compiler
it
generates
machine
code
tailored
to
the
data
types
that
your
program
actually
uses
for
example
if
a
part
of
your
program
uses
different
data
types
at
different
times
psyco
may
generate
a
different
version
of
machine
code
to
support
each
different
type
combination
psyco
has
been
shown
to
speed
python
code
dramatically
according
to
its
web
page
psyco
provides
x
to
x
speed
ups
typically
x
with
an
unmodified
python
interpreter
and
unmodified
source
code
just
a
dynamically
loadable
c
extension
module
of
equal
significance
the
largest
speedups
are
realized
for
algorithmic
code
written
in
pure
python
exactly
the
sort
of
code
you
might
normally
migrate
to
c
to
optimize
with
psyco
such
migrations
become
even
less
important
psyco
is
not
yet
a
standard
part
of
python
you
will
have
to
fetch
and
install
it
separately
it
is
also
still
something
of
a
research
project
so
you
ll
have
to
track
its
evolution
online
in
fact
at
this
writing
although
psyco
can
still
be
fetched
and
installed
by
itself
it
appears
that
much
of
the
system
may
eventually
be
absorbed
into
the
newer
pypy
project
an
attempt
to
reimplement
python
s
pvm
in
python
code
to
better
support
optimizations
like
psyco
perhaps
the
largest
downside
of
psyco
is
that
it
currently
only
generates
machine
code
for
intel
x
architecture
chips
though
this
includes
windows
and
linux
boxes
and
recent
macs
for
more
details
on
the
psyco
extension
and
other
jit
efforts
that
may
arise
consult
http
www
python
org
you
can
also
check
out
psyco
s
home
page
which
currently
resides
at
http
psyco
sourceforge
net
the
shedskin
c
translator
shedskin
is
an
emerging
system
that
takes
a
different
approach
to
python
program
execution
it
attempts
to
translate
python
source
code
to
c
code
which
your
computer
s
c
compiler
then
compiles
to
machine
code
as
such
it
represents
a
platformneutral
approach
to
running
python
code
shedskin
is
still
somewhat
experimental
as
i
write
these
words
and
it
limits
python
programs
to
an
implicit
statically
typed
constraint
that
is
technically
not
normal
python
so
we
won
t
go
into
further
detail
here
execution
model
variations
initial
results
though
show
that
it
has
the
potential
to
outperform
both
standard
python
and
the
psyco
extension
in
terms
of
execution
speed
and
it
is
a
promising
project
search
the
web
for
details
on
the
project
s
current
status
frozen
binaries
sometimes
when
people
ask
for
a
real
python
compiler
what
they
re
really
seeking
is
simply
a
way
to
generate
standalone
binary
executables
from
their
python
programs
this
is
more
a
packaging
and
shipping
idea
than
an
execution
flow
concept
but
it
s
somewhat
related
with
the
help
of
third
party
tools
that
you
can
fetch
off
the
web
it
is
possible
to
turn
your
python
programs
into
true
executables
known
as
frozen
binaries
in
the
python
world
frozen
binaries
bundle
together
the
byte
code
of
your
program
files
along
with
the
pvm
interpreter
and
any
python
support
files
your
program
needs
into
a
single
package
there
are
some
variations
on
this
theme
but
the
end
result
can
be
a
single
binary
executable
program
e
g
an
exe
file
on
windows
that
can
easily
be
shipped
to
customers
in
figure
it
is
as
though
the
byte
code
and
pvm
are
merged
into
a
single
component
a
frozen
binary
file
today
three
primary
systems
are
capable
of
generating
frozen
binaries
py
exe
for
windows
pyinstaller
which
is
similar
to
py
exe
but
also
works
on
linux
and
unix
and
is
capable
of
generating
self
installing
binaries
and
freeze
the
original
you
may
have
to
fetch
these
tools
separately
from
python
itself
but
they
are
available
free
of
charge
they
are
also
constantly
evolving
so
consult
http
www
python
org
or
your
favorite
web
search
engine
for
more
on
these
tools
to
give
you
an
idea
of
the
scope
of
these
systems
py
exe
can
freeze
standalone
programs
that
use
the
tkinter
pmw
wxpython
and
pygtk
gui
libraries
programs
that
use
the
pygame
game
programming
toolkit
win
com
client
programs
and
more
frozen
binaries
are
not
the
same
as
the
output
of
a
true
compiler
they
run
byte
code
through
a
virtual
machine
hence
apart
from
a
possible
startup
improvement
frozen
binaries
run
at
the
same
speed
as
the
original
source
files
frozen
binaries
are
not
small
they
contain
a
pvm
but
by
current
standards
they
are
not
unusually
large
either
because
python
is
embedded
in
the
frozen
binary
though
it
does
not
have
to
be
installed
on
the
receiving
end
to
run
your
program
moreover
because
your
code
is
embedded
in
the
frozen
binary
it
is
more
effectively
hidden
from
recipients
this
single
file
packaging
scheme
is
especially
appealing
to
developers
of
commercial
software
for
instance
a
python
coded
user
interface
program
based
on
the
tkinter
toolkit
can
be
frozen
into
an
executable
file
and
shipped
as
a
self
contained
program
on
a
cd
or
on
the
web
end
users
do
not
need
to
install
or
even
have
to
know
about
python
to
run
the
shipped
program
chapter
how
python
runs
programs
other
execution
options
still
other
schemes
for
running
python
programs
have
more
focused
goals
the
stackless
python
system
is
a
standard
cpython
implementation
variant
that
does
not
save
state
on
the
c
language
call
stack
this
makes
python
more
easy
to
port
to
small
stack
architectures
provides
efficient
multiprocessing
options
and
fosters
novel
programming
structures
such
as
coroutines
the
cython
system
based
on
work
done
by
the
pyrex
project
is
a
hybrid
language
that
combines
python
code
with
the
ability
to
call
c
functions
and
use
c
type
declarations
for
variables
parameters
and
class
attributes
cython
code
can
be
compiled
to
c
code
that
uses
the
python
c
api
which
may
then
be
compiled
completely
though
not
completely
compatible
with
standard
python
cython
can
be
useful
both
for
wrapping
external
c
libraries
and
for
coding
efficient
c
extensions
for
python
for
more
details
on
these
systems
search
the
web
for
recent
links
future
possibilities
finally
note
that
the
runtime
execution
model
sketched
here
is
really
an
artifact
of
the
current
implementation
of
python
not
of
the
language
itself
for
instance
it
s
not
impossible
that
a
full
traditional
compiler
for
translating
python
source
code
to
machine
code
may
appear
during
the
shelf
life
of
this
book
although
one
has
not
in
nearly
two
decades
new
byte
code
formats
and
implementation
variants
may
also
be
adopted
in
the
future
for
instance
the
parrot
project
aims
to
provide
a
common
byte
code
format
virtual
machine
and
optimization
techniques
for
a
variety
of
programming
languages
see
http
www
python
org
python
s
own
pvm
runs
python
code
more
efficiently
than
parrot
but
it
s
unclear
how
parrot
will
evolve
the
pypy
project
is
an
attempt
to
reimplement
the
pvm
in
python
itself
to
enable
new
implementation
techniques
its
goal
is
to
produce
a
fast
and
flexible
implementation
of
python
the
google
sponsored
unladen
swallow
project
aims
to
make
standard
python
faster
by
a
factor
of
at
least
and
fast
enough
to
replace
the
c
language
in
many
contexts
it
is
an
optimization
branch
of
cpython
intended
to
be
fully
compatible
and
significantly
faster
this
project
also
hopes
to
remove
the
python
multithreading
global
interpreter
lock
gil
which
prevents
pure
python
threads
from
truly
overlapping
in
time
this
is
currently
an
emerging
project
being
developed
as
open
source
by
google
engineers
it
is
initially
targeting
python
though
may
acquire
its
changes
too
search
google
for
up
to
date
details
although
such
future
implementation
schemes
may
alter
the
runtime
structure
of
python
somewhat
it
seems
likely
that
the
byte
code
compiler
will
still
be
the
standard
for
execution
model
variations
some
time
to
come
the
portability
and
runtime
flexibility
of
byte
code
are
important
features
of
many
python
systems
moreover
adding
type
constraint
declarations
to
support
static
compilation
would
break
the
flexibility
conciseness
simplicity
and
overall
spirit
of
python
coding
due
to
python
s
highly
dynamic
nature
any
future
implementation
will
likely
retain
many
artifacts
of
the
current
pvm
chapter
summary
this
chapter
introduced
the
execution
model
of
python
how
python
runs
your
programs
and
explored
some
common
variations
on
that
model
just
in
time
compilers
and
the
like
although
you
don
t
really
need
to
come
to
grips
with
python
internals
to
write
python
scripts
a
passing
acquaintance
with
this
chapter
s
topics
will
help
you
truly
understand
how
your
programs
run
once
you
start
coding
them
in
the
next
chapter
you
ll
start
actually
running
some
code
of
your
own
first
though
here
s
the
usual
chapter
quiz
test
your
knowledge
quiz
what
is
the
python
interpreter
what
is
source
code
what
is
byte
code
what
is
the
pvm
name
two
variations
on
python
s
standard
execution
model
how
are
cpython
jython
and
ironpython
different
test
your
knowledge
answers
the
python
interpreter
is
a
program
that
runs
the
python
programs
you
write
source
code
is
the
statements
you
write
for
your
program
it
consists
of
text
in
text
files
that
normally
end
with
a
py
extension
byte
code
is
the
lower
level
form
of
your
program
after
python
compiles
it
python
automatically
stores
byte
code
in
files
with
a
pyc
extension
the
pvm
is
the
python
virtual
machine
the
runtime
engine
of
python
that
interprets
your
compiled
byte
code
psyco
shedskin
and
frozen
binaries
are
all
variations
on
the
execution
model
cpython
is
the
standard
implementation
of
the
language
jython
and
ironpython
implement
python
programs
for
use
in
java
and
net
environments
respectively
they
are
alternative
compilers
for
python
chapter
how
python
runs
programs
chapter
how
you
run
programs
ok
it
s
time
to
start
running
some
code
now
that
you
have
a
handle
on
program
execution
you
re
finally
ready
to
start
some
real
python
programming
at
this
point
i
ll
assume
that
you
have
python
installed
on
your
computer
if
not
see
the
prior
chapter
and
appendix
a
for
installation
and
configuration
hints
there
are
a
variety
of
ways
to
tell
python
to
execute
the
code
you
type
this
chapter
discusses
all
the
program
launching
techniques
in
common
use
today
along
the
way
you
ll
learn
how
to
type
code
interactively
and
how
to
save
it
in
files
to
be
run
with
system
command
lines
icon
clicks
module
imports
and
reloads
exec
calls
menu
options
in
guis
such
as
idle
and
more
if
you
just
want
to
find
out
how
to
run
a
python
program
quickly
you
may
be
tempted
to
read
the
parts
of
this
chapter
that
pertain
only
to
your
platform
and
move
on
to
chapter
but
don
t
skip
the
material
on
module
imports
as
that
s
essential
to
understanding
python
s
program
architecture
i
also
encourage
you
to
at
least
skim
the
sections
on
idle
and
other
ides
so
you
ll
know
what
tools
are
available
for
when
you
start
developing
more
sophisticated
python
programs
the
interactive
prompt
perhaps
the
simplest
way
to
run
python
programs
is
to
type
them
at
python
s
interactive
command
line
sometimes
called
the
interactive
prompt
there
are
a
variety
of
ways
to
start
this
command
line
in
an
ide
from
a
system
console
and
so
on
assuming
the
interpreter
is
installed
as
an
executable
program
on
your
system
the
most
platformneutral
way
to
start
an
interactive
interpreter
session
is
usually
just
to
type
python
at
your
operating
system
s
prompt
without
any
arguments
for
example
python
python
r
feb
msc
v
bit
intel
type
help
copyright
credits
or
license
for
more
information
typing
the
word
python
at
your
system
shell
prompt
like
this
begins
an
interactive
python
session
the
character
at
the
start
of
this
listing
stands
for
a
generic
system
prompt
in
this
book
it
s
not
input
that
you
type
yourself
the
notion
of
a
system
shell
prompt
is
generic
but
exactly
how
you
access
it
varies
by
platform
on
windows
you
can
type
python
in
a
dos
console
window
a
k
a
the
command
prompt
usually
found
in
the
accessories
section
of
the
start
programs
menu
or
in
the
start
run
dialog
box
on
unix
linux
and
mac
os
x
you
might
type
this
command
in
a
shell
or
terminal
window
e
g
in
an
xterm
or
console
running
a
shell
such
as
ksh
or
csh
other
systems
may
use
similar
or
platform
specific
devices
on
handheld
devices
for
example
you
generally
click
the
python
icon
in
the
home
or
application
window
to
launch
an
interactive
session
if
you
have
not
set
your
shell
s
path
environment
variable
to
include
python
s
install
directory
you
may
need
to
replace
the
word
python
with
the
full
path
to
the
python
executable
on
your
machine
on
unix
linux
and
similar
usr
local
bin
python
or
usr
bin
python
will
often
suffice
on
windows
try
typing
c
python
python
for
version
c
misc
c
python
python
python
r
feb
msc
v
bit
intel
type
help
copyright
credits
or
license
for
more
information
alternatively
you
can
run
a
change
directory
command
to
go
to
python
s
install
directory
before
typing
python
try
the
cd
c
python
command
on
windows
for
example
c
misc
cd
c
python
c
python
python
python
r
feb
msc
v
bit
intel
type
help
copyright
credits
or
license
for
more
information
on
windows
besides
typing
python
in
a
shell
window
you
can
also
begin
similar
interactive
sessions
by
starting
idle
s
main
window
discussed
later
or
by
selecting
the
python
command
line
menu
option
from
the
start
button
menu
for
python
as
shown
in
figure
back
in
chapter
both
spawn
a
python
interactive
prompt
with
equivalent
functionality
typing
a
shell
command
isn
t
necessary
chapter
how
you
run
programs
running
code
interactively
however
it
s
started
the
python
interactive
session
begins
by
printing
two
lines
of
informational
text
which
i
ll
omit
from
most
of
this
book
s
examples
to
save
space
then
prompts
for
input
with
when
it
s
waiting
for
you
to
type
a
new
python
statement
or
expression
when
working
interactively
the
results
of
your
code
are
displayed
after
the
lines
after
you
press
the
enter
key
for
instance
here
are
the
results
of
two
python
print
statements
print
is
really
a
function
call
in
python
but
not
in
so
the
parentheses
here
are
required
in
only
python
print
hello
world
hello
world
print
again
you
don
t
need
to
worry
about
the
details
of
the
print
statements
shown
here
yet
we
ll
start
digging
into
syntax
in
the
next
chapter
in
short
they
print
a
python
string
and
an
integer
as
shown
by
the
output
lines
that
appear
after
each
input
line
means
raised
to
the
power
in
python
when
coding
interactively
like
this
you
can
type
as
many
python
commands
as
you
like
each
is
run
immediately
after
it
s
entered
moreover
because
the
interactive
session
automatically
prints
the
results
of
expressions
you
type
you
don
t
usually
need
to
say
print
explicitly
at
this
prompt
lumberjack
okay
lumberjack
okay
use
ctrl
d
on
unix
or
ctrl
z
on
windows
to
exit
here
the
fist
line
saves
a
value
by
assigning
it
to
a
variable
and
the
last
two
lines
typed
are
expressions
lumberjack
and
their
results
are
displayed
automatically
to
exit
an
interactive
session
like
this
one
and
return
to
your
system
shell
prompt
type
ctrl
d
on
unix
like
machines
on
ms
dos
and
windows
systems
type
ctrl
z
to
exit
in
the
idle
gui
discussed
later
either
type
ctrl
d
or
simply
close
the
window
now
we
didn
t
do
much
in
this
session
s
code
just
typed
some
python
print
and
assignment
statements
along
with
a
few
expressions
which
we
ll
study
in
detail
later
the
main
thing
to
notice
is
that
the
interpreter
executes
the
code
entered
on
each
line
immediately
when
the
enter
key
is
pressed
the
interactive
prompt
for
example
when
we
typed
the
first
print
statement
at
the
prompt
the
output
a
python
string
was
echoed
back
right
away
there
was
no
need
to
create
a
source
code
file
and
no
need
to
run
the
code
through
a
compiler
and
linker
first
as
you
d
normally
do
when
using
a
language
such
as
c
or
c
as
you
ll
see
in
later
chapters
you
can
also
run
multiline
statements
at
the
interactive
prompt
such
a
statement
runs
immediately
after
you
ve
entered
all
of
its
lines
and
pressed
enter
twice
to
add
a
blank
line
why
the
interactive
prompt
the
interactive
prompt
runs
code
and
echoes
results
as
you
go
but
it
doesn
t
save
your
code
in
a
file
although
this
means
you
won
t
do
the
bulk
of
your
coding
in
interactive
sessions
the
interactive
prompt
turns
out
to
be
a
great
place
to
both
experiment
with
the
language
and
test
program
files
on
the
fly
experimenting
because
code
is
executed
immediately
the
interactive
prompt
is
a
perfect
place
to
experiment
with
the
language
and
will
be
used
often
in
this
book
to
demonstrate
smaller
examples
in
fact
this
is
the
first
rule
of
thumb
to
remember
if
you
re
ever
in
doubt
about
how
a
piece
of
python
code
works
fire
up
the
interactive
command
line
and
try
it
out
to
see
what
happens
for
instance
suppose
you
re
reading
a
python
program
s
code
and
you
come
across
an
expression
like
spam
whose
meaning
you
don
t
understand
at
this
point
you
can
spend
minutes
wading
through
manuals
and
books
to
try
to
figure
out
what
the
code
does
or
you
can
simply
run
it
interactively
spam
spam
spam
spam
spam
spam
spam
spam
spam
learning
by
trying
the
immediate
feedback
you
receive
at
the
interactive
prompt
is
often
the
quickest
way
to
deduce
what
a
piece
of
code
does
here
it
s
clear
that
it
does
string
repetition
in
python
means
multiply
for
numbers
but
repeat
for
strings
it
s
like
concatenating
a
string
to
itself
repeatedly
more
on
strings
in
chapter
chances
are
good
that
you
won
t
break
anything
by
experimenting
this
way
at
least
not
yet
to
do
real
damage
like
deleting
files
and
running
shell
commands
you
must
really
try
by
importing
modules
explicitly
you
also
need
to
know
more
about
python
s
system
interfaces
in
general
before
you
will
become
that
dangerous
straight
python
code
is
almost
always
safe
to
run
for
instance
watch
what
happens
when
you
make
a
mistake
at
the
interactive
prompt
chapter
how
you
run
programs
x
traceback
most
recent
call
last
file
stdin
line
in
module
nameerror
name
x
is
not
defined
making
mistakes
in
python
using
a
variable
before
it
has
been
assigned
a
value
is
always
an
error
otherwise
if
names
were
filled
in
with
defaults
some
errors
might
go
undetected
we
ll
learn
more
about
that
later
the
important
point
here
is
that
you
don
t
crash
python
or
your
computer
when
you
make
a
mistake
this
way
instead
you
get
a
meaningful
error
message
pointing
out
the
mistake
and
the
line
of
code
that
made
it
and
you
can
continue
on
in
your
session
or
script
in
fact
once
you
get
comfortable
with
python
its
error
messages
may
often
provide
as
much
debugging
support
as
you
ll
need
you
ll
read
more
on
debugging
in
the
sidebar
debugging
python
code
on
page
testing
besides
serving
as
a
tool
for
experimenting
while
you
re
learning
the
language
the
interactive
interpreter
is
also
an
ideal
place
to
test
code
you
ve
written
in
files
you
can
import
your
module
files
interactively
and
run
tests
on
the
tools
they
define
by
typing
calls
at
the
interactive
prompt
for
instance
of
the
following
tests
a
function
in
a
precoded
module
that
ships
with
python
in
its
standard
library
it
prints
the
name
of
the
directory
you
re
currently
working
in
but
you
can
do
the
same
once
you
start
writing
module
files
of
your
own
import
os
os
getcwd
c
python
testing
on
the
fly
more
generally
the
interactive
prompt
is
a
place
to
test
program
components
regardless
of
their
source
you
can
import
and
test
functions
and
classes
in
your
python
files
type
calls
to
linked
in
c
functions
exercise
java
classes
under
jython
and
more
partly
because
of
its
interactive
nature
python
supports
an
experimental
and
exploratory
programming
style
you
ll
find
convenient
when
getting
started
using
the
interactive
prompt
although
the
interactive
prompt
is
simple
to
use
there
are
a
few
tips
that
beginners
should
keep
in
mind
i
m
including
lists
of
common
mistakes
like
this
in
this
chapter
for
reference
but
they
might
also
spare
you
from
a
few
headaches
if
you
read
them
up
front
type
python
commands
only
first
of
all
remember
that
you
can
only
type
python
code
at
the
python
prompt
not
system
commands
there
are
ways
to
run
system
commands
from
within
python
code
e
g
with
os
system
but
they
are
not
as
direct
as
simply
typing
the
commands
themselves
the
interactive
prompt
print
statements
are
required
only
in
files
because
the
interactive
interpreter
automatically
prints
the
results
of
expressions
you
do
not
need
to
type
complete
print
statements
interactively
this
is
a
nice
feature
but
it
tends
to
confuse
users
when
they
move
on
to
writing
code
in
files
within
a
code
file
you
must
use
print
statements
to
see
your
output
because
expression
results
are
not
automatically
echoed
remember
you
must
say
print
in
files
but
not
interactively
don
t
indent
at
the
interactive
prompt
yet
when
typing
python
programs
either
interactively
or
into
a
text
file
be
sure
to
start
all
your
unnested
statements
in
column
that
is
all
the
way
to
the
left
if
you
don
t
python
may
print
a
syntaxerror
message
because
blank
space
to
the
left
of
your
code
is
taken
to
be
indentation
that
groups
nested
statements
until
chapter
all
statements
you
write
will
be
unnested
so
this
includes
everything
for
now
this
seems
to
be
a
recurring
confusion
in
introductory
python
classes
remember
a
leading
space
generates
an
error
message
watch
out
for
prompt
changes
for
compound
statements
we
won
t
meet
compound
multiline
statements
until
chapter
and
not
in
earnest
until
chapter
but
as
a
preview
you
should
know
that
when
typing
lines
and
beyond
of
a
compound
statement
interactively
the
prompt
may
change
in
the
simple
shell
window
interface
the
interactive
prompt
changes
to
instead
of
for
lines
and
beyond
in
the
idle
interface
lines
after
the
first
are
automatically
indented
you
ll
see
why
this
matters
in
chapter
for
now
if
you
happen
to
come
across
a
prompt
or
a
blank
line
when
entering
your
code
it
probably
means
that
you
ve
somehow
confused
interactive
python
into
thinking
you
re
typing
a
multiline
statement
try
hitting
the
enter
key
or
a
ctrl
c
combination
to
get
back
to
the
main
prompt
the
and
prompt
strings
can
also
be
changed
they
are
available
in
the
built
in
module
sys
but
i
ll
assume
they
have
not
been
in
the
book
s
example
listings
terminate
compound
statements
at
the
interactive
prompt
with
a
blank
line
at
the
interactive
prompt
inserting
a
blank
line
by
hitting
the
enter
key
at
the
start
of
a
line
is
necessary
to
tell
interactive
python
that
you
re
done
typing
the
multiline
statement
that
is
you
must
press
enter
twice
to
make
a
compound
statement
run
by
contrast
blank
lines
are
not
required
in
files
and
are
simply
ignored
if
present
if
you
don
t
press
enter
twice
at
the
end
of
a
compound
statement
when
working
interactively
you
ll
appear
to
be
stuck
in
a
limbo
state
because
the
interactive
interpreter
will
do
nothing
at
all
it
s
waiting
for
you
to
press
enter
again
the
interactive
prompt
runs
one
statement
at
a
time
at
the
interactive
prompt
you
must
run
one
statement
to
completion
before
typing
another
this
is
natural
for
simple
statements
because
pressing
the
enter
key
runs
the
statement
entered
for
compound
statements
though
remember
that
you
must
submit
a
blank
line
to
terminate
the
statement
and
make
it
run
before
you
can
type
the
next
statement
chapter
how
you
run
programs
entering
multiline
statements
at
the
risk
of
repeating
myself
i
received
emails
from
readers
who
d
gotten
burned
by
the
last
two
points
as
i
was
updating
this
chapter
so
it
probably
merits
emphasis
i
ll
introduce
multiline
a
k
a
compound
statements
in
the
next
chapter
and
we
ll
explore
their
syntax
more
formally
later
in
this
book
because
their
behavior
differs
slightly
in
files
and
at
the
interactive
prompt
though
two
cautions
are
in
order
here
first
be
sure
to
terminate
multiline
compound
statements
like
for
loops
and
if
tests
at
the
interactive
prompt
with
a
blank
line
you
must
press
the
enter
key
twice
to
terminate
the
whole
multiline
statement
and
then
make
it
run
for
example
pun
not
intended
for
x
in
spam
print
x
press
enter
twice
here
to
make
this
loop
run
you
don
t
need
the
blank
line
after
compound
statements
in
a
script
file
though
this
is
required
only
at
the
interactive
prompt
in
a
file
blank
lines
are
not
required
and
are
simply
ignored
when
present
at
the
interactive
prompt
they
terminate
multiline
statements
also
bear
in
mind
that
the
interactive
prompt
runs
just
one
statement
at
a
time
you
must
press
enter
twice
to
run
a
loop
or
other
multiline
statement
before
you
can
type
the
next
statement
for
x
in
spam
print
x
print
done
file
stdin
line
print
done
syntaxerror
invalid
syntax
need
to
press
enter
twice
before
a
new
statement
this
means
you
can
t
cut
and
paste
multiple
lines
of
code
into
the
interactive
prompt
unless
the
code
includes
blank
lines
after
each
compound
statement
such
code
is
better
run
in
a
file
the
next
section
s
topic
system
command
lines
and
files
although
the
interactive
prompt
is
great
for
experimenting
and
testing
it
has
one
big
disadvantage
programs
you
type
there
go
away
as
soon
as
the
python
interpreter
executes
them
because
the
code
you
type
interactively
is
never
stored
in
a
file
you
can
t
run
it
again
without
retyping
it
from
scratch
cut
and
paste
and
command
recall
can
help
some
here
but
not
much
especially
when
you
start
writing
larger
programs
to
cut
and
paste
code
from
an
interactive
session
you
would
have
to
edit
out
python
prompts
program
outputs
and
so
on
not
exactly
a
modern
software
development
methodology
system
command
lines
and
files
to
save
programs
permanently
you
need
to
write
your
code
in
files
which
are
usually
known
as
modules
modules
are
simply
text
files
containing
python
statements
once
coded
you
can
ask
the
python
interpreter
to
execute
the
statements
in
such
a
file
any
number
of
times
and
in
a
variety
of
ways
by
system
command
lines
by
file
icon
clicks
by
options
in
the
idle
user
interface
and
more
regardless
of
how
it
is
run
python
executes
all
the
code
in
a
module
file
from
top
to
bottom
each
time
you
run
the
file
terminology
in
this
domain
can
vary
somewhat
for
instance
module
files
are
often
referred
to
as
programs
in
python
that
is
a
program
is
considered
to
be
a
series
of
precoded
statements
stored
in
a
file
for
repeated
execution
module
files
that
are
run
directly
are
also
sometimes
called
scripts
an
informal
term
usually
meaning
a
top
level
program
file
some
reserve
the
term
module
for
a
file
imported
from
another
file
more
on
the
meaning
of
top
level
and
imports
in
a
few
moments
whatever
you
call
them
the
next
few
sections
explore
ways
to
run
code
typed
into
module
files
in
this
section
you
ll
learn
how
to
run
files
in
the
most
basic
way
by
listing
their
names
in
a
python
command
line
entered
at
your
computer
s
system
prompt
though
it
might
seem
primitive
to
some
for
many
programmers
a
system
shell
command
line
window
together
with
a
text
editor
window
constitutes
as
much
of
an
integrated
development
environment
as
they
will
ever
need
a
first
script
let
s
get
started
open
your
favorite
text
editor
e
g
vi
notepad
or
the
idle
editor
and
type
the
following
statements
into
a
new
text
file
named
script
py
a
first
python
script
import
sys
print
sys
platform
print
x
spam
print
x
load
a
library
module
raise
to
a
power
string
repetition
this
file
is
our
first
official
python
script
not
counting
the
two
liner
in
chapter
you
shouldn
t
worry
too
much
about
this
file
s
code
but
as
a
brief
description
this
file
imports
a
python
module
libraries
of
additional
tools
to
fetch
the
name
of
the
platform
runs
three
print
function
calls
to
display
the
script
s
results
uses
a
variable
named
x
created
when
it
s
assigned
to
hold
onto
a
string
object
applies
various
object
operations
that
we
ll
begin
studying
in
the
next
chapter
the
sys
platform
here
is
just
a
string
that
identifies
the
kind
of
computer
you
re
working
on
it
lives
in
a
standard
python
module
called
sys
which
you
must
import
to
load
again
more
on
imports
later
chapter
how
you
run
programs
for
color
i
ve
also
added
some
formal
python
comments
here
the
text
after
the
characters
comments
can
show
up
on
lines
by
themselves
or
to
the
right
of
code
on
a
line
the
text
after
a
is
simply
ignored
as
a
human
readable
comment
and
is
not
considered
part
of
the
statement
s
syntax
if
you
re
copying
this
code
you
can
ignore
the
comments
as
well
in
this
book
we
usually
use
a
different
formatting
style
to
make
comments
more
visually
distinctive
but
they
ll
appear
as
normal
text
in
your
code
again
don
t
focus
on
the
syntax
of
the
code
in
this
file
for
now
we
ll
learn
about
all
of
it
later
the
main
point
to
notice
is
that
you
ve
typed
this
code
into
a
file
rather
than
at
the
interactive
prompt
in
the
process
you
ve
coded
a
fully
functional
python
script
notice
that
the
module
file
is
called
script
py
as
for
all
top
level
files
it
could
also
be
called
simply
script
but
files
of
code
you
want
to
import
into
a
client
have
to
end
with
a
py
suffix
we
ll
study
imports
later
in
this
chapter
because
you
may
want
to
import
them
in
the
future
it
s
a
good
idea
to
use
py
suffixes
for
most
python
files
that
you
code
also
some
text
editors
detect
python
files
by
their
py
suffix
if
the
suffix
is
not
present
you
may
not
get
features
like
syntax
colorization
and
automatic
indentation
running
files
with
command
lines
once
you
ve
saved
this
text
file
you
can
ask
python
to
run
it
by
listing
its
full
filename
as
the
first
argument
to
a
python
command
typed
at
the
system
shell
prompt
python
script
py
win
spam
spam
spam
spam
spam
spam
spam
spam
again
you
can
type
such
a
system
shell
command
in
whatever
your
system
provides
for
command
line
entry
a
windows
command
prompt
window
an
xterm
window
or
similar
remember
to
replace
python
with
a
full
directory
path
as
before
if
your
path
setting
is
not
configured
if
all
works
as
planned
this
shell
command
makes
python
run
the
code
in
this
file
line
by
line
and
you
will
see
the
output
of
the
script
s
three
print
statements
the
name
of
the
underlying
platform
raised
to
the
power
and
the
result
of
the
same
string
repetition
expression
we
saw
earlier
again
more
on
the
last
two
of
these
in
chapter
if
all
didn
t
work
as
planned
you
ll
get
an
error
message
make
sure
you
ve
entered
the
code
in
your
file
exactly
as
shown
and
try
again
we
ll
talk
about
debugging
options
in
the
sidebar
debugging
python
code
on
page
but
at
this
point
in
the
book
your
best
bet
is
probably
rote
imitation
because
this
scheme
uses
shell
command
lines
to
start
python
programs
all
the
usual
shell
syntax
applies
for
instance
you
can
route
the
output
of
a
python
script
to
a
file
to
save
it
for
later
use
or
inspection
by
using
special
shell
syntax
python
script
py
saveit
txt
system
command
lines
and
files
in
this
case
the
three
output
lines
shown
in
the
prior
run
are
stored
in
the
file
saveit
txt
instead
of
being
printed
this
is
generally
known
as
stream
redirection
it
works
for
input
and
output
text
and
is
available
on
windows
and
unix
like
systems
it
also
has
little
to
do
with
python
python
simply
supports
it
so
we
will
skip
further
details
on
shell
redirection
syntax
here
if
you
are
working
on
a
windows
platform
this
example
works
the
same
but
the
system
prompt
is
normally
different
c
python
python
script
py
win
spam
spam
spam
spam
spam
spam
spam
spam
as
usual
be
sure
to
type
the
full
path
to
python
if
you
haven
t
set
your
path
environment
variable
to
include
this
path
or
run
a
change
directory
command
to
go
to
the
path
d
temp
c
python
python
script
py
win
spam
spam
spam
spam
spam
spam
spam
spam
on
all
recent
versions
of
windows
you
can
also
type
just
the
name
of
your
script
and
omit
the
name
of
python
itself
because
newer
windows
systems
use
the
windows
registry
to
find
a
program
with
which
to
run
a
file
you
don
t
need
to
name
python
on
the
command
line
explicitly
to
run
a
py
file
the
prior
command
for
example
could
be
simplified
to
this
on
most
windows
machines
d
temp
script
py
finally
remember
to
give
the
full
path
to
your
script
file
if
it
lives
in
a
different
directory
from
the
one
in
which
you
are
working
for
example
the
following
system
command
line
run
from
d
other
assumes
python
is
in
your
system
path
but
runs
a
file
located
elsewhere
d
other
python
c
code
otherscript
py
if
your
path
doesn
t
include
python
s
directory
and
neither
python
nor
your
script
file
is
in
the
directory
you
re
working
in
use
full
paths
for
both
d
other
c
python
python
c
code
otherscript
py
using
command
lines
and
files
running
program
files
from
system
command
lines
is
also
a
fairly
straightforward
launch
option
especially
if
you
are
familiar
with
command
lines
in
general
from
prior
work
for
newcomers
though
here
are
a
few
pointers
about
common
beginner
traps
that
might
help
you
avoid
some
frustration
chapter
how
you
run
programs
beware
of
automatic
extensions
on
windows
if
you
use
the
notepad
program
to
code
program
files
on
windows
be
careful
to
pick
the
type
all
files
when
it
comes
time
to
save
your
file
and
give
the
file
a
py
suffix
explicitly
otherwise
notepad
will
save
your
file
with
a
txt
extension
e
g
as
script
py
txt
making
it
difficult
to
run
in
some
launching
schemes
worse
windows
hides
file
extensions
by
default
so
unless
you
have
changed
your
view
options
you
may
not
even
notice
that
you
ve
coded
a
text
file
and
not
a
python
file
the
file
s
icon
may
give
this
away
if
it
doesn
t
have
a
snake
on
it
you
may
have
trouble
uncolored
code
in
idle
and
files
that
open
to
edit
instead
of
run
when
clicked
are
other
symptoms
of
this
problem
microsoft
word
similarly
adds
a
doc
extension
by
default
much
worse
it
adds
formatting
characters
that
are
not
legal
python
syntax
as
a
rule
of
thumb
always
pick
all
files
when
saving
under
windows
or
use
a
more
programmer
friendly
text
editor
such
as
idle
idle
does
not
even
add
a
py
suffix
automatically
a
feature
programmers
tend
to
like
but
users
do
not
use
file
extensions
and
directory
paths
at
system
prompts
but
not
for
imports
don
t
forget
to
type
the
full
name
of
your
file
in
system
command
lines
that
is
use
python
script
py
rather
than
python
script
by
contrast
python
s
import
statements
which
we
ll
meet
later
in
this
chapter
omit
both
the
py
file
suffix
and
the
directory
path
e
g
import
script
this
may
seem
trivial
but
confusing
these
two
is
a
common
mistake
at
the
system
prompt
you
are
in
a
system
shell
not
python
so
python
s
module
file
search
rules
do
not
apply
because
of
that
you
must
include
both
the
py
extension
and
if
necessary
the
full
directory
path
leading
to
the
file
you
wish
to
run
for
instance
to
run
a
file
that
resides
in
a
different
directory
from
the
one
in
which
you
are
working
you
would
typically
list
its
full
path
e
g
python
d
tests
spam
py
within
python
code
however
you
can
just
say
import
spam
and
rely
on
the
python
module
search
path
to
locate
your
file
as
described
later
use
print
statements
in
files
yes
we
ve
already
been
over
this
but
it
is
such
a
common
mistake
that
it
s
worth
repeating
at
least
once
here
unlike
in
interactive
coding
you
generally
must
use
print
statements
to
see
output
from
program
files
if
you
don
t
see
any
output
make
sure
you
ve
said
print
in
your
file
again
though
print
statements
are
not
required
in
an
interactive
session
since
python
automatically
echoes
expression
results
prints
don
t
hurt
here
but
are
superfluous
extra
typing
system
command
lines
and
files
unix
executable
scripts
if
you
are
going
to
use
python
on
a
unix
linux
or
unix
like
system
you
can
also
turn
files
of
python
code
into
executable
programs
much
as
you
would
for
programs
coded
in
a
shell
language
such
as
csh
or
ksh
such
files
are
usually
called
executable
scripts
in
simple
terms
unix
style
executable
scripts
are
just
normal
text
files
containing
python
statements
but
with
two
special
properties
their
first
line
is
special
scripts
usually
start
with
a
line
that
begins
with
the
characters
often
called
hash
bang
followed
by
the
path
to
the
python
interpreter
on
your
machine
they
usually
have
executable
privileges
script
files
are
usually
marked
as
executable
to
tell
the
operating
system
that
they
may
be
run
as
top
level
programs
on
unix
systems
a
command
such
as
chmod
x
file
py
usually
does
the
trick
let
s
look
at
an
example
for
unix
like
systems
use
your
text
editor
again
to
create
a
file
of
python
code
called
brian
usr
local
bin
python
print
the
bright
side
of
life
means
concatenate
for
strings
the
special
line
at
the
top
of
the
file
tells
the
system
where
the
python
interpreter
lives
technically
the
first
line
is
a
python
comment
as
mentioned
earlier
all
comments
in
python
programs
start
with
a
and
span
to
the
end
of
the
line
they
are
a
place
to
insert
extra
information
for
human
readers
of
your
code
but
when
a
comment
such
as
the
first
line
in
this
file
appears
it
s
special
because
the
operating
system
uses
it
to
find
an
interpreter
for
running
the
program
code
in
the
rest
of
the
file
also
note
that
this
file
is
called
simply
brian
without
the
py
suffix
used
for
the
module
file
earlier
adding
a
py
to
the
name
wouldn
t
hurt
and
might
help
you
remember
that
this
is
a
python
program
file
but
because
you
don
t
plan
on
letting
other
modules
import
the
code
in
this
file
the
name
of
the
file
is
irrelevant
if
you
give
the
file
executable
privileges
with
a
chmod
x
brian
shell
command
you
can
run
it
from
the
operating
system
shell
as
though
it
were
a
binary
program
brian
the
bright
side
of
life
a
note
for
windows
users
the
method
described
here
is
a
unix
trick
and
it
may
not
work
on
your
platform
not
to
worry
just
use
the
basic
command
line
technique
explored
earlier
list
the
file
s
name
on
an
explicit
python
command
line
as
we
discussed
when
exploring
command
lines
modern
windows
versions
also
let
you
type
just
the
name
of
a
py
file
at
the
system
command
line
they
use
the
registry
to
determine
that
the
file
should
be
opened
with
python
e
g
typing
brian
py
is
equivalent
to
typing
python
brian
py
this
command
line
mode
is
similar
in
spirit
to
the
unix
though
it
is
system
wide
on
windows
not
per
file
note
that
some
programs
may
actually
interpret
and
use
a
first
line
on
windows
much
like
on
unix
but
the
dos
system
shell
on
windows
simply
ignores
it
chapter
how
you
run
programs
c
misc
python
brian
the
bright
side
of
life
in
this
case
you
don
t
need
the
special
comment
at
the
top
although
python
just
ignores
it
if
it
s
present
and
the
file
doesn
t
need
to
be
given
executable
privileges
in
fact
if
you
want
to
run
files
portably
between
unix
and
microsoft
windows
your
life
will
probably
be
simpler
if
you
always
use
the
basic
command
line
approach
not
unixstyle
scripts
to
launch
programs
the
unix
env
lookup
trick
on
some
unix
systems
you
can
avoid
hardcoding
the
path
to
the
python
interpreter
by
writing
the
special
first
line
comment
like
this
usr
bin
env
python
script
goes
here
when
coded
this
way
the
env
program
locates
the
python
interpreter
according
to
your
system
search
path
settings
i
e
in
most
unix
shells
by
looking
in
all
the
directories
listed
in
the
path
environment
variable
this
scheme
can
be
more
portable
as
you
don
t
need
to
hardcode
a
python
install
path
in
the
first
line
of
all
your
scripts
provided
you
have
access
to
env
everywhere
your
scripts
will
run
no
matter
where
python
lives
on
your
system
you
need
only
change
the
path
environment
variable
settings
across
platforms
not
in
the
first
line
in
all
your
scripts
of
course
this
assumes
that
env
lives
in
the
same
place
everywhere
on
some
machines
it
may
be
in
sbin
bin
or
elsewhere
if
not
all
portability
bets
are
off
clicking
file
icons
on
windows
the
registry
makes
opening
files
with
icon
clicks
easy
python
automatically
registers
itself
to
be
the
program
that
opens
python
program
files
when
they
are
clicked
because
of
that
it
is
possible
to
launch
the
python
programs
you
write
by
simply
clicking
or
double
clicking
on
their
file
icons
with
your
mouse
cursor
on
non
windows
systems
you
will
probably
be
able
to
perform
a
similar
trick
but
the
icons
file
explorer
navigation
schemes
and
more
may
differ
slightly
on
some
unix
systems
for
instance
you
may
need
to
register
the
py
extension
with
your
file
explorer
gui
make
your
script
executable
using
the
trick
discussed
in
the
previous
section
or
associate
the
file
mime
type
with
an
application
or
command
by
editing
files
installing
programs
or
using
other
tools
see
your
file
explorer
s
documentation
for
more
details
if
clicks
do
not
work
correctly
right
off
the
bat
clicking
icons
on
windows
to
illustrate
let
s
keep
using
the
script
we
wrote
earlier
script
py
repeated
here
to
minimize
page
flipping
clicking
file
icons
a
first
python
script
import
sys
print
sys
platform
print
x
spam
print
x
load
a
library
module
raise
to
a
power
string
repetition
as
we
ve
seen
you
can
always
run
this
file
from
a
system
command
line
c
misc
c
python
python
script
py
win
however
icon
clicks
allow
you
to
run
the
file
without
any
typing
at
all
if
you
find
this
file
s
icon
for
instance
by
selecting
computer
or
my
computer
in
xp
in
your
start
menu
and
working
your
way
down
on
the
c
drive
on
windows
you
will
get
the
file
explorer
picture
captured
in
figure
windows
vista
is
being
used
here
python
source
files
show
up
with
white
backgrounds
on
windows
and
byte
code
files
show
up
with
black
backgrounds
you
will
normally
want
to
click
or
otherwise
run
the
source
code
file
in
order
to
pick
up
your
most
recent
changes
to
launch
the
file
here
simply
click
on
the
icon
for
script
py
figure
on
windows
python
program
files
show
up
as
icons
in
file
explorer
windows
and
can
automatically
be
run
with
a
double
click
of
the
mouse
though
you
might
not
see
printed
output
or
error
messages
this
way
chapter
how
you
run
programs
the
input
trick
unfortunately
on
windows
the
result
of
clicking
on
a
file
icon
may
not
be
incredibly
satisfying
in
fact
as
it
is
this
example
script
generates
a
perplexing
flash
when
clicked
not
exactly
the
sort
of
feedback
that
budding
python
programmers
usually
hope
for
this
is
not
a
bug
but
has
to
do
with
the
way
the
windows
version
of
python
handles
printed
output
by
default
python
generates
a
pop
up
black
dos
console
window
to
serve
as
a
clicked
file
s
input
and
output
if
a
script
just
prints
and
exits
well
it
just
prints
and
exits
the
console
window
appears
and
text
is
printed
there
but
the
console
window
closes
and
disappears
on
program
exit
unless
you
are
very
fast
or
your
machine
is
very
slow
you
won
t
get
to
see
your
output
at
all
although
this
is
normal
behavior
it
s
probably
not
what
you
had
in
mind
luckily
it
s
easy
to
work
around
this
if
you
need
your
script
s
output
to
stick
around
when
you
launch
it
with
an
icon
click
simply
put
a
call
to
the
built
in
input
function
at
the
very
bottom
of
the
script
raw
input
in
see
the
note
ahead
for
example
a
first
python
script
import
sys
print
sys
platform
print
x
spam
print
x
input
load
a
library
module
raise
to
a
power
string
repetition
added
in
general
input
reads
the
next
line
of
standard
input
waiting
if
there
is
none
yet
available
the
net
effect
in
this
context
will
be
to
pause
the
script
thereby
keeping
the
output
window
shown
in
figure
open
until
you
press
the
enter
key
figure
when
you
click
a
program
s
icon
on
windows
you
will
be
able
to
see
its
printed
output
if
you
include
an
input
call
at
the
very
end
of
the
script
but
you
only
need
to
do
so
in
this
context
clicking
file
icons
now
that
i
ve
shown
you
this
trick
keep
in
mind
that
it
is
usually
only
required
for
windows
and
then
only
if
your
script
prints
text
and
exits
and
only
if
you
will
launch
the
script
by
clicking
its
file
icon
you
should
add
this
call
to
the
bottom
of
your
toplevel
files
if
and
only
if
all
of
these
three
conditions
apply
there
is
no
reason
to
add
this
call
in
any
other
contexts
unless
you
re
unreasonably
fond
of
pressing
your
computer
s
enter
key
that
may
sound
obvious
but
it
s
another
common
mistake
in
live
classes
before
we
move
ahead
note
that
the
input
call
applied
here
is
the
input
counterpart
of
using
the
print
statement
for
outputs
it
is
the
simplest
way
to
read
user
input
and
it
is
more
general
than
this
example
implies
for
instance
input
optionally
accepts
a
string
that
will
be
printed
as
a
prompt
e
g
input
press
enter
to
exit
returns
to
your
script
a
line
of
text
read
as
a
string
e
g
nextinput
input
supports
input
stream
redirections
at
the
system
shell
level
e
g
python
spam
py
input
txt
just
as
the
print
statement
does
for
output
we
ll
use
input
in
more
advanced
ways
later
in
this
text
for
instance
chapter
will
apply
it
in
an
interactive
loop
version
skew
note
if
you
are
working
in
python
or
earlier
use
raw
input
instead
of
input
in
this
code
the
former
was
renamed
to
the
latter
in
python
technically
has
an
input
too
but
it
also
evaluates
strings
as
though
they
are
program
code
typed
into
a
script
and
so
will
not
work
in
this
context
an
empty
string
is
an
error
python
s
input
and
s
raw
input
simply
returns
the
entered
text
as
a
string
unevaluated
to
simulate
s
input
in
use
eval
input
other
icon
click
limitations
even
with
the
input
trick
clicking
file
icons
is
not
without
its
perils
you
also
may
not
get
to
see
python
error
messages
if
your
script
generates
an
error
the
error
message
text
is
written
to
the
pop
up
console
window
which
then
immediately
disappears
worse
adding
an
input
call
to
your
file
will
not
help
this
time
because
your
script
will
likely
abort
long
before
it
reaches
this
call
in
other
words
you
won
t
be
able
to
tell
what
went
wrong
it
is
also
possible
to
completely
suppress
the
pop
up
dos
console
window
for
clicked
files
on
windows
files
whose
names
end
in
a
pyw
extension
will
display
only
windows
constructed
by
your
script
not
the
default
dos
console
window
pyw
files
are
simply
py
source
files
that
have
this
special
operational
behavior
on
windows
they
are
mostly
used
for
python
coded
user
interfaces
that
build
windows
of
their
own
often
in
conjunction
with
various
techniques
for
saving
printed
output
and
errors
to
files
chapter
how
you
run
programs
because
of
these
limitations
it
is
probably
best
to
view
icon
clicks
as
a
way
to
launch
programs
after
they
have
been
debugged
or
have
been
instrumented
to
write
their
output
to
a
file
especially
when
starting
out
use
other
techniques
such
as
system
command
lines
and
idle
discussed
further
in
the
section
the
idle
user
interface
on
page
so
that
you
can
see
generated
error
messages
and
view
your
normal
output
without
resorting
to
coding
tricks
when
we
discuss
exceptions
later
in
this
book
you
ll
also
learn
that
it
is
possible
to
intercept
and
recover
from
errors
so
that
they
do
not
terminate
your
programs
watch
for
the
discussion
of
the
try
statement
later
in
this
book
for
an
alternative
way
to
keep
the
console
window
from
closing
on
errors
module
imports
and
reloads
so
far
i
ve
been
talking
about
importing
modules
without
really
explaining
what
this
term
means
we
ll
study
modules
and
larger
program
architecture
in
depth
in
part
v
but
because
imports
are
also
a
way
to
launch
programs
this
section
will
introduce
enough
module
basics
to
get
you
started
in
simple
terms
every
file
of
python
source
code
whose
name
ends
in
a
py
extension
is
a
module
other
files
can
access
the
items
a
module
defines
by
importing
that
module
import
operations
essentially
load
another
file
and
grant
access
to
that
file
s
contents
the
contents
of
a
module
are
made
available
to
the
outside
world
through
its
attributes
a
term
i
ll
define
in
the
next
section
this
module
based
services
model
turns
out
to
be
the
core
idea
behind
program
architecture
in
python
larger
programs
usually
take
the
form
of
multiple
module
files
which
import
tools
from
other
module
files
one
of
the
modules
is
designated
as
the
main
or
top
level
file
and
this
is
the
one
launched
to
start
the
entire
program
we
ll
delve
into
such
architectural
issues
in
more
detail
later
in
this
book
this
chapter
is
mostly
interested
in
the
fact
that
import
operations
run
the
code
in
a
file
that
is
being
loaded
as
a
final
step
because
of
this
importing
a
file
is
yet
another
way
to
launch
it
for
instance
if
you
start
an
interactive
session
from
a
system
command
line
from
the
start
menu
from
idle
or
otherwise
you
can
run
the
script
py
file
you
created
earlier
with
a
simple
import
be
sure
to
delete
the
input
line
you
added
in
the
prior
section
first
or
you
ll
need
to
press
enter
for
no
reason
c
misc
c
python
python
import
script
win
spam
spam
spam
spam
spam
spam
spam
spam
module
imports
and
reloads
this
works
but
only
once
per
session
really
process
by
default
after
the
first
import
later
imports
do
nothing
even
if
you
change
and
save
the
module
s
source
file
again
in
another
window
import
script
import
script
this
is
by
design
imports
are
too
expensive
an
operation
to
repeat
more
than
once
per
file
per
program
run
as
you
ll
learn
in
chapter
imports
must
find
files
compile
them
to
byte
code
and
run
the
code
if
you
really
want
to
force
python
to
run
the
file
again
in
the
same
session
without
stopping
and
restarting
the
session
you
need
to
instead
call
the
reload
function
available
in
the
imp
standard
library
module
this
function
is
also
a
simple
built
in
in
python
but
not
in
from
imp
import
reload
must
load
from
module
in
reload
script
win
spam
spam
spam
spam
spam
spam
spam
spam
module
script
from
script
py
the
from
statement
here
simply
copies
a
name
out
of
a
module
more
on
this
soon
the
reload
function
itself
loads
and
runs
the
current
version
of
your
file
s
code
picking
up
changes
if
you
ve
changed
and
saved
it
in
another
window
this
allows
you
to
edit
and
pick
up
new
code
on
the
fly
within
the
current
python
interactive
session
in
this
session
for
example
the
second
print
statement
in
script
py
was
changed
in
another
window
to
print
between
the
time
of
the
first
import
and
the
reload
call
the
reload
function
expects
the
name
of
an
already
loaded
module
object
so
you
have
to
have
successfully
imported
a
module
once
before
you
reload
it
notice
that
reload
also
expects
parentheses
around
the
module
object
name
whereas
import
does
not
reload
is
a
function
that
is
called
and
import
is
a
statement
that
s
why
you
must
pass
the
module
name
to
reload
as
an
argument
in
parentheses
and
that
s
why
you
get
back
an
extra
output
line
when
reloading
the
last
output
line
is
just
the
display
representation
of
the
reload
call
s
return
value
a
python
module
object
we
ll
learn
more
about
using
functions
in
general
in
chapter
chapter
how
you
run
programs
version
skew
note
python
moved
the
reload
built
in
function
to
the
imp
standard
library
module
it
still
reloads
files
as
before
but
you
must
import
it
in
order
to
use
it
in
run
an
import
imp
and
use
imp
reload
m
or
run
a
from
imp
import
reload
and
use
reload
m
as
shown
here
we
ll
discuss
import
and
from
statements
in
the
next
section
and
more
formally
later
in
this
book
if
you
are
working
in
python
or
x
in
general
reload
is
available
as
a
built
in
function
so
no
import
is
required
in
python
reload
is
available
in
both
forms
built
in
and
module
function
to
aid
the
transition
to
in
other
words
reloading
is
still
available
in
but
an
extra
line
of
code
is
required
to
fetch
the
reload
call
the
move
in
was
likely
motivated
in
part
by
some
well
known
issues
involving
reload
and
from
statements
that
we
ll
encounter
in
the
next
section
in
short
names
loaded
with
a
from
are
not
directly
updated
by
a
reload
but
names
accessed
with
an
import
statement
are
if
your
names
don
t
seem
to
change
after
a
reload
try
using
import
and
module
attribute
name
references
instead
the
grander
module
story
attributes
imports
and
reloads
provide
a
natural
program
launch
option
because
import
operations
execute
files
as
a
last
step
in
the
broader
scheme
of
things
though
modules
serve
the
role
of
libraries
of
tools
as
you
ll
learn
in
part
v
more
generally
a
module
is
mostly
just
a
package
of
variable
names
known
as
a
namespace
the
names
within
that
package
are
called
attributes
an
attribute
is
simply
a
variable
name
that
is
attached
to
a
specific
object
like
a
module
in
typical
use
importers
gain
access
to
all
the
names
assigned
at
the
top
level
of
a
module
s
file
these
names
are
usually
assigned
to
tools
exported
by
the
module
functions
classes
variables
and
so
on
that
are
intended
to
be
used
in
other
files
and
other
programs
externally
a
module
file
s
names
can
be
fetched
with
two
python
statements
import
and
from
as
well
as
the
reload
call
to
illustrate
use
a
text
editor
to
create
a
one
line
python
module
file
called
myfile
py
with
the
following
contents
title
the
meaning
of
life
this
may
be
one
of
the
world
s
simplest
python
modules
it
contains
a
single
assignment
statement
but
it
s
enough
to
illustrate
the
point
when
this
file
is
imported
its
code
is
run
to
generate
the
module
s
attribute
the
assignment
statement
creates
a
module
attribute
named
title
module
imports
and
reloads
you
can
access
this
module
s
title
attribute
in
other
components
in
two
different
ways
first
you
can
load
the
module
as
a
whole
with
an
import
statement
and
then
qualify
the
module
name
with
the
attribute
name
to
fetch
it
python
import
myfile
print
myfile
title
the
meaning
of
life
start
python
run
file
load
module
as
a
whole
use
its
attribute
names
to
qualify
in
general
the
dot
expression
syntax
object
attribute
lets
you
fetch
any
attribute
attached
to
any
object
and
this
is
a
very
common
operation
in
python
code
here
we
ve
used
it
to
access
the
string
variable
title
inside
the
module
myfile
in
other
words
myfile
title
alternatively
you
can
fetch
really
copy
names
out
of
a
module
with
from
statements
python
from
myfile
import
title
print
title
the
meaning
of
life
start
python
run
file
copy
its
names
use
name
directly
no
need
to
qualify
as
you
ll
see
in
more
detail
later
from
is
just
like
an
import
with
an
extra
assignment
to
names
in
the
importing
component
technically
from
copies
a
module
s
attributes
such
that
they
become
simple
variables
in
the
recipient
thus
you
can
simply
refer
to
the
imported
string
this
time
as
title
a
variable
instead
of
myfile
title
an
attribute
reference
whether
you
use
import
or
from
to
invoke
an
import
operation
the
statements
in
the
module
file
myfile
py
are
executed
and
the
importing
component
here
the
interactive
prompt
gains
access
to
names
assigned
at
the
top
level
of
the
file
there
s
only
one
such
name
in
this
simple
example
the
variable
title
assigned
to
a
string
but
the
concept
will
be
more
useful
when
you
start
defining
objects
such
as
functions
and
classes
in
your
modules
such
objects
become
reusable
software
components
that
can
be
accessed
by
name
from
one
or
more
client
modules
in
practice
module
files
usually
define
more
than
one
name
to
be
used
in
and
outside
the
files
here
s
an
example
that
defines
three
a
dead
b
parrot
c
sketch
print
a
b
c
define
three
attributes
exported
to
other
files
also
used
in
this
file
this
file
threenames
py
assigns
three
variables
and
so
generates
three
attributes
for
the
outside
world
it
also
uses
its
own
three
variables
in
a
print
statement
as
we
see
when
we
run
this
as
a
top
level
file
notice
that
import
and
from
both
list
the
name
of
the
module
file
as
simply
myfile
without
its
py
suffix
as
you
ll
learn
in
part
v
when
python
looks
for
the
actual
file
it
knows
to
include
the
suffix
in
its
search
procedure
again
you
must
include
the
py
suffix
in
system
shell
command
lines
but
not
in
import
statements
chapter
how
you
run
programs
python
threenames
py
dead
parrot
sketch
all
of
this
file
s
code
runs
as
usual
the
first
time
it
is
imported
elsewhere
by
either
an
import
or
from
clients
of
this
file
that
use
import
get
a
module
with
attributes
while
clients
that
use
from
get
copies
of
the
file
s
names
python
import
threenames
dead
parrot
sketch
threenames
b
threenames
c
parrot
sketch
from
threenames
import
a
b
c
b
c
parrot
sketch
grab
the
whole
module
copy
multiple
names
the
results
here
are
printed
in
parentheses
because
they
are
really
tuples
a
kind
of
object
covered
in
the
next
part
of
this
book
you
can
safely
ignore
them
for
now
once
you
start
coding
modules
with
multiple
names
like
this
the
built
in
dir
function
starts
to
come
in
handy
you
can
use
it
to
fetch
a
list
of
the
names
available
inside
a
module
the
following
returns
a
python
list
of
strings
we
ll
start
studying
lists
in
the
next
chapter
dir
threenames
builtins
doc
file
name
package
a
b
c
i
ran
this
on
python
and
older
pythons
may
return
fewer
names
when
the
dir
function
is
called
with
the
name
of
an
imported
module
passed
in
parentheses
like
this
it
returns
all
the
attributes
inside
that
module
some
of
the
names
it
returns
are
names
you
get
for
free
names
with
leading
and
trailing
double
underscores
are
builtin
names
that
are
always
predefined
by
python
and
that
have
special
meaning
to
the
interpreter
the
variables
our
code
defined
by
assignment
a
b
and
c
show
up
last
in
the
dir
result
modules
and
namespaces
module
imports
are
a
way
to
run
files
of
code
but
as
we
ll
discuss
later
in
the
book
modules
are
also
the
largest
program
structure
in
python
programs
in
general
python
programs
are
composed
of
multiple
module
files
linked
together
by
import
statements
each
module
file
is
a
self
contained
package
of
variables
that
is
a
namespace
one
module
file
cannot
see
the
names
defined
in
another
file
unless
it
explicitly
imports
that
other
file
so
modules
serve
to
minimize
name
collisions
in
your
code
because
each
file
is
a
self
contained
namespace
the
names
in
one
file
cannot
clash
with
those
in
another
even
if
they
are
spelled
the
same
way
module
imports
and
reloads
in
fact
as
you
ll
see
modules
are
one
of
a
handful
of
ways
that
python
goes
to
great
lengths
to
package
your
variables
into
compartments
to
avoid
name
clashes
we
ll
discuss
modules
and
other
namespace
constructs
including
classes
and
function
scopes
further
later
in
the
book
for
now
modules
will
come
in
handy
as
a
way
to
run
your
code
many
times
without
having
to
retype
it
import
versus
from
i
should
point
out
that
the
from
statement
in
a
sense
defeats
the
namespace
partitioning
purpose
of
modules
because
the
from
copies
variables
from
one
file
to
another
it
can
cause
same
named
variables
in
the
importing
file
to
be
overwritten
and
won
t
warn
you
if
it
does
this
essentially
collapses
namespaces
together
at
least
in
terms
of
the
copied
variables
because
of
this
some
recommend
using
import
instead
of
from
i
won
t
go
that
far
though
not
only
does
from
involve
less
typing
but
its
purported
problem
is
rarely
an
issue
in
practice
besides
this
is
something
you
control
by
listing
the
variables
you
want
in
the
from
as
long
as
you
understand
that
they
ll
be
assigned
values
this
is
no
more
dangerous
than
coding
assignment
statements
another
feature
you
ll
probably
want
to
use
import
and
reload
usage
notes
for
some
reason
once
people
find
out
about
running
files
using
import
and
reload
many
tend
to
focus
on
this
alone
and
forget
about
other
launch
options
that
always
run
the
current
version
of
the
code
e
g
icon
clicks
idle
menu
options
and
system
command
lines
this
approach
can
quickly
lead
to
confusion
though
you
need
to
remember
when
you
ve
imported
to
know
if
you
can
reload
you
need
to
remember
to
use
parentheses
when
you
call
reload
only
and
you
need
to
remember
to
use
reload
in
the
first
place
to
get
the
current
version
of
your
code
to
run
moreover
reloads
aren
t
transitive
reloading
a
module
reloads
that
module
only
not
any
modules
it
may
import
so
you
sometimes
have
to
reload
multiple
files
because
of
these
complications
and
others
we
ll
explore
later
including
the
reload
from
issue
mentioned
in
a
prior
note
in
this
chapter
it
s
generally
a
good
idea
to
avoid
the
temptation
to
launch
by
imports
and
reloads
for
now
the
idle
run
run
module
menu
option
described
in
the
next
section
for
example
provides
a
simpler
and
less
error
prone
way
to
run
your
files
and
always
runs
the
current
version
of
your
code
system
shell
command
lines
offer
similar
benefits
you
don
t
need
to
use
reload
if
you
use
these
techniques
in
addition
you
may
run
into
trouble
if
you
use
modules
in
unusual
ways
at
this
point
in
the
book
for
instance
if
you
want
to
import
a
module
file
that
is
stored
in
a
directory
other
than
the
one
you
re
working
in
you
ll
have
to
skip
ahead
to
chapter
and
learn
about
the
module
search
path
chapter
how
you
run
programs
for
now
if
you
must
import
try
to
keep
all
your
files
in
the
directory
you
are
working
in
to
avoid
complications
that
said
imports
and
reloads
have
proven
to
be
a
popular
testing
technique
in
python
classes
and
you
may
prefer
using
this
approach
too
as
usual
though
if
you
find
yourself
running
into
a
wall
stop
running
into
a
wall
using
exec
to
run
module
files
in
fact
there
are
more
ways
to
run
code
stored
in
module
files
than
have
yet
been
exposed
here
for
instance
the
exec
open
module
py
read
built
in
function
call
is
another
way
to
launch
files
from
the
interactive
prompt
without
having
to
import
and
later
reload
each
exec
runs
the
current
version
of
the
file
without
requiring
later
reloads
script
py
is
as
we
left
it
after
a
reload
in
the
prior
section
c
misc
c
python
python
exec
open
script
py
read
win
spam
spam
spam
spam
spam
spam
spam
spam
change
script
py
in
a
text
edit
window
exec
open
script
py
read
win
spam
spam
spam
spam
spam
spam
spam
spam
the
exec
call
has
an
effect
similar
to
an
import
but
it
doesn
t
technically
import
the
module
by
default
each
time
you
call
exec
this
way
it
runs
the
file
anew
as
though
you
had
pasted
it
in
at
the
place
where
exec
is
called
because
of
that
exec
does
not
require
module
reloads
after
file
changes
it
skips
the
normal
module
import
logic
on
the
downside
because
it
works
as
if
pasting
code
into
the
place
where
it
is
called
exec
like
the
from
statement
mentioned
earlier
has
the
potential
to
silently
overwrite
variables
you
may
currently
be
using
for
example
our
script
py
assigns
to
a
variable
named
x
if
that
name
is
also
being
used
in
the
place
where
exec
is
called
the
name
s
value
is
replaced
x
exec
open
script
py
read
same
outout
x
spam
code
run
in
this
namespace
by
default
its
assignments
can
overwrite
names
here
if
you
re
burning
with
curiosity
the
short
story
is
that
python
searches
for
imported
modules
in
every
directory
listed
in
sys
path
a
python
list
of
directory
name
strings
in
the
sys
module
which
is
initialized
from
a
pythonpath
environment
variable
plus
a
set
of
standard
directories
if
you
want
to
import
from
a
directory
other
than
the
one
you
are
working
in
that
directory
must
generally
be
listed
in
your
pythonpath
setting
for
more
details
see
chapter
using
exec
to
run
module
files
by
contrast
the
basic
import
statement
runs
the
file
only
once
per
process
and
it
makes
the
file
a
separate
module
namespace
so
that
its
assignments
will
not
change
variables
in
your
scope
the
price
you
pay
for
the
namespace
partitioning
of
modules
is
the
need
to
reload
after
changes
version
skew
note
python
also
includes
an
execfile
module
py
built
in
function
in
addition
to
allowing
the
form
exec
open
module
py
which
both
automatically
read
the
file
s
content
both
of
these
are
equivalent
to
the
exec
open
module
py
read
form
which
is
more
complex
but
runs
in
both
and
unfortunately
neither
of
these
two
simpler
forms
is
available
in
which
means
you
must
understand
both
files
and
their
read
methods
to
fully
understand
this
technique
today
alas
this
seems
to
be
a
case
of
aesthetics
trouncing
practicality
in
in
fact
the
exec
form
in
involves
so
much
typing
that
the
best
advice
may
simply
be
not
to
do
it
it
s
usually
best
to
launch
files
by
typing
system
shell
command
lines
or
by
using
the
idle
menu
options
described
in
the
next
section
for
more
on
the
exec
form
see
chapter
the
idle
user
interface
so
far
we
ve
seen
how
to
run
python
code
with
the
interactive
prompt
system
command
lines
icon
clicks
and
module
imports
and
exec
calls
if
you
re
looking
for
something
a
bit
more
visual
idle
provides
a
graphical
user
interface
for
doing
python
development
and
it
s
a
standard
and
free
part
of
the
python
system
it
is
usually
referred
to
as
an
integrated
development
environment
ide
because
it
binds
together
various
development
tasks
into
a
single
view
in
short
idle
is
a
gui
that
lets
you
edit
run
browse
and
debug
python
programs
all
from
a
single
interface
moreover
because
idle
is
a
python
program
that
uses
the
tkinter
gui
toolkit
known
as
tkinter
in
it
runs
portably
on
most
python
platforms
including
microsoft
windows
x
windows
for
linux
unix
and
unix
like
platforms
and
the
mac
os
both
classic
and
os
x
for
many
idle
represents
an
easy
to
use
alternative
to
typing
command
lines
and
a
less
problem
prone
alternative
to
clicking
on
icons
idle
basics
let
s
jump
right
into
an
example
idle
is
easy
to
start
under
windows
it
has
an
entry
in
the
start
button
menu
for
python
see
figure
shown
previously
and
it
can
also
be
selected
by
right
clicking
on
a
python
program
icon
on
some
unix
like
systems
idle
is
officially
a
corruption
of
ide
but
it
s
really
named
in
honor
of
monty
python
member
eric
idle
chapter
how
you
run
programs
you
may
need
to
launch
idle
s
top
level
script
from
a
command
line
or
by
clicking
on
the
icon
for
the
idle
pyw
or
idle
py
file
located
in
the
idlelib
subdirectory
of
python
s
lib
directory
on
windows
idle
is
a
python
script
that
currently
lives
in
c
python
lib
idlelib
or
c
python
lib
idlelib
in
python
figure
shows
the
scene
after
starting
idle
on
windows
the
python
shell
window
that
opens
initially
is
the
main
window
which
runs
an
interactive
session
notice
the
prompt
this
works
like
all
interactive
sessions
code
you
type
here
is
run
immediately
after
you
type
it
and
serves
as
a
testing
tool
figure
the
main
python
shell
window
of
the
idle
development
gui
shown
here
running
on
windows
use
the
file
menu
to
begin
new
window
or
change
open
a
source
file
use
the
text
edit
window
s
run
menu
to
run
the
code
in
that
window
run
module
idle
is
a
python
program
that
uses
the
standard
library
s
tkinter
gui
toolkit
a
k
a
tkinter
in
python
to
build
the
idle
gui
this
makes
idle
portable
but
it
also
means
that
you
ll
need
to
have
tkinter
support
in
your
python
to
use
idle
the
windows
version
of
python
has
this
by
default
but
some
linux
and
unix
users
may
need
to
install
the
appropriate
tkinter
support
a
yum
tkinter
command
may
suffice
on
some
linux
distributions
but
see
the
installation
hints
in
appendix
a
for
details
mac
os
x
may
have
everything
you
need
preinstalled
too
look
for
an
idle
command
or
script
on
your
machine
the
idle
user
interface
idle
uses
familiar
menus
with
keyboard
shortcuts
for
most
of
its
operations
to
make
or
edit
a
source
code
file
under
idle
open
a
text
edit
window
in
the
main
window
select
the
file
pull
down
menu
and
pick
new
window
or
open
to
open
a
text
edit
window
displaying
an
existing
file
for
editing
although
it
may
not
show
up
fully
in
this
book
s
graphics
idle
uses
syntax
directed
colorization
for
the
code
typed
in
both
the
main
window
and
all
text
edit
windows
keywords
are
one
color
literals
are
another
and
so
on
this
helps
give
you
a
better
picture
of
the
components
in
your
code
and
can
even
help
you
spot
mistakes
run
on
strings
are
all
one
color
for
example
to
run
a
file
of
code
that
you
are
editing
in
idle
select
the
file
s
text
edit
window
open
that
window
s
run
pull
down
menu
and
choose
the
run
module
option
listed
there
or
use
the
equivalent
keyboard
shortcut
given
in
the
menu
python
will
let
you
know
that
you
need
to
save
your
file
first
if
you
ve
changed
it
since
it
was
opened
or
last
saved
and
forgot
to
save
your
changes
a
common
mistake
when
you
re
knee
deep
in
coding
when
run
this
way
the
output
of
your
script
and
any
error
messages
it
may
generate
show
up
back
in
the
main
interactive
window
the
python
shell
window
in
figure
for
example
the
three
lines
after
the
restart
line
near
the
middle
of
the
window
reflect
an
execution
of
our
script
py
file
opened
in
a
separate
edit
window
the
restart
message
tells
us
that
the
user
code
process
was
restarted
to
run
the
edited
script
and
serves
to
separate
script
output
it
does
not
appear
if
idle
is
started
without
a
user
code
subprocess
more
on
this
mode
in
a
moment
idle
hint
of
the
day
if
you
want
to
repeat
prior
commands
in
idle
s
main
interactive
window
you
can
use
the
alt
p
key
combination
to
scroll
backward
through
the
command
history
and
alt
n
to
scroll
forward
on
some
macs
try
ctrl
p
and
ctrl
n
instead
your
prior
commands
will
be
recalled
and
displayed
and
may
be
edited
and
rerun
you
can
also
recall
commands
by
positioning
the
cursor
on
them
or
use
cut
and
paste
operations
but
these
techniques
tend
to
involve
more
work
outside
idle
you
may
be
able
to
recall
commands
in
an
interactive
session
with
the
arrow
keys
on
windows
using
idle
idle
is
free
easy
to
use
portable
and
automatically
available
on
most
platforms
i
generally
recommend
it
to
python
newcomers
because
it
sugarcoats
some
of
the
details
and
does
not
assume
prior
experience
with
system
command
lines
however
it
is
somewhat
limited
compared
to
more
advanced
commercial
ides
to
help
you
avoid
some
common
pitfalls
here
is
a
list
of
issues
that
idle
beginners
should
bear
in
mind
you
must
add
py
explicitly
when
saving
your
files
i
mentioned
this
when
talking
about
files
in
general
but
it
s
a
common
idle
stumbling
block
especially
chapter
how
you
run
programs
for
windows
users
idle
does
not
automatically
add
a
py
extension
to
filenames
when
files
are
saved
be
careful
to
type
the
py
extension
yourself
when
saving
a
file
for
the
first
time
if
you
don
t
while
you
will
be
able
to
run
your
file
from
idle
and
system
command
lines
you
will
not
be
able
to
import
it
either
interactively
or
from
other
modules
run
scripts
by
selecting
run
run
module
in
text
edit
windows
not
by
interactive
imports
and
reloads
earlier
in
this
chapter
we
saw
that
it
s
possible
to
run
a
file
by
importing
it
interactively
however
this
scheme
can
grow
complex
because
it
requires
you
to
manually
reload
files
after
changes
by
contrast
using
the
run
run
module
menu
option
in
idle
always
runs
the
most
current
version
of
your
file
just
like
running
it
using
a
system
shell
command
line
idle
also
prompts
you
to
save
your
file
first
if
needed
another
common
mistake
outside
idle
you
need
to
reload
only
modules
being
tested
interactively
like
system
shell
command
lines
idle
s
run
run
module
menu
option
always
runs
the
current
version
of
both
the
top
level
file
and
any
modules
it
imports
because
of
this
run
run
module
eliminates
common
confusions
surrounding
imports
you
only
need
to
reload
modules
that
you
are
importing
and
testing
interactively
in
idle
if
you
choose
to
use
the
import
and
reload
technique
instead
of
run
run
module
remember
that
you
can
use
the
alt
p
alt
n
key
combinations
to
recall
prior
commands
you
can
customize
idle
to
change
the
text
fonts
and
colors
in
idle
select
the
configure
option
in
the
options
menu
of
any
idle
window
you
can
also
customize
key
combination
actions
indentation
settings
and
more
see
idle
s
help
pull
down
menu
for
more
hints
there
is
currently
no
clear
screen
option
in
idle
this
seems
to
be
a
frequent
request
perhaps
because
it
s
an
option
available
in
similar
ides
and
it
might
be
added
eventually
today
though
there
is
no
way
to
clear
the
interactive
window
s
text
if
you
want
the
window
s
text
to
go
away
you
can
either
press
and
hold
the
enter
key
or
type
a
python
loop
to
print
a
series
of
blank
lines
nobody
really
uses
the
latter
technique
of
course
but
it
sounds
more
high
tech
than
pressing
the
enter
key
tkinter
gui
and
threaded
programs
may
not
work
well
with
idle
because
idle
is
a
python
tkinter
program
it
can
hang
if
you
use
it
to
run
certain
types
of
advanced
python
tkinter
programs
this
has
become
less
of
an
issue
in
more
recent
versions
of
idle
that
run
user
code
in
one
process
and
the
idle
gui
itself
in
another
but
some
programs
especially
those
that
use
multithreading
might
still
hang
the
gui
your
code
may
not
exhibit
such
problems
but
as
a
rule
of
thumb
it
s
always
safe
to
use
idle
to
edit
gui
programs
but
launch
them
using
other
options
such
as
icon
clicks
or
system
command
lines
when
in
doubt
if
your
code
fails
in
idle
try
it
outside
the
gui
the
idle
user
interface
if
connection
errors
arise
try
starting
idle
in
single
process
mode
because
idle
requires
communication
between
its
separate
user
and
gui
processes
it
can
sometimes
have
trouble
starting
up
on
certain
platforms
notably
it
fails
to
start
occasionally
on
some
windows
machines
due
to
firewall
software
that
blocks
connections
if
you
run
into
such
connection
errors
it
s
always
possible
to
start
idle
with
a
system
command
line
that
forces
it
to
run
in
single
process
mode
without
a
user
code
subprocess
and
therefore
avoids
communication
issues
its
n
command
line
flag
forces
this
mode
on
windows
for
example
start
a
command
prompt
window
and
run
the
system
command
line
idle
py
n
from
within
the
directory
c
python
lib
idlelib
cd
there
first
if
needed
beware
of
some
idle
usability
features
idle
does
much
to
make
life
easier
for
beginners
but
some
of
its
tricks
won
t
apply
outside
the
idle
gui
for
instance
idle
runs
your
scripts
in
its
own
interactive
namespace
so
variables
in
your
code
show
up
automatically
in
the
idle
interactive
session
you
don
t
always
need
to
run
import
commands
to
access
names
at
the
top
level
of
files
you
ve
already
run
this
can
be
handy
but
it
can
also
be
confusing
because
outside
the
idle
environment
names
must
always
be
imported
from
files
to
be
used
idle
also
automatically
changes
both
to
the
directory
of
a
file
just
run
and
adds
its
directory
to
the
module
import
search
path
a
handy
feature
that
allows
you
to
import
files
there
without
search
path
settings
but
also
something
that
won
t
work
the
same
when
you
run
files
outside
idle
it
s
ok
to
use
such
features
but
don
t
forget
that
they
are
idle
behavior
not
python
behavior
advanced
idle
tools
besides
the
basic
edit
and
run
functions
idle
provides
more
advanced
features
including
a
point
and
click
program
debugger
and
an
object
browser
the
idle
debugger
is
enabled
via
the
debug
menu
and
the
object
browser
via
the
file
menu
the
browser
allows
you
to
navigate
through
the
module
search
path
to
files
and
objects
in
files
clicking
on
a
file
or
object
opens
the
corresponding
source
in
a
text
edit
window
idle
debugging
is
initiated
by
selecting
the
debug
debugger
menu
option
in
the
main
window
and
then
starting
your
script
by
selecting
the
run
run
module
option
in
the
text
edit
window
once
the
debugger
is
enabled
you
can
set
breakpoints
in
your
code
that
stop
its
execution
by
right
clicking
on
lines
in
the
text
edit
windows
show
variable
values
and
so
on
you
can
also
watch
program
execution
when
debugging
the
current
line
of
code
is
noted
as
you
step
through
your
code
for
simpler
debugging
operations
you
can
also
right
click
with
your
mouse
on
the
text
of
an
error
message
to
quickly
jump
to
the
line
of
code
where
the
error
occurred
a
trick
that
makes
it
simple
and
fast
to
repair
and
run
again
in
addition
idle
s
text
editor
offers
a
large
collection
of
programmer
friendly
tools
including
automatic
indentation
advanced
text
and
file
search
operations
and
more
because
idle
uses
chapter
how
you
run
programs
intuitive
gui
interactions
you
should
experiment
with
the
system
live
to
get
a
feel
for
its
other
tools
other
ides
because
idle
is
free
portable
and
a
standard
part
of
python
it
s
a
nice
first
development
tool
to
become
familiar
with
if
you
want
to
use
an
ide
at
all
again
i
recommend
that
you
use
idle
for
this
book
s
exercises
if
you
re
just
starting
out
unless
you
are
already
familiar
with
and
prefer
a
command
line
based
development
mode
there
are
however
a
handful
of
alternative
ides
for
python
developers
some
of
which
are
substantially
more
powerful
and
robust
than
idle
here
are
some
of
the
most
commonly
used
ides
eclipse
and
pydev
eclipse
is
an
advanced
open
source
ide
gui
originally
developed
as
a
java
ide
eclipse
also
supports
python
development
when
you
install
the
pydev
or
a
similar
plug
in
eclipse
is
a
popular
and
powerful
option
for
python
development
and
it
goes
well
beyond
idle
s
feature
set
it
includes
support
for
code
completion
syntax
highlighting
syntax
analysis
refactoring
debugging
and
more
its
downsides
are
that
it
is
a
large
system
to
install
and
may
require
shareware
extensions
for
some
features
this
may
vary
over
time
still
when
you
are
ready
to
graduate
from
idle
the
eclipse
pydev
combination
is
worth
your
attention
komodo
a
full
featured
development
environment
gui
for
python
and
other
languages
komodo
includes
standard
syntax
coloring
text
editing
debugging
and
other
features
in
addition
komodo
offers
many
advanced
features
that
idle
does
not
including
project
files
source
control
integration
regular
expression
debugging
and
a
drag
and
drop
gui
builder
that
generates
python
tkinter
code
to
implement
the
guis
you
design
interactively
at
this
writing
komodo
is
not
free
it
is
available
at
http
www
activestate
com
netbeans
ide
for
python
netbeans
is
a
powerful
open
source
development
environment
gui
with
support
for
many
advanced
features
for
python
developers
code
completion
automatic
indentation
and
code
colorization
editor
hints
code
folding
refactoring
debugging
code
coverage
and
testing
projects
and
more
it
may
be
used
to
develop
both
cpython
and
jython
code
like
eclipse
netbeans
requires
installation
steps
beyond
those
of
the
included
idle
gui
but
it
is
seen
by
many
as
more
than
worth
the
effort
search
the
web
for
the
latest
information
and
links
pythonwin
pythonwin
is
a
free
windows
only
ide
for
python
that
ships
as
part
of
activestate
s
activepython
distribution
and
may
also
be
fetched
separately
from
http
www
python
org
resources
it
is
roughly
like
idle
with
a
handful
of
useful
windows
specific
extensions
added
for
example
pythonwin
has
support
for
other
ides
com
objects
today
idle
is
probably
more
advanced
than
pythonwin
for
instance
idle
s
dual
process
architecture
often
prevents
it
from
hanging
however
pythonwin
still
offers
tools
for
windows
developers
that
idle
does
not
see
http
www
activestate
com
for
more
information
others
there
are
roughly
half
a
dozen
other
widely
used
ides
that
i
m
aware
of
including
the
commercial
wing
ide
and
pythoncard
but
do
not
have
space
to
do
justice
to
here
and
more
will
probably
appear
over
time
in
fact
almost
every
programmerfriendly
text
editor
has
some
sort
of
support
for
python
development
these
days
whether
it
be
preinstalled
or
fetched
separately
emacs
and
vim
for
instance
have
substantial
python
support
i
won
t
try
to
document
all
such
options
here
for
more
information
see
the
resources
available
at
http
www
python
org
or
search
the
web
for
python
ide
you
might
also
try
running
a
web
search
for
python
editors
today
this
leads
you
to
a
wiki
page
that
maintains
information
about
many
ide
and
text
editor
options
for
python
programming
other
launch
options
at
this
point
we
ve
seen
how
to
run
code
typed
interactively
and
how
to
launch
code
saved
in
files
in
a
variety
of
ways
system
command
lines
imports
and
execs
guis
like
idle
and
more
that
covers
most
of
the
cases
you
ll
see
in
this
book
there
are
additional
ways
to
run
python
code
though
most
of
which
have
special
or
narrow
roles
the
next
few
sections
take
a
quick
look
at
some
of
these
embedding
calls
in
some
specialized
domains
python
code
may
be
run
automatically
by
an
enclosing
system
in
such
cases
we
say
that
the
python
programs
are
embedded
in
i
e
run
by
another
program
the
python
code
itself
may
be
entered
into
a
text
file
stored
in
a
database
fetched
from
an
html
page
parsed
from
an
xml
document
and
so
on
but
from
an
operational
perspective
another
system
not
you
may
tell
python
to
run
the
code
you
ve
created
such
an
embedded
execution
mode
is
commonly
used
to
support
end
user
customization
a
game
program
for
instance
might
allow
for
play
modifications
by
running
user
accessible
embedded
python
code
at
strategic
points
in
time
users
can
modify
this
type
of
system
by
providing
or
changing
python
code
because
python
code
is
interpreted
there
is
no
need
to
recompile
the
entire
system
to
incorporate
the
change
see
chapter
for
more
on
how
python
code
is
run
chapter
how
you
run
programs
in
this
mode
the
enclosing
system
that
runs
your
code
might
be
written
in
c
c
or
even
java
when
the
jython
system
is
used
as
an
example
it
s
possible
to
create
and
run
strings
of
python
code
from
a
c
program
by
calling
functions
in
the
python
runtime
api
a
set
of
services
exported
by
the
libraries
created
when
python
is
compiled
on
your
machine
include
python
h
py
initialize
pyrun
simplestring
x
brave
sir
robin
this
is
c
not
python
but
it
runs
python
code
in
this
c
code
snippet
a
program
coded
in
the
c
language
embeds
the
python
interpreter
by
linking
in
its
libraries
and
passes
it
a
python
assignment
statement
string
to
run
c
programs
may
also
gain
access
to
python
modules
and
objects
and
process
or
execute
them
using
other
python
api
tools
this
book
isn
t
about
python
c
integration
but
you
should
be
aware
that
depending
on
how
your
organization
plans
to
use
python
you
may
or
may
not
be
the
one
who
actually
starts
the
python
programs
you
create
regardless
you
can
usually
still
use
the
interactive
and
file
based
launching
techniques
described
here
to
test
code
in
isolation
from
those
enclosing
systems
that
may
eventually
use
it
frozen
binary
executables
frozen
binary
executables
described
in
chapter
are
packages
that
combine
your
program
s
byte
code
and
the
python
interpreter
into
a
single
executable
program
this
approach
enables
python
programs
to
be
launched
in
the
same
ways
that
you
would
launch
any
other
executable
program
icon
clicks
command
lines
etc
while
this
option
works
well
for
delivery
of
products
it
is
not
really
intended
for
use
during
program
development
you
normally
freeze
just
before
shipping
after
development
is
finished
see
the
prior
chapter
for
more
on
this
option
text
editor
launch
options
as
mentioned
previously
although
they
re
not
full
blown
ide
guis
most
programmer
friendly
text
editors
have
support
for
editing
and
possibly
running
python
programs
such
support
may
be
built
in
or
fetchable
on
the
web
for
instance
if
you
are
familiar
with
the
emacs
text
editor
you
can
do
all
your
python
editing
and
launching
from
inside
that
text
editor
see
the
text
editor
resources
page
at
http
www
python
org
editors
for
more
details
or
search
the
web
for
the
phrase
python
editors
see
programming
python
o
reilly
for
more
details
on
embedding
python
in
c
c
the
embedding
api
can
call
python
functions
directly
load
modules
and
more
also
note
that
the
jython
system
allows
java
programs
to
invoke
python
code
using
a
java
based
api
a
python
interpreter
class
other
launch
options
still
other
launch
options
depending
on
your
platform
there
may
be
additional
ways
that
you
can
start
python
programs
for
instance
on
some
macintosh
systems
you
may
be
able
to
drag
python
program
file
icons
onto
the
python
interpreter
icon
to
make
them
execute
and
on
windows
you
can
always
start
python
scripts
with
the
run
option
in
the
start
menu
additionally
the
python
standard
library
has
utilities
that
allow
python
programs
to
be
started
by
other
python
programs
in
separate
processes
e
g
os
popen
os
system
and
python
scripts
might
also
be
spawned
in
larger
contexts
like
the
web
for
instance
a
web
page
might
invoke
a
script
on
a
server
however
these
are
beyond
the
scope
of
the
present
chapter
future
possibilities
this
chapter
reflects
current
practice
but
much
of
the
material
is
both
platform
and
time
specific
indeed
many
of
the
execution
and
launch
details
presented
arose
during
the
shelf
life
of
this
book
s
various
editions
as
with
program
execution
options
it
s
not
impossible
that
new
program
launch
options
may
arise
over
time
new
operating
systems
and
new
versions
of
existing
systems
may
also
provide
execution
techniques
beyond
those
outlined
here
in
general
because
python
keeps
pace
with
such
changes
you
should
be
able
to
launch
python
programs
in
whatever
way
makes
sense
for
the
machines
you
use
both
now
and
in
the
future
be
that
by
drawing
on
tablet
pcs
or
pdas
grabbing
icons
in
a
virtual
reality
or
shouting
a
script
s
name
over
your
coworkers
conversations
implementation
changes
may
also
impact
launch
schemes
somewhat
e
g
a
full
compiler
could
produce
normal
executables
that
are
launched
much
like
frozen
binaries
today
if
i
knew
what
the
future
truly
held
though
i
would
probably
be
talking
to
a
stockbroker
instead
of
writing
these
words
which
option
should
i
use
with
all
these
options
one
question
naturally
arises
which
one
is
best
for
me
in
general
you
should
give
the
idle
interface
a
try
if
you
are
just
getting
started
with
python
it
provides
a
user
friendly
gui
environment
and
hides
some
of
the
underlying
configuration
details
it
also
comes
with
a
platform
neutral
text
editor
for
coding
your
scripts
and
it
s
a
standard
and
free
part
of
the
python
system
if
on
the
other
hand
you
are
an
experienced
programmer
you
might
be
more
comfortable
with
simply
the
text
editor
of
your
choice
in
one
window
and
another
window
for
launching
the
programs
you
edit
via
system
command
lines
and
icon
clicks
in
fact
this
is
how
i
develop
python
programs
but
i
have
a
unix
biased
past
because
the
choice
of
development
environments
is
very
subjective
i
can
t
offer
much
more
in
the
chapter
how
you
run
programs
way
of
universal
guidelines
in
general
whatever
environment
you
like
to
use
will
be
the
best
for
you
to
use
debugging
python
code
naturally
none
of
my
readers
or
students
ever
have
bugs
in
their
code
insert
smiley
here
but
for
less
fortunate
friends
of
yours
who
may
here
s
a
quick
look
at
the
strategies
commonly
used
by
real
world
python
programmers
to
debug
code
do
nothing
by
this
i
don
t
mean
that
python
programmers
don
t
debug
their
code
but
when
you
make
a
mistake
in
a
python
program
you
get
a
very
useful
and
readable
error
message
you
ll
get
to
see
some
soon
if
you
haven
t
already
if
you
already
know
python
and
especially
for
your
own
code
this
is
often
enough
read
the
error
message
and
go
fix
the
tagged
line
and
file
for
many
this
is
debugging
in
python
it
may
not
always
be
ideal
for
larger
system
you
didn
t
write
though
insert
print
statements
probably
the
main
way
that
python
programmers
debug
their
code
and
the
way
that
i
debug
python
code
is
to
insert
print
statements
and
run
again
because
python
runs
immediately
after
changes
this
is
usually
the
quickest
way
to
get
more
information
than
error
messages
provide
the
print
statements
don
t
have
to
be
sophisticated
a
simple
i
am
here
or
display
of
variable
values
is
usually
enough
to
provide
the
context
you
need
just
remember
to
delete
or
comment
out
i
e
add
a
before
the
debugging
prints
before
you
ship
your
code
use
ide
gui
debuggers
for
larger
systems
you
didn
t
write
and
for
beginners
who
want
to
trace
code
in
more
detail
most
python
development
guis
have
some
sort
of
point
and
click
debugging
support
idle
has
a
debugger
too
but
it
doesn
t
appear
to
be
used
very
often
in
practice
perhaps
because
it
has
no
command
line
or
perhaps
because
adding
print
statements
is
usually
quicker
than
setting
up
a
gui
debugging
session
to
learn
more
see
idle
s
help
or
simply
try
it
on
your
own
its
basic
interface
is
described
in
the
section
advanced
idle
tools
on
page
other
ides
such
as
eclipse
netbeans
komodo
and
wing
ide
offer
advanced
point
and
click
debuggers
as
well
see
their
documentation
if
you
use
them
use
the
pdb
command
line
debugger
for
ultimate
control
python
comes
with
a
source
code
debugger
named
pdb
available
as
a
module
in
python
s
standard
library
in
pdb
you
type
commands
to
step
line
by
line
display
variables
set
and
clear
breakpoints
continue
to
a
breakpoint
or
error
and
so
on
pdb
can
be
launched
interactively
by
importing
it
or
as
a
top
level
script
either
way
because
you
can
type
commands
to
control
the
session
it
provides
a
powerful
debugging
tool
pdb
also
includes
a
postmortem
function
you
can
run
after
an
exception
occurs
to
get
information
from
the
time
of
the
error
see
the
python
library
manual
and
chapter
for
more
details
on
pdb
other
options
for
more
specific
debugging
requirements
you
can
find
additional
tools
in
the
open
source
domain
including
support
for
multithreaded
programs
embedded
code
and
process
attachment
the
winpdb
system
for
example
is
a
which
option
should
i
use
standalone
debugger
with
advanced
debugging
support
and
cross
platform
gui
and
console
interfaces
these
options
will
become
more
important
as
we
start
writing
larger
scripts
probably
the
best
news
on
the
debugging
front
though
is
that
errors
are
detected
and
reported
in
python
rather
than
passing
silently
or
crashing
the
system
altogether
in
fact
errors
themselves
are
a
well
defined
mechanism
known
as
exceptions
which
you
can
catch
and
process
more
on
exceptions
in
part
vii
making
mistakes
is
never
fun
of
course
but
speaking
as
someone
who
recalls
when
debugging
meant
getting
out
a
hex
calculator
and
poring
over
piles
of
memory
dump
printouts
python
s
debugging
support
makes
errors
much
less
painful
than
they
might
otherwise
be
chapter
summary
in
this
chapter
we
ve
looked
at
common
ways
to
launch
python
programs
by
running
code
typed
interactively
and
by
running
code
stored
in
files
with
system
command
lines
file
icon
clicks
module
imports
exec
calls
and
ide
guis
such
as
idle
we
ve
covered
a
lot
of
pragmatic
startup
territory
here
this
chapter
s
goal
was
to
equip
you
with
enough
information
to
enable
you
to
start
writing
some
code
which
you
ll
do
in
the
next
part
of
the
book
there
we
will
start
exploring
the
python
language
itself
beginning
with
its
core
data
types
first
though
take
the
usual
chapter
quiz
to
exercise
what
you
ve
learned
here
because
this
is
the
last
chapter
in
this
part
of
the
book
it
s
followed
with
a
set
of
more
complete
exercises
that
test
your
mastery
of
this
entire
part
s
topics
for
help
with
the
latter
set
of
problems
or
just
for
a
refresher
be
sure
to
turn
to
appendix
b
after
you
ve
given
the
exercises
a
try
test
your
knowledge
quiz
how
can
you
start
an
interactive
interpreter
session
where
do
you
type
a
system
command
line
to
launch
a
script
file
name
four
or
more
ways
to
run
the
code
saved
in
a
script
file
name
two
pitfalls
related
to
clicking
file
icons
on
windows
why
might
you
need
to
reload
a
module
how
do
you
run
a
script
from
within
idle
name
two
pitfalls
related
to
using
idle
what
is
a
namespace
and
how
does
it
relate
to
module
files
chapter
how
you
run
programs
test
your
knowledge
answers
you
can
start
an
interactive
session
on
windows
by
clicking
your
start
button
picking
the
all
programs
option
clicking
the
python
entry
and
selecting
the
python
command
line
menu
option
you
can
also
achieve
the
same
effect
on
windows
and
other
platforms
by
typing
python
as
a
system
command
line
in
your
system
s
console
window
a
command
prompt
window
on
windows
another
alternative
is
to
launch
idle
as
its
main
python
shell
window
is
an
interactive
session
if
you
have
not
set
your
system
s
path
variable
to
find
python
you
may
need
to
cd
to
where
python
is
installed
or
type
its
full
directory
path
instead
of
just
python
e
g
c
python
python
on
windows
you
type
system
command
lines
in
whatever
your
platform
provides
as
a
system
console
a
command
prompt
window
on
windows
an
xterm
or
terminal
window
on
unix
linux
and
mac
os
x
and
so
on
code
in
a
script
really
module
file
can
be
run
with
system
command
lines
file
icon
clicks
imports
and
reloads
the
exec
built
in
function
and
ide
gui
selections
such
as
idle
s
run
run
module
menu
option
on
unix
they
can
also
be
run
as
executables
with
the
trick
and
some
platforms
support
more
specialized
launching
techniques
e
g
drag
and
drop
in
addition
some
text
editors
have
unique
ways
to
run
python
code
some
python
programs
are
provided
as
standalone
frozen
binary
executables
and
some
systems
use
python
code
in
embedded
mode
where
it
is
run
automatically
by
an
enclosing
program
written
in
a
language
like
c
c
or
java
the
latter
technique
is
usually
done
to
provide
a
user
customization
layer
scripts
that
print
and
then
exit
cause
the
output
file
to
disappear
immediately
before
you
can
view
the
output
which
is
why
the
input
trick
comes
in
handy
error
messages
generated
by
your
script
also
appear
in
an
output
window
that
closes
before
you
can
examine
its
contents
which
is
one
reason
that
system
command
lines
and
ides
such
as
idle
are
better
for
most
development
python
only
imports
loads
a
module
once
per
process
by
default
so
if
you
ve
changed
its
source
code
and
want
to
run
the
new
version
without
stopping
and
restarting
python
you
ll
have
to
reload
it
you
must
import
a
module
at
least
once
before
you
can
reload
it
running
files
of
code
from
a
system
shell
command
line
via
an
icon
click
or
via
an
ide
such
as
idle
generally
makes
this
a
nonissue
as
those
launch
schemes
usually
run
the
current
version
of
the
source
code
file
each
time
within
the
text
edit
window
of
the
file
you
wish
to
run
select
the
window
s
run
run
module
menu
option
this
runs
the
window
s
source
code
as
a
top
level
script
file
and
displays
its
output
back
in
the
interactive
python
shell
window
idle
can
still
be
hung
by
some
types
of
programs
especially
gui
programs
that
perform
multithreading
an
advanced
technique
beyond
this
book
s
scope
also
idle
has
some
usability
features
that
can
burn
you
once
you
leave
the
idle
gui
test
your
knowledge
answers
a
script
s
variables
are
automatically
imported
to
the
interactive
scope
in
idle
for
instance
but
not
by
python
in
general
a
namespace
is
just
a
package
of
variables
i
e
names
it
takes
the
form
of
an
object
with
attributes
in
python
each
module
file
is
automatically
a
namespace
that
is
a
package
of
variables
reflecting
the
assignments
made
at
the
top
level
of
the
file
namespaces
help
avoid
name
collisions
in
python
programs
because
each
module
file
is
a
self
contained
namespace
files
must
explicitly
import
other
files
in
order
to
use
their
names
test
your
knowledge
part
i
exercises
it
s
time
to
start
doing
a
little
coding
on
your
own
this
first
exercise
session
is
fairly
simple
but
a
few
of
these
questions
hint
at
topics
to
come
in
later
chapters
be
sure
to
check
part
i
getting
started
on
page
in
the
solutions
appendix
appendix
b
for
the
answers
the
exercises
and
their
solutions
sometimes
contain
supplemental
information
not
discussed
in
the
main
text
so
you
should
take
a
peek
at
the
solutions
even
if
you
manage
to
answer
all
the
questions
on
your
own
interaction
using
a
system
command
line
idle
or
another
method
start
the
python
interactive
command
line
prompt
and
type
the
expression
hello
world
including
the
quotes
the
string
should
be
echoed
back
to
you
the
purpose
of
this
exercise
is
to
get
your
environment
configured
to
run
python
in
some
scenarios
you
may
need
to
first
run
a
cd
shell
command
type
the
full
path
to
the
python
executable
or
add
its
path
to
your
path
environment
variable
if
desired
you
can
set
path
in
your
cshrc
or
kshrc
file
to
make
python
permanently
available
on
unix
systems
on
windows
use
a
setup
bat
autoexec
bat
or
the
environment
variable
gui
see
appendix
a
for
help
with
environment
variable
settings
programs
with
the
text
editor
of
your
choice
write
a
simple
module
file
containing
the
single
statement
print
hello
module
world
and
store
it
as
module
py
now
run
this
file
by
using
any
launch
option
you
like
running
it
in
idle
clicking
on
its
file
icon
passing
it
to
the
python
interpreter
on
the
system
shell
s
command
line
e
g
python
module
py
built
in
exec
calls
imports
and
reloads
and
so
on
in
fact
experiment
by
running
your
file
with
as
many
of
the
launch
techniques
discussed
in
this
chapter
as
you
can
which
technique
seems
easiest
there
is
no
right
answer
to
this
of
course
modules
start
the
python
interactive
command
line
prompt
and
import
the
module
you
wrote
in
exercise
try
moving
the
file
to
a
different
directory
and
importing
it
again
from
its
original
directory
i
e
run
python
in
the
original
directory
when
you
import
what
happens
hint
is
there
still
a
module
pyc
byte
code
file
in
the
original
directory
chapter
how
you
run
programs
scripts
if
your
platform
supports
it
add
the
line
to
the
top
of
your
module
py
module
file
give
the
file
executable
privileges
and
run
it
directly
as
an
executable
what
does
the
first
line
need
to
contain
usually
only
has
meaning
on
unix
linux
and
unix
like
platforms
such
as
mac
os
x
if
you
re
working
on
windows
instead
try
running
your
file
by
listing
just
its
name
in
a
dos
console
window
without
the
word
python
before
it
this
works
on
recent
versions
of
windows
or
via
the
start
run
dialog
box
errors
and
debugging
experiment
with
typing
mathematical
expressions
and
assignments
at
the
python
interactive
command
line
along
the
way
type
the
expressions
and
and
reference
an
undefined
variable
name
as
we
did
in
this
chapter
what
happens
you
may
not
know
it
yet
but
when
you
make
a
mistake
you
re
doing
exception
processing
a
topic
we
ll
explore
in
depth
in
part
vii
as
you
ll
learn
there
you
are
technically
triggering
what
s
known
as
the
default
exception
handler
logic
that
prints
a
standard
error
message
if
you
do
not
catch
an
error
the
default
handler
does
and
prints
the
standard
error
message
in
response
exceptions
are
also
bound
up
with
the
notion
of
debugging
in
python
when
you
re
first
starting
out
python
s
default
error
messages
on
exceptions
will
probably
provide
as
much
error
handling
support
as
you
need
they
give
the
cause
of
the
error
as
well
as
showing
the
lines
in
your
code
that
were
active
when
the
error
occurred
for
more
about
debugging
see
the
sidebar
debugging
python
code
on
page
breaks
and
cycles
at
the
python
command
line
type
l
l
append
l
l
make
a
item
list
append
l
as
a
single
item
to
itself
print
l
what
happens
in
all
recent
versions
of
python
you
ll
see
a
strange
output
that
we
ll
describe
in
the
solutions
appendix
and
which
will
make
more
sense
when
we
study
references
in
the
next
part
of
the
book
if
you
re
using
a
python
version
older
than
a
ctrl
c
key
combination
will
probably
help
on
most
platforms
why
do
you
think
your
version
of
python
responds
the
way
it
does
for
this
code
if
you
do
have
a
python
older
than
release
a
hopefully
rare
scenario
today
make
sure
your
machine
can
stop
a
program
with
a
ctrl
c
key
combination
of
some
sort
before
running
this
test
or
you
may
be
waiting
a
long
time
documentation
spend
at
least
minutes
browsing
the
python
library
and
language
manuals
before
moving
on
to
get
a
feel
for
the
available
tools
in
the
standard
library
and
the
structure
of
the
documentation
set
it
takes
at
least
this
long
to
become
familiar
with
the
locations
of
major
topics
in
the
manual
set
once
you
ve
done
this
it
s
easy
to
find
what
you
need
you
can
find
this
manual
via
the
python
test
your
knowledge
part
i
exercises
start
button
entry
on
windows
in
the
python
docs
option
on
the
help
pull
down
menu
in
idle
or
online
at
http
www
python
org
doc
i
ll
also
have
a
few
more
words
to
say
about
the
manuals
and
other
documentation
sources
available
including
pydoc
and
the
help
function
in
chapter
if
you
still
have
time
go
explore
the
python
website
as
well
as
its
pypy
third
party
extension
repository
especially
check
out
the
python
org
documentation
and
search
pages
they
can
be
crucial
resources
chapter
how
you
run
programs
part
ii
types
and
operations
chapter
introducing
python
object
types
this
chapter
begins
our
tour
of
the
python
language
in
an
informal
sense
in
python
we
do
things
with
stuff
things
take
the
form
of
operations
like
addition
and
concatenation
and
stuff
refers
to
the
objects
on
which
we
perform
those
operations
in
this
part
of
the
book
our
focus
is
on
that
stuff
and
the
things
our
programs
can
do
with
it
somewhat
more
formally
in
python
data
takes
the
form
of
objects
either
built
in
objects
that
python
provides
or
objects
we
create
using
python
or
external
language
tools
such
as
c
extension
libraries
although
we
ll
firm
up
this
definition
later
objects
are
essentially
just
pieces
of
memory
with
values
and
sets
of
associated
operations
because
objects
are
the
most
fundamental
notion
in
python
programming
we
ll
start
this
chapter
with
a
survey
of
python
s
built
in
object
types
by
way
of
introduction
however
let
s
first
establish
a
clear
picture
of
how
this
chapter
fits
into
the
overall
python
picture
from
a
more
concrete
perspective
python
programs
can
be
decomposed
into
modules
statements
expressions
and
objects
as
follows
programs
are
composed
of
modules
modules
contain
statements
statements
contain
expressions
expressions
create
and
process
objects
the
discussion
of
modules
in
chapter
introduced
the
highest
level
of
this
hierarchy
this
part
s
chapters
begin
at
the
bottom
exploring
both
built
in
objects
and
the
expressions
you
can
code
to
use
them
why
use
built
in
types
if
you
ve
used
lower
level
languages
such
as
c
or
c
you
know
that
much
of
your
work
centers
on
implementing
objects
also
known
as
data
structures
to
represent
the
components
in
your
application
s
domain
you
need
to
lay
out
memory
structures
manage
memory
allocation
implement
search
and
access
routines
and
so
on
these
chores
are
about
as
tedious
and
error
prone
as
they
sound
and
they
usually
distract
from
your
program
s
real
goals
in
typical
python
programs
most
of
this
grunt
work
goes
away
because
python
provides
powerful
object
types
as
an
intrinsic
part
of
the
language
there
s
usually
no
need
to
code
object
implementations
before
you
start
solving
problems
in
fact
unless
you
have
a
need
for
special
processing
that
built
in
types
don
t
provide
you
re
almost
always
better
off
using
a
built
in
object
instead
of
implementing
your
own
here
are
some
reasons
why
built
in
objects
make
programs
easy
to
write
for
simple
tasks
built
in
types
are
often
all
you
need
to
represent
the
structure
of
problem
domains
because
you
get
powerful
tools
such
as
collections
lists
and
search
tables
dictionaries
for
free
you
can
use
them
immediately
you
can
get
a
lot
of
work
done
with
python
s
builtin
object
types
alone
built
in
objects
are
components
of
extensions
for
more
complex
tasks
you
may
need
to
provide
your
own
objects
using
python
classes
or
c
language
interfaces
but
as
you
ll
see
in
later
parts
of
this
book
objects
implemented
manually
are
often
built
on
top
of
built
in
types
such
as
lists
and
dictionaries
for
instance
a
stack
data
structure
may
be
implemented
as
a
class
that
manages
or
customizes
a
built
in
list
built
in
objects
are
often
more
efficient
than
custom
data
structures
python
s
built
in
types
employ
already
optimized
data
structure
algorithms
that
are
implemented
in
c
for
speed
although
you
can
write
similar
object
types
on
your
own
you
ll
usually
be
hard
pressed
to
get
the
level
of
performance
built
in
object
types
provide
built
in
objects
are
a
standard
part
of
the
language
in
some
ways
python
borrows
both
from
languages
that
rely
on
built
in
tools
e
g
lisp
and
languages
that
rely
on
the
programmer
to
provide
tool
implementations
or
frameworks
of
their
own
e
g
c
although
you
can
implement
unique
object
types
in
python
you
don
t
need
to
do
so
just
to
get
started
moreover
because
python
s
built
ins
are
standard
they
re
always
the
same
proprietary
frameworks
on
the
other
hand
tend
to
differ
from
site
to
site
in
other
words
not
only
do
built
in
object
types
make
programming
easier
but
they
re
also
more
powerful
and
efficient
than
most
of
what
can
be
created
from
scratch
regardless
of
whether
you
implement
new
object
types
built
in
objects
form
the
core
of
every
python
program
chapter
introducing
python
object
types
python
s
core
data
types
table
previews
python
s
built
in
object
types
and
some
of
the
syntax
used
to
code
their
literals
that
is
the
expressions
that
generate
these
objects
some
of
these
types
will
probably
seem
familiar
if
you
ve
used
other
languages
for
instance
numbers
and
strings
represent
numeric
and
textual
values
respectively
and
files
provide
an
interface
for
processing
files
stored
on
your
computer
table
built
in
objects
preview
object
type
example
literals
creation
numbers
j
decimal
fraction
strings
spam
guido
s
b
a
x
c
lists
three
dictionaries
food
spam
taste
yum
tuples
spam
u
files
myfile
open
eggs
r
sets
set
abc
a
b
c
other
core
types
booleans
types
none
program
unit
types
functions
modules
classes
part
iv
part
v
part
vi
implementation
related
types
compiled
code
stack
tracebacks
part
iv
part
vii
table
isn
t
really
complete
because
everything
we
process
in
python
programs
is
a
kind
of
object
for
instance
when
we
perform
text
pattern
matching
in
python
we
create
pattern
objects
and
when
we
perform
network
scripting
we
use
socket
objects
these
other
kinds
of
objects
are
generally
created
by
importing
and
using
modules
and
have
behavior
all
their
own
as
we
ll
see
in
later
parts
of
the
book
program
units
such
as
functions
modules
and
classes
are
objects
in
python
too
they
are
created
with
statements
and
expressions
such
as
def
class
import
and
lambda
and
may
be
passed
around
scripts
freely
stored
within
other
objects
and
so
on
python
also
provides
a
set
of
implementation
related
types
such
as
compiled
code
objects
which
are
generally
of
interest
to
tool
builders
more
than
application
developers
these
are
also
discussed
in
later
parts
of
this
text
we
usually
call
the
other
object
types
in
table
core
data
types
though
because
they
are
effectively
built
into
the
python
language
that
is
there
is
specific
expression
syntax
for
generating
most
of
them
for
instance
when
you
run
the
following
code
spam
in
this
book
the
term
literal
simply
means
an
expression
whose
syntax
generates
an
object
sometimes
also
called
a
constant
note
that
the
term
constant
does
not
imply
objects
or
variables
that
can
never
be
changed
i
e
this
term
is
unrelated
to
c
s
const
or
python
s
immutable
a
topic
explored
in
the
section
immutability
on
page
why
use
built
in
types
you
are
technically
speaking
running
a
literal
expression
that
generates
and
returns
a
new
string
object
there
is
specific
python
language
syntax
to
make
this
object
similarly
an
expression
wrapped
in
square
brackets
makes
a
list
one
in
curly
braces
makes
a
dictionary
and
so
on
even
though
as
we
ll
see
there
are
no
type
declarations
in
python
the
syntax
of
the
expressions
you
run
determines
the
types
of
objects
you
create
and
use
in
fact
object
generation
expressions
like
those
in
table
are
generally
where
types
originate
in
the
python
language
just
as
importantly
once
you
create
an
object
you
bind
its
operation
set
for
all
time
you
can
perform
only
string
operations
on
a
string
and
list
operations
on
a
list
as
you
ll
learn
python
is
dynamically
typed
it
keeps
track
of
types
for
you
automatically
instead
of
requiring
declaration
code
but
it
is
also
strongly
typed
you
can
perform
on
an
object
only
operations
that
are
valid
for
its
type
functionally
the
object
types
in
table
are
more
general
and
powerful
than
what
you
may
be
accustomed
to
for
instance
you
ll
find
that
lists
and
dictionaries
alone
are
powerful
data
representation
tools
that
obviate
most
of
the
work
you
do
to
support
collections
and
searching
in
lower
level
languages
in
short
lists
provide
ordered
collections
of
other
objects
while
dictionaries
store
objects
by
key
both
lists
and
dictionaries
may
be
nested
can
grow
and
shrink
on
demand
and
may
contain
objects
of
any
type
we
ll
study
each
of
the
object
types
in
table
in
detail
in
upcoming
chapters
before
digging
into
the
details
though
let
s
begin
by
taking
a
quick
look
at
python
s
core
objects
in
action
the
rest
of
this
chapter
provides
a
preview
of
the
operations
we
ll
explore
in
more
depth
in
the
chapters
that
follow
don
t
expect
to
find
the
full
story
here
the
goal
of
this
chapter
is
just
to
whet
your
appetite
and
introduce
some
key
ideas
still
the
best
way
to
get
started
is
to
get
started
so
let
s
jump
right
into
some
real
code
numbers
if
you
ve
done
any
programming
or
scripting
in
the
past
some
of
the
object
types
in
table
will
probably
seem
familiar
even
if
you
haven
t
numbers
are
fairly
straightforward
python
s
core
objects
set
includes
the
usual
suspects
integers
numbers
without
a
fractional
part
floating
point
numbers
roughly
numbers
with
a
decimal
point
in
them
and
more
exotic
numeric
types
complex
numbers
with
imaginary
parts
fixed
precision
decimals
rational
fractions
with
numerator
and
denominator
and
fullfeatured
sets
although
it
offers
some
fancier
options
python
s
basic
number
types
are
well
basic
numbers
in
python
support
the
normal
mathematical
operations
for
instance
the
plus
sign
performs
addition
a
star
is
used
for
multiplication
and
two
stars
are
used
for
exponentiation
chapter
introducing
python
object
types
integer
addition
floating
point
multiplication
to
the
power
notice
the
last
result
here
python
s
integer
type
automatically
provides
extra
precision
for
large
numbers
like
this
when
needed
in
a
separate
long
integer
type
handles
numbers
too
large
for
the
normal
integer
type
in
similar
ways
you
can
for
instance
compute
to
the
power
as
an
integer
in
python
but
you
probably
shouldn
t
try
to
print
the
result
with
more
than
digits
you
may
be
waiting
awhile
len
str
how
many
digits
in
a
really
big
number
once
you
start
experimenting
with
floating
point
numbers
you
re
likely
to
stumble
across
something
that
may
look
a
bit
odd
on
first
glance
print
repr
as
code
str
user
friendly
the
first
result
isn
t
a
bug
it
s
a
display
issue
it
turns
out
that
there
are
two
ways
to
print
every
object
with
full
precision
as
in
the
first
result
shown
here
and
in
a
userfriendly
form
as
in
the
second
formally
the
first
form
is
known
as
an
object
s
ascode
repr
and
the
second
is
its
user
friendly
str
the
difference
can
matter
when
we
step
up
to
using
classes
for
now
if
something
looks
odd
try
showing
it
with
a
print
built
in
call
statement
besides
expressions
there
are
a
handful
of
useful
numeric
modules
that
ship
with
python
modules
are
just
packages
of
additional
tools
that
we
import
to
use
import
math
math
pi
math
sqrt
the
math
module
contains
more
advanced
numeric
tools
as
functions
while
the
random
module
performs
random
number
generation
and
random
selections
here
from
a
python
list
introduced
later
in
this
chapter
import
random
random
random
random
choice
python
also
includes
more
exotic
numeric
objects
such
as
complex
fixed
precision
and
rational
numbers
as
well
as
sets
and
booleans
and
the
third
party
open
source
numbers
extension
domain
has
even
more
e
g
matrixes
and
vectors
we
ll
defer
discussion
of
these
types
until
later
in
the
book
so
far
we
ve
been
using
python
much
like
a
simple
calculator
to
do
better
justice
to
its
built
in
types
let
s
move
on
to
explore
strings
strings
strings
are
used
to
record
textual
information
as
well
as
arbitrary
collections
of
bytes
they
are
our
first
example
of
what
we
call
a
sequence
in
python
that
is
a
positionally
ordered
collection
of
other
objects
sequences
maintain
a
left
to
right
order
among
the
items
they
contain
their
items
are
stored
and
fetched
by
their
relative
position
strictly
speaking
strings
are
sequences
of
one
character
strings
other
types
of
sequences
include
lists
and
tuples
covered
later
sequence
operations
as
sequences
strings
support
operations
that
assume
a
positional
ordering
among
items
for
example
if
we
have
a
four
character
string
we
can
verify
its
length
with
the
built
in
len
function
and
fetch
its
components
with
indexing
expressions
s
p
s
spam
len
s
length
s
the
first
item
in
s
indexing
by
zero
based
position
s
the
second
item
from
the
left
in
python
indexes
are
coded
as
offsets
from
the
front
and
so
start
from
the
first
item
is
at
index
the
second
is
at
index
and
so
on
notice
how
we
assign
the
string
to
a
variable
named
s
here
we
ll
go
into
detail
on
how
this
works
later
especially
in
chapter
but
python
variables
never
need
to
be
declared
ahead
of
time
a
variable
is
created
when
you
assign
it
a
value
may
be
assigned
any
type
of
object
and
is
replaced
with
its
value
when
it
shows
up
in
an
expression
it
must
also
have
been
previously
assigned
by
the
time
you
use
its
value
for
the
purposes
of
this
chapter
it
s
enough
to
know
that
we
need
to
assign
an
object
to
a
variable
in
order
to
save
it
for
later
use
in
python
we
can
also
index
backward
from
the
end
positive
indexes
count
from
the
left
and
negative
indexes
count
back
from
the
right
s
m
s
a
the
last
item
from
the
end
in
s
the
second
to
last
item
from
the
end
chapter
introducing
python
object
types
formally
a
negative
index
is
simply
added
to
the
string
s
size
so
the
following
two
operations
are
equivalent
though
the
first
is
easier
to
code
and
less
easy
to
get
wrong
s
m
s
len
s
m
the
last
item
in
s
negative
indexing
the
hard
way
notice
that
we
can
use
an
arbitrary
expression
in
the
square
brackets
not
just
a
hardcoded
number
literal
anywhere
that
python
expects
a
value
we
can
use
a
literal
a
variable
or
any
expression
python
s
syntax
is
completely
general
this
way
in
addition
to
simple
positional
indexing
sequences
also
support
a
more
general
form
of
indexing
known
as
slicing
which
is
a
way
to
extract
an
entire
section
slice
in
a
single
step
for
example
s
spam
s
pa
a
character
string
slice
of
s
from
offsets
through
not
probably
the
easiest
way
to
think
of
slices
is
that
they
are
a
way
to
extract
an
entire
column
from
a
string
in
a
single
step
their
general
form
x
i
j
means
give
me
everything
in
x
from
offset
i
up
to
but
not
including
offset
j
the
result
is
returned
in
a
new
object
the
second
of
the
preceding
operations
for
instance
gives
us
all
the
characters
in
string
s
from
offsets
through
that
is
as
a
new
string
the
effect
is
to
slice
or
parse
out
the
two
characters
in
the
middle
in
a
slice
the
left
bound
defaults
to
zero
and
the
right
bound
defaults
to
the
length
of
the
sequence
being
sliced
this
leads
to
some
common
usage
variations
s
pam
s
spam
s
spa
s
spa
s
spa
s
spam
everything
past
the
first
len
s
s
itself
hasn
t
changed
everything
but
the
last
same
as
s
everything
but
the
last
again
but
simpler
all
of
s
as
a
top
level
copy
len
s
note
how
negative
offsets
can
be
used
to
give
bounds
for
slices
too
and
how
the
last
operation
effectively
copies
the
entire
string
as
you
ll
learn
later
there
is
no
reason
to
copy
a
string
but
this
form
can
be
useful
for
sequences
like
lists
finally
as
sequences
strings
also
support
concatenation
with
the
plus
sign
joining
two
strings
into
a
new
string
and
repetition
making
a
new
string
by
repeating
another
s
spam
s
xyz
concatenation
strings
spamxyz
s
s
is
unchanged
spam
s
repetition
spamspamspamspamspamspamspamspam
notice
that
the
plus
sign
means
different
things
for
different
objects
addition
for
numbers
and
concatenation
for
strings
this
is
a
general
property
of
python
that
we
ll
call
polymorphism
later
in
the
book
in
sum
the
meaning
of
an
operation
depends
on
the
objects
being
operated
on
as
you
ll
see
when
we
study
dynamic
typing
this
polymorphism
property
accounts
for
much
of
the
conciseness
and
flexibility
of
python
code
because
types
aren
t
constrained
a
python
coded
operation
can
normally
work
on
many
different
types
of
objects
automatically
as
long
as
they
support
a
compatible
interface
like
the
operation
here
this
turns
out
to
be
a
huge
idea
in
python
you
ll
learn
more
about
it
later
on
our
tour
immutability
notice
that
in
the
prior
examples
we
were
not
changing
the
original
string
with
any
of
the
operations
we
ran
on
it
every
string
operation
is
defined
to
produce
a
new
string
as
its
result
because
strings
are
immutable
in
python
they
cannot
be
changed
in
place
after
they
are
created
for
example
you
can
t
change
a
string
by
assigning
to
one
of
its
positions
but
you
can
always
build
a
new
one
and
assign
it
to
the
same
name
because
python
cleans
up
old
objects
as
you
go
as
you
ll
see
later
this
isn
t
as
inefficient
as
it
may
sound
s
spam
s
z
immutable
objects
cannot
be
changed
error
text
omitted
typeerror
str
object
does
not
support
item
assignment
s
z
s
s
zpam
but
we
can
run
expressions
to
make
new
objects
every
object
in
python
is
classified
as
either
immutable
unchangeable
or
not
in
terms
of
the
core
types
numbers
strings
and
tuples
are
immutable
lists
and
dictionaries
are
not
they
can
be
changed
in
place
freely
among
other
things
immutability
can
be
used
to
guarantee
that
an
object
remains
constant
throughout
your
program
type
specific
methods
every
string
operation
we
ve
studied
so
far
is
really
a
sequence
operation
that
is
these
operations
will
work
on
other
sequences
in
python
as
well
including
lists
and
tuples
in
addition
to
generic
sequence
operations
though
strings
also
have
operations
all
their
own
available
as
methods
functions
attached
to
the
object
which
are
triggered
with
a
call
expression
chapter
introducing
python
object
types
for
example
the
string
find
method
is
the
basic
substring
search
operation
it
returns
the
offset
of
the
passed
in
substring
or
if
it
is
not
present
and
the
string
replace
method
performs
global
searches
and
replacements
s
find
pa
s
spam
s
replace
pa
xyz
sxyzm
s
spam
find
the
offset
of
a
substring
replace
occurrences
of
a
substring
with
another
again
despite
the
names
of
these
string
methods
we
are
not
changing
the
original
strings
here
but
creating
new
strings
as
the
results
because
strings
are
immutable
we
have
to
do
it
this
way
string
methods
are
the
first
line
of
text
processing
tools
in
python
other
methods
split
a
string
into
substrings
on
a
delimiter
handy
as
a
simple
form
of
parsing
perform
case
conversions
test
the
content
of
the
string
digits
letters
and
so
on
and
strip
whitespace
characters
off
the
ends
of
the
string
line
aaa
bbb
ccccc
dd
line
split
split
on
a
delimiter
into
a
list
of
substrings
aaa
bbb
ccccc
dd
s
spam
s
upper
upper
and
lowercase
conversions
spam
s
isalpha
true
content
tests
isalpha
isdigit
etc
line
aaa
bbb
ccccc
dd
n
line
line
rstrip
remove
whitespace
characters
on
the
right
side
line
aaa
bbb
ccccc
dd
strings
also
support
an
advanced
substitution
operation
known
as
formatting
available
as
both
an
expression
the
original
and
a
string
method
call
new
in
and
s
eggs
and
s
spam
spam
spam
eggs
and
spam
formatting
expression
all
eggs
and
format
spam
spam
spam
eggs
and
spam
formatting
method
one
note
here
although
sequence
operations
are
generic
methods
are
not
although
some
types
share
some
method
names
string
method
operations
generally
work
only
on
strings
and
nothing
else
as
a
rule
of
thumb
python
s
toolset
is
layered
generic
operations
that
span
multiple
types
show
up
as
built
in
functions
or
expressions
e
g
len
x
x
but
type
specific
operations
are
method
calls
e
g
astring
upper
finding
the
tools
you
need
among
all
these
categories
will
become
more
natural
as
you
use
python
more
but
the
next
section
gives
a
few
tips
you
can
use
right
now
strings
getting
help
the
methods
introduced
in
the
prior
section
are
a
representative
but
small
sample
of
what
is
available
for
string
objects
in
general
this
book
is
not
exhaustive
in
its
look
at
object
methods
for
more
details
you
can
always
call
the
built
in
dir
function
which
returns
a
list
of
all
the
attributes
available
for
a
given
object
because
methods
are
function
attributes
they
will
show
up
in
this
list
assuming
s
is
still
the
string
here
are
its
attributes
on
python
python
varies
slightly
dir
s
add
class
contains
delattr
doc
eq
format
ge
getattribute
getitem
getnewargs
gt
hash
init
iter
le
len
lt
mod
mul
ne
new
reduce
reduce
ex
repr
rmod
rmul
setattr
sizeof
str
subclasshook
formatter
field
name
split
formatter
parser
capitalize
center
count
encode
endswith
expandtabs
find
format
index
isalnum
isalpha
isdecimal
isdigit
isidentifier
islower
isnumeric
isprintable
isspace
istitle
isupper
join
ljust
lower
lstrip
maketrans
partition
replace
rfind
rindex
rjust
rpartition
rsplit
rstrip
split
splitlines
startswith
strip
swapcase
title
translate
upper
zfill
you
probably
won
t
care
about
the
names
with
underscores
in
this
list
until
later
in
the
book
when
we
study
operator
overloading
in
classes
they
represent
the
implementation
of
the
string
object
and
are
available
to
support
customization
in
general
leading
and
trailing
double
underscores
is
the
naming
pattern
python
uses
for
implementation
details
the
names
without
the
underscores
in
this
list
are
the
callable
methods
on
string
objects
the
dir
function
simply
gives
the
methods
names
to
ask
what
they
do
you
can
pass
them
to
the
help
function
help
s
replace
help
on
built
in
function
replace
replace
s
replace
old
new
count
str
return
a
copy
of
s
with
all
occurrences
of
substring
old
replaced
by
new
if
the
optional
argument
count
is
given
only
the
first
count
occurrences
are
replaced
help
is
one
of
a
handful
of
interfaces
to
a
system
of
code
that
ships
with
python
known
as
pydoc
a
tool
for
extracting
documentation
from
objects
later
in
the
book
you
ll
see
that
pydoc
can
also
render
its
reports
in
html
format
you
can
also
ask
for
help
on
an
entire
string
e
g
help
s
but
you
may
get
more
help
than
you
want
to
see
i
e
information
about
every
string
method
it
s
generally
better
to
ask
about
a
specific
method
chapter
introducing
python
object
types
for
more
details
you
can
also
consult
python
s
standard
library
reference
manual
or
commercially
published
reference
books
but
dir
and
help
are
the
first
line
of
documentation
in
python
other
ways
to
code
strings
so
far
we
ve
looked
at
the
string
object
s
sequence
operations
and
type
specific
methods
python
also
provides
a
variety
of
ways
for
us
to
code
strings
which
we
ll
explore
in
greater
depth
later
for
instance
special
characters
can
be
represented
as
backslash
escape
sequences
s
a
nb
tc
len
s
n
is
end
of
line
t
is
tab
each
stands
for
just
one
character
ord
n
n
is
a
byte
with
the
binary
value
in
ascii
s
a
b
c
len
s
a
binary
zero
byte
does
not
terminate
string
python
allows
strings
to
be
enclosed
in
single
or
double
quote
characters
they
mean
the
same
thing
it
also
allows
multiline
string
literals
enclosed
in
triple
quotes
single
or
double
when
this
form
is
used
all
the
lines
are
concatenated
together
and
endof
line
characters
are
added
where
line
breaks
appear
this
is
a
minor
syntactic
convenience
but
it
s
useful
for
embedding
things
like
html
and
xml
code
in
a
python
script
msg
aaaaaaaaaaaaa
bbb
bbbbbbbbbb
bbbbbbb
bbbb
cccccccccccccc
msg
naaaaaaaaaaaaa
nbbb
bbbbbbbbbb
bbbbbbb
bbbb
ncccccccccccccc
python
also
supports
a
raw
string
literal
that
turns
off
the
backslash
escape
mechanism
such
string
literals
start
with
the
letter
r
as
well
as
unicode
string
support
that
supports
internationalization
in
the
basic
str
string
type
handles
unicode
too
which
makes
sense
given
that
ascii
text
is
a
simple
kind
of
unicode
and
a
bytes
type
represents
raw
byte
strings
in
unicode
is
a
separate
type
and
str
handles
both
bit
strings
and
binary
data
files
are
also
changed
in
to
return
and
accept
str
for
text
and
bytes
for
binary
data
we
ll
meet
all
these
special
string
forms
in
later
chapters
pattern
matching
one
point
worth
noting
before
we
move
on
is
that
none
of
the
string
object
s
methods
support
pattern
based
text
processing
text
pattern
matching
is
an
advanced
tool
outside
this
book
s
scope
but
readers
with
backgrounds
in
other
scripting
languages
may
be
interested
to
know
that
to
do
pattern
matching
in
python
we
import
a
module
called
strings
re
this
module
has
analogous
calls
for
searching
splitting
and
replacement
but
be
cause
we
can
use
patterns
to
specify
substrings
we
can
be
much
more
general
import
re
match
re
match
hello
t
world
hello
match
group
python
python
world
this
example
searches
for
a
substring
that
begins
with
the
word
hello
followed
by
zero
or
more
tabs
or
spaces
followed
by
arbitrary
characters
to
be
saved
as
a
matched
group
terminated
by
the
word
world
if
such
a
substring
is
found
portions
of
the
substring
matched
by
parts
of
the
pattern
enclosed
in
parentheses
are
available
as
groups
the
following
pattern
for
example
picks
out
three
groups
separated
by
slashes
match
re
match
usr
home
lumberjack
match
groups
usr
home
lumberjack
pattern
matching
is
a
fairly
advanced
text
processing
tool
by
itself
but
there
is
also
support
in
python
for
even
more
advanced
language
processing
including
natural
language
processing
i
ve
already
said
enough
about
strings
for
this
tutorial
though
so
let
s
move
on
to
the
next
type
lists
the
python
list
object
is
the
most
general
sequence
provided
by
the
language
lists
are
positionally
ordered
collections
of
arbitrarily
typed
objects
and
they
have
no
fixed
size
they
are
also
mutable
unlike
strings
lists
can
be
modified
in
place
by
assignment
to
offsets
as
well
as
a
variety
of
list
method
calls
sequence
operations
because
they
are
sequences
lists
support
all
the
sequence
operations
we
discussed
for
strings
the
only
difference
is
that
the
results
are
usually
lists
instead
of
strings
for
instance
given
a
three
item
list
l
spam
len
l
a
list
of
three
different
type
objects
number
of
items
in
the
list
we
can
index
slice
and
so
on
just
as
for
strings
l
indexing
by
position
l
spam
slicing
a
list
returns
a
new
list
l
spam
concatenation
makes
a
new
list
too
chapter
introducing
python
object
types
l
spam
we
re
not
changing
the
original
list
type
specific
operations
python
s
lists
are
related
to
arrays
in
other
languages
but
they
tend
to
be
more
powerful
for
one
thing
they
have
no
fixed
type
constraint
the
list
we
just
looked
at
for
example
contains
three
objects
of
completely
different
types
an
integer
a
string
and
a
floating
point
number
further
lists
have
no
fixed
size
that
is
they
can
grow
and
shrink
on
demand
in
response
to
list
specific
operations
l
append
ni
l
spam
ni
growing
add
object
at
end
of
list
l
pop
shrinking
delete
an
item
in
the
middle
l
spam
ni
del
l
deletes
from
a
list
too
here
the
list
append
method
expands
the
list
s
size
and
inserts
an
item
at
the
end
the
pop
method
or
an
equivalent
del
statement
then
removes
an
item
at
a
given
offset
causing
the
list
to
shrink
other
list
methods
insert
an
item
at
an
arbitrary
position
insert
remove
a
given
item
by
value
remove
and
so
on
because
lists
are
mutable
most
list
methods
also
change
the
list
object
in
place
instead
of
creating
a
new
one
m
bb
aa
cc
m
sort
m
aa
bb
cc
m
reverse
m
cc
bb
aa
the
list
sort
method
here
for
example
orders
the
list
in
ascending
fashion
by
default
and
reverse
reverses
it
in
both
cases
the
methods
modify
the
list
directly
bounds
checking
although
lists
have
no
fixed
size
python
still
doesn
t
allow
us
to
reference
items
that
are
not
present
indexing
off
the
end
of
a
list
is
always
a
mistake
but
so
is
assigning
off
the
end
l
spam
ni
l
error
text
omitted
indexerror
list
index
out
of
range
lists
l
error
text
omitted
indexerror
list
assignment
index
out
of
range
this
is
intentional
as
it
s
usually
an
error
to
try
to
assign
off
the
end
of
a
list
and
a
particularly
nasty
one
in
the
c
language
which
doesn
t
do
as
much
error
checking
as
python
rather
than
silently
growing
the
list
in
response
python
reports
an
error
to
grow
a
list
we
call
list
methods
such
as
append
instead
nesting
one
nice
feature
of
python
s
core
data
types
is
that
they
support
arbitrary
nesting
we
can
nest
them
in
any
combination
and
as
deeply
as
we
like
for
example
we
can
have
a
list
that
contains
a
dictionary
which
contains
another
list
and
so
on
one
immediate
application
of
this
feature
is
to
represent
matrixes
or
multidimensional
arrays
in
python
a
list
with
nested
lists
will
do
the
job
for
basic
applications
m
m
a
matrix
as
nested
lists
code
can
span
lines
if
bracketed
here
we
ve
coded
a
list
that
contains
three
other
lists
the
effect
is
to
represent
a
matrix
of
numbers
such
a
structure
can
be
accessed
in
a
variety
of
ways
m
get
row
m
get
row
then
get
item
within
the
row
the
first
operation
here
fetches
the
entire
second
row
and
the
second
grabs
the
third
item
within
that
row
stringing
together
index
operations
takes
us
deeper
and
deeper
into
our
nested
object
structure
comprehensions
in
addition
to
sequence
operations
and
list
methods
python
includes
a
more
advanced
operation
known
as
a
list
comprehension
expression
which
turns
out
to
be
a
powerful
way
to
process
structures
like
our
matrix
suppose
for
instance
that
we
need
to
extract
the
second
column
of
our
sample
matrix
it
s
easy
to
grab
rows
by
simple
indexing
this
matrix
structure
works
for
small
scale
tasks
but
for
more
serious
number
crunching
you
will
probably
want
to
use
one
of
the
numeric
extensions
to
python
such
as
the
open
source
numpy
system
such
tools
can
store
and
process
large
matrixes
much
more
efficiently
than
our
nested
list
structure
numpy
has
been
said
to
turn
python
into
the
equivalent
of
a
free
and
more
powerful
version
of
the
matlab
system
and
organizations
such
as
nasa
los
alamos
and
jpmorgan
chase
use
this
tool
for
scientific
and
financial
tasks
search
the
web
for
more
details
chapter
introducing
python
object
types
because
the
matrix
is
stored
by
rows
but
it
s
almost
as
easy
to
get
a
column
with
a
list
comprehension
col
row
for
row
in
m
col
collect
the
items
in
column
m
the
matrix
is
unchanged
list
comprehensions
derive
from
set
notation
they
are
a
way
to
build
a
new
list
by
running
an
expression
on
each
item
in
a
sequence
one
at
a
time
from
left
to
right
list
comprehensions
are
coded
in
square
brackets
to
tip
you
off
to
the
fact
that
they
make
a
list
and
are
composed
of
an
expression
and
a
looping
construct
that
share
a
variable
name
row
here
the
preceding
list
comprehension
means
basically
what
it
says
give
me
row
for
each
row
in
matrix
m
in
a
new
list
the
result
is
a
new
list
containing
column
of
the
matrix
list
comprehensions
can
be
more
complex
in
practice
row
for
row
in
m
add
to
each
item
in
column
row
for
row
in
m
if
row
filter
out
odd
items
the
first
operation
here
for
instance
adds
to
each
item
as
it
is
collected
and
the
second
uses
an
if
clause
to
filter
odd
numbers
out
of
the
result
using
the
modulus
expression
remainder
of
division
list
comprehensions
make
new
lists
of
results
but
they
can
be
used
to
iterate
over
any
iterable
object
here
for
instance
we
use
list
comprehensions
to
step
over
a
hardcoded
list
of
coordinates
and
a
string
diag
m
i
i
for
i
in
diag
collect
a
diagonal
from
matrix
doubles
c
for
c
in
spam
doubles
ss
pp
aa
mm
repeat
characters
in
a
string
list
comprehensions
and
relatives
like
the
map
and
filter
built
in
functions
are
a
bit
too
involved
for
me
to
say
more
about
them
here
the
main
point
of
this
brief
introduction
is
to
illustrate
that
python
includes
both
simple
and
advanced
tools
in
its
arsenal
list
comprehensions
are
an
optional
feature
but
they
tend
to
be
handy
in
practice
and
often
provide
a
substantial
processing
speed
advantage
they
also
work
on
any
type
that
is
a
sequence
in
python
as
well
as
some
types
that
are
not
you
ll
hear
much
more
about
them
later
in
this
book
as
a
preview
though
you
ll
find
that
in
recent
pythons
comprehension
syntax
in
parentheses
can
also
be
used
to
create
generators
that
produce
results
on
demand
the
sum
built
in
for
instance
sums
items
in
a
sequence
lists
g
sum
row
for
row
in
m
next
g
next
g
create
a
generator
of
row
sums
run
the
iteration
protocol
the
map
built
in
can
do
similar
work
by
generating
the
results
of
running
items
through
a
function
wrapping
it
in
list
forces
it
to
return
all
its
values
in
python
list
map
sum
m
map
sum
over
items
in
m
in
python
comprehension
syntax
can
also
be
used
to
create
sets
and
dictionaries
sum
row
for
row
in
m
create
a
set
of
row
sums
i
sum
m
i
for
i
in
range
creates
key
value
table
of
row
sums
in
fact
lists
sets
and
dictionaries
can
all
be
built
with
comprehensions
in
ord
x
for
x
in
spaam
ord
x
for
x
in
spaam
x
ord
x
for
x
in
spaam
a
p
s
m
list
of
character
ordinals
sets
remove
duplicates
dictionary
keys
are
unique
to
understand
objects
like
generators
sets
and
dictionaries
though
we
must
move
ahead
dictionaries
python
dictionaries
are
something
completely
different
monty
python
reference
intended
they
are
not
sequences
at
all
but
are
instead
known
as
mappings
mappings
are
also
collections
of
other
objects
but
they
store
objects
by
key
instead
of
by
relative
position
in
fact
mappings
don
t
maintain
any
reliable
left
to
right
order
they
simply
map
keys
to
associated
values
dictionaries
the
only
mapping
type
in
python
s
core
objects
set
are
also
mutable
they
may
be
changed
in
place
and
can
grow
and
shrink
on
demand
like
lists
mapping
operations
when
written
as
literals
dictionaries
are
coded
in
curly
braces
and
consist
of
a
series
of
key
value
pairs
dictionaries
are
useful
anytime
we
need
to
associate
a
set
of
values
with
keys
to
describe
the
properties
of
something
for
instance
as
an
example
consider
the
following
three
item
dictionary
with
keys
food
quantity
and
color
d
food
spam
quantity
color
pink
chapter
introducing
python
object
types
we
can
index
this
dictionary
by
key
to
fetch
and
change
the
keys
associated
values
the
dictionary
index
operation
uses
the
same
syntax
as
that
used
for
sequences
but
the
item
in
the
square
brackets
is
a
key
not
a
relative
position
d
food
spam
fetch
value
of
key
food
d
quantity
add
to
quantity
value
d
food
spam
color
pink
quantity
although
the
curly
braces
literal
form
does
see
use
it
is
perhaps
more
common
to
see
dictionaries
built
up
in
different
ways
the
following
code
for
example
starts
with
an
empty
dictionary
and
fills
it
out
one
key
at
a
time
unlike
out
of
bounds
assignments
in
lists
which
are
forbidden
assignments
to
new
dictionary
keys
create
those
keys
d
d
name
bob
d
job
dev
d
age
create
keys
by
assignment
d
age
job
dev
name
bob
print
d
name
bob
here
we
re
effectively
using
dictionary
keys
as
field
names
in
a
record
that
describes
someone
in
other
applications
dictionaries
can
also
be
used
to
replace
searching
operations
indexing
a
dictionary
by
key
is
often
the
fastest
way
to
code
a
search
in
python
nesting
revisited
in
the
prior
example
we
used
a
dictionary
to
describe
a
hypothetical
person
with
three
keys
suppose
though
that
the
information
is
more
complex
perhaps
we
need
to
record
a
first
name
and
a
last
name
along
with
multiple
job
titles
this
leads
to
another
application
of
python
s
object
nesting
in
action
the
following
dictionary
coded
all
at
once
as
a
literal
captures
more
structured
information
rec
name
first
bob
last
smith
job
dev
mgr
age
here
we
again
have
a
three
key
dictionary
at
the
top
keys
name
job
and
age
but
the
values
have
become
more
complex
a
nested
dictionary
for
the
name
to
support
multiple
parts
and
a
nested
list
for
the
job
to
support
multiple
roles
and
future
expansion
we
can
access
the
components
of
this
structure
much
as
we
did
for
our
matrix
earlier
but
this
time
some
of
our
indexes
are
dictionary
keys
not
list
offsets
dictionaries
rec
name
last
smith
first
bob
name
is
a
nested
dictionary
rec
name
last
smith
index
the
nested
dictionary
rec
job
dev
mgr
rec
job
mgr
job
is
a
nested
list
index
the
nested
list
rec
job
append
janitor
expand
bob
s
job
description
in
place
rec
age
job
dev
mgr
janitor
name
last
smith
first
bob
notice
how
the
last
operation
here
expands
the
nested
job
list
because
the
job
list
is
a
separate
piece
of
memory
from
the
dictionary
that
contains
it
it
can
grow
and
shrink
freely
object
memory
layout
will
be
discussed
further
later
in
this
book
the
real
reason
for
showing
you
this
example
is
to
demonstrate
the
flexibility
of
python
s
core
data
types
as
you
can
see
nesting
allows
us
to
build
up
complex
information
structures
directly
and
easily
building
a
similar
structure
in
a
low
level
language
like
c
would
be
tedious
and
require
much
more
code
we
would
have
to
lay
out
and
declare
structures
and
arrays
fill
out
values
link
everything
together
and
so
on
in
python
this
is
all
automatic
running
the
expression
creates
the
entire
nested
object
structure
for
us
in
fact
this
is
one
of
the
main
benefits
of
scripting
languages
like
python
just
as
importantly
in
a
lower
level
language
we
would
have
to
be
careful
to
clean
up
all
of
the
object
s
space
when
we
no
longer
need
it
in
python
when
we
lose
the
last
reference
to
the
object
by
assigning
its
variable
to
something
else
for
example
all
of
the
memory
space
occupied
by
that
object
s
structure
is
automatically
cleaned
up
for
us
rec
now
the
object
s
space
is
reclaimed
technically
speaking
python
has
a
feature
known
as
garbage
collection
that
cleans
up
unused
memory
as
your
program
runs
and
frees
you
from
having
to
manage
such
details
in
your
code
in
python
the
space
is
reclaimed
immediately
as
soon
as
the
last
reference
to
an
object
is
removed
we
ll
study
how
this
works
later
in
this
book
for
now
it
s
enough
to
know
that
you
can
use
objects
freely
without
worrying
about
creating
their
space
or
cleaning
up
as
you
go
keep
in
mind
that
the
rec
record
we
just
created
really
could
be
a
database
record
when
we
employ
python
s
object
persistence
system
an
easy
way
to
store
native
python
objects
in
files
or
access
by
key
databases
we
won
t
go
into
details
here
but
watch
for
discussion
of
python
s
pickle
and
shelve
modules
later
in
this
book
chapter
introducing
python
object
types
sorting
keys
for
loops
as
mappings
as
we
ve
already
seen
dictionaries
only
support
accessing
items
by
key
however
they
also
support
type
specific
operations
with
method
calls
that
are
useful
in
a
variety
of
common
use
cases
as
mentioned
earlier
because
dictionaries
are
not
sequences
they
don
t
maintain
any
dependable
left
to
right
order
this
means
that
if
we
make
a
dictionary
and
print
it
back
its
keys
may
come
back
in
a
different
order
than
that
in
which
we
typed
them
d
a
b
c
d
a
c
b
what
do
we
do
though
if
we
do
need
to
impose
an
ordering
on
a
dictionary
s
items
one
common
solution
is
to
grab
a
list
of
keys
with
the
dictionary
keys
method
sort
that
with
the
list
sort
method
and
then
step
through
the
result
with
a
python
for
loop
be
sure
to
press
the
enter
key
twice
after
coding
the
for
loop
below
as
explained
in
chapter
an
empty
line
means
go
at
the
interactive
prompt
and
the
prompt
changes
to
on
some
interfaces
ks
list
d
keys
ks
a
c
b
unordered
keys
list
a
list
in
view
in
use
list
ks
sort
ks
a
b
c
sorted
keys
list
for
key
in
ks
print
key
d
key
iterate
though
sorted
keys
press
enter
twice
here
a
b
c
this
is
a
three
step
process
although
as
we
ll
see
in
later
chapters
in
recent
versions
of
python
it
can
be
done
in
one
step
with
the
newer
sorted
built
in
function
the
sorted
call
returns
the
result
and
sorts
a
variety
of
object
types
in
this
case
sorting
dictionary
keys
automatically
d
a
c
b
for
key
in
sorted
d
print
key
d
key
a
b
c
besides
showcasing
dictionaries
this
use
case
serves
to
introduce
the
python
for
loop
the
for
loop
is
a
simple
and
efficient
way
to
step
through
all
the
items
in
a
sequence
dictionaries
and
run
a
block
of
code
for
each
item
in
turn
a
user
defined
loop
variable
key
here
is
used
to
reference
the
current
item
each
time
through
the
net
effect
in
our
example
is
to
print
the
unordered
dictionary
s
keys
and
values
in
sorted
key
order
the
for
loop
and
its
more
general
cousin
the
while
loop
are
the
main
ways
we
code
repetitive
tasks
as
statements
in
our
scripts
really
though
the
for
loop
like
its
relative
the
list
comprehension
which
we
met
earlier
is
a
sequence
operation
it
works
on
any
object
that
is
a
sequence
and
like
the
list
comprehension
even
on
some
things
that
are
not
here
for
example
it
is
stepping
across
the
characters
in
a
string
printing
the
uppercase
version
of
each
as
it
goes
for
c
in
spam
print
c
upper
s
p
a
m
python
s
while
loop
is
a
more
general
sort
of
looping
tool
not
limited
to
stepping
across
sequences
x
while
x
print
spam
x
x
spam
spam
spam
spam
spam
spam
spam
spam
spam
spam
we
ll
discuss
looping
statements
syntax
and
tools
in
depth
later
in
the
book
iteration
and
optimization
if
the
last
section
s
for
loop
looks
like
the
list
comprehension
expression
introduced
earlier
it
should
both
are
really
general
iteration
tools
in
fact
both
will
work
on
any
object
that
follows
the
iteration
protocol
a
pervasive
idea
in
python
that
essentially
means
a
physically
stored
sequence
in
memory
or
an
object
that
generates
one
item
at
a
time
in
the
context
of
an
iteration
operation
an
object
falls
into
the
latter
category
if
it
responds
to
the
iter
built
in
with
an
object
that
advances
in
response
to
next
the
generator
comprehension
expression
we
saw
earlier
is
such
an
object
i
ll
have
more
to
say
about
the
iteration
protocol
later
in
this
book
for
now
keep
in
mind
that
every
python
tool
that
scans
an
object
from
left
to
right
uses
the
iteration
protocol
this
is
why
the
sorted
call
used
in
the
prior
section
works
on
the
dictionary
directly
we
don
t
have
to
call
the
keys
method
to
get
a
sequence
because
dictionaries
are
iterable
objects
with
a
next
that
returns
successive
keys
chapter
introducing
python
object
types
this
also
means
that
any
list
comprehension
expression
such
as
this
one
which
computes
the
squares
of
a
list
of
numbers
squares
x
for
x
in
squares
can
always
be
coded
as
an
equivalent
for
loop
that
builds
the
result
list
manually
by
appending
as
it
goes
squares
for
x
in
squares
append
x
this
is
what
a
list
comprehension
does
both
run
the
iteration
protocol
internally
squares
the
list
comprehension
though
and
related
functional
programming
tools
like
map
and
filter
will
generally
run
faster
than
a
for
loop
today
perhaps
even
twice
as
fast
a
property
that
could
matter
in
your
programs
for
large
data
sets
having
said
that
though
i
should
point
out
that
performance
measures
are
tricky
business
in
python
because
it
optimizes
so
much
and
performance
can
vary
from
release
to
release
a
major
rule
of
thumb
in
python
is
to
code
for
simplicity
and
readability
first
and
worry
about
performance
later
after
your
program
is
working
and
after
you
ve
proved
that
there
is
a
genuine
performance
concern
more
often
than
not
your
code
will
be
quick
enough
as
it
is
if
you
do
need
to
tweak
code
for
performance
though
python
includes
tools
to
help
you
out
including
the
time
and
timeit
modules
and
the
profile
module
you
ll
find
more
on
these
later
in
this
book
and
in
the
python
manuals
missing
keys
if
tests
one
other
note
about
dictionaries
before
we
move
on
although
we
can
assign
to
a
new
key
to
expand
a
dictionary
fetching
a
nonexistent
key
is
still
a
mistake
d
a
c
b
d
e
d
a
c
b
e
assigning
new
keys
grows
dictionaries
d
f
error
text
omitted
keyerror
f
referencing
a
nonexistent
key
is
an
error
this
is
what
we
want
it
s
usually
a
programming
error
to
fetch
something
that
isn
t
really
there
but
in
some
generic
programs
we
can
t
always
know
what
keys
will
be
present
when
we
write
our
code
how
do
we
handle
such
cases
and
avoid
errors
one
trick
is
to
test
ahead
of
time
the
dictionary
in
membership
expression
allows
us
to
dictionaries
query
the
existence
of
a
key
and
branch
on
the
result
with
a
python
if
statement
as
with
the
for
be
sure
to
press
enter
twice
to
run
the
if
interactively
here
f
in
d
false
if
not
f
in
d
print
missing
missing
i
ll
have
much
more
to
say
about
the
if
statement
and
statement
syntax
in
general
later
in
this
book
but
the
form
we
re
using
here
is
straightforward
it
consists
of
the
word
if
followed
by
an
expression
that
is
interpreted
as
a
true
or
false
result
followed
by
a
block
of
code
to
run
if
the
test
is
true
in
its
full
form
the
if
statement
can
also
have
an
else
clause
for
a
default
case
and
one
or
more
elif
else
if
clauses
for
other
tests
it
s
the
main
selection
tool
in
python
and
it
s
the
way
we
code
logic
in
our
scripts
still
there
are
other
ways
to
create
dictionaries
and
avoid
accessing
nonexistent
keys
the
get
method
a
conditional
index
with
a
default
the
python
x
has
key
method
which
is
no
longer
available
in
the
try
statement
a
tool
we
ll
first
meet
in
chapter
that
catches
and
recovers
from
exceptions
altogether
and
the
if
else
expression
essentially
an
if
statement
squeezed
onto
a
single
line
here
are
a
few
examples
value
d
get
x
value
index
but
with
a
default
value
d
x
if
x
in
d
else
value
if
else
expression
form
we
ll
save
the
details
on
such
alternatives
until
a
later
chapter
for
now
let
s
move
on
to
tuples
tuples
the
tuple
object
pronounced
toople
or
tuhple
depending
on
who
you
ask
is
roughly
like
a
list
that
cannot
be
changed
tuples
are
sequences
like
lists
but
they
are
immutable
like
strings
syntactically
they
are
coded
in
parentheses
instead
of
square
brackets
and
they
support
arbitrary
types
arbitrary
nesting
and
the
usual
sequence
operations
t
len
t
a
item
tuple
length
t
concatenation
t
indexing
slicing
and
more
chapter
introducing
python
object
types
tuples
also
have
two
type
specific
callable
methods
in
python
but
not
nearly
as
many
as
lists
t
index
t
count
tuple
methods
appears
at
offset
appears
once
the
primary
distinction
for
tuples
is
that
they
cannot
be
changed
once
created
that
is
they
are
immutable
sequences
t
tuples
are
immutable
error
text
omitted
typeerror
tuple
object
does
not
support
item
assignment
like
lists
and
dictionaries
tuples
support
mixed
types
and
nesting
but
they
don
t
grow
and
shrink
because
they
are
immutable
t
spam
t
t
t
append
attributeerror
tuple
object
has
no
attribute
append
why
tuples
so
why
have
a
type
that
is
like
a
list
but
supports
fewer
operations
frankly
tuples
are
not
generally
used
as
often
as
lists
in
practice
but
their
immutability
is
the
whole
point
if
you
pass
a
collection
of
objects
around
your
program
as
a
list
it
can
be
changed
anywhere
if
you
use
a
tuple
it
cannot
that
is
tuples
provide
a
sort
of
integrity
constraint
that
is
convenient
in
programs
larger
than
those
we
ll
write
here
we
ll
talk
more
about
tuples
later
in
the
book
for
now
though
let
s
jump
ahead
to
our
last
major
core
type
the
file
files
file
objects
are
python
code
s
main
interface
to
external
files
on
your
computer
files
are
a
core
type
but
they
re
something
of
an
oddball
there
is
no
specific
literal
syntax
for
creating
them
rather
to
create
a
file
object
you
call
the
built
in
open
function
passing
in
an
external
filename
and
a
processing
mode
as
strings
for
example
to
create
a
text
output
file
you
would
pass
in
its
name
and
the
w
processing
mode
string
to
write
data
f
open
data
txt
w
f
write
hello
n
make
a
new
file
in
output
mode
write
strings
of
bytes
to
it
f
write
world
n
returns
number
of
bytes
written
in
python
f
close
close
to
flush
output
buffers
to
disk
files
this
creates
a
file
in
the
current
directory
and
writes
text
to
it
the
filename
can
be
a
full
directory
path
if
you
need
to
access
a
file
elsewhere
on
your
computer
to
read
back
what
you
just
wrote
reopen
the
file
in
r
processing
mode
for
reading
text
input
this
is
the
default
if
you
omit
the
mode
in
the
call
then
read
the
file
s
content
into
a
string
and
display
it
a
file
s
contents
are
always
a
string
in
your
script
regardless
of
the
type
of
data
the
file
contains
f
open
data
txt
text
f
read
text
hello
nworld
n
r
is
the
default
processing
mode
read
entire
file
into
a
string
print
text
hello
world
print
interprets
control
characters
text
split
hello
world
file
content
is
always
a
string
other
file
object
methods
support
additional
features
we
don
t
have
time
to
cover
here
for
instance
file
objects
provide
more
ways
of
reading
and
writing
read
accepts
an
optional
byte
size
readline
reads
one
line
at
a
time
and
so
on
as
well
as
other
tools
seek
moves
to
a
new
file
position
as
we
ll
see
later
though
the
best
way
to
read
a
file
today
is
to
not
read
it
at
all
files
provide
an
iterator
that
automatically
reads
line
by
line
in
for
loops
and
other
contexts
we
ll
meet
the
full
set
of
file
methods
later
in
this
book
but
if
you
want
a
quick
preview
now
run
a
dir
call
on
any
open
file
and
a
help
on
any
of
the
method
names
that
come
back
dir
f
many
names
omitted
buffer
close
closed
encoding
errors
fileno
flush
isatty
line
buffering
mode
name
newlines
read
readable
readline
readlines
seek
seekable
tell
truncate
writable
write
writelines
help
f
seek
try
it
and
see
later
in
the
book
we
ll
also
see
that
files
in
python
draw
a
sharp
distinction
between
text
and
binary
data
text
files
represent
content
as
strings
and
perform
unicode
encoding
and
decoding
automatically
while
binary
files
represent
content
as
a
special
bytes
string
type
and
allow
you
to
access
file
content
unaltered
data
open
data
bin
rb
read
data
b
x
x
x
x
spam
x
x
data
b
spam
chapter
introducing
python
object
types
open
binary
file
bytes
string
holds
binary
data
although
you
won
t
generally
need
to
care
about
this
distinction
if
you
deal
only
with
ascii
text
python
s
strings
and
files
are
an
asset
if
you
deal
with
internationalized
applications
or
byte
oriented
data
other
file
like
tools
the
open
function
is
the
workhorse
for
most
file
processing
you
will
do
in
python
for
more
advanced
tasks
though
python
comes
with
additional
file
like
tools
pipes
fifos
sockets
keyed
access
files
persistent
object
shelves
descriptor
based
files
relational
and
object
oriented
database
interfaces
and
more
descriptor
files
for
instance
support
file
locking
and
other
low
level
tools
and
sockets
provide
an
interface
for
networking
and
interprocess
communication
we
won
t
cover
many
of
these
topics
in
this
book
but
you
ll
find
them
useful
once
you
start
programming
python
in
earnest
other
core
types
beyond
the
core
types
we
ve
seen
so
far
there
are
others
that
may
or
may
not
qualify
for
membership
in
the
set
depending
on
how
broadly
it
is
defined
sets
for
example
are
a
recent
addition
to
the
language
that
are
neither
mappings
nor
sequences
rather
they
are
unordered
collections
of
unique
and
immutable
objects
sets
are
created
by
calling
the
built
in
set
function
or
using
new
set
literals
and
expressions
in
and
they
support
the
usual
mathematical
set
operations
the
choice
of
new
syntax
for
set
literals
in
makes
sense
since
sets
are
much
like
the
keys
of
a
valueless
dictionary
x
set
spam
make
a
set
out
of
a
sequence
in
and
y
h
a
m
make
a
set
with
new
set
literals
x
y
a
p
s
m
a
h
m
x
y
a
m
intersection
x
y
a
p
s
h
m
union
x
y
p
s
difference
x
for
x
in
set
comprehensions
in
in
addition
python
recently
grew
a
few
new
numeric
types
decimal
numbers
fixedprecision
floating
point
numbers
and
fraction
numbers
rational
numbers
with
both
a
numerator
and
a
denominator
both
can
be
used
to
work
around
the
limitations
and
inherent
inaccuracies
of
floating
point
math
floating
point
use
in
python
other
core
types
import
decimal
d
decimal
decimal
d
decimal
decimals
fixed
precision
decimal
getcontext
prec
decimal
decimal
decimal
decimal
decimal
from
fractions
import
fraction
f
fraction
f
fraction
f
fraction
fraction
fractions
numerator
denominator
python
also
comes
with
booleans
with
predefined
true
and
false
objects
that
are
essentially
just
the
integers
and
with
custom
display
logic
and
it
has
long
supported
a
special
placeholder
object
called
none
commonly
used
to
initialize
names
and
objects
false
true
bool
spam
true
booleans
x
none
none
placeholder
print
x
none
l
none
initialize
a
list
of
nones
l
none
none
none
none
none
none
none
none
none
none
none
none
none
none
none
none
none
none
none
none
a
list
of
nones
how
to
break
your
code
s
flexibility
i
ll
have
more
to
say
about
all
of
python
s
object
types
later
but
one
merits
special
treatment
here
the
type
object
returned
by
the
type
built
in
function
is
an
object
that
gives
the
type
of
another
object
its
result
differs
slightly
in
because
types
have
merged
with
classes
completely
something
we
ll
explore
in
the
context
of
new
style
classes
in
part
vi
assuming
l
is
still
the
list
of
the
prior
section
in
python
type
l
type
list
type
type
l
type
type
types
type
of
l
is
list
type
object
even
types
are
objects
in
python
type
l
class
list
chapter
introducing
python
object
types
types
are
classes
and
vice
versa
type
type
l
class
type
see
chapter
for
more
on
class
types
besides
allowing
you
to
explore
your
objects
interactively
the
practical
application
of
this
is
that
it
allows
code
to
check
the
types
of
the
objects
it
processes
in
fact
there
are
at
least
three
ways
to
do
so
in
a
python
script
if
type
l
type
print
yes
type
testing
if
you
must
yes
if
type
l
list
print
yes
using
the
type
name
yes
if
isinstance
l
list
print
yes
object
oriented
tests
yes
now
that
i
ve
shown
you
all
these
ways
to
do
type
testing
however
i
am
required
by
law
to
tell
you
that
doing
so
is
almost
always
the
wrong
thing
to
do
in
a
python
program
and
often
a
sign
of
an
ex
c
programmer
first
starting
to
use
python
the
reason
why
won
t
become
completely
clear
until
later
in
the
book
when
we
start
writing
larger
code
units
such
as
functions
but
it
s
a
perhaps
the
core
python
concept
by
checking
for
specific
types
in
your
code
you
effectively
break
its
flexibility
you
limit
it
to
working
on
just
one
type
without
such
tests
your
code
may
be
able
to
work
on
a
whole
range
of
types
this
is
related
to
the
idea
of
polymorphism
mentioned
earlier
and
it
stems
from
python
s
lack
of
type
declarations
as
you
ll
learn
in
python
we
code
to
object
interfaces
operations
supported
not
to
types
not
caring
about
specific
types
means
that
code
is
automatically
applicable
to
many
of
them
any
object
with
a
compatible
interface
will
work
regardless
of
its
specific
type
although
type
checking
is
supported
and
even
required
in
some
rare
cases
you
ll
see
that
it
s
not
usually
the
pythonic
way
of
thinking
in
fact
you
ll
find
that
polymorphism
is
probably
the
key
idea
behind
using
python
well
user
defined
classes
we
ll
study
object
oriented
programming
in
python
an
optional
but
powerful
feature
of
the
language
that
cuts
development
time
by
supporting
programming
by
customization
in
depth
later
in
this
book
in
abstract
terms
though
classes
define
new
types
of
objects
that
extend
the
core
set
so
they
merit
a
passing
glance
here
say
for
example
that
you
wish
to
have
a
type
of
object
that
models
employees
although
there
is
no
such
specific
core
type
in
python
the
following
user
defined
class
might
fit
the
bill
class
worker
def
init
self
name
pay
self
name
name
initialize
when
created
self
is
the
new
object
other
core
types
self
pay
pay
def
lastname
self
return
self
name
split
def
giveraise
self
percent
self
pay
percent
split
string
on
blanks
update
pay
in
place
this
class
defines
a
new
kind
of
object
that
will
have
name
and
pay
attributes
sometimes
called
state
information
as
well
as
two
bits
of
behavior
coded
as
functions
normally
called
methods
calling
the
class
like
a
function
generates
instances
of
our
new
type
and
the
class
s
methods
automatically
receive
the
instance
being
processed
by
a
given
method
call
in
the
self
argument
bob
worker
bob
smith
sue
worker
sue
jones
bob
lastname
smith
sue
lastname
jones
sue
giveraise
sue
pay
make
two
instances
each
has
name
and
pay
attrs
call
method
bob
is
self
sue
is
the
self
subject
updates
sue
s
pay
the
implied
self
object
is
why
we
call
this
an
object
oriented
model
there
is
always
an
implied
subject
in
functions
within
a
class
in
a
sense
though
the
class
based
type
simply
builds
on
and
uses
core
types
a
user
defined
worker
object
here
for
example
is
just
a
collection
of
a
string
and
a
number
name
and
pay
respectively
plus
functions
for
processing
those
two
built
in
objects
the
larger
story
of
classes
is
that
their
inheritance
mechanism
supports
software
hierarchies
that
lend
themselves
to
customization
by
extension
we
extend
software
by
writing
new
classes
not
by
changing
what
already
works
you
should
also
know
that
classes
are
an
optional
feature
of
python
and
simpler
built
in
types
such
as
lists
and
dictionaries
are
often
better
tools
than
user
coded
classes
this
is
all
well
beyond
the
bounds
of
our
introductory
object
type
tutorial
though
so
consider
this
just
a
preview
for
full
disclosure
on
user
defined
types
coded
with
classes
you
ll
have
to
read
on
to
part
vi
and
everything
else
as
mentioned
earlier
everything
you
can
process
in
a
python
script
is
a
type
of
object
so
our
object
type
tour
is
necessarily
incomplete
however
even
though
everything
in
python
is
an
object
only
those
types
of
objects
we
ve
met
so
far
are
considered
part
of
python
s
core
type
set
other
types
in
python
either
are
objects
related
to
program
execution
like
functions
modules
classes
and
compiled
code
which
we
will
study
later
or
are
implemented
by
imported
module
functions
not
language
syntax
the
latter
of
these
also
tend
to
have
application
specific
roles
text
patterns
database
interfaces
network
connections
and
so
on
chapter
introducing
python
object
types
moreover
keep
in
mind
that
the
objects
we
ve
met
here
are
objects
but
not
necessarily
object
oriented
a
concept
that
usually
requires
inheritance
and
the
python
class
statement
which
we
ll
meet
again
later
in
this
book
still
python
s
core
objects
are
the
workhorses
of
almost
every
python
script
you
re
likely
to
meet
and
they
usually
are
the
basis
of
larger
noncore
types
chapter
summary
and
that
s
a
wrap
for
our
concise
data
type
tour
this
chapter
has
offered
a
brief
introduction
to
python
s
core
object
types
and
the
sorts
of
operations
we
can
apply
to
them
we
ve
studied
generic
operations
that
work
on
many
object
types
sequence
operations
such
as
indexing
and
slicing
for
example
as
well
as
type
specific
operations
available
as
method
calls
for
instance
string
splits
and
list
appends
we
ve
also
defined
some
key
terms
such
as
immutability
sequences
and
polymorphism
along
the
way
we
ve
seen
that
python
s
core
object
types
are
more
flexible
and
powerful
than
what
is
available
in
lower
level
languages
such
as
c
for
instance
python
s
lists
and
dictionaries
obviate
most
of
the
work
you
do
to
support
collections
and
searching
in
lower
level
languages
lists
are
ordered
collections
of
other
objects
and
dictionaries
are
collections
of
other
objects
that
are
indexed
by
key
instead
of
by
position
both
dictionaries
and
lists
may
be
nested
can
grow
and
shrink
on
demand
and
may
contain
objects
of
any
type
moreover
their
space
is
automatically
cleaned
up
as
you
go
i
ve
skipped
most
of
the
details
here
in
order
to
provide
a
quick
tour
so
you
shouldn
t
expect
all
of
this
chapter
to
have
made
sense
yet
in
the
next
few
chapters
we
ll
start
to
dig
deeper
filling
in
details
of
python
s
core
object
types
that
were
omitted
here
so
you
can
gain
a
more
complete
understanding
we
ll
start
off
in
the
next
chapter
with
an
in
depth
look
at
python
numbers
first
though
another
quiz
to
review
test
your
knowledge
quiz
we
ll
explore
the
concepts
introduced
in
this
chapter
in
more
detail
in
upcoming
chapters
so
we
ll
just
cover
the
big
ideas
here
name
four
of
python
s
core
data
types
why
are
they
called
core
data
types
what
does
immutable
mean
and
which
three
of
python
s
core
types
are
considered
immutable
what
does
sequence
mean
and
which
three
types
fall
into
that
category
test
your
knowledge
quiz
what
does
mapping
mean
and
which
core
type
is
a
mapping
what
is
polymorphism
and
why
should
you
care
test
your
knowledge
answers
numbers
strings
lists
dictionaries
tuples
files
and
sets
are
generally
considered
to
be
the
core
object
data
types
types
none
and
booleans
are
sometimes
classified
this
way
as
well
there
are
multiple
number
types
integer
floating
point
complex
fraction
and
decimal
and
multiple
string
types
simple
strings
and
unicode
strings
in
python
x
and
text
strings
and
byte
strings
in
python
x
they
are
known
as
core
types
because
they
are
part
of
the
python
language
itself
and
are
always
available
to
create
other
objects
you
generally
must
call
functions
in
imported
modules
most
of
the
core
types
have
specific
syntax
for
generating
the
objects
spam
for
example
is
an
expression
that
makes
a
string
and
determines
the
set
of
operations
that
can
be
applied
to
it
because
of
this
core
types
are
hardwired
into
python
s
syntax
in
contrast
you
must
call
the
built
in
open
function
to
create
a
file
object
an
immutable
object
is
an
object
that
cannot
be
changed
after
it
is
created
numbers
strings
and
tuples
in
python
fall
into
this
category
while
you
cannot
change
an
immutable
object
in
place
you
can
always
make
a
new
one
by
running
an
expression
a
sequence
is
a
positionally
ordered
collection
of
objects
strings
lists
and
tuples
are
all
sequences
in
python
they
share
common
sequence
operations
such
as
indexing
concatenation
and
slicing
but
also
have
type
specific
method
calls
the
term
mapping
denotes
an
object
that
maps
keys
to
associated
values
python
s
dictionary
is
the
only
mapping
type
in
the
core
type
set
mappings
do
not
maintain
any
left
to
right
positional
ordering
they
support
access
to
data
stored
by
key
plus
type
specific
method
calls
polymorphism
means
that
the
meaning
of
an
operation
like
a
depends
on
the
objects
being
operated
on
this
turns
out
to
be
a
key
idea
perhaps
the
key
idea
behind
using
python
well
not
constraining
code
to
specific
types
makes
that
code
automatically
applicable
to
many
types
chapter
introducing
python
object
types
chapter
numeric
types
this
chapter
begins
our
in
depth
tour
of
the
python
language
in
python
data
takes
the
form
of
objects
either
built
in
objects
that
python
provides
or
objects
we
create
using
python
tools
and
other
languages
such
as
c
in
fact
objects
are
the
basis
of
every
python
program
you
will
ever
write
because
they
are
the
most
fundamental
notion
in
python
programming
objects
are
also
our
first
focus
in
this
book
in
the
preceding
chapter
we
took
a
quick
pass
over
python
s
core
object
types
although
essential
terms
were
introduced
in
that
chapter
we
avoided
covering
too
many
specifics
in
the
interest
of
space
here
we
ll
begin
a
more
careful
second
look
at
data
type
concepts
to
fill
in
details
we
glossed
over
earlier
let
s
get
started
by
exploring
our
first
data
type
category
python
s
numeric
types
numeric
type
basics
most
of
python
s
number
types
are
fairly
typical
and
will
probably
seem
familiar
if
you
ve
used
almost
any
other
programming
language
in
the
past
they
can
be
used
to
keep
track
of
your
bank
balance
the
distance
to
mars
the
number
of
visitors
to
your
website
and
just
about
any
other
numeric
quantity
in
python
numbers
are
not
really
a
single
object
type
but
a
category
of
similar
types
python
supports
the
usual
numeric
types
integers
and
floating
points
as
well
as
literals
for
creating
numbers
and
expressions
for
processing
them
in
addition
python
provides
more
advanced
numeric
programming
support
and
objects
for
more
advanced
work
a
complete
inventory
of
python
s
numeric
toolbox
includes
integers
and
floating
point
numbers
complex
numbers
fixed
precision
decimal
numbers
rational
fraction
numbers
sets
booleans
unlimited
integer
precision
a
variety
of
numeric
built
ins
and
modules
this
chapter
starts
with
basic
numbers
and
fundamentals
then
moves
on
to
explore
the
other
tools
in
this
list
before
we
jump
into
code
though
the
next
few
sections
get
us
started
with
a
brief
overview
of
how
we
write
and
process
numbers
in
our
scripts
numeric
literals
among
its
basic
types
python
provides
integers
positive
and
negative
whole
numbers
and
floating
point
numbers
numbers
with
a
fractional
part
sometimes
called
floats
for
economy
python
also
allows
us
to
write
integers
using
hexadecimal
octal
and
binary
literals
offers
a
complex
number
type
and
allows
integers
to
have
unlimited
precision
they
can
grow
to
have
as
many
digits
as
your
memory
space
allows
table
shows
what
python
s
numeric
types
look
like
when
written
out
in
a
program
as
literals
table
basic
numeric
literals
literal
interpretation
integers
unlimited
size
e
e
e
floating
point
numbers
x
ff
b
octal
hex
and
binary
literals
in
o
x
ff
b
octal
hex
and
binary
literals
in
j
j
j
complex
number
literals
in
general
python
s
numeric
type
literals
are
straightforward
to
write
but
a
few
coding
concepts
are
worth
highlighting
here
integer
and
floating
point
literals
integers
are
written
as
strings
of
decimal
digits
floating
point
numbers
have
a
decimal
point
and
or
an
optional
signed
exponent
introduced
by
an
e
or
e
and
followed
by
an
optional
sign
if
you
write
a
number
with
a
decimal
point
or
exponent
python
makes
it
a
floating
point
object
and
uses
floating
point
not
integer
math
when
the
object
is
used
in
an
expression
floating
point
numbers
are
implemented
as
c
doubles
and
therefore
get
as
much
precision
as
the
c
compiler
used
to
build
the
python
interpreter
gives
to
doubles
chapter
numeric
types
integers
in
python
normal
and
long
in
python
there
are
two
integer
types
normal
bits
and
long
unlimited
precision
and
an
integer
may
end
in
an
l
or
l
to
force
it
to
become
a
long
integer
because
integers
are
automatically
converted
to
long
integers
when
their
values
overflow
bits
you
never
need
to
type
the
letter
l
yourself
python
automatically
converts
up
to
long
integer
when
extra
precision
is
needed
integers
in
python
a
single
type
in
python
the
normal
and
long
integer
types
have
been
merged
there
is
only
integer
which
automatically
supports
the
unlimited
precision
of
python
s
separate
long
integer
type
because
of
this
integers
can
no
longer
be
coded
with
a
trailing
l
or
l
and
integers
never
print
with
this
character
either
apart
from
this
most
programs
are
unaffected
by
this
change
unless
they
do
type
testing
that
checks
for
long
integers
hexadecimal
octal
and
binary
literals
integers
may
be
coded
in
decimal
base
hexadecimal
base
octal
base
or
binary
base
hexadecimals
start
with
a
leading
x
or
x
followed
by
a
string
of
hexadecimal
digits
and
a
f
hex
digits
may
be
coded
in
lower
or
uppercase
octal
literals
start
with
a
leading
o
or
o
zero
and
lower
or
uppercase
letter
o
followed
by
a
string
of
digits
in
and
earlier
octal
literals
can
also
be
coded
with
just
a
leading
but
not
in
this
original
octal
form
is
too
easily
confused
with
decimal
and
is
replaced
by
the
new
o
format
binary
literals
new
in
and
begin
with
a
leading
b
or
b
followed
by
binary
digits
note
that
all
of
these
literals
produce
integer
objects
in
program
code
they
are
just
alternative
syntaxes
for
specifying
values
the
built
in
calls
hex
i
oct
i
and
bin
i
convert
an
integer
to
its
representation
string
in
these
three
bases
and
int
str
base
converts
a
runtime
string
to
an
integer
per
a
given
base
complex
numbers
python
complex
literals
are
written
as
realpart
imaginarypart
where
the
imaginarypart
is
terminated
with
a
j
or
j
the
realpart
is
technically
optional
so
the
imaginarypart
may
appear
on
its
own
internally
complex
numbers
are
implemented
as
pairs
of
floating
point
numbers
but
all
numeric
operations
perform
complex
math
when
applied
to
complex
numbers
complex
numbers
may
also
be
created
with
the
complex
real
imag
built
in
call
coding
other
numeric
types
as
we
ll
see
later
in
this
chapter
there
are
additional
more
advanced
number
types
not
included
in
table
some
of
these
are
created
by
calling
functions
in
imported
modules
e
g
decimals
and
fractions
and
others
have
literal
syntax
all
their
own
e
g
sets
numeric
type
basics
built
in
numeric
tools
besides
the
built
in
number
literals
shown
in
table
python
provides
a
set
of
tools
for
processing
number
objects
expression
operators
etc
built
in
mathematical
functions
pow
abs
round
int
hex
bin
etc
utility
modules
random
math
etc
we
ll
meet
all
of
these
as
we
go
along
although
numbers
are
primarily
processed
with
expressions
built
ins
and
modules
they
also
have
a
handful
of
type
specific
methods
today
which
we
ll
meet
in
this
chapter
as
well
floating
point
numbers
for
example
have
an
as
integer
ratio
method
that
is
useful
for
the
fraction
number
type
and
an
is
integer
method
to
test
if
the
number
is
an
integer
integers
have
various
attributes
including
a
new
bit
length
method
in
the
upcoming
python
release
that
gives
the
number
of
bits
necessary
to
represent
the
object
s
value
moreover
as
part
collection
and
part
number
sets
also
support
both
methods
and
expressions
since
expressions
are
the
most
essential
tool
for
most
number
types
though
let
s
turn
to
them
next
python
expression
operators
perhaps
the
most
fundamental
tool
that
processes
numbers
is
the
expression
a
combination
of
numbers
or
other
objects
and
operators
that
computes
a
value
when
executed
by
python
in
python
expressions
are
written
using
the
usual
mathematical
notation
and
operator
symbols
for
instance
to
add
two
numbers
x
and
y
you
would
say
x
y
which
tells
python
to
apply
the
operator
to
the
values
named
by
x
and
y
the
result
of
the
expression
is
the
sum
of
x
and
y
another
number
object
table
lists
all
the
operator
expressions
available
in
python
many
are
self
explanatory
for
instance
the
usual
mathematical
operators
and
so
on
are
supported
a
few
will
be
familiar
if
you
ve
used
other
languages
in
the
past
computes
a
division
remainder
performs
a
bitwise
left
shift
computes
a
bitwise
and
result
and
so
on
others
are
more
python
specific
and
not
all
are
numeric
in
nature
for
example
the
is
operator
tests
object
identity
i
e
address
in
memory
a
strict
form
of
equality
and
lambda
creates
unnamed
functions
chapter
numeric
types
table
python
expression
operators
and
precedence
operators
description
yield
x
generator
function
send
protocol
lambda
args
expression
anonymous
function
generation
x
if
y
else
z
ternary
selection
x
is
evaluated
only
if
y
is
true
x
or
y
logical
or
y
is
evaluated
only
if
x
is
false
x
and
y
logical
and
y
is
evaluated
only
if
x
is
true
not
x
logical
negation
x
in
y
x
not
in
y
membership
iterables
sets
x
is
y
x
is
not
y
object
identity
tests
x
y
x
y
x
y
x
y
magnitude
comparison
set
subset
and
superset
x
y
x
y
value
equality
operators
x
y
bitwise
or
set
union
x
y
bitwise
xor
set
symmetric
difference
x
y
bitwise
and
set
intersection
x
y
x
y
shift
x
left
or
right
by
y
bits
x
y
addition
concatenation
x
y
subtraction
set
difference
x
y
multiplication
repetition
x
y
remainder
format
x
y
x
y
division
true
and
floor
x
x
negation
identity
x
bitwise
not
inversion
x
y
power
exponentiation
x
i
indexing
sequence
mapping
others
x
i
j
k
slicing
x
call
function
method
class
other
callable
x
attr
attribute
reference
tuple
expression
generator
expression
list
list
comprehension
dictionary
set
set
and
dictionary
comprehensions
numeric
type
basics
since
this
book
addresses
both
python
and
here
are
some
notes
about
version
differences
and
recent
additions
related
to
the
operators
in
table
in
python
value
inequality
can
be
written
as
either
x
y
or
x
y
in
python
the
latter
of
these
options
is
removed
because
it
is
redundant
in
either
version
best
practice
is
to
use
x
y
for
all
value
inequality
tests
in
python
a
backquotes
expression
x
works
the
same
as
repr
x
and
converts
objects
to
display
strings
due
to
its
obscurity
this
expression
is
removed
in
python
use
the
more
readable
str
and
repr
built
in
functions
described
in
numeric
display
formats
on
page
the
x
y
floor
division
expression
always
truncates
fractional
remainders
in
both
python
and
the
x
y
expression
performs
true
division
in
retaining
remainders
and
classic
division
in
truncating
for
integers
see
division
classic
floor
and
true
on
page
the
syntax
is
used
for
both
list
literals
and
list
comprehension
expressions
the
latter
of
these
performs
an
implied
loop
and
collects
expression
results
in
a
new
list
see
chapters
and
for
examples
the
syntax
is
used
for
tuples
and
expressions
as
well
as
generator
expressions
a
form
of
list
comprehension
that
produces
results
on
demand
instead
of
building
a
result
list
see
chapters
and
for
examples
the
parentheses
may
sometimes
be
omitted
in
all
three
constructs
the
syntax
is
used
for
dictionary
literals
and
in
python
for
set
literals
and
both
dictionary
and
set
comprehensions
see
the
set
coverage
in
this
chapter
and
chapters
and
for
examples
the
yield
and
ternary
if
else
selection
expressions
are
available
in
python
and
later
the
former
returns
send
arguments
in
generators
the
latter
is
shorthand
for
a
multiline
if
statement
yield
requires
parentheses
if
not
alone
on
the
right
side
of
an
assignment
statement
comparison
operators
may
be
chained
x
y
z
produces
the
same
result
as
x
y
and
y
x
see
comparisons
normal
and
chained
on
page
for
details
in
recent
pythons
the
slice
expression
x
i
j
k
is
equivalent
to
indexing
with
a
slice
object
x
slice
i
j
k
in
python
x
magnitude
comparisons
of
mixed
types
converting
numbers
to
a
common
type
and
ordering
other
mixed
types
according
to
the
type
name
are
allowed
in
python
nonnumeric
mixed
type
magnitude
comparisons
are
not
allowed
and
raise
exceptions
this
includes
sorts
by
proxy
magnitude
comparisons
for
dictionaries
are
also
no
longer
supported
in
python
though
equality
tests
are
comparing
sorted
dict
items
is
one
possible
replacement
we
ll
see
most
of
the
operators
in
table
in
action
later
first
though
we
need
to
take
a
quick
look
at
the
ways
these
operators
may
be
combined
in
expressions
chapter
numeric
types
mixed
operators
follow
operator
precedence
as
in
most
languages
in
python
more
complex
expressions
are
coded
by
stringing
together
the
operator
expressions
in
table
for
instance
the
sum
of
two
multiplications
might
be
written
as
a
mix
of
variables
and
operators
a
b
c
d
so
how
does
python
know
which
operation
to
perform
first
the
answer
to
this
question
lies
in
operator
precedence
when
you
write
an
expression
with
more
than
one
operator
python
groups
its
parts
according
to
what
are
called
precedence
rules
and
this
grouping
determines
the
order
in
which
the
expression
s
parts
are
computed
table
is
ordered
by
operator
precedence
operators
lower
in
the
table
have
higher
precedence
and
so
bind
more
tightly
in
mixed
expressions
operators
in
the
same
row
in
table
generally
group
from
left
to
right
when
combined
except
for
exponentiation
which
groups
right
to
left
and
comparisons
which
chain
left
to
right
for
example
if
you
write
x
y
z
python
evaluates
the
multiplication
first
y
z
then
adds
that
result
to
x
because
has
higher
precedence
is
lower
in
the
table
than
similarly
in
this
section
s
original
example
both
multiplications
a
b
and
c
d
will
happen
before
their
results
are
added
parentheses
group
subexpressions
you
can
forget
about
precedence
completely
if
you
re
careful
to
group
parts
of
expressions
with
parentheses
when
you
enclose
subexpressions
in
parentheses
you
override
python
s
precedence
rules
python
always
evaluates
expressions
in
parentheses
first
before
using
their
results
in
the
enclosing
expressions
for
instance
instead
of
coding
x
y
z
you
could
write
one
of
the
following
to
force
python
to
evaluate
the
expression
in
the
desired
order
x
y
z
x
y
z
in
the
first
case
is
applied
to
x
and
y
first
because
this
subexpression
is
wrapped
in
parentheses
in
the
second
case
the
is
performed
first
just
as
if
there
were
no
parentheses
at
all
generally
speaking
adding
parentheses
in
large
expressions
is
a
good
idea
it
not
only
forces
the
evaluation
order
you
want
but
also
aids
readability
mixed
types
are
converted
up
besides
mixing
operators
in
expressions
you
can
also
mix
numeric
types
for
instance
you
can
add
an
integer
to
a
floating
point
number
numeric
type
basics
but
this
leads
to
another
question
what
type
is
the
result
integer
or
floating
point
the
answer
is
simple
especially
if
you
ve
used
almost
any
other
language
before
in
mixed
type
numeric
expressions
python
first
converts
operands
up
to
the
type
of
the
most
complicated
operand
and
then
performs
the
math
on
same
type
operands
this
behavior
is
similar
to
type
conversions
in
the
c
language
python
ranks
the
complexity
of
numeric
types
like
so
integers
are
simpler
than
floatingpoint
numbers
which
are
simpler
than
complex
numbers
so
when
an
integer
is
mixed
with
a
floating
point
as
in
the
preceding
example
the
integer
is
converted
up
to
a
floating
point
value
first
and
floating
point
math
yields
the
floating
point
result
similarly
any
mixed
type
expression
where
one
operand
is
a
complex
number
results
in
the
other
operand
being
converted
up
to
a
complex
number
and
the
expression
yields
a
complex
result
in
python
normal
integers
are
also
converted
to
long
integers
whenever
their
values
are
too
large
to
fit
in
a
normal
integer
in
integers
subsume
longs
entirely
you
can
force
the
issue
by
calling
built
in
functions
to
convert
types
manually
int
float
truncates
float
to
integer
converts
integer
to
float
however
you
won
t
usually
need
to
do
this
because
python
automatically
converts
up
to
the
more
complex
type
within
an
expression
the
results
are
normally
what
you
want
also
keep
in
mind
that
all
these
mixed
type
conversions
apply
only
when
mixing
numeric
types
e
g
an
integer
and
a
floating
point
in
an
expression
including
those
using
numeric
and
comparison
operators
in
general
python
does
not
convert
across
any
other
type
boundaries
automatically
adding
a
string
to
an
integer
for
example
results
in
an
error
unless
you
manually
convert
one
or
the
other
watch
for
an
example
when
we
meet
strings
in
chapter
in
python
nonnumeric
mixed
types
can
be
compared
but
no
conversions
are
performed
mixed
types
compare
according
to
a
fixed
but
arbitrary
rule
in
nonnumeric
mixed
type
comparisons
are
not
allowed
and
raise
exceptions
preview
operator
overloading
and
polymorphism
although
we
re
focusing
on
built
in
numbers
right
now
all
python
operators
may
be
overloaded
i
e
implemented
by
python
classes
and
c
extension
types
to
work
on
objects
you
create
for
instance
you
ll
see
later
that
objects
coded
with
classes
may
be
added
or
concatenated
with
expressions
indexed
with
i
expressions
and
so
on
furthermore
python
itself
automatically
overloads
some
operators
such
that
they
perform
different
actions
depending
on
the
type
of
built
in
objects
being
processed
chapter
numeric
types
for
example
the
operator
performs
addition
when
applied
to
numbers
but
performs
concatenation
when
applied
to
sequence
objects
such
as
strings
and
lists
in
fact
can
mean
anything
at
all
when
applied
to
objects
you
define
with
classes
as
we
saw
in
the
prior
chapter
this
property
is
usually
called
polymorphism
a
term
indicating
that
the
meaning
of
an
operation
depends
on
the
type
of
the
objects
being
operated
on
we
ll
revisit
this
concept
when
we
explore
functions
in
chapter
because
it
becomes
a
much
more
obvious
feature
in
that
context
numbers
in
action
on
to
the
code
probably
the
best
way
to
understand
numeric
objects
and
expressions
is
to
see
them
in
action
so
let
s
start
up
the
interactive
command
line
and
try
some
basic
but
illustrative
operations
see
chapter
for
pointers
if
you
need
help
starting
an
interactive
session
variables
and
basic
expressions
first
of
all
let
s
exercise
some
basic
math
in
the
following
interaction
we
first
assign
two
variables
a
and
b
to
integers
so
we
can
use
them
later
in
a
larger
expression
variables
are
simply
names
created
by
you
or
python
that
are
used
to
keep
track
of
information
in
your
program
we
ll
say
more
about
this
in
the
next
chapter
but
in
python
variables
are
created
when
they
are
first
assigned
values
variables
are
replaced
with
their
values
when
used
in
expressions
variables
must
be
assigned
before
they
can
be
used
in
expressions
variables
refer
to
objects
and
are
never
declared
ahead
of
time
in
other
words
these
assignments
cause
the
variables
a
and
b
to
spring
into
existence
automatically
python
a
b
name
created
i
ve
also
used
a
comment
here
recall
that
in
python
code
text
after
a
mark
and
continuing
to
the
end
of
the
line
is
considered
to
be
a
comment
and
is
ignored
comments
are
a
way
to
write
human
readable
documentation
for
your
code
because
code
you
type
interactively
is
temporary
you
won
t
normally
write
comments
in
this
context
but
i
ve
added
them
to
some
of
this
book
s
examples
to
help
explain
the
code
in
the
next
part
of
the
book
we
ll
meet
a
related
feature
documentation
strings
that
attaches
the
text
of
your
comments
to
objects
if
you
re
working
along
you
don
t
need
to
type
any
of
the
comment
text
from
the
through
to
the
end
of
the
line
comments
are
simply
ignored
by
python
and
not
required
parts
of
the
statements
we
re
running
numbers
in
action
now
let
s
use
our
new
integer
objects
in
some
expressions
at
this
point
the
values
of
a
and
b
are
still
and
respectively
variables
like
these
are
replaced
with
their
values
whenever
they
re
used
inside
an
expression
and
the
expression
results
are
echoed
back
immediately
when
working
interactively
a
a
b
b
a
b
addition
subtraction
multiplication
division
modulus
remainder
power
b
mixed
type
conversions
technically
the
results
being
echoed
back
here
are
tuples
of
two
values
because
the
lines
typed
at
the
prompt
contain
two
expressions
separated
by
commas
that
s
why
the
results
are
displayed
in
parentheses
more
on
tuples
later
note
that
the
expressions
work
because
the
variables
a
and
b
within
them
have
been
assigned
values
if
you
use
a
different
variable
that
has
never
been
assigned
python
reports
an
error
rather
than
filling
in
some
default
value
c
traceback
most
recent
call
last
file
stdin
line
in
nameerror
name
c
is
not
defined
you
don
t
need
to
predeclare
variables
in
python
but
they
must
have
been
assigned
at
least
once
before
you
can
use
them
in
practice
this
means
you
have
to
initialize
counters
to
zero
before
you
can
add
to
them
initialize
lists
to
an
empty
list
before
you
can
append
to
them
and
so
on
here
are
two
slightly
larger
expressions
to
illustrate
operator
grouping
and
more
about
conversions
b
a
print
b
a
same
as
same
as
in
the
first
expression
there
are
no
parentheses
so
python
automatically
groups
the
components
according
to
its
precedence
rules
because
is
lower
in
table
than
it
binds
more
tightly
and
so
is
evaluated
first
the
result
is
as
if
the
expression
had
been
organized
with
parentheses
as
shown
in
the
comment
to
the
right
of
the
code
also
notice
that
all
the
numbers
are
integers
in
the
first
expression
because
of
that
python
performs
integer
division
and
addition
and
will
give
a
result
of
whereas
python
performs
true
division
with
remainders
and
gives
the
result
shown
if
you
want
integer
division
in
code
this
as
b
a
more
on
division
in
a
moment
in
the
second
expression
parentheses
are
added
around
the
part
to
force
python
to
evaluate
it
first
i
e
before
the
we
also
made
one
of
the
operands
floating
point
by
adding
a
decimal
point
because
of
the
mixed
types
python
converts
the
integer
chapter
numeric
types
referenced
by
a
to
a
floating
point
value
before
performing
the
if
all
the
numbers
in
this
expression
were
integers
integer
division
would
yield
the
truncated
integer
in
python
but
the
floating
point
in
python
again
stay
tuned
for
division
details
numeric
display
formats
notice
that
we
used
a
print
operation
in
the
last
of
the
preceding
examples
without
the
print
you
ll
see
something
that
may
look
a
bit
odd
at
first
glance
b
a
auto
echo
output
more
digits
print
b
a
print
rounds
off
digits
the
full
story
behind
this
odd
result
has
to
do
with
the
limitations
of
floating
point
hardware
and
its
inability
to
exactly
represent
some
values
in
a
limited
number
of
bits
because
computer
architecture
is
well
beyond
this
book
s
scope
though
we
ll
finesse
this
by
saying
that
all
of
the
digits
in
the
first
output
are
really
there
in
your
computer
s
floating
point
hardware
it
s
just
that
you
re
not
accustomed
to
seeing
them
in
fact
this
is
really
just
a
display
issue
the
interactive
prompt
s
automatic
result
echo
shows
more
digits
than
the
print
statement
if
you
don
t
want
to
see
all
the
digits
use
print
as
the
sidebar
str
and
repr
display
formats
on
page
will
explain
you
ll
get
a
user
friendly
display
note
however
that
not
all
values
have
so
many
digits
to
display
and
that
there
are
more
ways
to
display
the
bits
of
a
number
inside
your
computer
than
using
print
and
automatic
echoes
num
num
print
num
e
num
e
f
num
f
format
num
echoes
print
rounds
string
formatting
expression
alternative
floating
point
format
string
formatting
method
python
and
the
last
three
of
these
expressions
employ
string
formatting
a
tool
that
allows
for
format
flexibility
which
we
will
explore
in
the
upcoming
chapter
on
strings
chapter
its
results
are
strings
that
are
typically
printed
to
displays
or
reports
numbers
in
action
str
and
repr
display
formats
technically
the
difference
between
default
interactive
echoes
and
print
corresponds
to
the
difference
between
the
built
in
repr
and
str
functions
num
repr
num
str
num
used
by
echoes
as
code
form
used
by
print
user
friendly
form
both
of
these
convert
arbitrary
objects
to
their
string
representations
repr
and
the
default
interactive
echo
produces
results
that
look
as
though
they
were
code
str
and
the
print
operation
converts
to
a
typically
more
user
friendly
format
if
available
some
objects
have
both
a
str
for
general
use
and
a
repr
with
extra
details
this
notion
will
resurface
when
we
study
both
strings
and
operator
overloading
in
classes
and
you
ll
find
more
on
these
built
ins
in
general
later
in
the
book
besides
providing
print
strings
for
arbitrary
objects
the
str
built
in
is
also
the
name
of
the
string
data
type
and
may
be
called
with
an
encoding
name
to
decode
a
unicode
string
from
a
byte
string
we
ll
study
the
latter
advanced
role
in
chapter
of
this
book
comparisons
normal
and
chained
so
far
we
ve
been
dealing
with
standard
numeric
operations
addition
and
multiplication
but
numbers
can
also
be
compared
normal
comparisons
work
for
numbers
exactly
as
you
d
expect
they
compare
the
relative
magnitudes
of
their
operands
and
return
a
boolean
result
which
we
would
normally
test
in
a
larger
statement
true
true
true
false
less
than
greater
than
or
equal
mixed
type
converted
to
equal
value
not
equal
value
notice
again
how
mixed
types
are
allowed
in
numeric
expressions
only
in
the
second
test
here
python
compares
values
in
terms
of
the
more
complex
type
float
interestingly
python
also
allows
us
to
chain
multiple
comparisons
together
to
perform
range
tests
chained
comparisons
are
a
sort
of
shorthand
for
larger
boolean
expressions
in
short
python
lets
us
string
together
magnitude
comparison
tests
to
code
chained
comparisons
such
as
range
tests
the
expression
a
b
c
for
instance
tests
whether
b
is
between
a
and
c
it
is
equivalent
to
the
boolean
test
a
b
and
b
c
but
is
easier
on
the
eyes
and
the
keyboard
for
example
assume
the
following
assignments
chapter
numeric
types
x
y
z
the
following
two
expressions
have
identical
effects
but
the
first
is
shorter
to
type
and
it
may
run
slightly
faster
since
python
needs
to
evaluate
y
only
once
x
y
z
true
x
y
and
y
z
true
chained
comparisons
range
tests
the
same
equivalence
holds
for
false
results
and
arbitrary
chain
lengths
are
allowed
x
y
z
false
x
y
and
y
z
false
true
false
you
can
use
other
comparisons
in
chained
tests
but
the
resulting
expressions
can
become
nonintuitive
unless
you
evaluate
them
the
way
python
does
the
following
for
instance
is
false
just
because
is
not
equal
to
false
same
as
and
not
same
as
false
which
means
which
is
true
python
does
not
compare
the
false
result
to
this
would
technically
mean
the
same
as
which
would
be
true
as
we
ll
see
later
in
this
chapter
true
and
false
are
just
customized
and
division
classic
floor
and
true
you
ve
seen
how
division
works
in
the
previous
sections
so
you
should
know
that
it
behaves
slightly
differently
in
python
and
in
fact
there
are
actually
three
flavors
of
division
and
two
different
division
operators
one
of
which
changes
in
x
y
classic
and
true
division
in
python
and
earlier
this
operator
performs
classic
division
truncating
results
for
integers
and
keeping
remainders
for
floating
point
numbers
in
python
it
performs
true
division
always
keeping
remainders
regardless
of
types
x
y
floor
division
added
in
python
and
available
in
both
python
and
this
operator
always
truncates
fractional
remainders
down
to
their
floor
regardless
of
types
numbers
in
action
true
division
was
added
to
address
the
fact
that
the
results
of
the
original
classic
division
model
are
dependent
on
operand
types
and
so
can
be
difficult
to
anticipate
in
a
dynamically
typed
language
like
python
classic
division
was
removed
in
because
of
this
constraint
the
and
operators
implement
true
and
floor
division
in
in
sum
in
the
now
always
performs
true
division
returning
a
float
result
that
includes
any
remainder
regardless
of
operand
types
the
performs
floor
division
which
truncates
the
remainder
and
returns
an
integer
for
integer
operands
or
a
float
if
any
operand
is
a
float
in
the
does
classic
division
performing
truncating
integer
division
if
both
operands
are
integers
and
float
division
keeping
remainders
otherwise
the
does
floor
division
and
works
as
it
does
in
performing
truncating
division
for
integers
and
floor
division
for
floats
here
are
the
two
operators
at
work
in
and
c
misc
c
python
python
differs
in
keeps
remainder
same
in
truncates
remainder
same
in
keeps
remainder
same
in
truncates
to
floor
c
misc
c
python
python
notice
that
the
data
type
of
the
result
for
is
still
dependent
on
the
operand
types
in
if
either
is
a
float
the
result
is
a
float
otherwise
it
is
an
integer
although
this
may
seem
similar
to
the
type
dependent
behavior
of
in
x
that
motivated
its
change
in
the
type
of
the
return
value
is
much
less
critical
than
differences
in
the
return
value
itself
moreover
because
was
provided
in
part
as
a
backward
compatibility
tool
for
programs
that
rely
on
truncating
integer
division
and
this
is
more
common
than
you
might
expect
it
must
return
integers
for
integers
chapter
numeric
types
supporting
either
python
although
behavior
differs
in
and
you
can
still
support
both
versions
in
your
code
if
your
programs
depend
on
truncating
integer
division
use
in
both
and
if
your
programs
require
floating
point
results
with
remainders
for
integers
use
float
to
guarantee
that
one
operand
is
a
float
around
a
when
run
in
x
y
z
always
truncates
always
an
int
result
for
ints
in
and
x
y
float
z
guarantees
float
division
with
remainder
in
either
or
alternatively
you
can
enable
division
in
with
a
future
import
rather
than
forcing
it
with
float
conversions
c
misc
c
python
python
from
future
import
division
enable
behavior
floor
versus
truncation
one
subtlety
the
operator
is
generally
referred
to
as
truncating
division
but
it
s
more
accurate
to
refer
to
it
as
floor
division
it
truncates
the
result
down
to
its
floor
which
means
the
closest
whole
number
below
the
true
result
the
net
effect
is
to
round
down
not
strictly
truncate
and
this
matters
for
negatives
you
can
see
the
difference
for
yourself
with
the
python
math
module
modules
must
be
imported
before
you
can
use
their
contents
more
on
this
later
import
math
math
floor
math
floor
math
trunc
math
trunc
when
running
division
operators
you
only
really
truncate
for
positive
results
since
truncation
is
the
same
as
floor
for
negatives
it
s
a
floor
result
really
they
are
both
floor
but
floor
is
the
same
as
truncation
for
positives
here
s
the
case
for
c
misc
c
python
python
truncates
to
floor
rounds
to
first
lower
integer
becomes
becomes
numbers
in
action
ditto
for
floats
though
result
is
float
too
the
case
is
similar
but
results
differ
again
c
misc
c
python
python
differs
in
this
and
the
rest
are
the
same
in
and
if
you
really
want
truncation
regardless
of
sign
you
can
always
run
a
float
division
result
through
math
trunc
regardless
of
python
version
also
see
the
round
built
in
for
related
functionality
c
misc
c
python
python
import
math
math
trunc
c
misc
c
python
python
import
math
float
math
trunc
float
keep
remainder
floor
below
result
truncate
instead
of
floor
remainder
in
floor
in
truncate
in
why
does
truncation
matter
if
you
are
using
here
is
the
short
story
on
division
operators
for
reference
true
division
floor
division
both
for
readers
division
works
as
follows
chapter
numeric
types
classic
division
floor
division
same
both
although
results
have
yet
to
come
in
it
s
possible
that
the
nontruncating
behavior
of
in
may
break
a
significant
number
of
programs
perhaps
because
of
a
c
language
legacy
many
programmers
rely
on
division
truncation
for
integers
and
will
have
to
learn
to
use
in
such
contexts
instead
watch
for
a
simple
prime
number
while
loop
example
in
chapter
and
a
corresponding
exercise
at
the
end
of
part
iv
that
illustrates
the
sort
of
code
that
may
be
impacted
by
this
change
also
stay
tuned
for
more
on
the
special
from
command
used
in
this
section
it
s
discussed
further
in
chapter
integer
precision
division
may
differ
slightly
across
python
releases
but
it
s
still
fairly
standard
here
s
something
a
bit
more
exotic
as
mentioned
earlier
python
integers
support
unlimited
size
python
has
a
separate
type
for
long
integers
but
it
automatically
converts
any
number
too
large
to
store
in
a
normal
integer
to
this
type
hence
you
don
t
need
to
code
any
special
syntax
to
use
longs
and
the
only
way
you
can
tell
that
you
re
using
longs
is
that
they
print
with
a
trailing
l
l
unlimited
precision
integers
are
a
convenient
built
in
tool
for
instance
you
can
use
them
to
count
the
u
s
national
debt
in
pennies
in
python
directly
if
you
are
so
inclined
and
have
enough
memory
on
your
computer
for
this
year
s
budget
they
are
also
why
we
were
able
to
raise
to
such
large
powers
in
the
examples
in
chapter
here
are
the
and
cases
l
because
python
must
do
extra
work
to
support
their
extended
precision
integer
math
is
usually
substantially
slower
than
normal
when
numbers
grow
large
however
if
you
need
the
precision
the
fact
that
it
s
built
in
for
you
to
use
will
likely
outweigh
its
performance
penalty
numbers
in
action
complex
numbers
although
less
widely
used
than
the
types
we
ve
been
exploring
thus
far
complex
numbers
are
a
distinct
core
object
type
in
python
if
you
know
what
they
are
you
know
why
they
are
useful
if
not
consider
this
section
optional
reading
complex
numbers
are
represented
as
two
floating
point
numbers
the
real
and
imaginary
parts
and
are
coded
by
adding
a
j
or
j
suffix
to
the
imaginary
part
we
can
also
write
complex
numbers
with
a
nonzero
real
part
by
adding
the
two
parts
with
a
for
example
the
complex
number
with
a
real
part
of
and
an
imaginary
part
of
is
written
j
here
are
some
examples
of
complex
math
at
work
j
j
j
j
j
j
j
complex
numbers
also
allow
us
to
extract
their
parts
as
attributes
support
all
the
usual
mathematical
expressions
and
may
be
processed
with
tools
in
the
standard
cmath
module
the
complex
version
of
the
standard
math
module
complex
numbers
typically
find
roles
in
engineering
oriented
programs
because
they
are
advanced
tools
check
python
s
language
reference
manual
for
additional
details
hexadecimal
octal
and
binary
notation
as
described
earlier
in
this
chapter
python
integers
can
be
coded
in
hexadecimal
octal
and
binary
notation
in
addition
to
the
normal
base
decimal
coding
the
coding
rules
were
laid
out
at
the
start
of
this
chapter
let
s
look
at
some
live
examples
here
keep
in
mind
that
these
literals
are
simply
an
alternative
syntax
for
specifying
the
value
of
an
integer
object
for
example
the
following
literals
coded
in
python
or
produce
normal
integers
with
the
specified
values
in
all
three
bases
o
o
o
x
x
xff
b
b
b
octal
literals
hex
literals
binary
literals
here
the
octal
value
o
the
hex
value
xff
and
the
binary
value
b
are
all
decimal
python
prints
in
decimal
base
by
default
but
provides
built
in
functions
that
allow
you
to
convert
integers
to
other
bases
digit
strings
oct
hex
bin
x
b
chapter
numeric
types
the
oct
function
converts
decimal
to
octal
hex
to
hexadecimal
and
bin
to
binary
to
go
the
other
way
the
built
in
int
function
converts
a
string
of
digits
to
an
integer
and
an
optional
second
argument
lets
you
specify
the
numeric
base
int
int
int
int
literals
okay
too
int
x
int
b
the
eval
function
which
you
ll
meet
later
in
this
book
treats
strings
as
though
they
were
python
code
therefore
it
has
a
similar
effect
but
usually
runs
more
slowly
it
actually
compiles
and
runs
the
string
as
a
piece
of
a
program
and
it
assumes
you
can
trust
the
source
of
the
string
being
run
a
clever
user
might
be
able
to
submit
a
string
that
deletes
files
on
your
machine
eval
eval
o
eval
x
eval
b
finally
you
can
also
convert
integers
to
octal
and
hexadecimal
strings
with
string
formatting
method
calls
and
expressions
o
x
b
format
o
x
x
ff
ff
string
formatting
is
covered
in
more
detail
in
chapter
two
notes
before
moving
on
first
python
users
should
remember
that
you
can
code
octals
with
simply
a
leading
zero
the
original
octal
format
in
python
o
o
o
new
octal
format
in
same
as
old
octal
literals
in
and
earlier
in
the
syntax
in
the
second
of
these
examples
generates
an
error
even
though
it
s
not
an
error
in
be
careful
not
to
begin
a
string
of
digits
with
a
leading
zero
unless
you
really
mean
to
code
an
octal
value
python
will
treat
it
as
base
which
may
not
work
as
you
d
expect
is
always
decimal
in
not
decimal
despite
what
you
may
or
may
not
think
this
along
with
symmetry
with
the
hex
and
binary
forms
is
why
the
octal
format
was
changed
in
you
must
use
o
in
and
probably
should
in
secondly
note
that
these
literals
can
produce
arbitrarily
long
integers
the
following
for
instance
creates
an
integer
with
hex
notation
and
then
displays
it
first
in
decimal
and
then
in
octal
and
binary
with
converters
x
xffffffffffffffffffffffffffff
x
l
oct
x
numbers
in
action
l
bin
x
b
and
so
on
speaking
of
binary
digits
the
next
section
shows
tools
for
processing
individual
bits
bitwise
operations
besides
the
normal
numeric
operations
addition
subtraction
and
so
on
python
supports
most
of
the
numeric
expressions
available
in
the
c
language
this
includes
operators
that
treat
integers
as
strings
of
binary
bits
for
instance
here
it
is
at
work
performing
bitwise
shift
and
boolean
operations
x
x
shift
left
bits
x
bitwise
or
x
bitwise
and
in
the
first
expression
a
binary
in
base
is
shifted
left
two
slots
to
create
a
binary
the
last
two
operations
perform
a
binary
or
and
a
binary
and
such
bit
masking
operations
allow
us
to
encode
multiple
flags
and
other
values
within
a
single
integer
this
is
one
area
where
the
binary
and
hexadecimal
number
support
in
python
and
become
especially
useful
they
allow
us
to
code
and
inspect
numbers
by
bit
strings
x
b
x
bin
x
b
binary
literals
shift
left
bin
x
b
b
bin
x
b
b
bitwise
or
binary
digits
string
bitwise
and
x
xff
hex
literals
bin
x
b
x
b
bitwise
xor
bin
x
b
b
int
hex
x
chapter
numeric
types
string
to
int
per
base
hex
digit
string
we
won
t
go
into
much
more
detail
on
bit
twiddling
here
it
s
supported
if
you
need
it
and
it
comes
in
handy
if
your
python
code
must
deal
with
things
like
network
packets
or
packed
binary
data
produced
by
a
c
program
be
aware
though
that
bitwise
operations
are
often
not
as
important
in
a
high
level
language
such
as
python
as
they
are
in
a
low
level
language
such
as
c
as
a
rule
of
thumb
if
you
find
yourself
wanting
to
flip
bits
in
python
you
should
think
about
which
language
you
re
really
coding
in
general
there
are
often
better
ways
to
encode
information
in
python
than
bit
strings
in
the
upcoming
python
release
the
integer
bit
length
method
also
allows
you
to
query
the
number
of
bits
required
to
represent
a
number
s
value
in
binary
the
same
effect
can
often
be
achieved
by
subtracting
from
the
length
of
the
bin
string
using
the
len
built
in
function
we
met
in
chapter
though
it
may
be
less
efficient
x
bin
x
x
bit
length
b
bin
bit
length
b
len
bin
other
built
in
numeric
tools
in
addition
to
its
core
object
types
python
also
provides
both
built
in
functions
and
standard
library
modules
for
numeric
processing
the
pow
and
abs
built
in
functions
for
instance
compute
powers
and
absolute
values
respectively
here
are
some
examples
of
the
built
in
math
module
which
contains
most
of
the
tools
in
the
c
language
s
math
library
and
a
few
built
in
functions
at
work
import
math
math
pi
math
e
common
constants
math
sin
math
pi
sine
tangent
cosine
math
sqrt
math
sqrt
square
root
pow
exponentiation
power
abs
sum
absolute
value
summation
min
max
minimum
maximum
the
sum
function
shown
here
works
on
a
sequence
of
numbers
and
min
and
max
accept
either
a
sequence
or
individual
arguments
there
are
a
variety
of
ways
to
drop
the
numbers
in
action
decimal
digits
of
floating
point
numbers
we
met
truncation
and
floor
earlier
we
can
also
round
both
numerically
and
for
display
purposes
math
floor
math
floor
floor
next
lower
integer
math
trunc
math
trunc
truncate
drop
decimal
digits
int
int
truncate
integer
conversion
round
round
round
round
python
version
f
f
format
round
for
display
chapter
as
we
saw
earlier
the
last
of
these
produces
strings
that
we
would
usually
print
and
supports
a
variety
of
formatting
options
as
also
described
earlier
the
second
to
last
test
here
will
output
if
we
wrap
it
in
a
print
call
to
request
a
more
userfriendly
display
the
last
two
lines
still
differ
though
round
rounds
a
floating
point
number
but
still
yields
a
floating
point
number
in
memory
whereas
string
formatting
produces
a
string
and
doesn
t
yield
a
modified
number
round
f
interestingly
there
are
three
ways
to
compute
square
roots
in
python
using
a
module
function
an
expression
or
a
built
in
function
if
you
re
interested
in
performance
we
will
revisit
these
in
an
exercise
and
its
solution
at
the
end
of
part
iv
to
see
which
runs
quicker
import
math
math
sqrt
pow
math
sqrt
pow
module
expression
built
in
larger
numbers
notice
that
standard
library
modules
such
as
math
must
be
imported
but
built
in
functions
such
as
abs
and
round
are
always
available
without
imports
in
other
words
modules
are
external
components
but
built
in
functions
live
in
an
implied
namespace
that
python
automatically
searches
to
find
names
used
in
your
program
this
namespace
corresponds
to
the
module
called
builtins
in
python
builtin
in
there
chapter
numeric
types
is
much
more
about
name
resolution
in
the
function
and
module
parts
of
this
book
for
now
when
you
hear
module
think
import
the
standard
library
random
module
must
be
imported
as
well
this
module
provides
tools
for
picking
a
random
floating
point
number
between
and
selecting
a
random
integer
between
two
numbers
choosing
an
item
at
random
from
a
sequence
and
more
import
random
random
random
random
random
random
randint
random
randint
random
choice
life
of
brian
holy
grail
meaning
of
life
life
of
brian
random
choice
life
of
brian
holy
grail
meaning
of
life
holy
grail
the
random
module
can
be
useful
for
shuffling
cards
in
games
picking
images
at
random
in
a
slideshow
gui
performing
statistical
simulations
and
much
more
for
more
details
see
python
s
library
manual
other
numeric
types
so
far
in
this
chapter
we
ve
been
using
python
s
core
numeric
types
integer
floating
point
and
complex
these
will
suffice
for
most
of
the
number
crunching
that
most
programmers
will
ever
need
to
do
python
comes
with
a
handful
of
more
exotic
numeric
types
though
that
merit
a
quick
look
here
decimal
type
python
introduced
a
new
core
numeric
type
the
decimal
object
formally
known
as
decimal
syntactically
decimals
are
created
by
calling
a
function
within
an
imported
module
rather
than
running
a
literal
expression
functionally
decimals
are
like
floating
point
numbers
but
they
have
a
fixed
number
of
decimal
points
hence
decimals
are
fixed
precision
floating
point
values
for
example
with
decimals
we
can
have
a
floating
point
value
that
always
retains
just
two
decimal
digits
furthermore
we
can
specify
how
to
round
or
truncate
the
extra
decimal
digits
beyond
the
object
s
cutoff
although
it
generally
incurs
a
small
performance
penalty
compared
to
the
normal
floating
point
type
the
decimal
type
is
well
suited
to
representing
fixed
precision
quantities
like
sums
of
money
and
can
help
you
achieve
better
numeric
accuracy
other
numeric
types
the
basics
the
last
point
merits
elaboration
as
you
may
or
may
not
already
know
floating
point
math
is
less
than
exact
because
of
the
limited
space
used
to
store
values
for
example
the
following
should
yield
zero
but
it
does
not
the
result
is
close
to
zero
but
there
are
not
enough
bits
to
be
precise
here
e
printing
the
result
to
produce
the
user
friendly
display
format
doesn
t
completely
help
either
because
the
hardware
related
to
floating
point
math
is
inherently
limited
in
terms
of
accuracy
print
e
however
with
decimals
the
result
can
be
dead
on
from
decimal
import
decimal
decimal
decimal
decimal
decimal
decimal
as
shown
here
we
can
make
decimal
objects
by
calling
the
decimal
constructor
function
in
the
decimal
module
and
passing
in
strings
that
have
the
desired
number
of
decimal
digits
for
the
resulting
object
we
can
use
the
str
function
to
convert
floating
point
values
to
strings
if
needed
when
decimals
of
different
precision
are
mixed
in
expressions
python
converts
up
to
the
largest
number
of
decimal
digits
automatically
decimal
decimal
decimal
decimal
decimal
in
python
to
be
released
after
this
book
s
publication
it
s
also
possible
to
create
a
decimal
object
from
a
floating
point
object
with
a
call
of
the
form
decimal
decimal
from
float
the
conversion
is
exact
but
can
sometimes
yield
a
large
number
of
digits
setting
precision
globally
other
tools
in
the
decimal
module
can
be
used
to
set
the
precision
of
all
decimal
numbers
set
up
error
handling
and
more
for
instance
a
context
object
in
this
module
allows
for
specifying
precision
number
of
decimal
digits
and
rounding
modes
down
ceiling
etc
the
precision
is
applied
globally
for
all
decimals
created
in
the
calling
thread
import
decimal
decimal
decimal
decimal
decimal
decimal
decimal
getcontext
prec
decimal
decimal
decimal
decimal
decimal
chapter
numeric
types
this
is
especially
useful
for
monetary
applications
where
cents
are
represented
as
two
decimal
digits
decimals
are
essentially
an
alternative
to
manual
rounding
and
string
formatting
in
this
context
decimal
getcontext
prec
pay
decimal
decimal
str
pay
decimal
decimal
context
manager
in
python
and
and
later
it
s
also
possible
to
reset
precision
temporarily
by
using
the
with
context
manager
statement
the
precision
is
reset
to
its
original
value
on
statement
exit
c
misc
c
python
python
import
decimal
decimal
decimal
decimal
decimal
decimal
with
decimal
localcontext
as
ctx
ctx
prec
decimal
decimal
decimal
decimal
decimal
decimal
decimal
decimal
decimal
decimal
though
useful
this
statement
requires
much
more
background
knowledge
than
you
ve
obtained
at
this
point
watch
for
coverage
of
the
with
statement
in
chapter
because
use
of
the
decimal
type
is
still
relatively
rare
in
practice
i
ll
defer
to
python
s
standard
library
manuals
and
interactive
help
for
more
details
and
because
decimals
address
some
of
the
same
floating
point
accuracy
issues
as
the
fraction
type
let
s
move
on
to
the
next
section
to
see
how
the
two
compare
fraction
type
python
and
debut
a
new
numeric
type
fraction
which
implements
a
rational
number
object
it
essentially
keeps
both
a
numerator
and
a
denominator
explicitly
so
as
to
avoid
some
of
the
inaccuracies
and
limitations
of
floating
point
math
the
basics
fraction
is
a
sort
of
cousin
to
the
existing
decimal
fixed
precision
type
described
in
the
prior
section
as
both
can
be
used
to
control
numerical
accuracy
by
fixing
decimal
digits
and
specifying
rounding
or
truncation
policies
it
s
also
used
in
similar
ways
like
other
numeric
types
decimal
fraction
resides
in
a
module
import
its
constructor
and
pass
in
a
numerator
and
a
denominator
to
make
one
the
following
interaction
shows
how
from
fractions
import
fraction
x
fraction
y
fraction
numerator
denominator
simplified
to
by
gcd
x
fraction
y
fraction
print
y
once
created
fractions
can
be
used
in
mathematical
expressions
as
usual
x
y
fraction
x
y
fraction
x
y
fraction
results
are
exact
numerator
denominator
fraction
objects
can
also
be
created
from
floating
point
number
strings
much
like
decimals
fraction
fraction
fraction
fraction
fraction
fraction
fraction
numeric
accuracy
notice
that
this
is
different
from
floating
point
type
math
which
is
constrained
by
the
underlying
limitations
of
floating
point
hardware
to
compare
here
are
the
same
operations
run
with
floating
point
objects
and
notes
on
their
limited
accuracy
a
b
a
b
only
as
accurate
as
floating
point
hardware
can
lose
precision
over
calculations
a
b
a
b
a
b
this
floating
point
limitation
is
especially
apparent
for
values
that
cannot
be
represented
accurately
given
their
limited
number
of
bits
in
memory
both
fraction
and
chapter
numeric
types
decimal
provide
ways
to
get
exact
results
albeit
at
the
cost
of
some
speed
for
instance
in
the
following
example
repeated
from
the
prior
section
floating
point
numbers
do
not
accurately
give
the
zero
answer
expected
but
both
of
the
other
types
do
this
should
be
zero
close
but
not
exact
e
from
fractions
import
fraction
fraction
fraction
fraction
fraction
fraction
from
decimal
import
decimal
decimal
decimal
decimal
decimal
decimal
moreover
fractions
and
decimals
both
allow
more
intuitive
and
accurate
results
than
floating
points
sometimes
can
in
different
ways
by
using
rational
representation
and
by
limiting
precision
use
in
python
for
true
fraction
fraction
numeric
accuracy
import
decimal
decimal
getcontext
prec
decimal
decimal
decimal
decimal
decimal
in
fact
fractions
both
retain
accuracy
and
automatically
simplify
results
continuing
the
preceding
interaction
use
in
python
for
true
fraction
fraction
automatically
simplified
fraction
fraction
fraction
decimal
decimal
str
decimal
decimal
str
decimal
e
fraction
fraction
conversions
and
mixed
types
to
support
fraction
conversions
floating
point
objects
now
have
a
method
that
yields
their
numerator
and
denominator
ratio
fractions
have
a
from
float
method
and
other
numeric
types
float
accepts
a
fraction
as
an
argument
trace
through
the
following
interaction
to
see
how
this
pans
out
the
in
the
second
test
is
special
syntax
that
expands
a
tuple
into
individual
arguments
more
on
this
when
we
study
function
argument
passing
in
chapter
as
integer
ratio
f
z
fraction
f
as
integer
ratio
z
fraction
float
object
method
convert
float
fraction
two
args
same
as
fraction
x
fraction
x
z
fraction
x
from
prior
interaction
float
x
float
z
float
x
z
convert
fraction
float
fraction
from
float
fraction
fraction
as
integer
ratio
fraction
convert
float
fraction
other
way
finally
some
type
mixing
is
allowed
in
expressions
though
fraction
must
sometimes
be
manually
propagated
to
retain
accuracy
study
the
following
interaction
to
see
how
this
works
x
fraction
x
fraction
x
x
x
x
fraction
fraction
fraction
int
fraction
fraction
float
float
fraction
float
float
fraction
fraction
fraction
caveat
although
you
can
convert
from
floating
point
to
fraction
in
some
cases
there
is
an
unavoidable
precision
loss
when
you
do
so
because
the
number
is
inaccurate
in
its
original
floating
point
form
when
needed
you
can
simplify
such
results
by
limiting
the
maximum
denominator
value
chapter
numeric
types
as
integer
ratio
precision
loss
from
float
x
fraction
a
x
fraction
as
integer
ratio
a
fraction
or
close
to
it
a
limit
denominator
fraction
simplify
to
closest
fraction
for
more
details
on
the
fraction
type
experiment
further
on
your
own
and
consult
the
python
and
library
manuals
and
other
documentation
sets
python
also
introduced
a
new
collection
type
the
set
an
unordered
collection
of
unique
and
immutable
objects
that
supports
operations
corresponding
to
mathematical
set
theory
by
definition
an
item
appears
only
once
in
a
set
no
matter
how
many
times
it
is
added
as
such
sets
have
a
variety
of
applications
especially
in
numeric
and
database
focused
work
because
sets
are
collections
of
other
objects
they
share
some
behavior
with
objects
such
as
lists
and
dictionaries
that
are
outside
the
scope
of
this
chapter
for
example
sets
are
iterable
can
grow
and
shrink
on
demand
and
may
contain
a
variety
of
object
types
as
we
ll
see
a
set
acts
much
like
the
keys
of
a
valueless
dictionary
but
it
supports
extra
operations
however
because
sets
are
unordered
and
do
not
map
keys
to
values
they
are
neither
sequence
nor
mapping
types
they
are
a
type
category
unto
themselves
moreover
because
sets
are
fundamentally
mathematical
in
nature
and
for
many
readers
may
seem
more
academic
and
be
used
much
less
often
than
more
pervasive
objects
like
dictionaries
we
ll
explore
the
basic
utility
of
python
s
set
objects
here
set
basics
in
python
there
are
a
few
ways
to
make
sets
today
depending
on
whether
you
are
using
python
or
since
this
book
covers
both
let
s
begin
with
the
case
which
also
is
available
and
sometimes
still
required
in
we
ll
refine
this
for
extensions
in
a
moment
to
make
a
set
object
pass
in
a
sequence
or
other
iterable
object
to
the
builtin
set
function
x
set
abcde
y
set
bdxyz
other
numeric
types
you
get
back
a
set
object
which
contains
all
the
items
in
the
object
passed
in
notice
that
sets
do
not
have
a
positional
ordering
and
so
are
not
sequences
x
set
a
c
b
e
d
display
format
sets
made
this
way
support
the
common
mathematical
set
operations
with
expression
operators
note
that
we
can
t
perform
these
expressions
on
plain
sequences
we
must
create
sets
from
them
in
order
to
apply
these
tools
e
in
x
true
membership
x
y
set
a
c
e
difference
x
y
set
a
c
b
e
d
y
x
z
union
x
y
set
b
d
intersection
x
y
set
a
c
e
y
x
z
symmetric
difference
xor
x
y
x
y
false
false
superset
subset
in
addition
to
expressions
the
set
object
provides
methods
that
correspond
to
these
operations
and
more
and
that
support
set
changes
the
set
add
method
inserts
one
item
update
is
an
in
place
union
and
remove
deletes
an
item
by
value
run
a
dir
call
on
any
set
instance
or
the
set
type
name
to
see
all
the
available
methods
assuming
x
and
y
are
still
as
they
were
in
the
prior
interaction
z
x
intersection
y
z
set
b
d
z
add
spam
z
set
b
d
spam
z
update
set
x
y
z
set
y
x
b
d
spam
z
remove
b
z
set
y
x
d
spam
same
as
x
y
insert
one
item
merge
in
place
union
delete
one
item
as
iterable
containers
sets
can
also
be
used
in
operations
such
as
len
for
loops
and
list
comprehensions
because
they
are
unordered
though
they
don
t
support
sequence
operations
like
indexing
and
slicing
for
item
in
set
abc
print
item
aaa
chapter
numeric
types
ccc
bbb
finally
although
the
set
expressions
shown
earlier
generally
require
two
sets
their
method
based
counterparts
can
often
work
with
any
iterable
type
as
well
s
set
s
set
expressions
require
both
to
be
sets
set
s
typeerror
unsupported
operand
type
s
for
set
and
list
s
union
but
their
methods
allow
any
iterable
set
s
intersection
set
s
issubset
range
true
for
more
details
on
set
operations
see
python
s
library
reference
manual
or
a
reference
book
although
set
operations
can
be
coded
manually
in
python
with
other
types
like
lists
and
dictionaries
and
often
were
in
the
past
python
s
built
in
sets
use
efficient
algorithms
and
implementation
techniques
to
provide
quick
and
standard
operation
set
literals
in
python
if
you
think
sets
are
cool
they
recently
became
noticeably
cooler
in
python
we
can
still
use
the
set
built
in
to
make
set
objects
but
also
adds
a
new
set
literal
form
using
the
curly
braces
formerly
reserved
for
dictionaries
in
the
following
are
equivalent
set
built
in
call
set
literals
this
syntax
makes
sense
given
that
sets
are
essentially
like
valueless
dictionaries
because
they
are
unordered
unique
and
immutable
a
set
s
items
behave
much
like
a
dictionary
s
keys
this
operational
similarity
is
even
more
striking
given
that
dictionary
key
lists
in
are
view
objects
which
support
set
like
behavior
such
as
intersections
and
unions
see
chapter
for
more
on
dictionary
view
objects
in
fact
regardless
of
how
a
set
is
made
displays
it
using
the
new
literal
format
the
set
built
in
is
still
required
in
to
create
empty
sets
and
to
build
sets
from
existing
iterable
objects
short
of
using
set
comprehensions
discussed
later
in
this
chapter
but
the
new
literal
is
convenient
for
initializing
sets
of
known
structure
c
misc
c
python
python
set
set
spam
a
p
s
m
built
in
same
as
in
add
all
items
in
an
iterable
set
literals
new
in
other
numeric
types
s
s
p
a
m
s
add
alot
s
a
p
s
m
alot
all
the
set
processing
operations
discussed
in
the
prior
section
work
the
same
in
but
the
result
sets
print
differently
s
s
s
s
s
true
intersection
union
difference
superset
note
that
is
still
a
dictionary
in
python
empty
sets
must
be
created
with
the
set
built
in
and
print
the
same
way
s
set
type
class
dict
empty
sets
print
differently
s
set
s
add
s
initialize
an
empty
set
because
is
an
empty
dictionary
as
in
python
sets
created
with
literals
support
the
same
methods
some
of
which
allow
general
iterable
operands
that
expressions
do
not
typeerror
unsupported
operand
type
s
for
set
and
list
union
union
union
set
intersection
issubset
range
true
immutable
constraints
and
frozen
sets
sets
are
powerful
and
flexible
objects
but
they
do
have
one
constraint
in
both
and
that
you
should
keep
in
mind
largely
because
of
their
implementation
sets
can
chapter
numeric
types
only
contain
immutable
a
k
a
hashable
object
types
hence
lists
and
dictionaries
cannot
be
embedded
in
sets
but
tuples
can
if
you
need
to
store
compound
values
tuples
compare
by
their
full
values
when
used
in
set
operations
s
s
add
typeerror
unhashable
type
list
s
add
a
typeerror
unhashable
type
dict
s
add
s
s
in
s
true
in
s
false
only
mutable
objects
work
in
a
set
no
list
or
dict
but
tuple
okay
union
same
as
s
union
membership
by
complete
values
tuples
in
a
set
for
instance
might
be
used
to
represent
dates
records
ip
addresses
and
so
on
more
on
tuples
later
in
this
part
of
the
book
sets
themselves
are
mutable
too
and
so
cannot
be
nested
in
other
sets
directly
if
you
need
to
store
a
set
inside
another
set
the
frozenset
built
in
call
works
just
like
set
but
creates
an
immutable
set
that
cannot
change
and
thus
can
be
embedded
in
other
sets
set
comprehensions
in
python
in
addition
to
literals
introduces
a
set
comprehension
construct
it
is
similar
in
form
to
the
list
comprehension
we
previewed
in
chapter
but
is
coded
in
curly
braces
instead
of
square
brackets
and
run
to
make
a
set
instead
of
a
list
set
comprehensions
run
a
loop
and
collect
the
result
of
an
expression
on
each
iteration
a
loop
variable
gives
access
to
the
current
iteration
value
for
use
in
the
collection
expression
the
result
is
a
new
set
created
by
running
the
code
with
all
the
normal
set
behavior
x
for
x
in
set
comprehension
in
this
expression
the
loop
is
coded
on
the
right
and
the
collection
expression
is
coded
on
the
left
x
as
for
list
comprehensions
we
get
back
pretty
much
what
this
expression
says
give
me
a
new
set
containing
x
squared
for
every
x
in
a
list
comprehensions
can
also
iterate
across
other
kinds
of
objects
such
as
strings
the
first
of
the
following
examples
illustrates
the
comprehension
based
way
to
make
a
set
from
an
existing
iterable
x
for
x
in
spam
a
p
s
m
same
as
set
spam
c
for
c
in
spam
ssss
aaaa
pppp
mmmm
c
for
c
in
spamham
set
of
collected
expression
results
other
numeric
types
ssss
aaaa
hhhh
pppp
mmmm
s
c
for
c
in
spam
s
mmmm
xxxx
ssss
aaaa
pppp
mmmm
xxxx
s
mmmm
xxxx
mmmm
because
the
rest
of
the
comprehensions
story
relies
upon
underlying
concepts
we
re
not
yet
prepared
to
address
we
ll
postpone
further
details
until
later
in
this
book
in
chapter
we
ll
meet
a
first
cousin
in
the
dictionary
comprehension
and
i
ll
have
much
more
to
say
about
all
comprehensions
list
set
dictionary
and
generator
later
especially
in
chapters
and
as
we
ll
learn
later
all
comprehensions
including
sets
support
additional
syntax
not
shown
here
including
nested
loops
and
if
tests
which
can
be
difficult
to
understand
until
you
ve
had
a
chance
to
study
larger
statements
why
sets
set
operations
have
a
variety
of
common
uses
some
more
practical
than
mathematical
for
example
because
items
are
stored
only
once
in
a
set
sets
can
be
used
to
filter
duplicates
out
of
other
collections
simply
convert
the
collection
to
a
set
and
then
convert
it
back
again
because
sets
are
iterable
they
work
in
the
list
call
here
l
set
l
l
list
set
l
l
remove
duplicates
sets
can
also
be
used
to
keep
track
of
where
you
ve
already
been
when
traversing
a
graph
or
other
cyclic
structure
for
example
the
transitive
module
reloader
and
inheritance
tree
lister
examples
we
ll
study
in
chapters
and
respectively
must
keep
track
of
items
visited
to
avoid
loops
although
recording
states
visited
as
keys
in
a
dictionary
is
efficient
sets
offer
an
alternative
that
s
essentially
equivalent
and
may
be
more
or
less
intuitive
depending
on
who
you
ask
finally
sets
are
also
convenient
when
dealing
with
large
data
sets
database
query
results
for
example
the
intersection
of
two
sets
contains
objects
in
common
to
both
categories
and
the
union
contains
all
items
in
either
set
to
illustrate
here
s
a
somewhat
more
realistic
example
of
set
operations
at
work
applied
to
lists
of
people
in
a
hypothetical
company
using
set
literals
use
set
in
engineers
bob
sue
ann
vic
managers
tom
sue
bob
in
engineers
true
is
bob
an
engineer
engineers
managers
who
is
both
engineer
and
manager
chapter
numeric
types
sue
engineers
managers
vic
sue
tom
bob
ann
all
people
in
either
category
engineers
managers
vic
bob
ann
engineers
who
are
not
managers
managers
engineers
tom
managers
who
are
not
engineers
engineers
managers
false
are
all
managers
engineers
superset
bob
sue
engineers
true
are
both
engineers
subset
managers
engineers
managers
true
all
people
is
a
superset
of
managers
managers
engineers
vic
bob
ann
tom
who
is
in
one
but
not
both
managers
engineers
managers
engineers
sue
intersection
you
can
find
more
details
on
set
operations
in
the
python
library
manual
and
some
mathematical
and
relational
database
theory
texts
also
stay
tuned
for
chapter
s
revival
of
some
of
the
set
operations
we
ve
seen
here
in
the
context
of
dictionary
view
objects
in
python
booleans
some
argue
that
the
python
boolean
type
bool
is
numeric
in
nature
because
its
two
values
true
and
false
are
just
customized
versions
of
the
integers
and
that
print
themselves
differently
although
that
s
all
most
programmers
need
to
know
let
s
explore
this
type
in
a
bit
more
detail
more
formally
python
today
has
an
explicit
boolean
data
type
called
bool
with
the
values
true
and
false
available
as
new
preassigned
built
in
names
internally
the
names
true
and
false
are
instances
of
bool
which
is
in
turn
just
a
subclass
in
the
objectoriented
sense
of
the
built
in
integer
type
int
true
and
false
behave
exactly
like
the
integers
and
except
that
they
have
customized
printing
logic
they
print
themselves
as
the
words
true
and
false
instead
of
the
digits
and
bool
accomplishes
this
by
redefining
str
and
repr
string
formats
for
its
two
objects
because
of
this
customization
the
output
of
boolean
expressions
typed
at
the
interactive
prompt
prints
as
the
words
true
and
false
instead
of
the
older
and
less
obvious
and
in
addition
booleans
make
truth
values
more
explicit
for
instance
an
infinite
loop
can
now
be
coded
as
while
true
instead
of
the
less
intuitive
while
similarly
other
numeric
types
flags
can
be
initialized
more
clearly
with
flag
false
we
ll
discuss
these
statements
further
in
part
iii
again
though
for
all
other
practical
purposes
you
can
treat
true
and
false
as
though
they
are
predefined
variables
set
to
integer
and
most
programmers
used
to
preassign
true
and
false
to
and
anyway
the
bool
type
simply
makes
this
standard
its
implementation
can
lead
to
curious
results
though
because
true
is
just
the
integer
with
a
custom
display
format
true
yields
in
python
type
true
class
bool
isinstance
true
int
true
true
true
true
is
false
true
or
false
true
true
same
value
but
different
object
see
the
next
chapter
same
as
or
hmmm
since
you
probably
won
t
come
across
an
expression
like
the
last
of
these
in
real
python
code
you
can
safely
ignore
its
deeper
metaphysical
implications
we
ll
revisit
booleans
in
chapter
to
define
python
s
notion
of
truth
and
again
in
chapter
to
see
how
boolean
operators
like
and
and
or
work
numeric
extensions
finally
although
python
core
numeric
types
offer
plenty
of
power
for
most
applications
there
is
a
large
library
of
third
party
open
source
extensions
available
to
address
more
focused
needs
because
numeric
programming
is
a
popular
domain
for
python
you
ll
find
a
wealth
of
advanced
tools
for
example
if
you
need
to
do
serious
number
crunching
an
optional
extension
for
python
called
numpy
numeric
python
provides
advanced
numeric
programming
tools
such
as
a
matrix
data
type
vector
processing
and
sophisticated
computation
libraries
hardcore
scientific
programming
groups
at
places
like
los
alamos
and
nasa
use
python
with
numpy
to
implement
the
sorts
of
tasks
they
previously
coded
in
c
fortran
or
matlab
the
combination
of
python
and
numpy
is
often
compared
to
a
free
more
flexible
version
of
matlab
you
get
numpy
s
performance
plus
the
python
language
and
its
libraries
because
it
s
so
advanced
we
won
t
talk
further
about
numpy
in
this
book
you
can
find
additional
support
for
advanced
numeric
programming
in
python
including
graphics
and
plotting
tools
statistics
libraries
and
the
popular
scipy
package
at
python
s
pypi
site
or
by
searching
the
web
also
note
that
numpy
is
currently
an
optional
extension
it
doesn
t
come
with
python
and
must
be
installed
separately
chapter
numeric
types
chapter
summary
this
chapter
has
taken
a
tour
of
python
s
numeric
object
types
and
the
operations
we
can
apply
to
them
along
the
way
we
met
the
standard
integer
and
floating
point
types
as
well
as
some
more
exotic
and
less
commonly
used
types
such
as
complex
numbers
fractions
and
sets
we
also
explored
python
s
expression
syntax
type
conversions
bitwise
operations
and
various
literal
forms
for
coding
numbers
in
scripts
later
in
this
part
of
the
book
i
ll
fill
in
some
details
about
the
next
object
type
the
string
in
the
next
chapter
however
we
ll
take
some
time
to
explore
the
mechanics
of
variable
assignment
in
more
detail
than
we
have
here
this
turns
out
to
be
perhaps
the
most
fundamental
idea
in
python
so
make
sure
you
check
out
the
next
chapter
before
moving
on
first
though
it
s
time
to
take
the
usual
chapter
quiz
test
your
knowledge
quiz
what
is
the
value
of
the
expression
in
python
what
is
the
value
of
the
expression
in
python
what
is
the
value
of
the
expression
in
python
what
tools
can
you
use
to
find
a
number
s
square
root
as
well
as
its
square
what
is
the
type
of
the
result
of
the
expression
how
can
you
truncate
and
round
a
floating
point
number
how
can
you
convert
an
integer
to
a
floating
point
number
how
would
you
display
an
integer
in
octal
hexadecimal
or
binary
notation
how
might
you
convert
an
octal
hexadecimal
or
binary
string
to
a
plain
integer
test
your
knowledge
answers
the
value
will
be
the
result
of
because
the
parentheses
force
the
addition
to
happen
before
the
multiplication
the
value
will
be
the
result
of
python
s
operator
precedence
rules
are
applied
in
the
absence
of
parentheses
and
multiplication
has
higher
precedence
than
i
e
happens
before
addition
per
table
this
expression
yields
the
result
of
for
the
same
precedence
reasons
as
in
the
prior
question
functions
for
obtaining
the
square
root
as
well
as
pi
tangents
and
more
are
available
in
the
imported
math
module
to
find
a
number
s
square
root
import
math
and
call
math
sqrt
n
to
get
a
number
s
square
use
either
the
exponent
test
your
knowledge
answers
expression
x
or
the
built
in
function
pow
x
either
of
these
last
two
can
also
compute
the
square
root
when
given
a
power
of
e
g
x
the
result
will
be
a
floating
point
number
the
integers
are
converted
up
to
floating
point
the
most
complex
type
in
the
expression
and
floating
point
math
is
used
to
evaluate
it
the
int
n
and
math
trunc
n
functions
truncate
and
the
round
n
digits
function
rounds
we
can
also
compute
the
floor
with
math
floor
n
and
round
for
display
with
string
formatting
operations
the
float
i
function
converts
an
integer
to
a
floating
point
mixing
an
integer
with
a
floating
point
within
an
expression
will
result
in
a
conversion
as
well
in
some
sense
python
division
converts
too
it
always
returns
a
floating
point
result
that
includes
the
remainder
even
if
both
operands
are
integers
the
oct
i
and
hex
i
built
in
functions
return
the
octal
and
hexadecimal
string
forms
for
an
integer
the
bin
i
call
also
returns
a
number
s
binary
digits
string
in
python
and
the
string
formatting
expression
and
format
string
method
also
provide
targets
for
some
such
conversions
the
int
s
base
function
can
be
used
to
convert
from
octal
and
hexadecimal
strings
to
normal
integers
pass
in
or
for
the
base
the
eval
s
function
can
be
used
for
this
purpose
too
but
it
s
more
expensive
to
run
and
can
have
security
issues
note
that
integers
are
always
stored
in
binary
in
computer
memory
these
are
just
display
string
format
conversions
chapter
numeric
types
chapter
the
dynamic
typing
interlude
in
the
prior
chapter
we
began
exploring
python
s
core
object
types
in
depth
with
a
look
at
python
numbers
we
ll
resume
our
object
type
tour
in
the
next
chapter
but
before
we
move
on
it
s
important
that
you
get
a
handle
on
what
may
be
the
most
fundamental
idea
in
python
programming
and
is
certainly
the
basis
of
much
of
both
the
conciseness
and
flexibility
of
the
python
language
dynamic
typing
and
the
polymorphism
it
yields
as
you
ll
see
here
and
later
in
this
book
in
python
we
do
not
declare
the
specific
types
of
the
objects
our
scripts
use
in
fact
programs
should
not
even
care
about
specific
types
in
exchange
they
are
naturally
applicable
in
more
contexts
than
we
can
sometimes
even
plan
ahead
for
because
dynamic
typing
is
the
root
of
this
flexibility
let
s
take
a
brief
look
at
the
model
here
the
case
of
the
missing
declaration
statements
if
you
have
a
background
in
compiled
or
statically
typed
languages
like
c
c
or
java
you
might
find
yourself
a
bit
perplexed
at
this
point
in
the
book
so
far
we
ve
been
using
variables
without
declaring
their
existence
or
their
types
and
it
somehow
works
when
we
type
a
in
an
interactive
session
or
program
file
for
instance
how
does
python
know
that
a
should
stand
for
an
integer
for
that
matter
how
does
python
know
what
a
is
at
all
once
you
start
asking
such
questions
you
ve
crossed
over
into
the
domain
of
python
s
dynamic
typing
model
in
python
types
are
determined
automatically
at
runtime
not
in
response
to
declarations
in
your
code
this
means
that
you
never
declare
variables
ahead
of
time
a
concept
that
is
perhaps
simpler
to
grasp
if
you
keep
in
mind
that
it
all
boils
down
to
variables
objects
and
the
links
between
them
variables
objects
and
references
as
you
ve
seen
in
many
of
the
examples
used
so
far
in
this
book
when
you
run
an
assignment
statement
such
as
a
in
python
it
works
even
if
you
ve
never
told
python
to
use
the
name
a
as
a
variable
or
that
a
should
stand
for
an
integer
type
object
in
the
python
language
this
all
pans
out
in
a
very
natural
way
as
follows
variable
creation
a
variable
i
e
name
like
a
is
created
when
your
code
first
assigns
it
a
value
future
assignments
change
the
value
of
the
already
created
name
technically
python
detects
some
names
before
your
code
runs
but
you
can
think
of
it
as
though
initial
assignments
make
variables
variable
types
a
variable
never
has
any
type
information
or
constraints
associated
with
it
the
notion
of
type
lives
with
objects
not
names
variables
are
generic
in
nature
they
always
simply
refer
to
a
particular
object
at
a
particular
point
in
time
variable
use
when
a
variable
appears
in
an
expression
it
is
immediately
replaced
with
the
object
that
it
currently
refers
to
whatever
that
may
be
further
all
variables
must
be
explicitly
assigned
before
they
can
be
used
referencing
unassigned
variables
results
in
errors
in
sum
variables
are
created
when
assigned
can
reference
any
type
of
object
and
must
be
assigned
before
they
are
referenced
this
means
that
you
never
need
to
declare
names
used
by
your
script
but
you
must
initialize
names
before
you
can
update
them
counters
for
example
must
be
initialized
to
zero
before
you
can
add
to
them
this
dynamic
typing
model
is
strikingly
different
from
the
typing
model
of
traditional
languages
when
you
are
first
starting
out
the
model
is
usually
easier
to
understand
if
you
keep
clear
the
distinction
between
names
and
objects
for
example
when
we
say
this
a
at
least
conceptually
python
will
perform
three
distinct
steps
to
carry
out
the
request
these
steps
reflect
the
operation
of
all
assignments
in
the
python
language
create
an
object
to
represent
the
value
create
the
variable
a
if
it
does
not
yet
exist
link
the
variable
a
to
the
new
object
the
net
result
will
be
a
structure
inside
python
that
resembles
figure
as
sketched
variables
and
objects
are
stored
in
different
parts
of
memory
and
are
associated
by
links
the
link
is
shown
as
a
pointer
in
the
figure
variables
always
link
to
objects
and
never
to
other
variables
but
larger
objects
may
link
to
other
objects
for
instance
a
list
object
has
links
to
the
objects
it
contains
chapter
the
dynamic
typing
interlude
figure
names
and
objects
after
running
the
assignment
a
variable
a
becomes
a
reference
to
the
object
internally
the
variable
is
really
a
pointer
to
the
object
s
memory
space
created
by
running
the
literal
expression
these
links
from
variables
to
objects
are
called
references
in
python
that
is
a
reference
is
a
kind
of
association
implemented
as
a
pointer
in
memory
whenever
the
variables
are
later
used
i
e
referenced
python
automatically
follows
the
variable
to
object
links
this
is
all
simpler
than
the
terminology
may
imply
in
concrete
terms
variables
are
entries
in
a
system
table
with
spaces
for
links
to
objects
objects
are
pieces
of
allocated
memory
with
enough
space
to
represent
the
values
for
which
they
stand
references
are
automatically
followed
pointers
from
variables
to
objects
at
least
conceptually
each
time
you
generate
a
new
value
in
your
script
by
running
an
expression
python
creates
a
new
object
i
e
a
chunk
of
memory
to
represent
that
value
internally
as
an
optimization
python
caches
and
reuses
certain
kinds
of
unchangeable
objects
such
as
small
integers
and
strings
each
is
not
really
a
new
piece
of
memory
more
on
this
caching
behavior
later
but
from
a
logical
perspective
it
works
as
though
each
expression
s
result
value
is
a
distinct
object
and
each
object
is
a
distinct
piece
of
memory
technically
speaking
objects
have
more
structure
than
just
enough
space
to
represent
their
values
each
object
also
has
two
standard
header
fields
a
type
designator
used
to
mark
the
type
of
the
object
and
a
reference
counter
used
to
determine
when
it
s
ok
to
reclaim
the
object
to
understand
how
these
two
header
fields
factor
into
the
model
we
need
to
move
on
types
live
with
objects
not
variables
to
see
how
object
types
come
into
play
watch
what
happens
if
we
assign
a
variable
multiple
times
readers
with
a
background
in
c
may
find
python
references
similar
to
c
pointers
memory
addresses
in
fact
references
are
implemented
as
pointers
and
they
often
serve
the
same
roles
especially
with
objects
that
can
be
changed
in
place
more
on
this
later
however
because
references
are
always
automatically
dereferenced
when
used
you
can
never
actually
do
anything
useful
with
a
reference
itself
this
is
a
feature
that
eliminates
a
vast
category
of
c
bugs
you
can
think
of
python
references
as
c
void
pointers
which
are
automatically
followed
whenever
used
the
case
of
the
missing
declaration
statements
a
a
spam
a
it
s
an
integer
now
it
s
a
string
now
it
s
a
floating
point
this
isn
t
typical
python
code
but
it
does
work
a
starts
out
as
an
integer
then
becomes
a
string
and
finally
becomes
a
floating
point
number
this
example
tends
to
look
especially
odd
to
ex
c
programmers
as
it
appears
as
though
the
type
of
a
changes
from
integer
to
string
when
we
say
a
spam
however
that
s
not
really
what
s
happening
in
python
things
work
more
simply
names
have
no
types
as
stated
earlier
types
live
with
objects
not
names
in
the
preceding
listing
we
ve
simply
changed
a
to
reference
different
objects
because
variables
have
no
type
we
haven
t
actually
changed
the
type
of
the
variable
a
we
ve
simply
made
the
variable
reference
a
different
type
of
object
in
fact
again
all
we
can
ever
say
about
a
variable
in
python
is
that
it
references
a
particular
object
at
a
particular
point
in
time
objects
on
the
other
hand
know
what
type
they
are
each
object
contains
a
header
field
that
tags
the
object
with
its
type
the
integer
object
for
example
will
contain
the
value
plus
a
designator
that
tells
python
that
the
object
is
an
integer
strictly
speaking
a
pointer
to
an
object
called
int
the
name
of
the
integer
type
the
type
designator
of
the
spam
string
object
points
to
the
string
type
called
str
instead
because
objects
know
their
types
variables
don
t
have
to
to
recap
types
are
associated
with
objects
in
python
not
with
variables
in
typical
code
a
given
variable
usually
will
reference
just
one
kind
of
object
because
this
isn
t
a
requirement
though
you
ll
find
that
python
code
tends
to
be
much
more
flexible
than
you
may
be
accustomed
to
if
you
use
python
well
your
code
might
work
on
many
types
automatically
i
mentioned
that
objects
have
two
header
fields
a
type
designator
and
a
reference
counter
to
understand
the
latter
of
these
we
need
to
move
on
and
take
a
brief
look
at
what
happens
at
the
end
of
an
object
s
life
objects
are
garbage
collected
in
the
prior
section
s
listings
we
assigned
the
variable
a
to
different
types
of
objects
in
each
assignment
but
when
we
reassign
a
variable
what
happens
to
the
value
it
was
previously
referencing
for
example
after
the
following
statements
what
happens
to
the
object
a
a
spam
the
answer
is
that
in
python
whenever
a
name
is
assigned
to
a
new
object
the
space
held
by
the
prior
object
is
reclaimed
if
it
is
not
referenced
by
any
other
name
or
object
this
automatic
reclamation
of
objects
space
is
known
as
garbage
collection
to
illustrate
consider
the
following
example
which
sets
the
name
x
to
a
different
object
on
each
assignment
chapter
the
dynamic
typing
interlude
x
x
x
x
shrubbery
reclaim
now
unless
referenced
elsewhere
reclaim
shrubbery
now
reclaim
now
first
notice
that
x
is
set
to
a
different
type
of
object
each
time
again
though
this
is
not
really
the
case
the
effect
is
as
though
the
type
of
x
is
changing
over
time
remember
in
python
types
live
with
objects
not
names
because
names
are
just
generic
references
to
objects
this
sort
of
code
works
naturally
second
notice
that
references
to
objects
are
discarded
along
the
way
each
time
x
is
assigned
to
a
new
object
python
reclaims
the
prior
object
s
space
for
instance
when
it
is
assigned
the
string
shrubbery
the
object
is
immediately
reclaimed
assuming
it
is
not
referenced
anywhere
else
that
is
the
object
s
space
is
automatically
thrown
back
into
the
free
space
pool
to
be
reused
for
a
future
object
internally
python
accomplishes
this
feat
by
keeping
a
counter
in
every
object
that
keeps
track
of
the
number
of
references
currently
pointing
to
that
object
as
soon
as
and
exactly
when
this
counter
drops
to
zero
the
object
s
memory
space
is
automatically
reclaimed
in
the
preceding
listing
we
re
assuming
that
each
time
x
is
assigned
to
a
new
object
the
prior
object
s
reference
counter
drops
to
zero
causing
it
to
be
reclaimed
the
most
immediately
tangible
benefit
of
garbage
collection
is
that
it
means
you
can
use
objects
liberally
without
ever
needing
to
free
up
space
in
your
script
python
will
clean
up
unused
space
for
you
as
your
program
runs
in
practice
this
eliminates
a
substantial
amount
of
bookkeeping
code
required
in
lower
level
languages
such
as
c
and
c
technically
speaking
python
s
garbage
collection
is
based
mainly
upon
reference
counters
as
described
here
however
it
also
has
a
component
that
detects
and
reclaims
objects
with
cyclic
references
in
time
this
component
can
be
disabled
if
you
re
sure
that
your
code
doesn
t
create
cycles
but
it
is
enabled
by
default
because
references
are
implemented
as
pointers
it
s
possible
for
an
object
to
reference
itself
or
reference
another
object
that
does
for
example
exercise
at
the
end
of
part
i
and
its
solution
in
appendix
b
show
how
to
create
a
cycle
by
embedding
a
reference
to
a
list
within
itself
the
same
phenomenon
can
occur
for
assignments
to
attributes
of
objects
created
from
user
defined
classes
though
relatively
rare
because
the
reference
counts
for
such
objects
never
drop
to
zero
they
must
be
treated
specially
for
more
details
on
python
s
cycle
detector
see
the
documentation
for
the
gc
module
in
python
s
library
manual
also
note
that
this
description
of
python
s
garbage
collector
applies
to
the
standard
cpython
only
jython
and
ironpython
may
use
different
schemes
though
the
net
effect
in
all
is
similar
unused
space
is
reclaimed
for
you
automatically
the
case
of
the
missing
declaration
statements
shared
references
so
far
we
ve
seen
what
happens
as
a
single
variable
is
assigned
references
to
objects
now
let
s
introduce
another
variable
into
our
interaction
and
watch
what
happens
to
its
names
and
objects
a
b
a
typing
these
two
statements
generates
the
scene
captured
in
figure
the
second
line
causes
python
to
create
the
variable
b
the
variable
a
is
being
used
and
not
assigned
here
so
it
is
replaced
with
the
object
it
references
and
b
is
made
to
reference
that
object
the
net
effect
is
that
the
variables
a
and
b
wind
up
referencing
the
same
object
that
is
pointing
to
the
same
chunk
of
memory
this
scenario
with
multiple
names
referencing
the
same
object
is
called
a
shared
reference
in
python
figure
names
and
objects
after
next
running
the
assignment
b
a
variable
b
becomes
a
reference
to
the
object
internally
the
variable
is
really
a
pointer
to
the
object
s
memory
space
created
by
running
the
literal
expression
next
suppose
we
extend
the
session
with
one
more
statement
a
b
a
a
spam
as
with
all
python
assignments
this
statement
simply
makes
a
new
object
to
represent
the
string
value
spam
and
sets
a
to
reference
this
new
object
it
does
not
however
change
the
value
of
b
b
still
references
the
original
object
the
integer
the
resulting
reference
structure
is
shown
in
figure
the
same
sort
of
thing
would
happen
if
we
changed
b
to
spam
instead
the
assignment
would
change
only
b
not
a
this
behavior
also
occurs
if
there
are
no
type
differences
at
all
for
example
consider
these
three
statements
a
b
a
a
a
chapter
the
dynamic
typing
interlude
figure
names
and
objects
after
finally
running
the
assignment
a
spam
variable
a
references
the
new
object
i
e
piece
of
memory
created
by
running
the
literal
expression
spam
but
variable
b
still
refers
to
the
original
object
because
this
assignment
is
not
an
in
place
change
to
the
object
it
changes
only
variable
a
not
b
in
this
sequence
the
same
events
transpire
python
makes
the
variable
a
reference
the
object
and
makes
b
reference
the
same
object
as
a
as
in
figure
as
before
the
last
assignment
then
sets
a
to
a
completely
different
object
in
this
case
the
integer
which
is
the
result
of
the
expression
it
does
not
change
b
as
a
side
effect
in
fact
there
is
no
way
to
ever
overwrite
the
value
of
the
object
as
introduced
in
chapter
integers
are
immutable
and
thus
can
never
be
changed
in
place
one
way
to
think
of
this
is
that
unlike
in
some
languages
in
python
variables
are
always
pointers
to
objects
not
labels
of
changeable
memory
areas
setting
a
variable
to
a
new
value
does
not
alter
the
original
object
but
rather
causes
the
variable
to
reference
an
entirely
different
object
the
net
effect
is
that
assignment
to
a
variable
can
impact
only
the
single
variable
being
assigned
when
mutable
objects
and
in
place
changes
enter
the
equation
though
the
picture
changes
somewhat
to
see
how
let
s
move
on
shared
references
and
in
place
changes
as
you
ll
see
later
in
this
part
s
chapters
there
are
objects
and
operations
that
perform
in
place
object
changes
for
instance
an
assignment
to
an
offset
in
a
list
actually
changes
the
list
object
itself
in
place
rather
than
generating
a
brand
new
list
object
for
objects
that
support
such
in
place
changes
you
need
to
be
more
aware
of
shared
references
since
a
change
from
one
name
may
impact
others
to
further
illustrate
let
s
take
another
look
at
the
list
objects
introduced
in
chapter
recall
that
lists
which
do
support
in
place
assignments
to
positions
are
simply
collections
of
other
objects
coded
in
square
brackets
l
l
l
shared
references
l
here
is
a
list
containing
the
objects
and
items
inside
a
list
are
accessed
by
their
positions
so
l
refers
to
object
the
first
item
in
the
list
l
of
course
lists
are
also
objects
in
their
own
right
just
like
integers
and
strings
after
running
the
two
prior
assignments
l
and
l
reference
the
same
object
just
like
a
and
b
in
the
prior
example
see
figure
now
say
that
as
before
we
extend
this
interaction
to
say
the
following
l
this
assignment
simply
sets
l
is
to
a
different
object
l
still
references
the
original
list
if
we
change
this
statement
s
syntax
slightly
however
it
has
a
radically
different
effect
l
l
l
l
a
mutable
object
make
a
reference
to
the
same
object
an
in
place
change
l
l
l
is
different
but
so
is
l
really
we
haven
t
changed
l
itself
here
we
ve
changed
a
component
of
the
object
that
l
references
this
sort
of
change
overwrites
part
of
the
list
object
in
place
because
the
list
object
is
shared
by
referenced
from
other
variables
though
an
in
place
change
like
this
doesn
t
only
affect
l
that
is
you
must
be
aware
that
when
you
make
such
changes
they
can
impact
other
parts
of
your
program
in
this
example
the
effect
shows
up
in
l
as
well
because
it
references
the
same
object
as
l
again
we
haven
t
actually
changed
l
either
but
its
value
will
appear
different
because
it
has
been
overwritten
this
behavior
is
usually
what
you
want
but
you
should
be
aware
of
how
it
works
so
that
it
s
expected
it
s
also
just
the
default
if
you
don
t
want
such
behavior
you
can
request
that
python
copy
objects
instead
of
making
references
there
are
a
variety
of
ways
to
copy
a
list
including
using
the
built
in
list
function
and
the
standard
library
copy
module
perhaps
the
most
common
way
is
to
slice
from
start
to
finish
see
chapters
and
for
more
on
slicing
l
l
l
l
l
l
make
a
copy
of
l
l
is
not
changed
here
the
change
made
through
l
is
not
reflected
in
l
because
l
references
a
copy
of
the
object
l
references
that
is
the
two
variables
point
to
different
pieces
of
memory
chapter
the
dynamic
typing
interlude
note
that
this
slicing
technique
won
t
work
on
the
other
major
mutable
core
types
dictionaries
and
sets
because
they
are
not
sequences
to
copy
a
dictionary
or
set
instead
use
their
x
copy
method
call
also
note
that
the
standard
library
copy
module
has
a
call
for
copying
any
object
type
generically
as
well
as
a
call
for
copying
nested
object
structures
a
dictionary
with
nested
lists
for
example
import
copy
x
copy
copy
y
x
copy
deepcopy
y
make
top
level
shallow
copy
of
any
object
y
make
deep
copy
of
any
object
y
copy
all
nested
parts
we
ll
explore
lists
and
dictionaries
in
more
depth
and
revisit
the
concept
of
shared
references
and
copies
in
chapters
and
for
now
keep
in
mind
that
objects
that
can
be
changed
in
place
that
is
mutable
objects
are
always
open
to
these
kinds
of
effects
in
python
this
includes
lists
dictionaries
and
some
objects
defined
with
class
statements
if
this
is
not
the
desired
behavior
you
can
simply
copy
your
objects
as
needed
shared
references
and
equality
in
the
interest
of
full
disclosure
i
should
point
out
that
the
garbage
collection
behavior
described
earlier
in
this
chapter
may
be
more
conceptual
than
literal
for
certain
types
consider
these
statements
x
x
shrubbery
reclaim
now
because
python
caches
and
reuses
small
integers
and
small
strings
as
mentioned
earlier
the
object
here
is
probably
not
literally
reclaimed
instead
it
will
likely
remain
in
a
system
table
to
be
reused
the
next
time
you
generate
a
in
your
code
most
kinds
of
objects
though
are
reclaimed
immediately
when
they
are
no
longer
referenced
for
those
that
are
not
the
caching
mechanism
is
irrelevant
to
your
code
for
instance
because
of
python
s
reference
model
there
are
two
different
ways
to
check
for
equality
in
a
python
program
let
s
create
a
shared
reference
to
demonstrate
l
m
l
true
l
true
l
m
m
and
l
reference
the
same
object
same
value
is
m
same
object
the
first
technique
here
the
operator
tests
whether
the
two
referenced
objects
have
the
same
values
this
is
the
method
almost
always
used
for
equality
checks
in
python
the
second
method
the
is
operator
instead
tests
for
object
identity
it
returns
true
only
if
both
names
point
to
the
exact
same
object
so
it
is
a
much
stronger
form
of
equality
testing
shared
references
really
is
simply
compares
the
pointers
that
implement
references
and
it
serves
as
a
way
to
detect
shared
references
in
your
code
if
needed
it
returns
false
if
the
names
point
to
equivalent
but
different
objects
as
is
the
case
when
we
run
two
different
literal
expressions
l
m
l
true
l
false
m
m
and
l
reference
different
objects
same
values
is
m
different
objects
now
watch
what
happens
when
we
perform
the
same
operations
on
small
numbers
x
y
x
true
x
true
y
should
be
two
different
objects
is
y
same
object
anyhow
caching
at
work
in
this
interaction
x
and
y
should
be
same
value
but
not
is
same
object
because
we
ran
two
different
literal
expressions
because
small
integers
and
strings
are
cached
and
reused
though
is
tells
us
they
reference
the
same
single
object
in
fact
if
you
really
want
to
look
under
the
hood
you
can
always
ask
python
how
many
references
there
are
to
an
object
the
getrefcount
function
in
the
standard
sys
module
returns
the
object
s
reference
count
when
i
ask
about
the
integer
object
in
the
idle
gui
for
instance
it
reports
reuses
of
this
same
object
most
of
which
are
in
idle
s
system
code
not
mine
import
sys
sys
getrefcount
pointers
to
this
shared
piece
of
memory
this
object
caching
and
reuse
is
irrelevant
to
your
code
unless
you
run
the
is
check
because
you
cannot
change
numbers
or
strings
in
place
it
doesn
t
matter
how
many
references
there
are
to
the
same
object
still
this
behavior
reflects
one
of
the
many
ways
python
optimizes
its
model
for
execution
speed
dynamic
typing
is
everywhere
of
course
you
don
t
really
need
to
draw
name
object
diagrams
with
circles
and
arrows
to
use
python
when
you
re
starting
out
though
it
sometimes
helps
you
understand
unusual
cases
if
you
can
trace
their
reference
structures
if
a
mutable
object
changes
out
from
under
you
when
passed
around
your
program
for
example
chances
are
you
are
witnessing
some
of
this
chapter
s
subject
matter
firsthand
moreover
even
if
dynamic
typing
seems
a
little
abstract
at
this
point
you
probably
will
care
about
it
eventually
because
everything
seems
to
work
by
assignment
and
references
in
python
a
basic
understanding
of
this
model
is
useful
in
many
different
chapter
the
dynamic
typing
interlude
contexts
as
you
ll
see
it
works
the
same
in
assignment
statements
function
arguments
for
loop
variables
module
imports
class
attributes
and
more
the
good
news
is
that
there
is
just
one
assignment
model
in
python
once
you
get
a
handle
on
dynamic
typing
you
ll
find
that
it
works
the
same
everywhere
in
the
language
at
the
most
practical
level
dynamic
typing
means
there
is
less
code
for
you
to
write
just
as
importantly
though
dynamic
typing
is
also
the
root
of
python
s
polymorphism
a
concept
we
introduced
in
chapter
and
will
revisit
again
later
in
this
book
because
we
do
not
constrain
types
in
python
code
it
is
highly
flexible
as
you
ll
see
when
used
well
dynamic
typing
and
the
polymorphism
it
provides
produce
code
that
automatically
adapts
to
new
requirements
as
your
systems
evolve
chapter
summary
this
chapter
took
a
deeper
look
at
python
s
dynamic
typing
model
that
is
the
way
that
python
keeps
track
of
object
types
for
us
automatically
rather
than
requiring
us
to
code
declaration
statements
in
our
scripts
along
the
way
we
learned
how
variables
and
objects
are
associated
by
references
in
python
we
also
explored
the
idea
of
garbage
collection
learned
how
shared
references
to
objects
can
affect
multiple
variables
and
saw
how
references
impact
the
notion
of
equality
in
python
because
there
is
just
one
assignment
model
in
python
and
because
assignment
pops
up
everywhere
in
the
language
it
s
important
that
you
have
a
handle
on
the
model
before
moving
on
the
following
quiz
should
help
you
review
some
of
this
chapter
s
ideas
after
that
we
ll
resume
our
object
tour
in
the
next
chapter
with
strings
test
your
knowledge
quiz
consider
the
following
three
statements
do
they
change
the
value
printed
for
a
a
spam
b
a
b
shrubbery
consider
these
three
statements
do
they
change
the
printed
value
of
a
a
spam
b
a
b
shrubbery
how
about
these
is
a
changed
now
a
spam
b
a
b
shrubbery
test
your
knowledge
quiz
test
your
knowledge
answers
no
a
still
prints
as
spam
when
b
is
assigned
to
the
string
shrubbery
all
that
happens
is
that
the
variable
b
is
reset
to
point
to
the
new
string
object
a
and
b
initially
share
i
e
reference
point
to
the
same
single
string
object
spam
but
two
names
are
never
linked
together
in
python
thus
setting
b
to
a
different
object
has
no
effect
on
a
the
same
would
be
true
if
the
last
statement
here
was
b
b
shrubbery
by
the
way
the
concatenation
would
make
a
new
object
for
its
result
which
would
then
be
assigned
to
b
only
we
can
never
overwrite
a
string
or
number
or
tuple
in
place
because
strings
are
immutable
yes
a
now
prints
as
shrubbery
technically
we
haven
t
really
changed
either
a
or
b
instead
we
ve
changed
part
of
the
object
they
both
reference
point
to
by
overwriting
that
object
in
place
through
the
variable
b
because
a
references
the
same
object
as
b
the
update
is
reflected
in
a
as
well
no
a
still
prints
as
spam
the
in
place
assignment
through
b
has
no
effect
this
time
because
the
slice
expression
made
a
copy
of
the
list
object
before
it
was
assigned
to
b
after
the
second
assignment
statement
there
are
two
different
list
objects
that
have
the
same
value
in
python
we
say
they
are
but
not
is
the
third
statement
changes
the
value
of
the
list
object
pointed
to
by
b
but
not
that
pointed
to
by
a
chapter
the
dynamic
typing
interlude
chapter
strings
the
next
major
type
on
our
built
in
object
tour
is
the
python
string
an
ordered
collection
of
characters
used
to
store
and
represent
text
based
information
we
looked
briefly
at
strings
in
chapter
here
we
will
revisit
them
in
more
depth
filling
in
some
of
the
details
we
skipped
then
from
a
functional
perspective
strings
can
be
used
to
represent
just
about
anything
that
can
be
encoded
as
text
symbols
and
words
e
g
your
name
contents
of
text
files
loaded
into
memory
internet
addresses
python
programs
and
so
on
they
can
also
be
used
to
hold
the
absolute
binary
values
of
bytes
and
multibyte
unicode
text
used
in
internationalized
programs
you
may
have
used
strings
in
other
languages
too
python
s
strings
serve
the
same
role
as
character
arrays
in
languages
such
as
c
but
they
are
a
somewhat
higher
level
tool
than
arrays
unlike
in
c
in
python
strings
come
with
a
powerful
set
of
processing
tools
also
unlike
languages
such
as
c
python
has
no
distinct
type
for
individual
characters
instead
you
just
use
one
character
strings
strictly
speaking
python
strings
are
categorized
as
immutable
sequences
meaning
that
the
characters
they
contain
have
a
left
to
right
positional
order
and
that
they
cannot
be
changed
in
place
in
fact
strings
are
the
first
representative
of
the
larger
class
of
objects
called
sequences
that
we
will
study
here
pay
special
attention
to
the
sequence
operations
introduced
in
this
chapter
because
they
will
work
the
same
on
other
sequence
types
we
ll
explore
later
such
as
lists
and
tuples
table
previews
common
string
literals
and
operations
we
will
discuss
in
this
chapter
empty
strings
are
written
as
a
pair
of
quotation
marks
single
or
double
with
nothing
in
between
and
there
are
a
variety
of
ways
to
code
strings
for
processing
strings
support
expression
operations
such
as
concatenation
combining
strings
slicing
extracting
sections
indexing
fetching
by
offset
and
so
on
besides
expressions
python
also
provides
a
set
of
string
methods
that
implement
common
string
specific
tasks
as
well
as
modules
for
more
advanced
text
processing
tasks
such
as
pattern
matching
we
ll
explore
all
of
these
later
in
the
chapter
table
common
string
literals
and
operations
operation
interpretation
s
empty
string
s
spam
s
double
quotes
same
as
single
s
s
np
ta
x
m
escape
sequences
s
triple
quoted
block
strings
s
r
temp
spam
raw
strings
s
b
spam
byte
strings
in
chapter
s
u
spam
unicode
strings
in
only
chapter
s
s
concatenate
repeat
s
s
i
index
slice
length
s
i
j
len
s
a
s
parrot
kind
string
formatting
expression
a
parrot
format
kind
string
formatting
method
in
and
s
find
pa
string
method
calls
search
s
rstrip
remove
whitespace
s
replace
pa
xx
replacement
s
split
split
on
delimiter
s
isdigit
content
test
s
lower
case
conversion
s
endswith
spam
end
test
spam
join
strlist
delimiter
join
s
encode
latin
unicode
encoding
etc
for
x
in
s
print
x
iteration
membership
spam
in
s
c
for
c
in
s
map
ord
s
beyond
the
core
set
of
string
tools
in
table
python
also
supports
more
advanced
pattern
based
string
processing
with
the
standard
library
s
re
regular
expression
module
introduced
in
chapter
and
even
higher
level
text
processing
tools
such
as
xml
parsers
discussed
briefly
in
chapter
this
book
s
scope
though
is
focused
on
the
fundamentals
represented
by
table
chapter
strings
to
cover
the
basics
this
chapter
begins
with
an
overview
of
string
literal
forms
and
string
expressions
then
moves
on
to
look
at
more
advanced
tools
such
as
string
methods
and
formatting
python
comes
with
many
string
tools
and
we
won
t
look
at
them
all
here
the
complete
story
is
chronicled
in
the
python
library
manual
our
goal
here
is
to
explore
enough
commonly
used
tools
to
give
you
a
representative
sample
methods
we
won
t
see
in
action
here
for
example
are
largely
analogous
to
those
we
will
content
note
technically
speaking
this
chapter
tells
only
part
of
the
string
story
in
python
the
part
most
programmers
need
to
know
it
presents
the
basic
str
string
type
which
handles
ascii
text
and
works
the
same
regardless
of
which
version
of
python
you
use
that
is
this
chapter
intentionally
limits
its
scope
to
the
string
processing
essentials
that
are
used
in
most
python
scripts
from
a
more
formal
perspective
ascii
is
a
simple
form
of
unicode
text
python
addresses
the
distinction
between
text
and
binary
data
by
including
distinct
object
types
in
python
there
are
three
string
types
str
is
used
for
unicode
text
ascii
or
otherwise
bytes
is
used
for
binary
data
including
encoded
text
and
bytearray
is
a
mutable
variant
of
bytes
in
python
unicode
strings
represent
wide
unicode
text
and
str
strings
handle
both
bit
text
and
binary
data
the
bytearray
type
is
also
available
as
a
back
port
in
but
not
earlier
and
it
s
not
as
closely
bound
to
binary
data
as
it
is
in
because
most
programmers
don
t
need
to
dig
into
the
details
of
unicode
encodings
or
binary
data
formats
though
i
ve
moved
all
such
details
to
the
advanced
topics
part
of
this
book
in
chapter
if
you
do
need
to
deal
with
more
advanced
string
concepts
such
as
alternative
character
sets
or
packed
binary
data
and
files
see
chapter
after
reading
the
material
here
for
now
we
ll
focus
on
the
basic
string
type
and
its
operations
as
you
ll
find
the
basics
we
ll
study
here
also
apply
directly
to
the
more
advanced
string
types
in
python
s
toolset
string
literals
by
and
large
strings
are
fairly
easy
to
use
in
python
perhaps
the
most
complicated
thing
about
them
is
that
there
are
so
many
ways
to
write
them
in
your
code
single
quotes
spa
m
double
quotes
spa
m
triple
quotes
spam
spam
escape
sequences
s
tp
na
m
raw
strings
r
c
new
test
spm
string
literals
byte
strings
in
see
chapter
b
sp
x
am
unicode
strings
in
only
see
chapter
u
eggs
u
spam
the
single
and
double
quoted
forms
are
by
far
the
most
common
the
others
serve
specialized
roles
and
we
re
postponing
discussion
of
the
last
two
advanced
forms
until
chapter
let
s
take
a
quick
look
at
all
the
other
options
in
turn
single
and
double
quoted
strings
are
the
same
around
python
strings
single
and
double
quote
characters
are
interchangeable
that
is
string
literals
can
be
written
enclosed
in
either
two
single
or
two
double
quotes
the
two
forms
work
the
same
and
return
the
same
type
of
object
for
example
the
following
two
strings
are
identical
once
coded
shrubbery
shrubbery
shrubbery
shrubbery
the
reason
for
supporting
both
is
that
it
allows
you
to
embed
a
quote
character
of
the
other
variety
inside
a
string
without
escaping
it
with
a
backslash
you
may
embed
a
single
quote
character
in
a
string
enclosed
in
double
quote
characters
and
vice
versa
knight
s
knight
s
knight
s
knight
s
incidentally
python
automatically
concatenates
adjacent
string
literals
in
any
expression
although
it
is
almost
as
simple
to
add
a
operator
between
them
to
invoke
concatenation
explicitly
as
we
ll
see
in
chapter
wrapping
this
form
in
parentheses
also
allows
it
to
span
multiple
lines
title
meaning
of
life
title
meaning
of
life
implicit
concatenation
notice
that
adding
commas
between
these
strings
would
result
in
a
tuple
not
a
string
also
notice
in
all
of
these
outputs
that
python
prefers
to
print
strings
in
single
quotes
unless
they
embed
one
you
can
also
embed
quotes
by
escaping
them
with
backslashes
knight
s
knight
s
knight
s
knight
s
to
understand
why
you
need
to
know
how
escapes
work
in
general
escape
sequences
represent
special
bytes
the
last
example
embedded
a
quote
inside
a
string
by
preceding
it
with
a
backslash
this
is
representative
of
a
general
pattern
in
strings
backslashes
are
used
to
introduce
special
byte
codings
known
as
escape
sequences
escape
sequences
let
us
embed
byte
codes
in
strings
that
cannot
easily
be
typed
on
a
keyboard
the
character
and
one
or
more
characters
following
it
in
the
string
literal
are
replaced
with
a
single
character
in
the
resulting
string
object
which
has
the
binary
chapter
strings
value
specified
by
the
escape
sequence
for
example
here
is
a
five
character
string
that
embeds
a
newline
and
a
tab
s
a
nb
tc
the
two
characters
n
stand
for
a
single
character
the
byte
containing
the
binary
value
of
the
newline
character
in
your
character
set
usually
ascii
code
similarly
the
sequence
t
is
replaced
with
the
tab
character
the
way
this
string
looks
when
printed
depends
on
how
you
print
it
the
interactive
echo
shows
the
special
characters
as
escapes
but
print
interprets
them
instead
s
a
nb
tc
print
s
a
b
c
to
be
completely
sure
how
many
bytes
are
in
this
string
use
the
built
in
len
function
it
returns
the
actual
number
of
bytes
in
a
string
regardless
of
how
it
is
displayed
len
s
this
string
is
five
bytes
long
it
contains
an
ascii
a
byte
a
newline
byte
an
ascii
b
byte
and
so
on
note
that
the
original
backslash
characters
are
not
really
stored
with
the
string
in
memory
they
are
used
to
tell
python
to
store
special
byte
values
in
the
string
for
coding
such
special
bytes
python
recognizes
a
full
set
of
escape
code
sequences
listed
in
table
table
string
backslash
characters
escape
meaning
newline
ignored
continuation
line
backslash
stores
one
single
quote
stores
double
quote
stores
a
bell
b
backspace
f
formfeed
n
newline
linefeed
r
carriage
return
t
horizontal
tab
v
vertical
tab
xhh
character
with
hex
value
hh
at
most
digits
ooo
character
with
octal
value
ooo
up
to
digits
null
binary
character
doesn
t
end
string
string
literals
a
escape
meaning
n
id
unicode
database
id
uhhhh
unicode
bit
hex
uhhhhhhhh
unicode
bit
hexa
other
not
an
escape
keeps
both
and
other
the
uhhhh
escape
sequence
takes
exactly
eight
hexadecimal
digits
h
both
u
and
u
can
be
used
only
in
unicode
string
literals
some
escape
sequences
allow
you
to
embed
absolute
binary
values
into
the
bytes
of
a
string
for
instance
here
s
a
five
character
string
that
embeds
two
binary
zero
bytes
coded
as
octal
escapes
of
one
digit
s
a
b
c
s
a
x
b
x
c
len
s
in
python
the
zero
null
byte
does
not
terminate
a
string
the
way
it
typically
does
in
c
instead
python
keeps
both
the
string
s
length
and
text
in
memory
in
fact
no
character
terminates
a
string
in
python
here
s
a
string
that
is
all
absolute
binary
escape
codes
a
binary
and
coded
in
octal
followed
by
a
binary
coded
in
hexadecimal
s
x
s
x
x
x
len
s
notice
that
python
displays
nonprintable
characters
in
hex
regardless
of
how
they
were
specified
you
can
freely
combine
absolute
value
escapes
and
the
more
symbolic
escape
types
in
table
the
following
string
contains
the
characters
spam
a
tab
and
newline
and
an
absolute
zero
value
byte
coded
in
hex
s
s
tp
na
x
m
s
s
tp
na
x
m
len
s
print
s
s
p
a
m
this
becomes
more
important
to
know
when
you
process
binary
data
files
in
python
because
their
contents
are
represented
as
strings
in
your
scripts
it
s
ok
to
process
binary
files
that
contain
any
sorts
of
binary
byte
values
more
on
files
in
chapter
if
you
need
to
care
about
binary
data
files
the
chief
distinction
is
that
you
open
them
in
binary
mode
using
open
mode
flags
with
a
b
such
as
rb
wb
and
so
on
in
python
binary
file
content
is
a
bytes
string
with
an
interface
similar
to
that
of
normal
strings
in
such
content
is
a
normal
str
string
see
also
the
standard
struct
module
introduced
in
chapter
which
can
parse
binary
data
loaded
from
a
file
and
the
extended
coverage
of
binary
files
and
byte
strings
in
chapter
chapter
strings
finally
as
the
last
entry
in
table
implies
if
python
does
not
recognize
the
character
after
a
as
being
a
valid
escape
code
it
simply
keeps
the
backslash
in
the
resulting
string
x
c
py
code
x
c
py
code
len
x
keeps
literally
unless
you
re
able
to
commit
all
of
table
to
memory
though
you
probably
shouldn
t
rely
on
this
behavior
to
code
literal
backslashes
explicitly
such
that
they
are
retained
in
your
strings
double
them
up
is
an
escape
for
one
or
use
raw
strings
the
next
section
shows
how
raw
strings
suppress
escapes
as
we
ve
seen
escape
sequences
are
handy
for
embedding
special
byte
codes
within
strings
sometimes
though
the
special
treatment
of
backslashes
for
introducing
escapes
can
lead
to
trouble
it
s
surprisingly
common
for
instance
to
see
python
newcomers
in
classes
trying
to
open
a
file
with
a
filename
argument
that
looks
something
like
this
myfile
open
c
new
text
dat
w
thinking
that
they
will
open
a
file
called
text
dat
in
the
directory
c
new
the
problem
here
is
that
n
is
taken
to
stand
for
a
newline
character
and
t
is
replaced
with
a
tab
in
effect
the
call
tries
to
open
a
file
named
c
newline
ew
tab
ext
dat
with
usually
less
than
stellar
results
this
is
just
the
sort
of
thing
that
raw
strings
are
useful
for
if
the
letter
r
uppercase
or
lowercase
appears
just
before
the
opening
quote
of
a
string
it
turns
off
the
escape
mechanism
the
result
is
that
python
retains
your
backslashes
literally
exactly
as
you
type
them
therefore
to
fix
the
filename
problem
just
remember
to
add
the
letter
r
on
windows
myfile
open
r
c
new
text
dat
w
alternatively
because
two
backslashes
are
really
an
escape
sequence
for
one
backslash
you
can
keep
your
backslashes
by
simply
doubling
them
up
myfile
open
c
new
text
dat
w
in
fact
python
itself
sometimes
uses
this
doubling
scheme
when
it
prints
strings
with
embedded
backslashes
path
r
c
new
text
dat
path
c
new
text
dat
print
path
show
as
python
code
user
friendly
format
in
classes
i
ve
met
people
who
have
indeed
committed
most
or
all
of
this
table
to
memory
i
d
probably
think
that
was
really
sick
but
for
the
fact
that
i
m
a
member
of
the
set
too
string
literals
c
new
text
dat
len
path
string
length
as
with
numeric
representation
the
default
format
at
the
interactive
prompt
prints
results
as
if
they
were
code
and
therefore
escapes
backslashes
in
the
output
the
print
statement
provides
a
more
user
friendly
format
that
shows
that
there
is
actually
only
one
backslash
in
each
spot
to
verify
this
is
the
case
you
can
check
the
result
of
the
built
in
len
function
which
returns
the
number
of
bytes
in
the
string
independent
of
display
formats
if
you
count
the
characters
in
the
print
path
output
you
ll
see
that
there
really
is
just
character
per
backslash
for
a
total
of
besides
directory
paths
on
windows
raw
strings
are
also
commonly
used
for
regular
expressions
text
pattern
matching
supported
with
the
re
module
introduced
in
chapter
also
note
that
python
scripts
can
usually
use
forward
slashes
in
directory
paths
on
windows
and
unix
because
python
tries
to
interpret
paths
portably
i
e
c
new
text
dat
works
when
opening
files
too
raw
strings
are
useful
if
you
code
paths
using
native
windows
backslashes
though
despite
its
role
even
a
raw
string
cannot
end
in
a
single
backslash
because
the
backslash
escapes
the
following
quote
character
you
still
must
escape
the
surrounding
quote
character
to
embed
it
in
the
string
that
is
r
is
not
a
valid
string
literal
a
raw
string
cannot
end
in
an
odd
number
of
backslashes
if
you
need
to
end
a
raw
string
with
a
single
backslash
you
can
use
two
and
slice
off
the
second
r
nb
tc
tack
one
on
manually
r
nb
tc
or
skip
the
raw
string
syntax
and
just
double
up
the
backslashes
in
a
normal
string
nb
tc
all
three
of
these
forms
create
the
same
eightcharacter
string
containing
three
backslashes
triple
quotes
code
multiline
block
strings
so
far
you
ve
seen
single
quotes
double
quotes
escapes
and
raw
strings
in
action
python
also
has
a
triple
quoted
string
literal
format
sometimes
called
a
block
string
that
is
a
syntactic
convenience
for
coding
multiline
text
data
this
form
begins
with
three
quotes
of
either
the
single
or
double
variety
is
followed
by
any
number
of
lines
of
text
and
is
closed
with
the
same
triple
quote
sequence
that
opened
it
single
and
double
quotes
embedded
in
the
string
s
text
may
be
but
do
not
have
to
be
escaped
the
string
does
not
end
until
python
sees
three
unescaped
quotes
of
the
same
kind
used
to
start
the
literal
for
example
mantra
always
look
on
the
bright
side
of
life
mantra
always
look
n
on
the
bright
nside
of
life
chapter
strings
this
string
spans
three
lines
in
some
interfaces
the
interactive
prompt
changes
to
on
continuation
lines
idle
simply
drops
down
one
line
python
collects
all
the
triple
quoted
text
into
a
single
multiline
string
with
embedded
newline
characters
n
at
the
places
where
your
code
has
line
breaks
notice
that
as
in
the
literal
the
second
line
in
the
result
has
a
leading
space
but
the
third
does
not
what
you
type
is
truly
what
you
get
to
see
the
string
with
the
newlines
interpreted
print
it
instead
of
echoing
print
mantra
always
look
on
the
bright
side
of
life
triple
quoted
strings
are
useful
any
time
you
need
multiline
text
in
your
program
for
example
to
embed
multiline
error
messages
or
html
or
xml
code
in
your
source
code
files
you
can
embed
such
blocks
directly
in
your
scripts
without
resorting
to
external
text
files
or
explicit
concatenation
and
newline
characters
triple
quoted
strings
are
also
commonly
used
for
documentation
strings
which
are
string
literals
that
are
taken
as
comments
when
they
appear
at
specific
points
in
your
file
more
on
these
later
in
the
book
these
don
t
have
to
be
triple
quoted
blocks
but
they
usually
are
to
allow
for
multiline
comments
finally
triple
quoted
strings
are
also
sometimes
used
as
a
horribly
hackish
way
to
temporarily
disable
lines
of
code
during
development
ok
it
s
not
really
too
horrible
and
it
s
actually
a
fairly
common
practice
if
you
wish
to
turn
off
a
few
lines
of
code
and
run
your
script
again
simply
put
three
quotes
above
and
below
them
like
this
x
import
os
print
os
getcwd
y
disable
this
code
temporarily
i
said
this
was
hackish
because
python
really
does
make
a
string
out
of
the
lines
of
code
disabled
this
way
but
this
is
probably
not
significant
in
terms
of
performance
for
large
sections
of
code
it
s
also
easier
than
manually
adding
hash
marks
before
each
line
and
later
removing
them
this
is
especially
true
if
you
are
using
a
text
editor
that
does
not
have
support
for
editing
python
code
specifically
in
python
practicality
often
beats
aesthetics
strings
in
action
once
you
ve
created
a
string
with
the
literal
expressions
we
just
met
you
will
almost
certainly
want
to
do
things
with
it
this
section
and
the
next
two
demonstrate
string
expressions
methods
and
formatting
the
first
line
of
text
processing
tools
in
the
python
language
strings
in
action
basic
operations
let
s
begin
by
interacting
with
the
python
interpreter
to
illustrate
the
basic
string
operations
listed
earlier
in
table
strings
can
be
concatenated
using
the
operator
and
repeated
using
the
operator
python
len
abc
abc
def
abcdef
ni
ni
ni
ni
ni
length
number
of
items
concatenation
a
new
string
repetition
like
ni
ni
formally
adding
two
string
objects
creates
a
new
string
object
with
the
contents
of
its
operands
joined
repetition
is
like
adding
a
string
to
itself
a
number
of
times
in
both
cases
python
lets
you
create
arbitrarily
sized
strings
there
s
no
need
to
predeclare
anything
in
python
including
the
sizes
of
data
structures
the
len
built
in
function
returns
the
length
of
a
string
or
any
other
object
with
a
length
repetition
may
seem
a
bit
obscure
at
first
but
it
comes
in
handy
in
a
surprising
number
of
contexts
for
example
to
print
a
line
of
dashes
you
can
count
up
to
or
let
python
count
for
you
print
more
print
dashes
the
hard
way
dashes
the
easy
way
notice
that
operator
overloading
is
at
work
here
already
we
re
using
the
same
and
operators
that
perform
addition
and
multiplication
when
using
numbers
python
does
the
correct
operation
because
it
knows
the
types
of
the
objects
being
added
and
multiplied
but
be
careful
the
rules
aren
t
quite
as
liberal
as
you
might
expect
for
instance
python
doesn
t
allow
you
to
mix
numbers
and
strings
in
expressions
abc
raises
an
error
instead
of
automatically
converting
to
a
string
as
shown
in
the
last
row
in
table
you
can
also
iterate
over
strings
in
loops
using
for
statements
and
test
membership
for
both
characters
and
substrings
with
the
in
expression
operator
which
is
essentially
a
search
for
substrings
in
is
much
like
the
str
find
method
covered
later
in
this
chapter
but
it
returns
a
boolean
result
instead
of
the
substring
s
position
myjob
hacker
for
c
in
myjob
print
c
end
step
through
items
unlike
with
c
character
arrays
you
don
t
need
to
allocate
or
manage
storage
arrays
when
using
python
strings
you
can
simply
create
string
objects
as
needed
and
let
python
manage
the
underlying
memory
space
as
discussed
in
chapter
python
reclaims
unused
objects
memory
space
automatically
using
a
referencecount
garbage
collection
strategy
each
object
keeps
track
of
the
number
of
names
data
structures
etc
that
reference
it
when
the
count
reaches
zero
python
frees
the
object
s
space
this
scheme
means
python
doesn
t
have
to
stop
and
scan
all
the
memory
to
find
unused
space
to
free
an
additional
garbage
component
also
collects
cyclic
objects
chapter
strings
h
a
c
k
e
r
k
in
myjob
true
z
in
myjob
false
spam
in
abcspamdef
true
found
not
found
substring
search
no
position
returned
the
for
loop
assigns
a
variable
to
successive
items
in
a
sequence
here
a
string
and
executes
one
or
more
statements
for
each
item
in
effect
the
variable
c
becomes
a
cursor
stepping
across
the
string
here
we
will
discuss
iteration
tools
like
these
and
others
listed
in
table
in
more
detail
later
in
this
book
especially
in
chapters
and
indexing
and
slicing
because
strings
are
defined
as
ordered
collections
of
characters
we
can
access
their
components
by
position
in
python
characters
in
a
string
are
fetched
by
indexing
providing
the
numeric
offset
of
the
desired
component
in
square
brackets
after
the
string
you
get
back
the
one
character
string
at
the
specified
position
as
in
the
c
language
python
offsets
start
at
and
end
at
one
less
than
the
length
of
the
string
unlike
c
however
python
also
lets
you
fetch
items
from
sequences
such
as
strings
using
negative
offsets
technically
a
negative
offset
is
added
to
the
length
of
a
string
to
derive
a
positive
offset
you
can
also
think
of
negative
offsets
as
counting
backward
from
the
end
the
following
interaction
demonstrates
s
spam
s
s
s
a
s
s
s
pa
pam
spa
indexing
from
front
or
end
slicing
extract
a
section
the
first
line
defines
a
four
character
string
and
assigns
it
the
name
s
the
next
line
indexes
it
in
two
ways
s
fetches
the
item
at
offset
from
the
left
the
one
character
string
s
and
s
gets
the
item
at
offset
back
from
the
end
or
equivalently
at
offset
from
the
front
offsets
and
slices
map
to
cells
as
shown
in
figure
the
last
line
in
the
preceding
example
demonstrates
slicing
a
generalized
form
of
indexing
that
returns
an
entire
section
not
a
single
item
probably
the
best
way
to
think
of
slicing
is
that
it
is
a
type
of
parsing
analyzing
structure
especially
when
applied
to
strings
it
allows
us
to
extract
an
entire
section
substring
in
a
single
step
slices
can
be
used
to
extract
columns
of
data
chop
off
leading
and
trailing
text
and
more
in
fact
we
ll
explore
slicing
in
the
context
of
text
parsing
later
in
this
chapter
the
basics
of
slicing
are
straightforward
when
you
index
a
sequence
object
such
as
a
string
on
a
pair
of
offsets
separated
by
a
colon
python
returns
a
new
object
containing
more
mathematically
minded
readers
and
students
in
my
classes
sometimes
detect
a
small
asymmetry
here
the
leftmost
item
is
at
offset
but
the
rightmost
is
at
offset
alas
there
is
no
such
thing
as
a
distinct
value
in
python
strings
in
action
figure
offsets
and
slices
positive
offsets
start
from
the
left
end
offset
is
the
first
item
and
negatives
count
back
from
the
right
end
offset
is
the
last
item
either
kind
of
offset
can
be
used
to
give
positions
in
indexing
and
slicing
operations
the
contiguous
section
identified
by
the
offset
pair
the
left
offset
is
taken
to
be
the
lower
bound
inclusive
and
the
right
is
the
upper
bound
noninclusive
that
is
python
fetches
all
items
from
the
lower
bound
up
to
but
not
including
the
upper
bound
and
returns
a
new
object
containing
the
fetched
items
if
omitted
the
left
and
right
bounds
default
to
and
the
length
of
the
object
you
are
slicing
respectively
for
instance
in
the
example
we
just
saw
s
extracts
the
items
at
offsets
and
it
grabs
the
second
and
third
items
and
stops
before
the
fourth
item
at
offset
next
s
gets
all
items
beyond
the
first
the
upper
bound
which
is
not
specified
defaults
to
the
length
of
the
string
finally
s
fetches
all
but
the
last
item
the
lower
bound
defaults
to
and
refers
to
the
last
item
noninclusive
this
may
seem
confusing
at
first
glance
but
indexing
and
slicing
are
simple
and
powerful
tools
to
use
once
you
get
the
knack
remember
if
you
re
unsure
about
the
effects
of
a
slice
try
it
out
interactively
in
the
next
chapter
you
ll
see
that
it
s
even
possible
to
change
an
entire
section
of
another
object
in
one
step
by
assigning
to
a
slice
though
not
for
immutables
like
strings
here
s
a
summary
of
the
details
for
reference
indexing
s
i
fetches
components
at
offsets
the
first
item
is
at
offset
negative
indexes
mean
to
count
backward
from
the
end
or
right
s
fetches
the
first
item
s
fetches
the
second
item
from
the
end
like
s
len
s
slicing
s
i
j
extracts
contiguous
sections
of
sequences
the
upper
bound
is
noninclusive
slice
boundaries
default
to
and
the
sequence
length
if
omitted
s
fetches
items
at
offsets
up
to
but
not
including
s
fetches
items
at
offset
through
the
end
the
sequence
length
chapter
strings
s
fetches
items
at
offset
up
to
but
not
including
s
fetches
items
at
offset
up
to
but
not
including
the
last
item
s
fetches
items
at
offsets
through
the
end
this
effectively
performs
a
toplevel
copy
of
s
the
last
item
listed
here
turns
out
to
be
a
very
common
trick
it
makes
a
full
top
level
copy
of
a
sequence
object
an
object
with
the
same
value
but
a
distinct
piece
of
memory
you
ll
find
more
on
copies
in
chapter
this
isn
t
very
useful
for
immutable
objects
like
strings
but
it
comes
in
handy
for
objects
that
may
be
changed
in
place
such
as
lists
in
the
next
chapter
you
ll
see
that
the
syntax
used
to
index
by
offset
square
brackets
is
used
to
index
dictionaries
by
key
as
well
the
operations
look
the
same
but
have
different
interpretations
extended
slicing
the
third
limit
and
slice
objects
in
python
and
later
slice
expressions
have
support
for
an
optional
third
index
used
as
a
step
sometimes
called
a
stride
the
step
is
added
to
the
index
of
each
item
extracted
the
full
blown
form
of
a
slice
is
now
x
i
j
k
which
means
extract
all
the
items
in
x
from
offset
i
through
j
by
k
the
third
limit
k
defaults
to
which
is
why
normally
all
items
in
a
slice
are
extracted
from
left
to
right
if
you
specify
an
explicit
value
however
you
can
use
the
third
limit
to
skip
items
or
to
reverse
their
order
for
instance
x
will
fetch
every
other
item
in
x
from
offsets
that
is
it
will
collect
the
items
at
offsets
and
as
usual
the
first
and
second
limits
default
to
and
the
length
of
the
sequence
respectively
so
x
gets
every
other
item
from
the
beginning
to
the
end
of
the
sequence
s
abcdefghijklmnop
s
bdfhj
s
acegikmo
you
can
also
use
a
negative
stride
for
example
the
slicing
expression
hello
returns
the
new
string
olleh
the
first
two
bounds
default
to
and
the
length
of
the
sequence
as
before
and
a
stride
of
indicates
that
the
slice
should
go
from
right
to
left
instead
of
the
usual
left
to
right
the
effect
therefore
is
to
reverse
the
sequence
s
hello
s
olleh
with
a
negative
stride
the
meanings
of
the
first
two
bounds
are
essentially
reversed
that
is
the
slice
s
fetches
the
items
from
to
in
reverse
order
the
result
contains
items
from
offsets
and
strings
in
action
s
abcedfg
s
fdec
skipping
and
reversing
like
this
are
the
most
common
use
cases
for
three
limit
slices
but
see
python
s
standard
library
manual
for
more
details
or
run
a
few
experiments
interactively
we
ll
revisit
three
limit
slices
again
later
in
this
book
in
conjunction
with
the
for
loop
statement
later
in
the
book
we
ll
also
learn
that
slicing
is
equivalent
to
indexing
with
a
slice
object
a
finding
of
importance
to
class
writers
seeking
to
support
both
operations
spam
pa
spam
slice
pa
spam
maps
spam
slice
none
none
maps
slicing
syntax
slice
objects
why
you
will
care
slices
throughout
this
book
i
will
include
common
use
case
sidebars
such
as
this
one
to
give
you
a
peek
at
how
some
of
the
language
features
being
introduced
are
typically
used
in
real
programs
because
you
won
t
be
able
to
make
much
sense
of
real
use
cases
until
you
ve
seen
more
of
the
python
picture
these
sidebars
necessarily
contain
many
references
to
topics
not
introduced
yet
at
most
you
should
consider
them
previews
of
ways
that
you
may
find
these
abstract
language
concepts
useful
for
common
programming
tasks
for
instance
you
ll
see
later
that
the
argument
words
listed
on
a
system
command
line
used
to
launch
a
python
program
are
made
available
in
the
argv
attribute
of
the
builtin
sys
module
file
echo
py
import
sys
print
sys
argv
python
echo
py
a
b
c
echo
py
a
b
c
usually
you
re
only
interested
in
inspecting
the
arguments
that
follow
the
program
name
this
leads
to
a
very
typical
application
of
slices
a
single
slice
expression
can
be
used
to
return
all
but
the
first
item
of
a
list
here
sys
argv
returns
the
desired
list
a
b
c
you
can
then
process
this
list
without
having
to
accommodate
the
program
name
at
the
front
slices
are
also
often
used
to
clean
up
lines
read
from
input
files
if
you
know
that
a
line
will
have
an
end
of
line
character
at
the
end
a
n
newline
marker
you
can
get
rid
of
it
with
a
single
expression
such
as
line
which
extracts
all
but
the
last
character
in
the
line
the
lower
limit
defaults
to
in
both
cases
slices
do
the
job
of
logic
that
must
be
explicit
in
a
lower
level
language
chapter
strings
note
that
calling
the
line
rstrip
method
is
often
preferred
for
stripping
newline
characters
because
this
call
leaves
the
line
intact
if
it
has
no
newline
character
at
the
end
a
common
case
for
files
created
with
some
text
editing
tools
slicing
works
if
you
re
sure
the
line
is
properly
terminated
string
conversion
tools
one
of
python
s
design
mottos
is
that
it
refuses
the
temptation
to
guess
as
a
prime
example
you
cannot
add
a
number
and
a
string
together
in
python
even
if
the
string
looks
like
a
number
i
e
is
all
digits
typeerror
cannot
concatenate
str
and
int
objects
this
is
by
design
because
can
mean
both
addition
and
concatenation
the
choice
of
conversion
would
be
ambiguous
so
python
treats
this
as
an
error
in
python
magic
is
generally
omitted
if
it
will
make
your
life
more
complex
what
to
do
then
if
your
script
obtains
a
number
as
a
text
string
from
a
file
or
user
interface
the
trick
is
that
you
need
to
employ
conversion
tools
before
you
can
treat
a
string
like
a
number
or
vice
versa
for
instance
int
str
repr
convert
from
to
string
convert
to
as
code
string
the
int
function
converts
a
string
to
a
number
and
the
str
function
converts
a
number
to
its
string
representation
essentially
what
it
looks
like
when
printed
the
repr
function
and
the
older
backquotes
expression
removed
in
python
also
converts
an
object
to
its
string
representation
but
returns
the
object
as
a
string
of
code
that
can
be
rerun
to
recreate
the
object
for
strings
the
result
has
quotes
around
it
if
displayed
with
a
print
statement
print
str
spam
repr
spam
spam
spam
see
the
sidebar
str
and
repr
display
formats
on
page
for
more
on
this
topic
of
these
int
and
str
are
the
generally
prescribed
conversion
techniques
now
although
you
can
t
mix
strings
and
number
types
around
operators
such
as
you
can
manually
convert
operands
before
that
operation
if
needed
s
i
s
i
typeerror
cannot
concatenate
str
and
int
objects
int
s
i
force
addition
strings
in
action
s
str
i
force
concatenation
similar
built
in
functions
handle
floating
point
number
conversions
to
and
from
strings
str
float
text
e
float
text
e
later
we
ll
further
study
the
built
in
eval
function
it
runs
a
string
containing
python
expression
code
and
so
can
convert
a
string
to
any
kind
of
object
the
functions
int
and
float
convert
only
to
numbers
but
this
restriction
means
they
are
usually
faster
and
more
secure
because
they
do
not
accept
arbitrary
expression
code
as
we
saw
briefly
in
chapter
the
string
formatting
expression
also
provides
a
way
to
convert
numbers
to
strings
we
ll
discuss
formatting
further
later
in
this
chapter
character
code
conversions
on
the
subject
of
conversions
it
is
also
possible
to
convert
a
single
character
to
its
underlying
ascii
integer
code
by
passing
it
to
the
built
in
ord
function
this
returns
the
actual
binary
value
of
the
corresponding
byte
in
memory
the
chr
function
performs
the
inverse
operation
taking
an
ascii
integer
code
and
converting
it
to
the
corresponding
character
ord
s
chr
s
you
can
use
a
loop
to
apply
these
functions
to
all
characters
in
a
string
these
tools
can
also
be
used
to
perform
a
sort
of
string
based
math
to
advance
to
the
next
character
for
example
convert
and
do
the
math
in
integer
s
s
chr
ord
s
s
s
chr
ord
s
s
at
least
for
single
character
strings
this
provides
an
alternative
to
using
the
built
in
int
function
to
convert
from
string
to
integer
int
ord
ord
chapter
strings
such
conversions
can
be
used
in
conjunction
with
looping
statements
introduced
in
chapter
and
covered
in
depth
in
the
next
part
of
this
book
to
convert
a
string
of
binary
digits
to
their
corresponding
integer
values
each
time
through
the
loop
multiply
the
current
value
by
and
add
the
next
digit
s
integer
value
b
convert
binary
digits
to
integer
with
ord
i
while
b
i
i
ord
b
ord
b
b
i
a
left
shift
operation
i
would
have
the
same
effect
as
multiplying
by
here
we
ll
leave
this
change
as
a
suggested
exercise
though
both
because
we
haven
t
studied
loops
in
detail
yet
and
because
the
int
and
bin
built
ins
we
met
in
chapter
handle
binary
conversion
tasks
for
us
in
python
and
int
bin
b
convert
binary
to
integer
built
in
convert
integer
to
binary
given
enough
time
python
tends
to
automate
most
common
tasks
changing
strings
remember
the
term
immutable
sequence
the
immutable
part
means
that
you
can
t
change
a
string
in
place
e
g
by
assigning
to
an
index
s
spam
s
x
raises
an
error
so
how
do
you
modify
text
information
in
python
to
change
a
string
you
need
to
build
and
assign
a
new
string
using
tools
such
as
concatenation
and
slicing
and
then
if
desired
assign
the
result
back
to
the
string
s
original
name
s
s
spam
to
change
a
string
make
a
new
one
s
spamspam
s
s
burger
s
s
spamburger
the
first
example
adds
a
substring
at
the
end
of
s
by
concatenation
really
it
makes
a
new
string
and
assigns
it
back
to
s
but
you
can
think
of
this
as
changing
the
original
string
the
second
example
replaces
four
characters
with
six
by
slicing
indexing
and
concatenating
as
you
ll
see
in
the
next
section
you
can
achieve
similar
effects
with
string
method
calls
like
replace
strings
in
action
s
splot
s
s
replace
pl
pamal
s
spamalot
like
every
operation
that
yields
a
new
string
value
string
methods
generate
new
string
objects
if
you
want
to
retain
those
objects
you
can
assign
them
to
variable
names
generating
a
new
string
object
for
each
string
change
is
not
as
inefficient
as
it
may
sound
remember
as
discussed
in
the
preceding
chapter
python
automatically
garbage
collects
reclaims
the
space
of
old
unused
string
objects
as
you
go
so
newer
objects
reuse
the
space
held
by
prior
values
python
is
usually
more
efficient
than
you
might
expect
finally
it
s
also
possible
to
build
up
new
text
values
with
string
formatting
expressions
both
of
the
following
substitute
objects
into
a
string
in
a
sense
converting
the
objects
to
strings
and
changing
the
original
string
according
to
a
format
specification
that
is
d
s
bird
dead
that
is
dead
bird
that
is
bird
format
dead
that
is
dead
bird
format
expression
format
method
in
and
despite
the
substitution
metaphor
though
the
result
of
formatting
is
a
new
string
object
not
a
modified
one
we
ll
study
formatting
later
in
this
chapter
as
we
ll
find
formatting
turns
out
to
be
more
general
and
useful
than
this
example
implies
because
the
second
of
the
preceding
calls
is
provided
as
a
method
though
let
s
get
a
handle
on
string
method
calls
before
we
explore
formatting
further
as
we
ll
see
in
chapter
python
and
introduce
a
new
string
type
known
as
bytearray
which
is
mutable
and
so
may
be
changed
in
place
bytearray
objects
aren
t
really
strings
they
re
sequences
of
small
bit
integers
however
they
support
most
of
the
same
operations
as
normal
strings
and
print
as
ascii
characters
when
displayed
as
such
they
provide
another
option
for
large
amounts
of
text
that
must
be
changed
frequently
in
chapter
we
ll
also
see
that
ord
and
chr
handle
unicode
characters
too
which
might
not
be
stored
in
single
bytes
string
methods
in
addition
to
expression
operators
strings
provide
a
set
of
methods
that
implement
more
sophisticated
text
processing
tasks
methods
are
simply
functions
that
are
associated
with
particular
objects
technically
they
are
attributes
attached
to
objects
that
happen
to
reference
callable
functions
in
python
expressions
and
built
in
functions
may
work
across
a
range
of
types
but
methods
are
generally
specific
to
object
types
string
methods
for
example
work
only
on
string
objects
the
method
sets
of
some
types
intersect
in
python
e
g
many
types
have
a
count
method
but
they
are
still
more
type
specific
than
other
tools
chapter
strings
in
finer
grained
detail
functions
are
packages
of
code
and
method
calls
combine
two
operations
at
once
an
attribute
fetch
and
a
call
attribute
fetches
an
expression
of
the
form
object
attribute
means
fetch
the
value
of
attribute
in
object
call
expressions
an
expression
of
the
form
function
arguments
means
invoke
the
code
of
function
passing
zero
or
more
comma
separated
argument
objects
to
it
and
return
function
s
result
value
putting
these
two
together
allows
us
to
call
a
method
of
an
object
the
method
call
expression
object
method
arguments
is
evaluated
from
left
to
right
python
will
first
fetch
the
method
of
the
object
and
then
call
it
passing
in
the
arguments
if
the
method
computes
a
result
it
will
come
back
as
the
result
of
the
entire
method
call
expression
as
you
ll
see
throughout
this
part
of
the
book
most
objects
have
callable
methods
and
all
are
accessed
using
this
same
method
call
syntax
to
call
an
object
method
as
you
ll
see
in
the
following
sections
you
have
to
go
through
an
existing
object
table
summarizes
the
methods
and
call
patterns
for
built
in
string
objects
in
python
these
change
frequently
so
be
sure
to
check
python
s
standard
library
manual
for
the
most
up
to
date
list
or
run
a
help
call
on
any
string
interactively
python
s
string
methods
vary
slightly
it
includes
a
decode
for
example
because
of
its
different
handling
of
unicode
data
something
we
ll
discuss
in
chapter
in
this
table
s
is
a
string
object
and
optional
arguments
are
enclosed
in
square
brackets
string
methods
in
this
table
implement
higher
level
operations
such
as
splitting
and
joining
case
conversions
content
tests
and
substring
searches
and
replacements
table
string
method
calls
in
python
s
capitalize
s
ljust
width
fill
s
center
width
fill
s
lower
s
count
sub
start
end
s
lstrip
chars
s
encode
encoding
errors
s
maketrans
x
y
z
s
endswith
suffix
start
end
s
partition
sep
s
expandtabs
tabsize
s
replace
old
new
count
s
find
sub
start
end
s
rfind
sub
start
end
s
format
fmtstr
args
kwargs
s
rindex
sub
start
end
s
index
sub
start
end
s
rjust
width
fill
s
isalnum
s
rpartition
sep
s
isalpha
s
rsplit
sep
maxsplit
s
isdecimal
s
rstrip
chars
s
isdigit
s
split
sep
maxsplit
string
methods
s
isidentifier
s
splitlines
keepends
s
islower
s
startswith
prefix
start
end
s
isnumeric
s
strip
chars
s
isprintable
s
swapcase
s
isspace
s
title
s
istitle
s
translate
map
s
isupper
s
upper
s
join
iterable
s
zfill
width
as
you
can
see
there
are
quite
a
few
string
methods
and
we
don
t
have
space
to
cover
them
all
see
python
s
library
manual
or
reference
texts
for
all
the
fine
points
to
help
you
get
started
though
let
s
work
through
some
code
that
demonstrates
some
of
the
most
commonly
used
methods
in
action
and
illustrates
python
text
processing
basics
along
the
way
string
method
examples
changing
strings
as
we
ve
seen
because
strings
are
immutable
they
cannot
be
changed
in
place
directly
to
make
a
new
text
value
from
an
existing
string
you
construct
a
new
string
with
operations
such
as
slicing
and
concatenation
for
example
to
replace
two
characters
in
the
middle
of
a
string
you
can
use
code
like
this
s
spammy
s
s
xx
s
s
spaxxy
but
if
you
re
really
just
out
to
replace
a
substring
you
can
use
the
string
replace
method
instead
s
spammy
s
s
replace
mm
xx
s
spaxxy
the
replace
method
is
more
general
than
this
code
implies
it
takes
as
arguments
the
original
substring
of
any
length
and
the
string
of
any
length
to
replace
it
with
and
performs
a
global
search
and
replace
aa
bb
cc
dd
replace
spam
aaspambbspamccspamdd
in
such
a
role
replace
can
be
used
as
a
tool
to
implement
template
replacements
e
g
in
form
letters
notice
that
this
time
we
simply
printed
the
result
instead
of
assigning
it
to
a
name
you
need
to
assign
results
to
names
only
if
you
want
to
retain
them
for
later
use
chapter
strings
if
you
need
to
replace
one
fixed
size
string
that
can
occur
at
any
offset
you
can
do
a
replacement
again
or
search
for
the
substring
with
the
string
find
method
and
then
slice
s
xxxxspamxxxxspamxxxx
where
s
find
spam
search
for
position
where
occurs
at
offset
s
s
where
eggs
s
where
s
xxxxeggsxxxxspamxxxx
the
find
method
returns
the
offset
where
the
substring
appears
by
default
searching
from
the
front
or
if
it
is
not
found
as
we
saw
earlier
it
s
a
substring
search
operation
just
like
the
in
expression
but
find
returns
the
position
of
a
located
substring
another
option
is
to
use
replace
with
a
third
argument
to
limit
it
to
a
single
substitution
s
xxxxspamxxxxspamxxxx
s
replace
spam
eggs
xxxxeggsxxxxeggsxxxx
s
replace
spam
eggs
xxxxeggsxxxxspamxxxx
replace
all
replace
one
notice
that
replace
returns
a
new
string
object
each
time
because
strings
are
immutable
methods
never
really
change
the
subject
strings
in
place
even
if
they
are
called
replace
the
fact
that
concatenation
operations
and
the
replace
method
generate
new
string
objects
each
time
they
are
run
is
actually
a
potential
downside
of
using
them
to
change
strings
if
you
have
to
apply
many
changes
to
a
very
large
string
you
might
be
able
to
improve
your
script
s
performance
by
converting
the
string
to
an
object
that
does
support
in
place
changes
s
spammy
l
list
s
l
s
p
a
m
m
y
the
built
in
list
function
or
an
object
construction
call
builds
a
new
list
out
of
the
items
in
any
sequence
in
this
case
exploding
the
characters
of
a
string
into
a
list
once
the
string
is
in
this
form
you
can
make
multiple
changes
to
it
without
generating
a
new
copy
for
each
change
l
x
l
x
l
s
p
a
x
x
y
works
for
lists
not
strings
if
after
your
changes
you
need
to
convert
back
to
a
string
e
g
to
write
to
a
file
use
the
string
join
method
to
implode
the
list
back
into
a
string
string
methods
s
join
l
s
spaxxy
the
join
method
may
look
a
bit
backward
at
first
sight
because
it
is
a
method
of
strings
not
of
lists
it
is
called
through
the
desired
delimiter
join
puts
the
strings
in
a
list
or
other
iterable
together
with
the
delimiter
between
list
items
in
this
case
it
uses
an
empty
string
delimiter
to
convert
from
a
list
back
to
a
string
more
generally
any
string
delimiter
and
iterable
of
strings
will
do
spam
join
eggs
sausage
ham
toast
eggsspamsausagespamhamspamtoast
in
fact
joining
substrings
all
at
once
this
way
often
runs
much
faster
than
concatenating
them
individually
be
sure
to
also
see
the
earlier
note
about
the
mutable
bytearray
string
in
python
and
described
fully
in
chapter
because
it
may
be
changed
in
place
it
offers
an
alternative
to
this
list
join
combination
for
some
kinds
of
text
that
must
be
changed
often
string
method
examples
parsing
text
another
common
role
for
string
methods
is
as
a
simple
form
of
text
parsing
that
is
analyzing
structure
and
extracting
substrings
to
extract
substrings
at
fixed
offsets
we
can
employ
slicing
techniques
line
aaa
bbb
ccc
col
line
col
line
col
aaa
col
ccc
here
the
columns
of
data
appear
at
fixed
offsets
and
so
may
be
sliced
out
of
the
original
string
this
technique
passes
for
parsing
as
long
as
the
components
of
your
data
have
fixed
positions
if
instead
some
sort
of
delimiter
separates
the
data
you
can
pull
out
its
components
by
splitting
this
will
work
even
if
the
data
may
show
up
at
arbitrary
positions
within
the
string
line
aaa
bbb
ccc
cols
line
split
cols
aaa
bbb
ccc
the
string
split
method
chops
up
a
string
into
a
list
of
substrings
around
a
delimiter
string
we
didn
t
pass
a
delimiter
in
the
prior
example
so
it
defaults
to
whitespace
the
string
is
split
at
groups
of
one
or
more
spaces
tabs
and
newlines
and
we
get
back
a
list
of
the
resulting
substrings
in
other
applications
more
tangible
delimiters
may
separate
the
data
this
example
splits
and
hence
parses
the
string
at
commas
a
separator
common
in
data
returned
by
some
database
tools
chapter
strings
line
bob
hacker
line
split
bob
hacker
delimiters
can
be
longer
than
a
single
character
too
line
i
mspamaspamlumberjack
line
split
spam
i
m
a
lumberjack
although
there
are
limits
to
the
parsing
potential
of
slicing
and
splitting
both
run
very
fast
and
can
handle
basic
text
extraction
chores
other
common
string
methods
in
action
other
string
methods
have
more
focused
roles
for
example
to
strip
off
whitespace
at
the
end
of
a
line
of
text
perform
case
conversions
test
content
and
test
for
a
substring
at
the
end
or
front
line
the
knights
who
say
ni
n
line
rstrip
the
knights
who
say
ni
line
upper
the
knights
who
say
ni
n
line
isalpha
false
line
endswith
ni
n
true
line
startswith
the
true
alternative
techniques
can
also
sometimes
be
used
to
achieve
the
same
results
as
string
methods
the
in
membership
operator
can
be
used
to
test
for
the
presence
of
a
substring
for
instance
and
length
and
slicing
operations
can
be
used
to
mimic
endswith
line
the
knights
who
say
ni
n
line
find
ni
true
ni
in
line
true
sub
ni
n
line
endswith
sub
true
line
len
sub
sub
true
search
via
method
call
or
expression
end
test
via
method
call
or
slice
see
also
the
format
string
formatting
method
described
later
in
this
chapter
it
provides
more
advanced
substitution
tools
that
combine
many
operations
in
a
single
step
again
because
there
are
so
many
methods
available
for
strings
we
won
t
look
at
every
one
here
you
ll
see
some
additional
string
examples
later
in
this
book
but
for
more
string
methods
details
you
can
also
turn
to
the
python
library
manual
and
other
documentation
sources
or
simply
experiment
interactively
on
your
own
you
can
also
check
the
help
s
method
results
for
a
method
of
any
string
object
s
for
more
hints
note
that
none
of
the
string
methods
accepts
patterns
for
pattern
based
text
processing
you
must
use
the
python
re
standard
library
module
an
advanced
tool
that
was
introduced
in
chapter
but
is
mostly
outside
the
scope
of
this
text
one
further
example
appears
at
the
end
of
chapter
because
of
this
limitation
though
string
methods
may
sometimes
run
more
quickly
than
the
re
module
s
tools
the
original
string
module
gone
in
the
history
of
python
s
string
methods
is
somewhat
convoluted
for
roughly
the
first
decade
of
its
existence
python
provided
a
standard
library
module
called
string
that
contained
functions
that
largely
mirrored
the
current
set
of
string
object
methods
in
response
to
user
requests
in
python
these
functions
were
made
available
as
methods
of
string
objects
because
so
many
people
had
written
so
much
code
that
relied
on
the
original
string
module
however
it
was
retained
for
backward
compatibility
today
you
should
use
only
string
methods
not
the
original
string
module
in
fact
the
original
module
call
forms
of
today
s
string
methods
have
been
removed
completely
from
python
in
release
however
because
you
may
still
see
the
module
in
use
in
older
python
code
a
brief
look
is
in
order
here
the
upshot
of
this
legacy
is
that
in
python
there
technically
are
still
two
ways
to
invoke
advanced
string
operations
by
calling
object
methods
or
by
calling
string
module
functions
and
passing
in
the
objects
as
arguments
for
instance
given
a
variable
x
assigned
to
a
string
object
calling
an
object
method
x
method
arguments
is
usually
equivalent
to
calling
the
same
operation
through
the
string
module
provided
that
you
have
already
imported
the
module
string
method
x
arguments
here
s
an
example
of
the
method
scheme
in
action
s
a
b
c
x
s
replace
spam
x
aspambspamcspam
to
access
the
same
operation
through
the
string
module
in
python
you
need
to
import
the
module
at
least
once
in
your
process
and
pass
in
the
object
import
string
y
string
replace
s
spam
y
aspambspamcspam
chapter
strings
because
the
module
approach
was
the
standard
for
so
long
and
because
strings
are
such
a
central
component
of
most
programs
you
might
see
both
call
patterns
in
python
x
code
you
come
across
again
though
today
you
should
always
use
method
calls
instead
of
the
older
module
calls
there
are
good
reasons
for
this
besides
the
fact
that
the
module
calls
have
gone
away
in
release
for
one
thing
the
module
call
scheme
requires
you
to
import
the
string
module
methods
do
not
require
imports
for
another
the
module
makes
calls
a
few
characters
longer
to
type
when
you
load
the
module
with
import
that
is
not
using
from
and
finally
the
module
runs
more
slowly
than
methods
the
module
maps
most
calls
back
to
the
methods
and
so
incurs
an
extra
call
along
the
way
the
original
string
module
itself
without
its
string
method
equivalents
is
retained
in
python
because
it
contains
additional
tools
including
predefined
string
constants
and
a
template
object
system
a
relatively
obscure
tool
omitted
here
see
the
python
library
manual
for
details
on
template
objects
unless
you
really
want
to
have
to
change
your
code
to
use
though
you
should
consider
the
basic
string
operation
calls
in
it
to
be
just
ghosts
from
the
past
string
formatting
expressions
although
you
can
get
a
lot
done
with
the
string
methods
and
sequence
operations
we
ve
already
met
python
also
provides
a
more
advanced
way
to
combine
string
processing
tasks
string
formatting
allows
us
to
perform
multiple
type
specific
substitutions
on
a
string
in
a
single
step
it
s
never
strictly
required
but
it
can
be
convenient
especially
when
formatting
text
to
be
displayed
to
a
program
s
users
due
to
the
wealth
of
new
ideas
in
the
python
world
string
formatting
is
available
in
two
flavors
in
python
today
string
formatting
expressions
the
original
technique
available
since
python
s
inception
this
is
based
upon
the
c
language
s
printf
model
and
is
used
in
much
existing
code
string
formatting
method
calls
a
newer
technique
added
in
python
and
this
is
more
unique
to
python
and
largely
overlaps
with
string
formatting
expression
functionality
since
the
method
call
flavor
is
new
there
is
some
chance
that
one
or
the
other
of
these
may
become
deprecated
over
time
the
expressions
are
more
likely
to
be
deprecated
in
later
python
releases
though
this
should
depend
on
the
future
practice
of
real
python
programmers
as
they
are
largely
just
variations
on
a
theme
though
either
technique
is
valid
to
use
today
since
string
formatting
expressions
are
the
original
in
this
department
let
s
start
with
them
python
defines
the
binary
operator
to
work
on
strings
you
may
recall
that
this
is
also
the
remainder
of
division
or
modulus
operator
for
numbers
when
applied
to
strings
the
operator
provides
a
simple
way
to
format
values
as
strings
according
to
a
format
string
formatting
expressions
definition
in
short
the
operator
provides
a
compact
way
to
code
multiple
string
substitutions
all
at
once
instead
of
building
and
concatenating
parts
individually
to
format
strings
on
the
left
of
the
operator
provide
a
format
string
containing
one
or
more
embedded
conversion
targets
each
of
which
starts
with
a
e
g
d
on
the
right
of
the
operator
provide
the
object
or
objects
embedded
in
a
tuple
that
you
want
python
to
insert
into
the
format
string
on
the
left
in
place
of
the
conversion
target
or
targets
for
instance
in
the
formatting
example
we
saw
earlier
in
this
chapter
the
integer
replaces
the
d
in
the
format
string
on
the
left
and
the
string
dead
replaces
the
s
the
result
is
a
new
string
that
reflects
these
two
substitutions
that
is
d
s
bird
dead
that
is
dead
bird
format
expression
technically
speaking
string
formatting
expressions
are
usually
optional
you
can
generally
do
similar
work
with
multiple
concatenations
and
conversions
however
formatting
allows
us
to
combine
many
steps
into
a
single
operation
it
s
powerful
enough
to
warrant
a
few
more
examples
exclamation
ni
the
knights
who
say
s
exclamation
the
knights
who
say
ni
d
s
d
you
spam
spam
you
s
s
s
the
first
example
here
plugs
the
string
ni
into
the
target
on
the
left
replacing
the
s
marker
in
the
second
example
three
values
are
inserted
into
the
target
string
note
that
when
you
re
inserting
more
than
one
value
you
need
to
group
the
values
on
the
right
in
parentheses
i
e
put
them
in
a
tuple
the
formatting
expression
operator
expects
either
a
single
item
or
a
tuple
of
one
or
more
items
on
its
right
side
the
third
example
again
inserts
three
values
an
integer
a
floating
point
object
and
a
list
object
but
notice
that
all
of
the
targets
on
the
left
are
s
which
stands
for
conversion
to
string
as
every
type
of
object
can
be
converted
to
a
string
the
one
used
when
printing
every
object
type
works
with
the
s
conversion
code
because
of
this
unless
you
will
be
doing
some
special
formatting
s
is
often
the
only
code
you
need
to
remember
for
the
formatting
expression
again
keep
in
mind
that
formatting
always
makes
a
new
string
rather
than
changing
the
string
on
the
left
because
strings
are
immutable
it
must
work
this
way
as
before
assign
the
result
to
a
variable
name
if
you
need
to
retain
it
chapter
strings
advanced
string
formatting
expressions
for
more
advanced
type
specific
formatting
you
can
use
any
of
the
conversion
type
codes
listed
in
table
in
formatting
expressions
they
appear
after
the
character
in
substitution
targets
c
programmers
will
recognize
most
of
these
because
python
string
formatting
supports
all
the
usual
c
printf
format
codes
but
returns
the
result
instead
of
displaying
it
like
printf
some
of
the
format
codes
in
the
table
provide
alternative
ways
to
format
the
same
type
for
instance
e
f
and
g
provide
alternative
ways
to
format
floating
point
numbers
table
string
formatting
type
codes
code
meaning
s
string
or
any
object
s
str
x
string
r
s
but
uses
repr
not
str
c
character
d
decimal
integer
i
integer
u
same
as
d
obsolete
no
longer
unsigned
o
octal
integer
x
hex
integer
x
x
but
prints
uppercase
e
floating
point
exponent
lowercase
e
same
as
e
but
prints
uppercase
f
floating
point
decimal
f
floating
point
decimal
g
floating
point
e
or
f
g
floating
point
e
or
f
literal
in
fact
conversion
targets
in
the
format
string
on
the
expression
s
left
side
support
a
variety
of
conversion
operations
with
a
fairly
sophisticated
syntax
all
their
own
the
general
structure
of
conversion
targets
looks
like
this
name
flags
width
precision
typecode
the
character
type
codes
in
table
show
up
at
the
end
of
the
target
string
between
the
and
the
character
code
you
can
do
any
of
the
following
provide
a
dictionary
key
list
flags
that
specify
things
like
left
justification
numeric
sign
and
zero
fills
give
a
total
minimum
field
width
and
the
number
of
digits
after
a
decimal
point
and
more
both
width
and
precision
can
also
be
coded
as
a
to
specify
that
they
should
take
their
values
from
the
next
item
in
the
input
values
string
formatting
expressions
formatting
target
syntax
is
documented
in
full
in
the
python
standard
manuals
but
to
demonstrate
common
usage
let
s
look
at
a
few
examples
this
one
formats
integers
by
default
and
then
in
a
six
character
field
with
left
justification
and
zero
padding
x
res
integers
d
d
d
x
x
x
res
integers
the
e
f
and
g
formats
display
floating
point
numbers
in
different
ways
as
the
following
interaction
demonstrates
e
is
the
same
as
e
but
the
exponent
is
uppercase
x
x
e
f
g
x
x
x
e
e
x
e
for
floating
point
numbers
you
can
achieve
a
variety
of
additional
formatting
effects
by
specifying
left
justification
zero
padding
numeric
signs
field
width
and
digits
after
the
decimal
point
for
simpler
tasks
you
might
get
by
with
simply
converting
to
strings
with
a
format
expression
or
the
str
built
in
function
shown
earlier
f
f
f
x
x
x
s
x
str
x
when
sizes
are
not
known
until
runtime
you
can
have
the
width
and
precision
computed
by
specifying
them
with
a
in
the
format
string
to
force
their
values
to
be
taken
from
the
next
item
in
the
inputs
to
the
right
of
the
operator
the
in
the
tuple
here
gives
precision
f
f
f
if
you
re
interested
in
this
feature
experiment
with
some
of
these
examples
and
operations
on
your
own
for
more
information
dictionary
based
string
formatting
expressions
string
formatting
also
allows
conversion
targets
on
the
left
to
refer
to
the
keys
in
a
dictionary
on
the
right
and
fetch
the
corresponding
values
i
haven
t
told
you
much
about
dictionaries
yet
so
here
s
an
example
that
demonstrates
the
basics
n
d
x
s
n
x
spam
spam
chapter
strings
here
the
n
and
x
in
the
format
string
refer
to
keys
in
the
dictionary
literal
on
the
right
and
fetch
their
associated
values
programs
that
generate
text
such
as
html
or
xml
often
use
this
technique
you
can
build
up
a
dictionary
of
values
and
substitute
them
all
at
once
with
a
single
formatting
expression
that
uses
key
based
references
reply
greetings
hello
name
s
your
age
squared
is
age
s
values
name
bob
age
print
reply
values
template
with
substitution
targets
build
up
values
to
substitute
perform
substitutions
greetings
hello
bob
your
age
squared
is
this
trick
is
also
used
in
conjunction
with
the
vars
built
in
function
which
returns
a
dictionary
containing
all
the
variables
that
exist
in
the
place
it
is
called
food
spam
age
vars
food
spam
age
many
more
when
used
on
the
right
of
a
format
operation
this
allows
the
format
string
to
refer
to
variables
by
name
i
e
by
dictionary
key
age
d
food
s
vars
spam
we
ll
study
dictionaries
in
more
depth
in
chapter
see
also
chapter
for
examples
that
convert
to
hexadecimal
and
octal
number
strings
with
the
x
and
o
formatting
target
codes
string
formatting
method
calls
as
mentioned
earlier
python
and
introduced
a
new
way
to
format
strings
that
is
seen
by
some
as
a
bit
more
python
specific
unlike
formatting
expressions
formatting
method
calls
are
not
closely
based
upon
the
c
language
s
printf
model
and
they
are
more
verbose
and
explicit
in
intent
on
the
other
hand
the
new
technique
still
relies
on
some
printf
concepts
such
as
type
codes
and
formatting
specifications
moreover
it
largely
overlaps
with
and
sometimes
requires
a
bit
more
code
than
formatting
expressions
and
it
can
be
just
as
complex
in
advanced
roles
because
of
this
there
is
no
best
use
recommendation
between
expressions
and
method
calls
today
so
most
programmers
would
be
well
served
by
a
cursory
understanding
of
both
schemes
string
formatting
method
calls
the
basics
in
short
the
new
string
object
s
format
method
in
and
and
later
uses
the
subject
string
as
a
template
and
takes
any
number
of
arguments
that
represent
values
to
be
substituted
according
to
the
template
within
the
subject
string
curly
braces
designate
substitution
targets
and
arguments
to
be
inserted
either
by
position
e
g
or
keyword
e
g
food
as
we
ll
learn
when
we
study
argument
passing
in
depth
in
chapter
arguments
to
functions
and
methods
may
be
passed
by
position
or
keyword
name
and
python
s
ability
to
collect
arbitrarily
many
positional
and
keyword
arguments
allows
for
such
general
method
call
patterns
in
python
and
for
example
template
and
template
format
spam
ham
eggs
spam
ham
and
eggs
by
position
template
motto
pork
and
food
template
format
motto
spam
pork
ham
food
eggs
spam
ham
and
eggs
by
keyword
template
motto
and
food
template
format
ham
motto
spam
food
eggs
spam
ham
and
eggs
by
both
naturally
the
string
can
also
be
a
literal
that
creates
a
temporary
string
and
arbitrary
object
types
can
be
substituted
motto
and
food
format
motto
food
and
just
as
with
the
expression
and
other
string
methods
format
creates
and
returns
a
new
string
object
which
can
be
printed
immediately
or
saved
for
further
work
recall
that
strings
are
immutable
so
format
really
must
make
a
new
object
string
formatting
is
not
just
for
display
x
motto
and
food
format
motto
food
x
and
x
split
and
y
x
replace
and
but
under
no
circumstances
y
but
under
no
circumstances
adding
keys
attributes
and
offsets
like
formatting
expressions
format
calls
can
become
more
complex
to
support
more
advanced
usage
for
instance
format
strings
can
name
object
attributes
and
dictionary
keys
as
in
normal
python
syntax
square
brackets
name
dictionary
keys
and
dots
denote
object
attributes
of
an
item
referenced
by
position
or
keyword
the
first
of
the
chapter
strings
following
examples
indexes
a
dictionary
on
the
key
spam
and
then
fetches
the
attribute
platform
from
the
already
imported
sys
module
object
the
second
does
the
same
but
names
the
objects
by
keyword
instead
of
position
import
sys
my
spam
runs
platform
format
sys
spam
laptop
my
laptop
runs
win
my
config
spam
runs
sys
platform
format
sys
sys
config
spam
laptop
my
laptop
runs
win
square
brackets
in
format
strings
can
name
list
and
other
sequence
offsets
to
perform
indexing
too
but
only
single
positive
offsets
work
syntactically
within
format
strings
so
this
feature
is
not
as
general
as
you
might
think
as
with
expressions
to
name
negative
offsets
or
slices
or
to
use
arbitrary
expression
results
in
general
you
must
run
expressions
outside
the
format
string
itself
somelist
list
spam
somelist
s
p
a
m
first
third
format
somelist
first
s
third
a
first
last
format
somelist
somelist
first
s
last
m
fails
in
fmt
parts
somelist
somelist
somelist
first
last
middle
format
parts
first
s
last
m
middle
p
a
fails
in
fmt
adding
specific
formatting
another
similarity
with
expressions
is
that
more
specific
layouts
can
be
achieved
by
adding
extra
syntax
in
the
format
string
for
the
formatting
method
we
use
a
colon
after
the
substitution
target
s
identification
followed
by
a
format
specifier
that
can
name
the
field
size
justification
and
a
specific
type
code
here
s
the
formal
structure
of
what
can
appear
as
a
substitution
target
in
a
format
string
fieldname
conversionflag
formatspec
in
this
substitution
target
syntax
fieldname
is
a
number
or
keyword
naming
an
argument
followed
by
optional
name
attribute
or
index
component
references
conversionflag
can
be
r
s
or
a
to
call
repr
str
or
ascii
built
in
functions
on
the
value
respectively
string
formatting
method
calls
formatspec
specifies
how
the
value
should
be
presented
including
details
such
as
field
width
alignment
padding
decimal
precision
and
so
on
and
ends
with
an
optional
data
type
code
the
formatspec
component
after
the
colon
character
is
formally
described
as
follows
brackets
denote
optional
components
and
are
not
coded
literally
fill
align
sign
width
precision
typecode
align
may
be
or
for
left
alignment
right
alignment
padding
after
a
sign
character
or
centered
alignment
respectively
the
formatspec
also
contains
nested
format
strings
with
field
names
only
to
take
values
from
the
arguments
list
dynamically
much
like
the
in
formatting
expressions
see
python
s
library
manual
for
more
on
substitution
syntax
and
a
list
of
the
available
type
codes
they
almost
completely
overlap
with
those
used
in
expressions
and
listed
previously
in
table
but
the
format
method
also
allows
a
b
type
code
used
to
display
integers
in
binary
format
it
s
equivalent
to
using
the
bin
built
in
call
allows
a
type
code
to
display
percentages
and
uses
only
d
for
base
integers
not
i
or
u
as
an
example
in
the
following
means
the
first
positional
argument
in
a
field
characters
wide
means
the
second
positional
argument
left
justified
in
a
character
wide
field
and
platform
means
the
platform
attribute
of
the
first
argument
right
justified
in
a
character
wide
field
format
spam
spam
format
spam
spam
platform
item
format
sys
dict
item
laptop
win
laptop
floating
point
numbers
support
the
same
type
codes
and
formatting
specificity
in
formatting
method
calls
as
in
expressions
for
instance
in
the
following
g
means
the
third
argument
formatted
by
default
according
to
the
g
floating
point
representation
f
designates
the
f
floating
point
format
with
just
decimal
digits
and
f
adds
a
field
with
a
width
of
characters
and
zero
padding
on
the
left
e
e
g
format
e
e
f
f
f
format
hex
octal
and
binary
formats
are
supported
by
the
format
method
as
well
in
fact
string
formatting
is
an
alternative
to
some
of
the
built
in
functions
that
format
integers
to
a
given
base
chapter
strings
x
o
b
format
ff
hex
octal
binary
bin
int
b
b
other
to
from
binary
hex
int
ff
xff
xff
other
to
from
hex
oct
int
o
other
to
from
octal
works
in
not
formatting
parameters
can
either
be
hardcoded
in
format
strings
or
taken
from
the
arguments
list
dynamically
by
nested
format
syntax
much
like
the
star
syntax
in
formatting
expressions
f
format
f
parameters
hardcoded
f
format
f
take
value
from
arguments
ditto
for
expression
finally
python
and
also
provide
a
new
built
in
format
function
which
can
be
used
to
format
a
single
item
it
s
a
more
concise
alternative
to
the
string
format
method
and
is
roughly
similar
to
formatting
a
single
item
with
the
formatting
expression
string
method
f
format
format
f
f
built
in
function
expression
technically
the
format
built
in
runs
the
subject
object
s
format
method
which
the
str
format
method
does
internally
for
each
formatted
item
it
s
still
more
verbose
than
the
original
expression
s
equivalent
though
which
leads
us
to
the
next
section
comparison
to
the
formatting
expression
if
you
study
the
prior
sections
closely
you
ll
probably
notice
that
at
least
for
positional
references
and
dictionary
keys
the
string
format
method
looks
very
much
like
the
formatting
expression
especially
in
advanced
use
with
type
codes
and
extra
formatting
syntax
in
fact
in
common
use
cases
formatting
expressions
may
be
easier
to
code
than
formatting
method
calls
especially
when
using
the
generic
s
print
string
substitution
target
print
s
s
spam
x
format
expression
print
format
spam
and
format
method
string
formatting
method
calls
as
we
ll
see
in
a
moment
though
more
complex
formatting
tends
to
be
a
draw
in
terms
of
complexity
difficult
tasks
are
generally
difficult
regardless
of
approach
and
some
see
the
formatting
method
as
largely
redundant
on
the
other
hand
the
formatting
method
also
offers
a
few
potential
advantages
for
example
the
original
expression
can
t
handle
keywords
attribute
references
and
binary
type
codes
although
dictionary
key
references
in
format
strings
can
often
achieve
similar
goals
to
see
how
the
two
techniques
overlap
compare
the
following
expressions
to
the
equivalent
format
method
calls
shown
earlier
the
basics
with
instead
of
format
template
s
s
s
template
spam
ham
eggs
spam
ham
eggs
by
position
template
motto
s
pork
s
and
food
s
template
dict
motto
spam
pork
ham
food
eggs
spam
ham
and
eggs
by
key
s
s
and
s
and
arbitrary
types
adding
keys
attributes
and
offsets
my
spam
s
runs
platform
s
spam
laptop
platform
sys
platform
my
laptop
runs
win
my
spam
s
runs
platform
s
dict
spam
laptop
platform
sys
platform
my
laptop
runs
win
somelist
list
spam
parts
somelist
somelist
somelist
first
s
last
s
middle
s
parts
first
s
last
m
middle
p
a
when
more
complex
formatting
is
applied
the
two
techniques
approach
parity
in
terms
of
complexity
although
if
you
compare
the
following
with
the
format
method
call
equivalents
listed
earlier
you
ll
again
find
that
the
expressions
tend
to
be
a
bit
simpler
and
more
concise
adding
specific
formatting
s
s
spam
spam
s
s
spam
spam
plat
s
item
s
dict
plat
sys
platform
item
laptop
win
laptop
chapter
strings
floating
point
numbers
e
e
g
e
e
f
f
f
hex
and
octal
but
not
binary
x
o
ff
the
format
method
has
a
handful
of
advanced
features
that
the
expression
does
not
but
even
more
involved
formatting
still
seems
to
be
essentially
a
draw
in
terms
of
complexity
for
instance
the
following
shows
the
same
result
generated
with
both
techniques
with
field
sizes
and
justifications
and
various
argument
reference
methods
hardcoded
references
in
both
import
sys
my
spam
runs
platform
format
sys
spam
laptop
my
laptop
runs
win
my
spam
s
runs
plat
s
dict
spam
laptop
plat
sys
platform
my
laptop
runs
win
in
practice
programs
are
less
likely
to
hardcode
references
like
this
than
to
execute
code
that
builds
up
a
set
of
substitution
data
ahead
of
time
to
collect
data
to
substitute
into
an
html
template
all
at
once
for
instance
when
we
account
for
common
practice
in
examples
like
this
the
comparison
between
the
format
method
and
the
expression
is
even
more
direct
as
we
ll
see
in
chapter
the
data
in
the
method
call
here
is
special
syntax
that
unpacks
a
dictionary
of
keys
and
values
into
individual
name
value
keyword
arguments
so
they
can
be
referenced
by
name
in
the
format
string
building
data
ahead
of
time
in
both
data
dict
platform
sys
platform
spam
laptop
my
spam
runs
platform
format
data
my
laptop
runs
win
my
spam
s
runs
platform
s
data
my
laptop
runs
win
as
usual
the
python
community
will
have
to
decide
whether
expressions
format
method
calls
or
a
toolset
with
both
techniques
proves
better
over
time
experiment
with
these
techniques
on
your
own
to
get
a
feel
for
what
they
offer
and
be
sure
to
see
the
python
and
library
manuals
for
more
details
string
formatting
method
calls
string
format
method
enhancements
in
python
the
upcoming
release
in
alpha
form
as
this
chapter
was
being
written
will
add
a
thousand
separator
syntax
for
numbers
which
inserts
commas
between
three
digit
groups
add
a
comma
before
the
type
code
to
make
this
work
as
follows
d
format
d
format
python
also
assigns
relative
numbers
to
substitution
targets
automatically
if
they
are
not
included
explicitly
though
using
this
extension
may
negate
one
of
the
main
benefits
of
the
formatting
method
as
the
next
section
describes
d
format
d
d
format
f
format
this
book
doesn
t
cover
officially
so
you
should
take
this
as
a
preview
python
will
also
address
a
major
performance
issue
in
related
to
the
speed
of
file
input
output
operations
which
made
impractical
for
many
types
of
programs
see
the
release
notes
for
more
details
see
also
the
formats
py
comma
insertion
and
money
formatting
function
examples
in
chapter
for
a
manual
solution
that
can
be
imported
and
used
prior
to
python
why
the
new
format
method
now
that
i
ve
gone
to
such
lengths
to
compare
and
contrast
the
two
formatting
techniques
i
need
to
explain
why
you
might
want
to
consider
using
the
format
method
variant
at
times
in
short
although
the
formatting
method
can
sometimes
require
more
code
it
also
has
a
few
extra
features
not
found
in
the
expression
can
make
substitution
value
references
more
explicit
trades
an
operator
for
an
arguably
more
mnemonic
method
name
does
not
support
different
syntax
for
single
and
multiple
substitution
value
cases
although
both
techniques
are
available
today
and
the
formatting
expression
is
still
widely
used
the
format
method
might
eventually
subsume
it
but
because
the
choice
is
currently
still
yours
to
make
let
s
briefly
expand
on
some
of
the
differences
before
moving
on
chapter
strings
extra
features
the
method
call
supports
a
few
extras
that
the
expression
does
not
such
as
binary
type
codes
and
coming
in
python
thousands
groupings
in
addition
the
method
call
supports
key
and
attribute
references
directly
as
we
ve
seen
though
the
formatting
expression
can
usually
achieve
the
same
effects
in
other
ways
b
format
b
valueerror
unsupported
format
character
b
x
at
index
bin
b
s
bin
see
also
the
prior
examples
that
compare
dictionary
based
formatting
in
the
expression
to
key
and
attribute
references
in
the
format
method
especially
in
common
practice
the
two
seem
largely
variations
on
a
theme
explicit
value
references
one
use
case
where
the
format
method
is
at
least
debatably
clearer
is
when
there
are
many
values
to
be
substituted
into
the
format
string
the
lister
py
classes
example
we
ll
meet
in
chapter
for
example
substitutes
six
items
into
a
single
string
and
in
this
case
the
method
s
i
position
labels
seem
easier
to
read
than
the
expression
s
s
n
s
class
s
address
s
n
s
s
s
n
expression
n
class
address
n
n
format
method
on
the
other
hand
using
dictionary
keys
in
expressions
can
mitigate
much
of
this
difference
this
is
also
something
of
a
worst
case
scenario
for
formatting
complexity
and
not
very
common
in
practice
more
typical
use
cases
seem
largely
a
tossup
moreover
in
python
still
in
alpha
release
form
as
i
write
these
words
numbering
substitution
values
will
become
optional
thereby
subverting
this
purported
benefit
altogether
c
misc
c
python
python
the
side
format
bright
of
life
the
bright
side
of
life
the
side
format
bright
of
life
the
bright
side
of
life
the
s
side
s
s
bright
of
life
the
bright
side
of
life
python
string
formatting
method
calls
using
s
automatic
relative
numbering
like
this
seems
to
negate
a
large
part
of
the
method
s
advantage
compare
the
effect
on
floating
point
formatting
for
example
the
formatting
expression
is
still
more
concise
and
still
seems
less
cluttered
c
misc
c
python
python
f
f
f
format
f
f
f
format
f
f
f
method
names
and
general
arguments
given
this
auto
numbering
change
the
only
clearly
remaining
potential
advantages
of
the
formatting
method
are
that
it
replaces
the
operator
with
a
more
mnemonic
format
method
name
and
does
not
distinguish
between
single
and
multiple
substitution
values
the
former
may
make
the
method
appear
simpler
to
beginners
at
first
glance
format
may
be
easier
to
parse
than
multiple
characters
though
this
is
too
subjective
to
call
the
latter
difference
might
be
more
significant
with
the
format
expression
a
single
value
can
be
given
by
itself
but
multiple
values
must
be
enclosed
in
a
tuple
f
f
s
technically
the
formatting
expression
accepts
either
a
single
substitution
value
or
a
tuple
of
one
or
more
items
in
fact
because
a
single
item
can
be
given
either
by
itself
or
within
a
tuple
a
tuple
to
be
formatted
must
be
provided
as
nested
tuples
s
s
s
the
formatting
method
on
the
other
hand
tightens
this
up
by
accepting
general
function
arguments
in
both
cases
f
format
f
format
format
format
chapter
strings
consequently
it
might
be
less
confusing
to
beginners
and
cause
fewer
programming
mistakes
this
is
still
a
fairly
minor
issue
though
if
you
always
enclose
values
in
a
tuple
and
ignore
the
nontupled
option
the
expression
is
essentially
the
same
as
the
method
call
here
moreover
the
method
incurs
an
extra
price
in
inflated
code
size
to
achieve
its
limited
flexibility
given
that
the
expression
has
been
used
extensively
throughout
python
s
history
it
s
not
clear
that
this
point
justifies
breaking
existing
code
for
a
new
tool
that
is
so
similar
as
the
next
section
argues
possible
future
deprecation
as
mentioned
earlier
there
is
some
risk
that
python
developers
may
deprecate
the
expression
in
favor
of
the
format
method
in
the
future
in
fact
there
is
a
note
to
this
effect
in
python
s
manuals
this
has
not
yet
occurred
of
course
and
both
formatting
techniques
are
fully
available
and
reasonable
to
use
in
python
and
the
versions
of
python
this
book
covers
both
techniques
are
supported
in
the
upcoming
python
release
as
well
so
deprecation
of
either
seems
unlikely
for
the
foreseeable
future
moreover
because
formatting
expressions
are
used
extensively
in
almost
all
existing
python
code
written
to
date
most
programmers
will
benefit
from
being
familiar
with
both
techniques
for
many
years
to
come
if
this
deprecation
ever
does
occur
though
you
may
need
to
recode
all
your
expressions
as
format
methods
and
translate
those
that
appear
in
this
book
in
order
to
use
a
newer
python
release
at
the
risk
of
editorializing
here
i
hope
that
such
a
change
will
be
based
upon
the
future
common
practice
of
actual
python
programmers
not
the
whims
of
a
handful
of
core
developers
particularly
given
that
the
window
for
python
s
many
incompatible
changes
is
now
closed
frankly
this
deprecation
would
seem
like
trading
one
complicated
thing
for
another
complicated
thing
one
that
is
largely
equivalent
to
the
tool
it
would
replace
if
you
care
about
migrating
to
future
python
releases
though
be
sure
to
watch
for
developments
on
this
front
over
time
general
type
categories
now
that
we
ve
explored
the
first
of
python
s
collection
objects
the
string
let
s
pause
to
define
a
few
general
type
concepts
that
will
apply
to
most
of
the
types
we
look
at
from
here
on
with
regard
to
built
in
types
it
turns
out
that
operations
work
the
same
for
all
the
types
in
the
same
category
so
we
ll
only
need
to
define
most
of
these
ideas
once
we
ve
only
examined
numbers
and
strings
so
far
but
because
they
are
representative
of
two
of
the
three
major
type
categories
in
python
you
already
know
more
about
several
other
types
than
you
might
think
general
type
categories
types
share
operation
sets
by
categories
as
you
ve
learned
strings
are
immutable
sequences
they
cannot
be
changed
in
place
the
immutable
part
and
they
are
positionally
ordered
collections
that
are
accessed
by
offset
the
sequence
part
now
it
so
happens
that
all
the
sequences
we
ll
study
in
this
part
of
the
book
respond
to
the
same
sequence
operations
shown
in
this
chapter
at
work
on
strings
concatenation
indexing
iteration
and
so
on
more
formally
there
are
three
major
type
and
operation
categories
in
python
numbers
integer
floating
point
decimal
fraction
others
support
addition
multiplication
etc
sequences
strings
lists
tuples
support
indexing
slicing
concatenation
etc
mappings
dictionaries
support
indexing
by
key
etc
sets
are
something
of
a
category
unto
themselves
they
don
t
map
keys
to
values
and
are
not
positionally
ordered
sequences
and
we
haven
t
yet
explored
mappings
on
our
in
depth
tour
dictionaries
are
discussed
in
the
next
chapter
however
many
of
the
other
types
we
will
encounter
will
be
similar
to
numbers
and
strings
for
example
for
any
sequence
objects
x
and
y
x
y
makes
a
new
sequence
object
with
the
contents
of
both
operands
x
n
makes
a
new
sequence
object
with
n
copies
of
the
sequence
operand
x
in
other
words
these
operations
work
the
same
way
on
any
kind
of
sequence
including
strings
lists
tuples
and
some
user
defined
object
types
the
only
difference
is
that
the
new
result
object
you
get
back
is
of
the
same
type
as
the
operands
x
and
y
if
you
concatenate
lists
you
get
back
a
new
list
not
a
string
indexing
slicing
and
other
sequence
operations
work
the
same
on
all
sequences
too
the
type
of
the
objects
being
processed
tells
python
which
flavor
of
the
task
to
perform
mutable
types
can
be
changed
in
place
the
immutable
classification
is
an
important
constraint
to
be
aware
of
yet
it
tends
to
trip
up
new
users
if
an
object
type
is
immutable
you
cannot
change
its
value
in
place
python
raises
an
error
if
you
try
instead
you
must
run
code
to
make
a
new
object
containing
the
new
value
the
major
core
types
in
python
break
down
as
follows
immutables
numbers
strings
tuples
frozensets
none
of
the
object
types
in
the
immutable
category
support
in
place
changes
though
we
can
always
run
expressions
to
make
new
objects
and
assign
their
results
to
variables
as
needed
chapter
strings
mutables
lists
dictionaries
sets
conversely
the
mutable
types
can
always
be
changed
in
place
with
operations
that
do
not
create
new
objects
although
such
objects
can
be
copied
in
place
changes
support
direct
modification
generally
immutable
types
give
some
degree
of
integrity
by
guaranteeing
that
an
object
won
t
be
changed
by
another
part
of
a
program
for
a
refresher
on
why
this
matters
see
the
discussion
of
shared
object
references
in
chapter
to
see
how
lists
dictionaries
and
tuples
participate
in
type
categories
we
need
to
move
ahead
to
the
next
chapter
chapter
summary
in
this
chapter
we
took
an
in
depth
tour
of
the
string
object
type
we
learned
about
coding
string
literals
and
we
explored
string
operations
including
sequence
expressions
string
method
calls
and
string
formatting
with
both
expressions
and
method
calls
along
the
way
we
studied
a
variety
of
concepts
in
depth
such
as
slicing
method
call
syntax
and
triple
quoted
block
strings
we
also
defined
some
core
ideas
common
to
a
variety
of
types
sequences
for
example
share
an
entire
set
of
operations
in
the
next
chapter
we
ll
continue
our
types
tour
with
a
look
at
the
most
general
object
collections
in
python
lists
and
dictionaries
as
you
ll
find
much
of
what
you
ve
learned
here
will
apply
to
those
types
as
well
and
as
mentioned
earlier
in
the
final
part
of
this
book
we
ll
return
to
python
s
string
model
to
flesh
out
the
details
of
unicode
text
and
binary
data
which
are
of
interest
to
some
but
not
all
python
programmers
before
moving
on
though
here
s
another
chapter
quiz
to
review
the
material
covered
here
test
your
knowledge
quiz
can
the
string
find
method
be
used
to
search
a
list
can
a
string
slice
expression
be
used
on
a
list
how
would
you
convert
a
character
to
its
ascii
integer
code
how
would
you
convert
the
other
way
from
an
integer
to
a
character
how
might
you
go
about
changing
a
string
in
python
given
a
string
s
with
the
value
s
pa
m
name
two
ways
to
extract
the
two
characters
in
the
middle
how
many
characters
are
there
in
the
string
a
nb
x
f
d
why
might
you
use
the
string
module
instead
of
string
method
calls
test
your
knowledge
quiz
test
your
knowledge
answers
no
because
methods
are
always
type
specific
that
is
they
only
work
on
a
single
data
type
expressions
like
x
y
and
built
in
functions
like
len
x
are
generic
though
and
may
work
on
a
variety
of
types
in
this
case
for
instance
the
in
membership
expression
has
a
similar
effect
as
the
string
find
but
it
can
be
used
to
search
both
strings
and
lists
in
python
there
is
some
attempt
to
group
methods
by
categories
for
example
the
mutable
sequence
types
list
and
bytearray
have
similar
method
sets
but
methods
are
still
more
type
specific
than
other
operation
sets
yes
unlike
methods
expressions
are
generic
and
apply
to
many
types
in
this
case
the
slice
expression
is
really
a
sequence
operation
it
works
on
any
type
of
sequence
object
including
strings
lists
and
tuples
the
only
difference
is
that
when
you
slice
a
list
you
get
back
a
new
list
the
built
in
ord
s
function
converts
from
a
one
character
string
to
an
integer
character
code
chr
i
converts
from
the
integer
code
back
to
a
string
strings
cannot
be
changed
they
are
immutable
however
you
can
achieve
a
similar
effect
by
creating
a
new
string
by
concatenating
slicing
running
formatting
expressions
or
using
a
method
call
like
replace
and
then
assigning
the
result
back
to
the
original
variable
name
you
can
slice
the
string
using
s
or
split
on
the
comma
and
index
the
string
using
s
split
try
these
interactively
to
see
for
yourself
six
the
string
a
nb
x
f
d
contains
the
bytes
a
newline
n
b
binary
a
hex
escape
x
f
binary
an
octal
escape
and
d
pass
the
string
to
the
builtin
len
function
to
verify
this
and
print
each
of
its
character
s
ord
results
to
see
the
actual
byte
values
see
table
for
more
details
you
should
never
use
the
string
module
instead
of
string
object
method
calls
today
it
s
deprecated
and
its
calls
are
removed
completely
in
python
the
only
reason
for
using
the
string
module
at
all
is
for
its
other
tools
such
as
predefined
constants
you
might
also
see
it
appear
in
what
is
now
very
old
and
dusty
python
code
chapter
strings
chapter
lists
and
dictionaries
this
chapter
presents
the
list
and
dictionary
object
types
both
of
which
are
collections
of
other
objects
these
two
types
are
the
main
workhorses
in
almost
all
python
scripts
as
you
ll
see
both
types
are
remarkably
flexible
they
can
be
changed
in
place
can
grow
and
shrink
on
demand
and
may
contain
and
be
nested
in
any
other
kind
of
object
by
leveraging
these
types
you
can
build
up
and
process
arbitrarily
rich
information
structures
in
your
scripts
lists
the
next
stop
on
our
built
in
object
tour
is
the
python
list
lists
are
python
s
most
flexible
ordered
collection
object
type
unlike
strings
lists
can
contain
any
sort
of
object
numbers
strings
and
even
other
lists
also
unlike
strings
lists
may
be
changed
in
place
by
assignment
to
offsets
and
slices
list
method
calls
deletion
statements
and
more
they
are
mutable
objects
python
lists
do
the
work
of
most
of
the
collection
data
structures
you
might
have
to
implement
manually
in
lower
level
languages
such
as
c
here
is
a
quick
look
at
their
main
properties
python
lists
are
ordered
collections
of
arbitrary
objects
from
a
functional
view
lists
are
just
places
to
collect
other
objects
so
you
can
treat
them
as
groups
lists
also
maintain
a
left
to
right
positional
ordering
among
the
items
they
contain
i
e
they
are
sequences
accessed
by
offset
just
as
with
strings
you
can
fetch
a
component
object
out
of
a
list
by
indexing
the
list
on
the
object
s
offset
because
items
in
lists
are
ordered
by
their
positions
you
can
also
do
tasks
such
as
slicing
and
concatenation
variable
length
heterogeneous
and
arbitrarily
nestable
unlike
strings
lists
can
grow
and
shrink
in
place
their
lengths
can
vary
and
they
can
contain
any
sort
of
object
not
just
one
character
strings
they
re
heterogeneous
because
lists
can
contain
other
complex
objects
they
also
support
arbitrary
nesting
you
can
create
lists
of
lists
of
lists
and
so
on
of
the
category
mutable
sequence
in
terms
of
our
type
category
qualifiers
lists
are
mutable
i
e
can
be
changed
inplace
and
can
respond
to
all
the
sequence
operations
used
with
strings
such
as
indexing
slicing
and
concatenation
in
fact
sequence
operations
work
the
same
on
lists
as
they
do
on
strings
the
only
difference
is
that
sequence
operations
such
as
concatenation
and
slicing
return
new
lists
instead
of
new
strings
when
applied
to
lists
because
lists
are
mutable
however
they
also
support
other
operations
that
strings
don
t
such
as
deletion
and
index
assignment
operations
which
change
the
lists
in
place
arrays
of
object
references
technically
python
lists
contain
zero
or
more
references
to
other
objects
lists
might
remind
you
of
arrays
of
pointers
addresses
if
you
have
a
background
in
some
other
languages
fetching
an
item
from
a
python
list
is
about
as
fast
as
indexing
a
c
array
in
fact
lists
really
are
arrays
inside
the
standard
python
interpreter
not
linked
structures
as
we
learned
in
chapter
though
python
always
follows
a
reference
to
an
object
whenever
the
reference
is
used
so
your
program
deals
only
with
objects
whenever
you
assign
an
object
to
a
data
structure
component
or
variable
name
python
always
stores
a
reference
to
that
same
object
not
a
copy
of
it
unless
you
request
a
copy
explicitly
table
summarizes
common
and
representative
list
object
operations
as
usual
for
the
full
story
see
the
python
standard
library
manual
or
run
a
help
list
or
dir
list
call
interactively
for
a
complete
list
of
list
methods
you
can
pass
in
a
real
list
or
the
word
list
which
is
the
name
of
the
list
data
type
table
common
list
literals
and
operations
operation
interpretation
l
an
empty
list
l
four
items
indexes
l
abc
def
ghi
nested
sublists
l
list
spam
lists
of
an
iterable
s
items
list
of
successive
integers
l
list
range
l
i
l
i
j
l
i
j
len
l
chapter
lists
and
dictionaries
index
index
of
index
slice
length
operation
interpretation
l
l
concatenate
repeat
l
for
x
in
l
print
x
iteration
membership
in
l
l
append
methods
growing
l
extend
l
insert
i
x
l
index
methods
searching
l
count
x
l
sort
methods
sorting
reversing
etc
l
reverse
del
l
k
methods
statement
shrinking
del
l
i
j
l
pop
l
remove
l
i
j
l
i
index
assignment
slice
assignment
l
i
j
l
x
for
x
in
range
list
comprehensions
and
maps
chapters
list
map
ord
spam
when
written
down
as
a
literal
expression
a
list
is
coded
as
a
series
of
objects
really
expressions
that
return
objects
in
square
brackets
separated
by
commas
for
instance
the
second
row
in
table
assigns
the
variable
l
to
a
four
item
list
a
nested
list
is
coded
as
a
nested
square
bracketed
series
row
and
the
empty
list
is
just
a
squarebracket
pair
with
nothing
inside
row
many
of
the
operations
in
table
should
look
familiar
as
they
are
the
same
sequence
operations
we
put
to
work
on
strings
indexing
concatenation
iteration
and
so
on
lists
also
respond
to
list
specific
method
calls
which
provide
utilities
such
as
sorting
reversing
adding
items
to
the
end
etc
as
well
as
in
place
change
operations
deleting
items
assignment
to
indexes
and
slices
and
so
forth
lists
have
these
tools
for
change
operations
because
they
are
a
mutable
object
type
in
practice
you
won
t
see
many
lists
written
out
like
this
in
list
processing
programs
it
s
more
common
to
see
code
that
processes
lists
constructed
dynamically
at
runtime
in
fact
although
it
s
important
to
master
literal
syntax
most
data
structures
in
python
are
built
by
running
program
code
at
runtime
lists
lists
in
action
perhaps
the
best
way
to
understand
lists
is
to
see
them
at
work
let
s
once
again
turn
to
some
simple
interpreter
interactions
to
illustrate
the
operations
in
table
basic
list
operations
because
they
are
sequences
lists
support
many
of
the
same
operations
as
strings
for
example
lists
respond
to
the
and
operators
much
like
strings
they
mean
concatenation
and
repetition
here
too
except
that
the
result
is
a
new
list
not
a
string
python
len
ni
ni
ni
ni
ni
length
concatenation
repetition
although
the
operator
works
the
same
for
lists
and
strings
it
s
important
to
know
that
it
expects
the
same
sort
of
sequence
on
both
sides
otherwise
you
get
a
type
error
when
the
code
runs
for
instance
you
cannot
concatenate
a
list
and
a
string
unless
you
first
convert
the
list
to
a
string
using
tools
such
as
str
or
formatting
or
convert
the
string
to
a
list
the
list
built
in
function
does
the
trick
str
list
same
as
same
as
list
iteration
and
comprehensions
more
generally
lists
respond
to
all
the
sequence
operations
we
used
on
strings
in
the
prior
chapter
including
iteration
tools
in
true
for
x
in
print
x
end
membership
iteration
we
will
talk
more
formally
about
for
iteration
and
the
range
built
ins
in
chapter
because
they
are
related
to
statement
syntax
in
short
for
loops
step
through
items
in
any
sequence
from
left
to
right
executing
one
or
more
statements
for
each
item
the
last
items
in
table
list
comprehensions
and
map
calls
are
covered
in
more
detail
in
chapter
and
expanded
on
in
chapter
their
basic
operation
is
straightforward
though
as
introduced
in
chapter
list
comprehensions
are
a
way
to
build
a
new
list
chapter
lists
and
dictionaries
by
applying
an
expression
to
each
item
in
a
sequence
and
are
close
relatives
to
for
loops
list
comprehensions
res
c
for
c
in
spam
res
ssss
pppp
aaaa
mmmm
this
expression
is
functionally
equivalent
to
a
for
loop
that
builds
up
a
list
of
results
manually
but
as
we
ll
learn
in
later
chapters
list
comprehensions
are
simpler
to
code
and
faster
to
run
today
res
for
c
in
spam
res
append
c
res
ssss
pppp
aaaa
mmmm
list
comprehension
equivalent
as
also
introduced
in
chapter
the
map
built
in
function
does
similar
work
but
applies
a
function
to
items
in
a
sequence
and
collects
all
the
results
in
a
new
list
map
function
across
sequence
list
map
abs
because
we
re
not
quite
ready
for
the
full
iteration
story
we
ll
postpone
further
details
for
now
but
watch
for
a
similar
comprehension
expression
for
dictionaries
later
in
this
chapter
indexing
slicing
and
matrixes
becauselists
are
sequences
indexing
and
slicing
work
the
same
way
for
lists
as
they
do
for
strings
however
the
result
of
indexing
a
list
is
whatever
type
of
object
lives
at
the
offset
you
specify
while
slicing
a
list
always
returns
a
new
list
l
spam
spam
spam
l
spam
l
spam
l
spam
spam
offsets
start
at
zero
negative
count
from
the
right
slicing
fetches
sections
one
note
here
because
you
can
nest
lists
and
other
object
types
within
lists
you
will
sometimes
need
to
string
together
index
operations
to
go
deeper
into
a
data
structure
for
example
one
of
the
simplest
ways
to
represent
matrixes
multidimensional
arrays
in
python
is
as
lists
with
nested
sublists
here
s
a
basic
two
dimensional
list
based
array
matrix
with
one
index
you
get
an
entire
row
really
a
nested
sublist
and
with
two
you
get
an
item
within
the
row
lists
in
action
matrix
matrix
matrix
matrix
matrix
notice
in
the
preceding
interaction
that
lists
can
naturally
span
multiple
lines
if
you
want
them
to
because
they
are
contained
by
a
pair
of
brackets
more
on
syntax
in
the
next
part
of
the
book
later
in
this
chapter
you
ll
also
see
a
dictionary
based
matrix
representation
for
high
powered
numeric
work
the
numpy
extension
mentioned
in
chapter
provides
other
ways
to
handle
matrixes
changing
lists
in
place
because
lists
are
mutable
they
support
operations
that
change
a
list
object
in
place
that
is
the
operations
in
this
section
all
modify
the
list
object
directly
without
requiring
that
you
make
a
new
copy
as
you
had
to
for
strings
because
python
deals
only
in
object
references
this
distinction
between
changing
an
object
in
place
and
creating
a
new
object
matters
as
discussed
in
chapter
if
you
change
an
object
in
place
you
might
impact
more
than
one
reference
to
it
at
the
same
time
index
and
slice
assignments
when
using
a
list
you
can
change
its
contents
by
assigning
to
either
a
particular
item
offset
or
an
entire
section
slice
l
spam
spam
spam
l
eggs
index
assignment
l
spam
eggs
spam
l
eat
more
slice
assignment
delete
insert
l
replaces
items
eat
more
spam
both
index
and
slice
assignments
are
in
place
changes
they
modify
the
subject
list
directly
rather
than
generating
a
new
list
object
for
the
result
index
assignment
in
python
works
much
as
it
does
in
c
and
most
other
languages
python
replaces
the
object
reference
at
the
designated
offset
with
a
new
one
slice
assignment
the
last
operation
in
the
preceding
example
replaces
an
entire
section
of
a
list
in
a
single
step
because
it
can
be
a
bit
complex
it
is
perhaps
best
thought
of
as
a
combination
of
two
steps
chapter
lists
and
dictionaries
deletion
the
slice
you
specify
to
the
left
of
the
is
deleted
insertion
the
new
items
contained
in
the
object
to
the
right
of
the
are
inserted
into
the
list
on
the
left
at
the
place
where
the
old
slice
was
deleted
this
isn
t
what
really
happens
but
it
tends
to
help
clarify
why
the
number
of
items
inserted
doesn
t
have
to
match
the
number
of
items
deleted
for
instance
given
a
list
l
that
has
the
value
the
assignment
l
sets
l
to
the
list
python
first
deletes
the
a
one
item
slice
then
inserts
the
and
where
the
deleted
used
to
be
this
also
explains
why
l
is
really
a
deletion
operation
python
deletes
the
slice
the
item
at
offset
and
then
inserts
nothing
in
effect
slice
assignment
replaces
an
entire
section
or
column
all
at
once
because
the
length
of
the
sequence
being
assigned
does
not
have
to
match
the
length
of
the
slice
being
assigned
to
slice
assignment
can
be
used
to
replace
by
overwriting
expand
by
inserting
or
shrink
by
deleting
the
subject
list
it
s
a
powerful
operation
but
frankly
one
that
you
may
not
see
very
often
in
practice
there
are
usually
more
straightforward
ways
to
replace
insert
and
delete
concatenation
and
the
insert
pop
and
remove
list
methods
for
example
which
python
programmers
tend
to
prefer
in
practice
list
method
calls
like
strings
python
list
objects
also
support
type
specific
method
calls
many
of
which
change
the
subject
list
in
place
l
append
please
l
eat
more
spam
please
l
sort
l
spam
eat
more
please
append
method
call
add
item
at
end
sort
list
items
s
e
methods
were
introduced
in
chapter
in
brief
they
are
functions
really
attributes
that
reference
functions
that
are
associated
with
particular
objects
methods
provide
type
specific
tools
the
list
methods
presented
here
for
instance
are
generally
available
only
for
lists
perhaps
the
most
commonly
used
list
method
is
append
which
simply
tacks
a
single
item
object
reference
onto
the
end
of
the
list
unlike
concatenation
append
expects
you
to
pass
in
a
single
object
not
a
list
the
effect
of
l
append
x
is
similar
to
l
x
but
while
the
former
changes
l
in
place
the
latter
makes
a
new
list
another
commonly
seen
method
sort
orders
a
list
in
place
it
uses
python
standard
comparison
tests
here
string
comparisons
and
by
default
sorts
in
ascending
order
this
description
needs
elaboration
when
the
value
and
the
slice
being
assigned
overlap
l
l
for
instance
works
fine
because
the
value
to
be
inserted
is
fetched
before
the
deletion
happens
on
the
left
unlike
concatenation
append
doesn
t
have
to
generate
new
objects
so
it
s
usually
faster
you
can
also
mimic
append
with
clever
slice
assignments
l
len
l
x
is
like
l
append
x
and
l
x
is
like
appending
at
the
front
of
a
list
both
delete
an
empty
slice
and
insert
x
changing
l
in
place
quickly
like
append
lists
in
action
you
can
modify
sort
behavior
by
passing
in
keyword
arguments
a
special
name
value
syntax
in
function
calls
that
specifies
passing
by
name
and
is
often
used
for
giving
configuration
options
in
sorts
the
key
argument
gives
a
one
argument
function
that
returns
the
value
to
be
used
in
sorting
and
the
reverse
argument
allows
sorts
to
be
made
in
descending
instead
of
ascending
order
l
abc
abd
abe
l
sort
l
abd
abe
abc
l
abc
abd
abe
l
sort
key
str
lower
l
abc
abd
abe
l
abc
abd
abe
l
sort
key
str
lower
reverse
true
l
abe
abd
abc
sort
with
mixed
case
normalize
to
lowercase
change
sort
order
the
sort
key
argument
might
also
be
useful
when
sorting
lists
of
dictionaries
to
pick
out
a
sort
key
by
indexing
each
dictionary
we
ll
study
dictionaries
later
in
this
chapter
and
you
ll
learn
more
about
keyword
function
arguments
in
part
iv
comparison
and
sorts
in
in
python
and
earlier
comparisons
of
differently
typed
objects
e
g
a
string
and
a
list
work
the
language
defines
a
fixed
ordering
among
different
types
which
is
deterministic
if
not
aesthetically
pleasing
that
is
the
ordering
is
based
on
the
names
of
the
types
involved
all
integers
are
less
than
all
strings
for
example
because
int
is
less
than
str
comparisons
never
automatically
convert
types
except
when
comparing
numeric
type
objects
in
python
this
has
changed
comparison
of
mixed
types
raises
an
exception
instead
of
falling
back
on
the
fixed
cross
type
ordering
because
sorting
uses
comparisons
internally
this
means
that
spam
sort
succeeds
in
python
x
but
will
raise
an
exception
in
python
and
later
python
also
no
longer
supports
passing
in
an
arbitrary
comparison
function
to
sorts
to
implement
different
orderings
the
suggested
workaround
is
to
use
the
key
func
keyword
argument
to
code
value
transformations
during
the
sort
and
use
the
reverse
true
keyword
argument
to
change
the
sort
order
to
descending
these
were
the
typical
uses
of
comparison
functions
in
the
past
one
warning
here
beware
that
append
and
sort
change
the
associated
list
object
inplace
but
don
t
return
the
list
as
a
result
technically
they
both
return
a
value
called
none
if
you
say
something
like
l
l
append
x
you
won
t
get
the
modified
value
of
l
in
fact
you
ll
lose
the
reference
to
the
list
altogether
when
you
use
attributes
such
as
append
and
sort
objects
are
changed
as
a
side
effect
so
there
s
no
reason
to
reassign
chapter
lists
and
dictionaries
partly
because
of
such
constraints
sorting
is
also
available
in
recent
pythons
as
a
builtin
function
which
sorts
any
collection
not
just
lists
and
returns
a
new
list
for
the
result
instead
of
in
place
changes
l
abc
abd
abe
sorted
l
key
str
lower
reverse
true
abe
abd
abc
sorting
built
in
l
abc
abd
abe
sorted
x
lower
for
x
in
l
reverse
true
abe
abd
abc
pretransform
items
differs
notice
the
last
example
here
we
can
convert
to
lowercase
prior
to
the
sort
with
a
list
comprehension
but
the
result
does
not
contain
the
original
list
s
values
as
it
does
with
the
key
argument
the
latter
is
applied
temporarily
during
the
sort
instead
of
changing
the
values
to
be
sorted
as
we
move
along
we
ll
see
contexts
in
which
the
sorted
builtin
can
sometimes
be
more
useful
than
the
sort
method
like
strings
lists
have
other
methods
that
perform
other
specialized
operations
for
instance
reverse
reverses
the
list
in
place
and
the
extend
and
pop
methods
insert
multiple
items
at
the
end
of
and
delete
an
item
from
the
end
of
the
list
respectively
there
is
also
a
reversed
built
in
function
that
works
much
like
sorted
but
it
must
be
wrapped
in
a
list
call
because
it
s
an
iterator
more
on
iterators
later
l
l
extend
l
l
pop
l
l
reverse
l
list
reversed
l
add
many
items
at
end
delete
and
return
last
item
in
place
reversal
method
reversal
built
in
with
a
result
in
some
types
of
programs
the
list
pop
method
used
here
is
often
used
in
conjunction
with
append
to
implement
a
quick
last
in
first
out
lifo
stack
structure
the
end
of
the
list
serves
as
the
top
of
the
stack
l
l
append
l
append
l
l
pop
push
onto
stack
pop
off
stack
l
lists
in
action
the
pop
method
also
accepts
an
optional
offset
of
the
item
to
be
deleted
and
returned
the
default
is
the
last
item
other
list
methods
remove
an
item
by
value
remove
insert
an
item
at
an
offset
insert
search
for
an
item
s
offset
index
and
more
l
spam
eggs
ham
l
index
eggs
l
insert
toast
l
spam
toast
eggs
ham
l
remove
eggs
l
spam
toast
ham
l
pop
toast
l
spam
ham
index
of
an
object
insert
at
position
delete
by
value
delete
by
position
see
other
documentation
sources
or
experiment
with
these
calls
interactively
on
your
own
to
learn
more
about
list
methods
other
common
list
operations
because
lists
are
mutable
you
can
use
the
del
statement
to
delete
an
item
or
section
in
place
l
spam
eat
more
please
del
l
l
eat
more
please
del
l
l
eat
delete
one
item
delete
an
entire
section
same
as
l
because
slice
assignment
is
a
deletion
plus
an
insertion
you
can
also
delete
a
section
of
a
list
by
assigning
an
empty
list
to
a
slice
l
i
j
python
deletes
the
slice
named
on
the
left
and
then
inserts
nothing
assigning
an
empty
list
to
an
index
on
the
other
hand
just
stores
a
reference
to
the
empty
list
in
the
specified
slot
rather
than
deleting
it
l
already
got
one
l
l
already
l
l
although
all
the
operations
just
discussed
are
typical
there
are
additional
list
methods
and
operations
not
illustrated
here
including
methods
for
inserting
and
searching
for
a
comprehensive
and
up
to
date
list
of
type
tools
you
should
always
consult
chapter
lists
and
dictionaries
python
s
manuals
python
s
dir
and
help
functions
which
we
first
met
in
chapter
or
one
of
the
reference
texts
mentioned
in
the
preface
i
d
also
like
to
remind
you
one
more
time
that
all
the
in
place
change
operations
discussed
here
work
only
for
mutable
objects
they
won
t
work
on
strings
or
tuples
discussed
in
chapter
no
matter
how
hard
you
try
mutability
is
an
inherent
property
of
each
object
type
dictionaries
apart
from
lists
dictionaries
are
perhaps
the
most
flexible
built
in
data
type
in
python
if
you
think
of
lists
as
ordered
collections
of
objects
you
can
think
of
dictionaries
as
unordered
collections
the
chief
distinction
is
that
in
dictionaries
items
are
stored
and
fetched
by
key
instead
of
by
positional
offset
being
a
built
in
type
dictionaries
can
replace
many
of
the
searching
algorithms
and
data
structures
you
might
have
to
implement
manually
in
lower
level
languages
indexing
a
dictionary
is
a
very
fast
search
operation
dictionaries
also
sometimes
do
the
work
of
records
and
symbol
tables
used
in
other
languages
can
represent
sparse
mostly
empty
data
structures
and
much
more
here
s
a
rundown
of
their
main
properties
python
dictionaries
are
accessed
by
key
not
offset
dictionaries
are
sometimes
called
associative
arrays
or
hashes
they
associate
a
set
of
values
with
keys
so
you
can
fetch
an
item
out
of
a
dictionary
using
the
key
under
which
you
originally
stored
it
you
use
the
same
indexing
operation
to
get
components
in
a
dictionary
as
you
do
in
a
list
but
the
index
takes
the
form
of
a
key
not
a
relative
offset
unordered
collections
of
arbitrary
objects
unlike
in
a
list
items
stored
in
a
dictionary
aren
t
kept
in
any
particular
order
in
fact
python
randomizes
their
left
to
right
order
to
provide
quick
lookup
keys
provide
the
symbolic
not
physical
locations
of
items
in
a
dictionary
variable
length
heterogeneous
and
arbitrarily
nestable
like
lists
dictionaries
can
grow
and
shrink
in
place
without
new
copies
being
made
they
can
contain
objects
of
any
type
and
they
support
nesting
to
any
depth
they
can
contain
lists
other
dictionaries
and
so
on
of
the
category
mutable
mapping
dictionaries
can
be
changed
in
place
by
assigning
to
indexes
they
are
mutable
but
they
don
t
support
the
sequence
operations
that
work
on
strings
and
lists
because
dictionaries
are
unordered
collections
operations
that
depend
on
a
fixed
positional
order
e
g
concatenation
slicing
don
t
make
sense
instead
dictionaries
are
the
only
built
in
representatives
of
the
mapping
type
category
objects
that
map
keys
to
values
dictionaries
tables
of
object
references
hash
tables
if
lists
are
arrays
of
object
references
that
support
access
by
position
dictionaries
are
unordered
tables
of
object
references
that
support
access
by
key
internally
dictionaries
are
implemented
as
hash
tables
data
structures
that
support
very
fast
retrieval
which
start
small
and
grow
on
demand
moreover
python
employs
optimized
hashing
algorithms
to
find
keys
so
retrieval
is
quick
like
lists
dictionaries
store
object
references
not
copies
table
summarizes
some
of
the
most
common
and
representative
dictionary
operations
again
see
the
library
manual
or
run
a
dir
dict
or
help
dict
call
for
a
complete
list
dict
is
the
name
of
the
type
when
coded
as
a
literal
expression
a
dictionary
is
written
as
a
series
of
key
value
pairs
separated
by
commas
enclosed
in
curly
braces
an
empty
dictionary
is
an
empty
set
of
braces
and
dictionaries
can
be
nested
by
writing
one
as
a
value
inside
another
dictionary
or
within
a
list
or
tuple
table
common
dictionary
literals
and
operations
operation
interpretation
d
empty
dictionary
d
spam
eggs
two
item
dictionary
d
food
ham
egg
nesting
d
dict
name
bob
age
alternative
construction
techniques
d
dict
zip
keyslist
valslist
keywords
zipped
pairs
key
lists
d
dict
fromkeys
a
b
d
eggs
indexing
by
key
d
food
ham
eggs
in
d
membership
key
present
test
d
keys
methods
keys
d
values
values
d
items
keys
values
d
copy
copies
d
get
key
default
defaults
d
update
d
merge
d
pop
key
delete
etc
len
d
length
number
of
stored
entries
d
key
adding
changing
keys
as
with
lists
you
won
t
often
see
dictionaries
constructed
using
literals
lists
and
dictionaries
are
grown
in
different
ways
though
as
you
ll
see
in
the
next
section
dictionaries
are
typically
built
up
by
assigning
to
new
keys
at
runtime
this
approach
fails
for
lists
lists
are
commonly
grown
with
append
instead
chapter
lists
and
dictionaries
operation
interpretation
del
d
key
deleting
entries
by
key
list
d
keys
dictionary
views
python
d
keys
d
keys
d
x
x
for
x
in
range
dictionary
comprehensions
python
dictionaries
in
action
as
table
suggests
dictionaries
are
indexed
by
key
and
nested
dictionary
entries
are
referenced
by
a
series
of
indexes
keys
in
square
brackets
when
python
creates
a
dictionary
it
stores
its
items
in
any
left
to
right
order
it
chooses
to
fetch
a
value
back
you
supply
the
key
with
which
it
is
associated
not
its
relative
position
let
s
go
back
to
the
interpreter
to
get
a
feel
for
some
of
the
dictionary
operations
in
table
basic
dictionary
operations
in
normal
operation
you
create
dictionaries
with
literals
and
store
and
access
items
by
key
with
indexing
python
d
spam
ham
eggs
d
spam
d
eggs
ham
spam
make
a
dictionary
fetch
a
value
by
key
order
is
scrambled
here
the
dictionary
is
assigned
to
the
variable
d
the
value
of
the
key
spam
is
the
integer
and
so
on
we
use
the
same
square
bracket
syntax
to
index
dictionaries
by
key
as
we
did
to
index
lists
by
offset
but
here
it
means
access
by
key
not
by
position
notice
the
end
of
this
example
the
left
to
right
order
of
keys
in
a
dictionary
will
almost
always
be
different
from
what
you
originally
typed
this
is
on
purpose
to
implement
fast
key
lookup
a
k
a
hashing
keys
need
to
be
reordered
in
memory
that
s
why
operations
that
assume
a
fixed
left
to
right
order
e
g
slicing
concatenation
do
not
apply
to
dictionaries
you
can
fetch
values
only
by
key
not
by
position
the
built
in
len
function
works
on
dictionaries
too
it
returns
the
number
of
items
stored
in
the
dictionary
or
equivalently
the
length
of
its
keys
list
the
dictionary
in
membership
operator
allows
you
to
test
for
key
existence
and
the
keys
method
returns
all
the
keys
in
the
dictionary
the
latter
of
these
can
be
useful
for
processing
dictionaries
sequentially
but
you
shouldn
t
depend
on
the
order
of
the
keys
list
because
the
keys
result
can
be
used
as
a
normal
list
however
it
can
always
be
sorted
if
order
matters
more
on
sorting
and
dictionaries
later
len
d
ham
in
d
number
of
entries
in
dictionary
key
membership
test
alternative
dictionaries
in
action
true
list
d
keys
eggs
ham
spam
create
a
new
list
of
my
keys
notice
the
second
expression
in
this
listing
as
mentioned
earlier
the
in
membership
test
used
for
strings
and
lists
also
works
on
dictionaries
it
checks
whether
a
key
is
stored
in
the
dictionary
technically
this
works
because
dictionaries
define
iterators
that
step
through
their
keys
lists
other
types
provide
iterators
that
reflect
their
common
uses
files
for
example
have
iterators
that
read
line
by
line
we
ll
discuss
iterators
in
chapters
and
also
note
the
syntax
of
the
last
example
in
this
listing
we
have
to
enclose
it
in
a
list
call
in
python
for
similar
reasons
keys
in
returns
an
iterator
instead
of
a
physical
list
the
list
call
forces
it
to
produce
all
its
values
at
once
so
we
can
print
them
in
keys
builds
and
returns
an
actual
list
so
the
list
call
isn
t
needed
to
display
results
more
on
this
later
in
this
chapter
the
order
of
keys
in
a
dictionary
is
arbitrary
and
can
change
from
release
to
release
so
don
t
be
alarmed
if
your
dictionaries
print
in
a
different
order
than
shown
here
in
fact
the
order
has
changed
for
me
too
i
m
running
all
these
examples
with
python
but
their
keys
had
a
different
order
in
an
earlier
edition
when
displayed
you
shouldn
t
depend
on
dictionary
key
ordering
in
either
programs
or
books
changing
dictionaries
in
place
let
s
continue
with
our
interactive
session
dictionaries
like
lists
are
mutable
so
you
can
change
expand
and
shrink
them
in
place
without
making
new
dictionaries
simply
assign
a
value
to
a
key
to
change
or
create
an
entry
the
del
statement
works
here
too
it
deletes
the
entry
associated
with
the
key
specified
as
an
index
notice
also
the
nesting
of
a
list
inside
a
dictionary
in
this
example
the
value
of
the
key
ham
all
collection
data
types
in
python
can
nest
inside
each
other
arbitrarily
d
eggs
ham
spam
d
ham
grill
bake
fry
change
entry
d
eggs
ham
grill
bake
fry
spam
del
d
eggs
d
ham
grill
bake
fry
spam
delete
entry
d
brunch
bacon
add
new
entry
d
brunch
bacon
ham
grill
bake
fry
spam
chapter
lists
and
dictionaries
as
with
lists
assigning
to
an
existing
index
in
a
dictionary
changes
its
associated
value
unlike
with
lists
however
whenever
you
assign
a
new
dictionary
key
one
that
hasn
t
been
assigned
before
you
create
a
new
entry
in
the
dictionary
as
was
done
in
the
previous
example
for
the
key
brunch
this
doesn
t
work
for
lists
because
python
considers
an
offset
beyond
the
end
of
a
list
out
of
bounds
and
throws
an
error
to
expand
a
list
you
need
to
use
tools
such
as
the
append
method
or
slice
assignment
instead
more
dictionary
methods
dictionary
methods
provide
a
variety
of
tools
for
instance
the
dictionary
values
and
items
methods
return
the
dictionary
s
values
and
key
value
pair
tuples
respectively
as
with
keys
wrap
them
in
a
list
call
in
python
to
collect
their
values
for
display
d
spam
ham
eggs
list
d
values
list
d
items
eggs
ham
spam
such
lists
are
useful
in
loops
that
need
to
step
through
dictionary
entries
one
by
one
fetching
a
nonexistent
key
is
normally
an
error
but
the
get
method
returns
a
default
value
none
or
a
passed
in
default
if
the
key
doesn
t
exist
it
s
an
easy
way
to
fill
in
a
default
for
a
key
that
isn
t
present
and
avoid
a
missing
key
error
d
get
spam
print
d
get
toast
none
d
get
toast
a
key
that
is
there
a
key
that
is
missing
the
update
method
provides
something
similar
to
concatenation
for
dictionaries
though
it
has
nothing
to
do
with
left
to
right
ordering
again
there
is
no
such
thing
in
dictionaries
it
merges
the
keys
and
values
of
one
dictionary
into
another
blindly
overwriting
values
of
the
same
key
d
eggs
ham
spam
d
toast
muffin
d
update
d
d
toast
muffin
eggs
ham
spam
finally
the
dictionary
pop
method
deletes
a
key
from
a
dictionary
and
returns
the
value
it
had
it
s
similar
to
the
list
pop
method
but
it
takes
a
key
instead
of
an
optional
position
pop
a
dictionary
by
key
d
toast
muffin
eggs
ham
spam
d
pop
muffin
dictionaries
in
action
d
pop
toast
d
eggs
ham
spam
pop
a
list
by
position
l
aa
bb
cc
dd
l
pop
dd
l
aa
bb
cc
l
pop
bb
l
aa
cc
delete
and
return
from
a
key
delete
and
return
from
the
end
delete
from
a
specific
position
dictionaries
also
provide
a
copy
method
we
ll
discuss
this
in
chapter
as
it
s
a
way
to
avoid
the
potential
side
effects
of
shared
references
to
the
same
dictionary
in
fact
dictionaries
come
with
many
more
methods
than
those
listed
in
table
see
the
python
library
manual
or
other
documentation
sources
for
a
comprehensive
list
a
languages
table
let
s
look
at
a
more
realistic
dictionary
example
the
following
example
creates
a
table
that
maps
programming
language
names
the
keys
to
their
creators
the
values
you
fetch
creator
names
by
indexing
on
language
names
table
python
guido
van
rossum
perl
larry
wall
tcl
john
ousterhout
language
python
creator
table
language
creator
guido
van
rossum
for
tcl
python
perl
lang
in
table
print
lang
t
table
lang
same
as
for
lang
in
table
keys
john
ousterhout
guido
van
rossum
larry
wall
the
last
command
uses
a
for
loop
which
we
haven
t
covered
in
detail
yet
if
you
aren
t
familiar
with
for
loops
this
command
simply
iterates
through
each
key
in
the
table
and
prints
a
tab
separated
list
of
keys
and
their
values
we
ll
learn
more
about
for
loops
in
chapter
dictionaries
aren
t
sequences
like
lists
and
strings
but
if
you
need
to
step
through
the
items
in
a
dictionary
it
s
easy
calling
the
dictionary
keys
method
returns
all
stored
chapter
lists
and
dictionaries
keys
which
you
can
iterate
through
with
a
for
if
needed
you
can
index
from
key
to
value
inside
the
for
loop
as
was
done
in
this
code
in
fact
python
also
lets
you
step
through
a
dictionary
s
keys
list
without
actually
calling
the
keys
method
in
most
for
loops
for
any
dictionary
d
saying
for
key
in
d
works
the
same
as
saying
the
complete
for
key
in
d
keys
this
is
really
just
another
instance
of
the
iterators
mentioned
earlier
which
allow
the
in
membership
operator
to
work
on
dictionaries
as
well
more
on
iterators
later
in
this
book
dictionary
usage
notes
dictionaries
are
fairly
straightforward
tools
once
you
get
the
hang
of
them
but
here
are
a
few
additional
pointers
and
reminders
you
should
be
aware
of
when
using
them
sequence
operations
don
t
work
dictionaries
are
mappings
not
sequences
because
there
s
no
notion
of
ordering
among
their
items
things
like
concatenation
an
ordered
joining
and
slicing
extracting
a
contiguous
section
simply
don
t
apply
in
fact
python
raises
an
error
when
your
code
runs
if
you
try
to
do
such
things
assigning
to
new
indexes
adds
entries
keys
can
be
created
when
you
write
a
dictionary
literal
in
which
case
they
are
embedded
in
the
literal
itself
or
when
you
assign
values
to
new
keys
of
an
existing
dictionary
object
the
end
result
is
the
same
keys
need
not
always
be
strings
our
examples
so
far
have
used
strings
as
keys
but
any
other
immutable
objects
i
e
not
lists
work
just
as
well
for
instance
you
can
use
integers
as
keys
which
makes
the
dictionary
look
much
like
a
list
when
indexing
at
least
tuples
are
sometimes
used
as
dictionary
keys
too
allowing
for
compound
key
values
class
instance
objects
discussed
in
part
vi
can
also
be
used
as
keys
as
long
as
they
have
the
proper
protocol
methods
roughly
they
need
to
tell
python
that
their
values
are
hashable
and
won
t
change
as
otherwise
they
would
be
useless
as
fixed
keys
using
dictionaries
to
simulate
flexible
lists
the
last
point
in
the
prior
list
is
important
enough
to
demonstrate
with
a
few
examples
when
you
use
lists
it
is
illegal
to
assign
to
an
offset
that
is
off
the
end
of
the
list
l
l
spam
traceback
most
recent
call
last
file
stdin
line
in
indexerror
list
assignment
index
out
of
range
although
you
can
use
repetition
to
preallocate
as
big
a
list
as
you
ll
need
e
g
you
can
also
do
something
that
looks
similar
with
dictionaries
that
does
not
require
such
space
allocations
by
using
integer
keys
dictionaries
can
emulate
lists
that
seem
to
grow
on
offset
assignment
dictionaries
in
action
d
d
spam
d
spam
d
spam
here
it
looks
as
if
d
is
a
item
list
but
it
s
really
a
dictionary
with
a
single
entry
the
value
of
the
key
is
the
string
spam
you
can
access
this
structure
with
offsets
much
like
a
list
but
you
don
t
have
to
allocate
space
for
all
the
positions
you
might
ever
need
to
assign
values
to
in
the
future
when
used
like
this
dictionaries
are
like
more
flexible
equivalents
of
lists
using
dictionaries
for
sparse
data
structures
in
a
similar
way
dictionary
keys
are
also
commonly
leveraged
to
implement
sparse
data
structures
for
example
multidimensional
arrays
where
only
a
few
positions
have
values
stored
in
them
matrix
matrix
matrix
x
y
z
matrix
x
y
z
matrix
separates
statements
here
we
ve
used
a
dictionary
to
represent
a
three
dimensional
array
that
is
empty
except
for
the
two
positions
and
the
keys
are
tuples
that
record
the
coordinates
of
nonempty
slots
rather
than
allocating
a
large
and
mostly
empty
threedimensional
matrix
to
hold
these
values
we
can
use
a
simple
two
item
dictionary
in
this
scheme
accessing
an
empty
slot
triggers
a
nonexistent
key
exception
as
these
slots
are
not
physically
stored
matrix
traceback
most
recent
call
last
file
stdin
line
in
keyerror
avoiding
missing
key
errors
errors
for
nonexistent
key
fetches
are
common
in
sparse
matrixes
but
you
probably
won
t
want
them
to
shut
down
your
program
there
are
at
least
three
ways
to
fill
in
a
default
value
instead
of
getting
such
an
error
message
you
can
test
for
keys
ahead
of
time
in
if
statements
use
a
try
statement
to
catch
and
recover
from
the
exception
explicitly
or
simply
use
the
dictionary
get
method
shown
earlier
to
provide
a
default
for
keys
that
do
not
exist
if
in
matrix
print
matrix
chapter
lists
and
dictionaries
check
for
key
before
fetch
see
chapter
for
if
else
else
print
try
print
matrix
except
keyerror
print
try
to
index
catch
and
recover
see
chapter
for
try
except
matrix
get
exists
fetch
and
return
matrix
get
doesn
t
exist
use
default
arg
of
these
the
get
method
is
the
most
concise
in
terms
of
coding
requirements
we
ll
study
the
if
and
try
statements
in
more
detail
later
in
this
book
using
dictionaries
as
records
as
you
can
see
dictionaries
can
play
many
roles
in
python
in
general
they
can
replace
search
data
structures
because
indexing
by
key
is
a
search
operation
and
can
represent
many
types
of
structured
information
for
example
dictionaries
are
one
of
many
ways
to
describe
the
properties
of
an
item
in
your
program
s
domain
that
is
they
can
serve
the
same
role
as
records
or
structs
in
other
languages
the
following
for
example
fills
out
a
dictionary
by
assigning
to
new
keys
over
time
mel
rec
rec
name
mel
rec
age
rec
job
trainer
writer
print
rec
name
especially
when
nested
python
s
built
in
data
types
allow
us
to
easily
represent
structured
information
this
example
again
uses
a
dictionary
to
capture
object
properties
but
it
codes
it
all
at
once
rather
than
assigning
to
each
key
separately
and
nests
a
list
and
a
dictionary
to
represent
structured
property
values
mel
name
mark
jobs
trainer
writer
web
www
rmi
net
lutz
home
state
co
zip
to
fetch
components
of
nested
objects
simply
string
together
indexing
operations
mel
name
mark
mel
jobs
trainer
writer
mel
jobs
writer
dictionaries
in
action
mel
home
zip
although
we
ll
learn
in
part
vi
that
classes
which
group
both
data
and
logic
can
be
better
in
this
record
role
dictionaries
are
an
easy
to
use
tool
for
simpler
requirements
why
you
will
care
dictionary
interfaces
dictionaries
aren
t
just
a
convenient
way
to
store
information
by
key
in
your
programs
some
python
extensions
also
present
interfaces
that
look
like
and
work
the
same
as
dictionaries
for
instance
python
s
interface
to
dbm
access
by
key
files
looks
much
like
a
dictionary
that
must
be
opened
strings
are
stored
and
fetched
using
key
indexes
import
anydbm
file
anydbm
open
filename
link
to
file
file
key
data
store
data
by
key
data
file
key
fetch
data
by
key
in
chapter
you
ll
see
that
you
can
store
entire
python
objects
this
way
too
if
you
replace
anydbm
in
the
preceding
code
with
shelve
shelves
are
access
by
key
databases
of
persistent
python
objects
for
internet
work
python
s
cgi
script
support
also
presents
a
dictionary
like
interface
a
call
to
cgi
fieldstorage
yields
a
dictionary
like
object
with
one
entry
per
input
field
on
the
client
s
web
page
import
cgi
form
cgi
fieldstorage
parse
form
data
if
name
in
form
showreply
hello
form
name
value
all
of
these
like
dictionaries
are
instances
of
mappings
once
you
learn
dictionary
interfaces
you
ll
find
that
they
apply
to
a
variety
of
built
in
tools
in
python
other
ways
to
make
dictionaries
finally
note
that
because
dictionaries
are
so
useful
more
ways
to
build
them
have
emerged
over
time
in
python
and
later
for
example
the
last
two
calls
to
the
dict
constructor
really
type
name
shown
here
have
the
same
effect
as
the
literal
and
keyassignment
forms
above
them
name
mel
age
traditional
literal
expression
d
d
name
mel
d
age
assign
by
keys
dynamically
dict
name
mel
age
dict
keyword
argument
form
dict
name
mel
age
dict
key
value
tuples
form
all
four
of
these
forms
create
the
same
two
key
dictionary
but
they
are
useful
in
differing
circumstances
chapter
lists
and
dictionaries
the
first
is
handy
if
you
can
spell
out
the
entire
dictionary
ahead
of
time
the
second
is
of
use
if
you
need
to
create
the
dictionary
one
field
at
a
time
on
the
fly
the
third
involves
less
typing
than
the
first
but
it
requires
all
keys
to
be
strings
the
last
is
useful
if
you
need
to
build
up
keys
and
values
as
sequences
at
runtime
we
met
keyword
arguments
earlier
when
sorting
the
third
form
illustrated
in
this
code
listing
has
become
especially
popular
in
python
code
today
since
it
has
less
syntax
and
hence
there
is
less
opportunity
for
mistakes
as
suggested
previously
in
table
the
last
form
in
the
listing
is
also
commonly
used
in
conjunction
with
the
zip
function
to
combine
separate
lists
of
keys
and
values
obtained
dynamically
at
runtime
parsed
out
of
a
data
file
s
columns
for
instance
more
on
this
option
in
the
next
section
provided
all
the
key
s
values
are
the
same
initially
you
can
also
create
a
dictionary
with
this
special
form
simply
pass
in
a
list
of
keys
and
an
initial
value
for
all
of
the
values
the
default
is
none
dict
fromkeys
a
b
a
b
although
you
could
get
by
with
just
literals
and
key
assignments
at
this
point
in
your
python
career
you
ll
probably
find
uses
for
all
of
these
dictionary
creation
forms
as
you
start
applying
them
in
realistic
flexible
and
dynamic
python
programs
the
listings
in
this
section
document
the
various
ways
to
create
dictionaries
in
both
python
and
however
there
is
yet
another
way
to
create
dictionaries
available
only
in
python
and
later
the
dictionary
comprehension
expression
to
see
how
this
last
form
looks
we
need
to
move
on
to
the
next
section
dictionary
changes
in
python
this
chapter
has
so
far
focused
on
dictionary
basics
that
span
releases
but
the
dictionary
s
functionality
has
mutated
in
python
if
you
are
using
python
x
code
you
may
come
across
some
dictionary
tools
that
either
behave
differently
or
are
missing
altogether
in
moreover
coders
have
access
to
additional
dictionary
tools
not
available
in
x
specifically
dictionaries
in
support
a
new
dictionary
comprehension
expression
a
close
cousin
to
list
and
set
comprehensions
return
iterable
views
instead
of
lists
for
the
methods
d
keys
d
values
and
d
items
require
new
coding
styles
for
scanning
by
sorted
keys
because
of
the
prior
point
no
longer
support
relative
magnitude
comparisons
directly
compare
manually
instead
no
longer
have
the
d
has
key
method
the
in
membership
test
is
used
instead
let
s
take
a
look
at
what
s
new
in
dictionaries
dictionaries
in
action
dictionary
comprehensions
as
mentioned
at
the
end
of
the
prior
section
dictionaries
in
can
also
be
created
with
dictionary
comprehensions
like
the
set
comprehensions
we
met
in
chapter
dictionary
comprehensions
are
available
only
in
not
in
like
the
longstanding
list
comprehensions
we
met
briefly
in
chapter
and
earlier
in
this
chapter
they
run
an
implied
loop
collecting
the
key
value
results
of
expressions
on
each
iteration
and
using
them
to
fill
out
a
new
dictionary
a
loop
variable
allows
the
comprehension
to
use
loop
iteration
values
along
the
way
for
example
a
standard
way
to
initialize
a
dictionary
dynamically
in
both
and
is
to
zip
together
its
keys
and
values
and
pass
the
result
to
the
dict
call
as
we
ll
learn
in
more
detail
in
chapter
the
zip
function
is
a
way
to
construct
a
dictionary
from
key
and
value
lists
in
a
single
call
if
you
cannot
predict
the
set
of
keys
and
values
in
your
code
you
can
always
build
them
up
as
lists
and
zip
them
together
list
zip
a
b
c
a
b
c
zip
together
keys
and
values
d
dict
zip
a
b
c
d
a
c
b
make
a
dict
from
zip
result
in
python
you
can
achieve
the
same
effect
with
a
dictionary
comprehension
expression
the
following
builds
a
new
dictionary
with
a
key
value
pair
for
every
such
pair
in
the
zip
result
it
reads
almost
the
same
in
python
but
with
a
bit
more
formality
c
misc
c
python
python
use
a
dict
comprehension
d
k
v
for
k
v
in
zip
a
b
c
d
a
c
b
comprehensions
actually
require
more
code
in
this
case
but
they
are
also
more
general
than
this
example
implies
we
can
use
them
to
map
a
single
stream
of
values
to
dictionaries
as
well
and
keys
can
be
computed
with
expressions
just
like
values
d
x
x
for
x
in
d
or
range
d
c
c
for
c
in
spam
loop
over
any
iterable
d
a
aaaa
p
pppp
s
ssss
m
mmmm
d
c
lower
c
for
c
in
spam
eggs
ham
d
eggs
eggs
ham
ham
spam
spam
dictionary
comprehensions
are
also
useful
for
initializing
dictionaries
from
keys
lists
in
much
the
same
way
as
the
fromkeys
method
we
met
at
the
end
of
the
preceding
section
chapter
lists
and
dictionaries
d
dict
fromkeys
a
b
c
d
a
c
b
initialize
dict
from
keys
d
k
for
k
in
a
b
c
d
a
c
b
same
but
with
a
comprehension
d
dict
fromkeys
spam
d
a
none
p
none
s
none
m
none
other
iterators
default
value
d
k
none
for
k
in
spam
d
a
none
p
none
s
none
m
none
like
related
tools
dictionary
comprehensions
support
additional
syntax
not
shown
here
including
nested
loops
and
if
clauses
unfortunately
to
truly
understand
dictionary
comprehensions
we
need
to
also
know
more
about
iteration
statements
and
concepts
in
python
and
we
don
t
yet
have
enough
information
to
address
that
story
well
we
ll
learn
much
more
about
all
flavors
of
comprehensions
list
set
and
dictionary
in
chapters
and
so
we
ll
defer
further
details
until
later
we
ll
also
study
the
zip
built
in
we
used
in
this
section
in
more
detail
in
chapter
when
we
explore
for
loops
dictionary
views
in
the
dictionary
keys
values
and
items
methods
all
return
view
objects
whereas
in
they
return
actual
result
lists
view
objects
are
iterables
which
simply
means
objects
that
generate
result
items
one
at
a
time
instead
of
producing
the
result
list
all
at
once
in
memory
besides
being
iterable
dictionary
views
also
retain
the
original
order
of
dictionary
components
reflect
future
changes
to
the
dictionary
and
may
support
set
operations
on
the
other
hand
they
are
not
lists
and
they
do
not
support
operations
like
indexing
or
the
list
sort
method
nor
do
they
display
their
items
when
printed
we
ll
discuss
the
notion
of
iterables
more
formally
in
chapter
but
for
our
purposes
here
it
s
enough
to
know
that
we
have
to
run
the
results
of
these
three
methods
through
the
list
built
in
if
we
want
to
apply
list
operations
or
display
their
values
d
dict
a
b
c
d
a
c
b
k
d
keys
k
dict
keys
object
at
x
d
c
list
k
a
c
b
makes
a
view
object
in
not
a
list
force
a
real
list
in
if
needed
v
d
values
ditto
for
values
and
items
views
v
dict
values
object
at
x
d
dictionaries
in
action
list
v
list
d
items
a
c
b
k
list
operations
fail
unless
converted
typeerror
dict
keys
object
does
not
support
indexing
list
k
a
apart
from
when
displaying
results
at
the
interactive
prompt
you
will
probably
rarely
even
notice
this
change
because
looping
constructs
in
python
automatically
force
iterable
objects
to
produce
one
result
on
each
iteration
for
k
in
d
keys
print
k
a
c
b
iterators
used
automatically
in
loops
in
addition
dictionaries
still
have
iterators
themselves
which
return
successive
keys
as
in
it
s
still
often
not
necessary
to
call
keys
directly
for
key
in
d
print
key
a
c
b
still
no
need
to
call
keys
to
iterate
unlike
x
s
list
results
though
dictionary
views
in
are
not
carved
in
stone
when
created
they
dynamically
reflect
future
changes
made
to
the
dictionary
after
the
view
object
has
been
created
d
a
b
c
d
a
c
b
k
d
keys
v
d
values
list
k
a
c
b
list
v
views
maintain
same
order
as
dictionary
del
d
b
d
a
c
change
the
dictionary
in
place
list
k
a
c
list
v
reflected
in
any
current
view
objects
chapter
lists
and
dictionaries
not
true
in
x
dictionary
views
and
sets
also
unlike
x
s
list
results
s
view
objects
returned
by
the
keys
method
are
setlike
and
support
common
set
operations
such
as
intersection
and
union
values
views
are
not
since
they
aren
t
unique
but
items
results
are
if
their
key
value
pairs
are
unique
and
hashable
given
that
sets
behave
much
like
valueless
dictionaries
and
are
even
coded
in
curly
braces
like
dictionaries
in
this
is
a
logical
symmetry
like
dictionary
keys
set
items
are
unordered
unique
and
immutable
here
is
what
keys
lists
look
like
when
used
in
set
operations
in
set
operations
views
may
be
mixed
with
other
views
sets
and
dictionaries
dictionaries
are
treated
the
same
as
their
keys
views
in
this
context
k
x
a
x
c
keys
and
some
items
views
are
set
like
v
x
typeerror
unsupported
operand
type
s
for
dict
values
and
dict
v
x
values
typeerror
unsupported
operand
type
s
for
dict
values
and
dict
values
d
a
b
c
d
keys
d
keys
a
c
b
d
keys
b
b
d
keys
b
b
d
keys
b
c
d
a
c
b
d
intersect
keys
views
intersect
keys
and
set
intersect
keys
and
dict
union
keys
and
set
dictionary
items
views
are
set
like
too
if
they
are
hashable
that
is
if
they
contain
only
immutable
objects
d
a
list
d
items
a
d
items
d
keys
a
a
d
items
d
a
a
items
set
like
if
hashable
union
view
and
view
dict
treated
same
as
its
keys
d
items
c
d
a
d
c
dict
d
items
c
d
a
c
d
set
of
key
value
pairs
dict
accepts
iterable
sets
too
for
more
details
on
set
operations
in
general
see
chapter
now
let
s
look
at
three
other
quick
coding
notes
for
dictionaries
dictionaries
in
action
sorting
dictionary
keys
first
of
all
because
keys
does
not
return
a
list
the
traditional
coding
pattern
for
scanning
a
dictionary
by
sorted
keys
in
x
won
t
work
in
you
must
either
convert
to
a
list
manually
or
use
the
sorted
call
introduced
in
chapter
and
earlier
in
this
chapter
on
either
a
keys
view
or
the
dictionary
itself
d
a
b
c
d
a
c
b
ks
d
keys
sorting
a
view
object
doesn
t
work
ks
sort
attributeerror
dict
keys
object
has
no
attribute
sort
ks
list
ks
ks
sort
for
k
in
ks
print
k
d
k
a
b
c
d
a
c
b
ks
d
keys
for
k
in
sorted
ks
print
k
d
k
a
b
c
d
a
c
b
for
k
in
sorted
d
print
k
d
k
a
b
c
force
it
to
be
a
list
and
then
sort
or
you
can
use
sorted
on
the
keys
sorted
accepts
any
iterable
sorted
returns
its
result
better
yet
sort
the
dict
directly
dict
iterators
return
keys
dictionary
magnitude
comparisons
no
longer
work
secondly
while
in
python
dictionaries
may
be
compared
for
relative
magnitude
directly
with
and
so
on
in
python
this
no
longer
works
however
it
can
be
simulated
by
comparing
sorted
keys
lists
manually
sorted
d
items
sorted
d
items
like
d
d
dictionary
equality
tests
still
work
in
though
since
we
ll
revisit
this
in
the
next
chapter
in
the
context
of
comparisons
at
large
we
ll
defer
further
details
here
chapter
lists
and
dictionaries
the
has
key
method
is
dead
long
live
in
finally
the
widely
used
dictionary
has
key
key
presence
test
method
is
gone
in
instead
use
the
in
membership
expression
or
a
get
with
a
default
test
of
these
in
is
generally
preferred
d
a
c
b
d
has
key
c
x
only
true
false
attributeerror
dict
object
has
no
attribute
has
key
c
in
d
true
x
in
d
false
if
c
in
d
print
present
d
c
present
print
d
get
c
print
d
get
x
none
if
d
get
c
none
print
present
d
c
present
preferred
in
another
option
if
you
work
in
and
care
about
compatibility
note
that
the
first
two
changes
comprehensions
and
views
can
only
be
coded
in
but
the
last
three
sorted
manual
comparisons
and
in
can
be
coded
in
today
to
ease
migration
in
the
future
chapter
summary
in
this
chapter
we
explored
the
list
and
dictionary
types
probably
the
two
most
common
flexible
and
powerful
collection
types
you
will
see
and
use
in
python
code
we
learned
that
the
list
type
supports
positionally
ordered
collections
of
arbitrary
objects
and
that
it
may
be
freely
nested
and
grown
and
shrunk
on
demand
the
dictionary
type
is
similar
but
it
stores
items
by
key
instead
of
by
position
and
does
not
maintain
any
reliable
left
to
right
order
among
its
items
both
lists
and
dictionaries
are
mutable
and
so
support
a
variety
of
in
place
change
operations
not
available
for
strings
for
example
lists
can
be
grown
by
append
calls
and
dictionaries
by
assignment
to
new
keys
in
the
next
chapter
we
will
wrap
up
our
in
depth
core
object
type
tour
by
looking
at
tuples
and
files
after
that
we
ll
move
on
to
statements
that
code
the
logic
that
processes
our
objects
taking
us
another
step
toward
writing
complete
programs
before
we
tackle
those
topics
though
here
are
some
chapter
quiz
questions
to
review
chapter
summary
test
your
knowledge
quiz
name
two
ways
to
build
a
list
containing
five
integer
zeros
name
two
ways
to
build
a
dictionary
with
two
keys
a
and
b
each
having
an
associated
value
of
name
four
operations
that
change
a
list
object
in
place
name
four
operations
that
change
a
dictionary
object
in
place
test
your
knowledge
answers
a
literal
expression
like
and
a
repetition
expression
like
will
each
create
a
list
of
five
zeros
in
practice
you
might
also
build
one
up
with
a
loop
that
starts
with
an
empty
list
and
appends
to
it
in
each
iteration
l
append
a
list
comprehension
for
i
in
range
could
work
here
too
but
this
is
more
work
than
you
need
to
do
a
literal
expression
such
as
a
b
or
a
series
of
assignments
like
d
d
a
and
d
b
would
create
the
desired
dictionary
you
can
also
use
the
newer
and
simpler
to
code
dict
a
b
keyword
form
or
the
more
flexible
dict
a
b
key
value
sequences
form
or
because
all
the
values
are
the
same
you
can
use
the
special
form
dict
fromkeys
ab
in
you
can
also
use
a
dictionary
comprehension
k
for
k
in
ab
the
append
and
extend
methods
grow
a
list
in
place
the
sort
and
reverse
methods
order
and
reverse
lists
the
insert
method
inserts
an
item
at
an
offset
the
remove
and
pop
methods
delete
from
a
list
by
value
and
by
position
the
del
statement
deletes
an
item
or
slice
and
index
and
slice
assignment
statements
replace
an
item
or
entire
section
pick
any
four
of
these
for
the
quiz
dictionaries
are
primarily
changed
by
assignment
to
a
new
or
existing
key
which
creates
or
changes
the
key
s
entry
in
the
table
also
the
del
statement
deletes
a
key
s
entry
the
dictionary
update
method
merges
one
dictionary
into
another
inplace
and
d
pop
key
removes
a
key
and
returns
the
value
it
had
dictionaries
also
have
other
more
exotic
in
place
change
methods
not
listed
in
this
chapter
such
as
setdefault
see
reference
sources
for
more
details
chapter
lists
and
dictionaries
chapter
tuples
files
and
everything
else
this
chapter
rounds
out
our
in
depth
look
at
the
core
object
types
in
python
by
exploring
the
tuple
a
collection
of
other
objects
that
cannot
be
changed
and
the
file
an
interface
to
external
files
on
your
computer
as
you
ll
see
the
tuple
is
a
relatively
simple
object
that
largely
performs
operations
you
ve
already
learned
about
for
strings
and
lists
the
file
object
is
a
commonly
used
and
full
featured
tool
for
processing
files
the
basic
overview
of
files
here
is
supplemented
by
larger
examples
in
later
chapters
this
chapter
also
concludes
this
part
of
the
book
by
looking
at
properties
common
to
all
the
core
object
types
we
ve
met
the
notions
of
equality
comparisons
object
copies
and
so
on
we
ll
also
briefly
explore
other
object
types
in
the
python
toolbox
as
you
ll
see
although
we
ve
covered
all
the
primary
built
in
types
the
object
story
in
python
is
broader
than
i
ve
implied
thus
far
finally
we
ll
close
this
part
of
the
book
by
taking
a
look
at
a
set
of
common
object
type
pitfalls
and
exploring
some
exercises
that
will
allow
you
to
experiment
with
the
ideas
you
ve
learned
tuples
the
last
collection
type
in
our
survey
is
the
python
tuple
tuples
construct
simple
groups
of
objects
they
work
exactly
like
lists
except
that
tuples
can
t
be
changed
inplace
they
re
immutable
and
are
usually
written
as
a
series
of
items
in
parentheses
not
square
brackets
although
they
don
t
support
as
many
methods
tuples
share
most
of
their
properties
with
lists
here
s
a
quick
look
at
the
basics
tuples
are
ordered
collections
of
arbitrary
objects
like
strings
and
lists
tuples
are
positionally
ordered
collections
of
objects
i
e
they
maintain
a
left
to
right
order
among
their
contents
like
lists
they
can
embed
any
kind
of
object
accessed
by
offset
like
strings
and
lists
items
in
a
tuple
are
accessed
by
offset
not
by
key
they
support
all
the
offset
based
access
operations
such
as
indexing
and
slicing
of
the
category
immutable
sequence
like
strings
and
lists
tuples
are
sequences
they
support
many
of
the
same
operations
however
like
strings
tuples
are
immutable
they
don
t
support
any
of
the
in
place
change
operations
applied
to
lists
fixed
length
heterogeneous
and
arbitrarily
nestable
because
tuples
are
immutable
you
cannot
change
the
size
of
a
tuple
without
making
a
copy
on
the
other
hand
tuples
can
hold
any
type
of
object
including
other
compound
objects
e
g
lists
dictionaries
other
tuples
and
so
support
arbitrary
nesting
arrays
of
object
references
like
lists
tuples
are
best
thought
of
as
object
reference
arrays
tuples
store
access
points
to
other
objects
references
and
indexing
a
tuple
is
relatively
quick
table
highlights
common
tuple
operations
a
tuple
is
written
as
a
series
of
objects
technically
expressions
that
generate
objects
separated
by
commas
and
normally
enclosed
in
parentheses
an
empty
tuple
is
just
a
parentheses
pair
with
nothing
inside
table
common
tuple
literals
and
operations
operation
interpretation
an
empty
tuple
t
a
one
item
tuple
not
an
expression
t
ni
a
four
item
tuple
t
ni
another
four
item
tuple
same
as
prior
line
t
abc
def
ghi
nested
tuples
t
tuple
spam
tuple
of
items
in
an
iterable
t
i
index
index
of
index
slice
length
t
i
j
t
i
j
len
t
t
t
concatenate
repeat
t
for
x
in
t
print
x
iteration
membership
spam
in
t
x
for
x
in
t
t
index
ni
methods
in
and
search
count
t
count
ni
chapter
tuples
files
and
everything
else
tuples
in
action
as
usual
let
s
start
an
interactive
session
to
explore
tuples
at
work
notice
in
table
that
tuples
do
not
have
all
the
methods
that
lists
have
e
g
an
append
call
won
t
work
here
they
do
however
support
the
usual
sequence
operations
that
we
saw
for
both
strings
and
lists
concatenation
repetition
t
t
t
indexing
slicing
tuple
syntax
peculiarities
commas
and
parentheses
the
second
and
fourth
entries
in
table
merit
a
bit
more
explanation
because
parentheses
can
also
enclose
expressions
see
chapter
you
need
to
do
something
special
to
tell
python
when
a
single
object
in
parentheses
is
a
tuple
object
and
not
a
simple
expression
if
you
really
want
a
single
item
tuple
simply
add
a
trailing
comma
after
the
single
item
before
the
closing
parenthesis
x
x
y
y
an
integer
a
tuple
containing
an
integer
as
a
special
case
python
also
allows
you
to
omit
the
opening
and
closing
parentheses
for
a
tuple
in
contexts
where
it
isn
t
syntactically
ambiguous
to
do
so
for
instance
the
fourth
line
of
table
simply
lists
four
items
separated
by
commas
in
the
context
of
an
assignment
statement
python
recognizes
this
as
a
tuple
even
though
it
doesn
t
have
parentheses
now
some
people
will
tell
you
to
always
use
parentheses
in
your
tuples
and
some
will
tell
you
to
never
use
parentheses
in
tuples
and
still
others
have
lives
and
won
t
tell
you
what
to
do
with
your
tuples
the
only
significant
places
where
the
parentheses
are
required
are
when
a
tuple
is
passed
as
a
literal
in
a
function
call
where
parentheses
matter
and
when
one
is
listed
in
a
python
x
print
statement
where
commas
are
significant
for
beginners
the
best
advice
is
that
it
s
probably
easier
to
use
the
parentheses
than
it
is
to
figure
out
when
they
are
optional
many
programmers
myself
included
also
find
that
parentheses
tend
to
aid
script
readability
by
making
the
tuples
more
explicit
but
your
mileage
may
vary
tuples
conversions
methods
and
immutability
apart
from
literal
syntax
differences
tuple
operations
the
middle
rows
in
table
are
identical
to
string
and
list
operations
the
only
differences
worth
noting
are
that
the
and
slicing
operations
return
new
tuples
when
applied
to
tuples
and
that
tuples
don
t
provide
the
same
methods
you
saw
for
strings
lists
and
dictionaries
if
you
want
to
sort
a
tuple
for
example
you
ll
usually
have
to
either
first
convert
it
to
a
list
to
gain
access
to
a
sorting
method
call
and
make
it
a
mutable
object
or
use
the
newer
sorted
built
in
that
accepts
any
sequence
object
and
more
t
cc
aa
dd
bb
tmp
list
t
tmp
sort
tmp
aa
bb
cc
dd
t
tuple
tmp
t
aa
bb
cc
dd
sorted
t
aa
bb
cc
dd
make
a
list
from
a
tuple
s
items
sort
the
list
make
a
tuple
from
the
list
s
items
or
use
the
sorted
built
in
here
the
list
and
tuple
built
in
functions
are
used
to
convert
the
object
to
a
list
and
then
back
to
a
tuple
really
both
calls
make
new
objects
but
the
net
effect
is
like
a
conversion
list
comprehensions
can
also
be
used
to
convert
tuples
the
following
for
example
makes
a
list
from
a
tuple
adding
to
each
item
along
the
way
t
l
x
for
x
in
t
l
list
comprehensions
are
really
sequence
operations
they
always
build
new
lists
but
they
may
be
used
to
iterate
over
any
sequence
objects
including
tuples
strings
and
other
lists
as
we
ll
see
later
in
the
book
they
even
work
on
some
things
that
are
not
physically
stored
sequences
any
iterable
objects
will
do
including
files
which
are
automatically
read
line
by
line
although
tuples
don
t
have
the
same
methods
as
lists
and
strings
they
do
have
two
of
their
own
as
of
python
and
index
and
count
works
as
they
do
for
lists
but
they
are
defined
for
tuple
objects
t
t
index
tuple
methods
in
and
offset
of
first
appearance
of
t
index
offset
of
appearance
after
offset
t
count
how
many
s
are
there
chapter
tuples
files
and
everything
else
prior
to
and
tuples
have
no
methods
at
all
this
was
an
old
python
convention
for
immutable
types
which
was
violated
years
ago
on
grounds
of
practicality
with
strings
and
more
recently
with
both
numbers
and
tuples
also
note
that
the
rule
about
tuple
immutability
applies
only
to
the
top
level
of
the
tuple
itself
not
to
its
contents
a
list
inside
a
tuple
for
instance
can
be
changed
as
usual
t
t
spam
this
fails
can
t
change
tuple
itself
typeerror
object
doesn
t
support
item
assignment
t
spam
t
spam
this
works
can
change
mutables
inside
for
most
programs
this
one
level
deep
immutability
is
sufficient
for
common
tuple
roles
which
coincidentally
brings
us
to
the
next
section
why
lists
and
tuples
this
seems
to
be
the
first
question
that
always
comes
up
when
teaching
beginners
about
tuples
why
do
we
need
tuples
if
we
have
lists
some
of
the
reasoning
may
be
historic
python
s
creator
is
a
mathematician
by
training
and
he
has
been
quoted
as
seeing
a
tuple
as
a
simple
association
of
objects
and
a
list
as
a
data
structure
that
changes
over
time
in
fact
this
use
of
the
word
tuple
derives
from
mathematics
as
does
its
frequent
use
for
a
row
in
a
relational
database
table
the
best
answer
however
seems
to
be
that
the
immutability
of
tuples
provides
some
integrity
you
can
be
sure
a
tuple
won
t
be
changed
through
another
reference
elsewhere
in
a
program
but
there
s
no
such
guarantee
for
lists
tuples
therefore
serve
a
similar
role
to
constant
declarations
in
other
languages
though
the
notion
of
constantness
is
associated
with
objects
in
python
not
variables
tuples
can
also
be
used
in
places
that
lists
cannot
for
example
as
dictionary
keys
see
the
sparse
matrix
example
in
chapter
some
built
in
operations
may
also
require
or
imply
tuples
not
lists
though
such
operations
have
often
been
generalized
in
recent
years
as
a
rule
of
thumb
lists
are
the
tool
of
choice
for
ordered
collections
that
might
need
to
change
tuples
can
handle
the
other
cases
of
fixed
associations
files
you
may
already
be
familiar
with
the
notion
of
files
which
are
named
storage
compartments
on
your
computer
that
are
managed
by
your
operating
system
the
last
major
built
in
object
type
that
we
ll
examine
on
our
object
types
tour
provides
a
way
to
access
those
files
inside
python
programs
files
in
short
the
built
in
open
function
creates
a
python
file
object
which
serves
as
a
link
to
a
file
residing
on
your
machine
after
calling
open
you
can
transfer
strings
of
data
to
and
from
the
associated
external
file
by
calling
the
returned
file
object
s
methods
compared
to
the
types
you
ve
seen
so
far
file
objects
are
somewhat
unusual
they
re
not
numbers
sequences
or
mappings
and
they
don
t
respond
to
expression
operators
they
export
only
methods
for
common
file
processing
tasks
most
file
methods
are
concerned
with
performing
input
from
and
output
to
the
external
file
associated
with
a
file
object
but
other
file
methods
allow
us
to
seek
to
a
new
position
in
the
file
flush
output
buffers
and
so
on
table
summarizes
common
file
operations
table
common
file
operations
operation
interpretation
output
open
r
c
spam
w
create
output
file
w
means
write
input
open
data
r
create
input
file
r
means
read
input
open
data
same
as
prior
line
r
is
the
default
astring
input
read
read
entire
file
into
a
single
string
astring
input
read
n
read
up
to
next
n
characters
or
bytes
into
a
string
astring
input
readline
read
next
line
including
n
newline
into
a
string
alist
input
readlines
read
entire
file
into
list
of
line
strings
with
n
output
write
astring
write
a
string
of
characters
or
bytes
into
file
output
writelines
alist
write
all
line
strings
in
a
list
into
file
output
close
manual
close
done
for
you
when
file
is
collected
output
flush
flush
output
buffer
to
disk
without
closing
anyfile
seek
n
change
file
position
to
offset
n
for
next
operation
for
line
in
open
data
use
line
file
iterators
read
line
by
line
open
f
txt
encoding
latin
python
unicode
text
files
str
strings
open
f
bin
rb
python
binary
bytes
files
bytes
strings
opening
files
to
open
a
file
a
program
calls
the
built
in
open
function
with
the
external
filename
first
followed
by
a
processing
mode
the
mode
is
typically
the
string
r
to
open
for
text
input
the
default
w
to
create
and
open
for
text
output
or
a
to
open
for
appending
text
to
the
end
the
processing
mode
argument
can
specify
additional
options
adding
a
b
to
the
mode
string
allows
for
binary
data
end
of
line
translations
and
unicode
encodings
are
turned
off
chapter
tuples
files
and
everything
else
adding
a
opens
the
file
for
both
input
and
output
i
e
you
can
both
read
and
write
to
the
same
file
object
often
in
conjunction
with
seek
operations
to
reposition
in
the
file
both
arguments
to
open
must
be
python
strings
and
an
optional
third
argument
can
be
used
to
control
output
buffering
passing
a
zero
means
that
output
is
unbuffered
it
is
transferred
to
the
external
file
immediately
on
a
write
method
call
the
external
filename
argument
may
include
a
platform
specific
and
absolute
or
relative
directory
path
prefix
without
a
directory
path
the
file
is
assumed
to
exist
in
the
current
working
directory
i
e
where
the
script
runs
we
ll
cover
file
fundamentals
and
explore
some
basic
examples
here
but
we
won
t
go
into
all
file
processing
mode
options
as
usual
consult
the
python
library
manual
for
additional
details
using
files
once
you
make
a
file
object
with
open
you
can
call
its
methods
to
read
from
or
write
to
the
associated
external
file
in
all
cases
file
text
takes
the
form
of
strings
in
python
programs
reading
a
file
returns
its
text
in
strings
and
text
is
passed
to
the
write
methods
as
strings
reading
and
writing
methods
come
in
multiple
flavors
table
lists
the
most
common
here
are
a
few
fundamental
usage
notes
file
iterators
are
best
for
reading
lines
though
the
reading
and
writing
methods
in
the
table
are
common
keep
in
mind
that
probably
the
best
way
to
read
lines
from
a
text
file
today
is
to
not
read
the
file
at
all
as
we
ll
see
in
chapter
files
also
have
an
iterator
that
automatically
reads
one
line
at
a
time
in
a
for
loop
list
comprehension
or
other
iteration
context
content
is
strings
not
objects
notice
in
table
that
data
read
from
a
file
always
comes
back
to
your
script
as
a
string
so
you
ll
have
to
convert
it
to
a
different
type
of
python
object
if
a
string
is
not
what
you
need
similarly
unlike
with
the
print
operation
python
does
not
add
any
formatting
and
does
not
convert
objects
to
strings
automatically
when
you
write
data
to
a
file
you
must
send
an
already
formatted
string
because
of
this
the
tools
we
have
already
met
to
convert
objects
to
and
from
strings
e
g
int
float
str
and
the
string
formatting
expression
and
method
come
in
handy
when
dealing
with
files
python
also
includes
advanced
standard
library
tools
for
handling
generic
object
storage
such
as
the
pickle
module
and
for
dealing
with
packed
binary
data
in
files
such
as
the
struct
module
we
ll
see
both
of
these
at
work
later
in
this
chapter
close
is
usually
optional
calling
the
file
close
method
terminates
your
connection
to
the
external
file
as
discussed
in
chapter
in
python
an
object
s
memory
space
is
automatically
reclaimed
as
soon
as
the
object
is
no
longer
referenced
anywhere
in
the
program
when
file
objects
are
reclaimed
python
also
automatically
closes
the
files
if
they
are
still
open
this
also
happens
when
a
program
shuts
down
this
means
you
files
don
t
always
need
to
manually
close
your
files
especially
in
simple
scripts
that
don
t
run
for
long
on
the
other
hand
including
manual
close
calls
can
t
hurt
and
is
usually
a
good
idea
in
larger
systems
also
strictly
speaking
this
auto
close
oncollection
feature
of
files
is
not
part
of
the
language
definition
and
it
may
change
over
time
consequently
manually
issuing
file
close
method
calls
is
a
good
habit
to
form
for
an
alternative
way
to
guarantee
automatic
file
closes
also
see
this
section
s
later
discussion
of
the
file
object
s
context
manager
used
with
the
new
with
as
statement
in
python
and
files
are
buffered
and
seekable
the
prior
paragraph
s
notes
about
closing
files
are
important
because
closing
both
frees
up
operating
system
resources
and
flushes
output
buffers
by
default
output
files
are
always
buffered
which
means
that
text
you
write
may
not
be
transferred
from
memory
to
disk
immediately
closing
a
file
or
running
its
flush
method
forces
the
buffered
data
to
disk
you
can
avoid
buffering
with
extra
open
arguments
but
it
may
impede
performance
python
files
are
also
random
access
on
a
byte
offset
basis
their
seek
method
allows
your
scripts
to
jump
around
to
read
and
write
at
specific
locations
files
in
action
let
s
work
through
a
simple
example
that
demonstrates
file
processing
basics
the
following
code
begins
by
opening
a
new
text
file
for
output
writing
two
lines
strings
terminated
with
a
newline
marker
n
and
closing
the
file
later
the
example
opens
the
same
file
again
in
input
mode
and
reads
the
lines
back
one
at
a
time
with
readline
notice
that
the
third
readline
call
returns
an
empty
string
this
is
how
python
file
methods
tell
you
that
you
ve
reached
the
end
of
the
file
empty
lines
in
the
file
come
back
as
strings
containing
just
a
newline
character
not
as
empty
strings
here
s
the
complete
interaction
myfile
open
myfile
txt
w
myfile
write
hello
text
file
n
open
for
text
output
create
empty
write
a
line
of
text
string
myfile
write
goodbye
text
file
n
myfile
close
myfile
open
myfile
txt
myfile
readline
hello
text
file
n
myfile
readline
goodbye
text
file
n
myfile
readline
flush
output
buffers
to
disk
open
for
text
input
r
is
default
read
the
lines
back
empty
string
end
of
file
notice
that
file
write
calls
return
the
number
of
characters
written
in
python
in
they
don
t
so
you
won
t
see
these
numbers
echoed
interactively
this
example
writes
each
line
of
text
including
its
end
of
line
terminator
n
as
a
string
write
chapter
tuples
files
and
everything
else
methods
don
t
add
the
end
of
line
character
for
us
so
we
must
include
it
to
properly
terminate
our
lines
otherwise
the
next
write
will
simply
extend
the
current
line
in
the
file
if
you
want
to
display
the
file
s
content
with
end
of
line
characters
interpreted
read
the
entire
file
into
a
string
all
at
once
with
the
file
object
s
read
method
and
print
it
open
myfile
txt
read
hello
text
file
ngoodbye
text
file
n
read
all
at
once
into
string
print
open
myfile
txt
read
hello
text
file
goodbye
text
file
user
friendly
display
and
if
you
want
to
scan
a
text
file
line
by
line
file
iterators
are
often
your
best
option
for
line
in
open
myfile
print
line
end
hello
text
file
goodbye
text
file
use
file
iterators
not
reads
when
coded
this
way
the
temporary
file
object
created
by
open
will
automatically
read
and
return
one
line
on
each
loop
iteration
this
form
is
usually
easiest
to
code
good
on
memory
use
and
may
be
faster
than
some
other
options
depending
on
many
variables
of
course
since
we
haven
t
reached
statements
or
iterators
yet
though
you
ll
have
to
wait
until
chapter
for
a
more
complete
explanation
of
this
code
text
and
binary
files
in
python
strictly
speaking
the
example
in
the
prior
section
uses
text
files
in
both
python
and
file
type
is
determined
by
the
second
argument
to
open
the
mode
string
an
included
b
means
binary
python
has
always
supported
both
text
and
binary
files
but
in
python
there
is
a
sharper
distinction
between
the
two
text
files
represent
content
as
normal
str
strings
perform
unicode
encoding
and
decoding
automatically
and
perform
end
of
line
translation
by
default
binary
files
represent
content
as
a
special
bytes
string
type
and
allow
programs
to
access
file
content
unaltered
in
contrast
python
text
files
handle
both
bit
text
and
binary
data
and
a
special
string
type
and
file
interface
unicode
strings
and
codecs
open
handles
unicode
text
the
differences
in
python
stem
from
the
fact
that
simple
and
unicode
text
have
been
merged
in
the
normal
string
type
which
makes
sense
given
that
all
text
is
unicode
including
ascii
and
other
bit
encodings
because
most
programmers
deal
only
with
ascii
text
they
can
get
by
with
the
basic
text
file
interface
used
in
the
prior
example
and
normal
strings
all
strings
are
technically
unicode
in
but
ascii
users
will
not
generally
notice
in
fact
files
and
strings
work
the
same
in
and
if
your
script
s
scope
is
limited
to
such
simple
forms
of
text
files
if
you
need
to
handle
internationalized
applications
or
byte
oriented
data
though
the
distinction
in
impacts
your
code
usually
for
the
better
in
general
you
must
use
bytes
strings
for
binary
files
and
normal
str
strings
for
text
files
moreover
because
text
files
implement
unicode
encodings
you
cannot
open
a
binary
data
file
in
text
mode
decoding
its
content
to
unicode
text
will
likely
fail
let
s
look
at
an
example
when
you
read
a
binary
data
file
you
get
back
a
bytes
object
a
sequence
of
small
integers
that
represent
absolute
byte
values
which
may
or
may
not
correspond
to
characters
which
looks
and
feels
almost
exactly
like
a
normal
string
data
open
data
bin
rb
read
data
b
x
x
x
x
spam
x
x
data
b
spam
data
bin
data
b
open
binary
file
rb
read
binary
bytes
string
holds
binary
data
act
like
strings
but
really
are
small
bit
integers
python
bin
function
in
addition
binary
files
do
not
perform
any
end
of
line
translation
on
data
text
files
by
default
map
all
forms
to
and
from
n
when
written
and
read
and
implement
unicode
encodings
on
transfers
since
unicode
and
binary
data
is
of
marginal
interest
to
many
python
programmers
we
ll
postpone
the
full
story
until
chapter
for
now
let
s
move
on
to
some
more
substantial
file
examples
storing
and
parsing
python
objects
in
files
our
next
example
writes
a
variety
of
python
objects
into
a
text
file
on
multiple
lines
notice
that
it
must
convert
objects
to
strings
using
conversion
tools
again
file
data
is
always
strings
in
our
scripts
and
write
methods
do
not
do
any
automatic
to
string
formatting
for
us
for
space
i
m
omitting
byte
count
return
values
from
write
methods
from
here
on
x
y
z
s
spam
d
a
b
l
native
python
objects
must
be
strings
to
store
in
file
f
open
datafile
txt
w
f
write
s
n
f
write
s
s
s
n
x
y
z
f
write
str
l
str
d
n
f
close
create
output
file
terminate
lines
with
n
convert
numbers
to
strings
convert
and
separate
with
once
we
have
created
our
file
we
can
inspect
its
contents
by
opening
it
and
reading
it
into
a
string
a
single
operation
notice
that
the
interactive
echo
gives
the
exact
byte
contents
while
the
print
operation
interprets
embedded
end
of
line
characters
to
render
a
more
user
friendly
display
chars
open
datafile
txt
read
chars
chapter
tuples
files
and
everything
else
raw
string
display
spam
n
n
a
b
n
print
chars
user
friendly
display
spam
a
b
we
now
have
to
use
other
conversion
tools
to
translate
from
the
strings
in
the
text
file
to
real
python
objects
as
python
never
converts
strings
to
numbers
or
other
types
of
objects
automatically
this
is
required
if
we
need
to
gain
access
to
normal
object
tools
like
indexing
addition
and
so
on
f
open
datafile
txt
line
f
readline
line
spam
n
line
rstrip
spam
open
again
read
one
line
remove
end
of
line
for
this
first
line
we
used
the
string
rstrip
method
to
get
rid
of
the
trailing
end
of
line
character
a
line
slice
would
work
too
but
only
if
we
can
be
sure
all
lines
end
in
the
n
character
the
last
line
in
a
file
sometimes
does
not
so
far
we
ve
read
the
line
containing
the
string
now
let
s
grab
the
next
line
which
contains
numbers
and
parse
out
that
is
extract
the
objects
on
that
line
line
f
readline
line
n
parts
line
split
parts
n
next
line
from
file
it
s
a
string
here
split
parse
on
commas
we
used
the
string
split
method
here
to
chop
up
the
line
on
its
comma
delimiters
the
result
is
a
list
of
substrings
containing
the
individual
numbers
we
still
must
convert
from
strings
to
integers
though
if
we
wish
to
perform
math
on
these
int
parts
numbers
int
p
for
p
in
parts
numbers
convert
from
string
to
int
convert
all
in
list
at
once
as
we
have
learned
int
translates
a
string
of
digits
into
an
integer
object
and
the
list
comprehension
expression
introduced
in
chapter
can
apply
the
call
to
each
item
in
our
list
all
at
once
you
ll
find
more
on
list
comprehensions
later
in
this
book
notice
that
we
didn
t
have
to
run
rstrip
to
delete
the
n
at
the
end
of
the
last
part
int
and
some
other
converters
quietly
ignore
whitespace
around
digits
finally
to
convert
the
stored
list
and
dictionary
in
the
third
line
of
the
file
we
can
run
them
through
eval
a
built
in
function
that
treats
a
string
as
a
piece
of
executable
program
code
technically
a
string
containing
a
python
expression
line
f
readline
line
files
a
b
n
parts
line
split
parts
a
b
n
eval
parts
objects
eval
p
for
p
in
parts
objects
a
b
split
parse
on
convert
to
any
object
type
do
same
for
all
in
list
because
the
end
result
of
all
this
parsing
and
converting
is
a
list
of
normal
python
objects
instead
of
strings
we
can
now
apply
list
and
dictionary
operations
to
them
in
our
script
storing
native
python
objects
with
pickle
using
eval
to
convert
from
strings
to
objects
as
demonstrated
in
the
preceding
code
is
a
powerful
tool
in
fact
sometimes
it
s
too
powerful
eval
will
happily
run
any
python
expression
even
one
that
might
delete
all
the
files
on
your
computer
given
the
necessary
permissions
if
you
really
want
to
store
native
python
objects
but
you
can
t
trust
the
source
of
the
data
in
the
file
python
s
standard
library
pickle
module
is
ideal
the
pickle
module
is
an
advanced
tool
that
allows
us
to
store
almost
any
python
object
in
a
file
directly
with
no
to
or
from
string
conversion
requirement
on
our
part
it
s
like
a
super
general
data
formatting
and
parsing
utility
to
store
a
dictionary
in
a
file
for
instance
we
pickle
it
directly
d
a
b
f
open
datafile
pkl
wb
import
pickle
pickle
dump
d
f
f
close
pickle
any
object
to
file
then
to
get
the
dictionary
back
later
we
simply
use
pickle
again
to
re
create
it
f
open
datafile
pkl
rb
e
pickle
load
f
e
a
b
load
any
object
from
file
we
get
back
an
equivalent
dictionary
object
with
no
manual
splitting
or
converting
required
the
pickle
module
performs
what
is
known
as
object
serialization
converting
objects
to
and
from
strings
of
bytes
but
requires
very
little
work
on
our
part
in
fact
pickle
internally
translates
our
dictionary
to
a
string
form
though
it
s
not
much
to
look
at
and
may
vary
if
we
pickle
in
other
data
protocol
modes
open
datafile
pkl
rb
read
format
is
prone
to
change
b
x
x
q
x
x
x
x
x
x
aq
x
k
x
x
x
x
x
x
bq
x
k
x
u
because
pickle
can
reconstruct
the
object
from
this
format
we
don
t
have
to
deal
with
that
ourselves
for
more
on
the
pickle
module
see
the
python
standard
library
manual
or
import
pickle
and
pass
it
to
help
interactively
while
you
re
exploring
also
take
a
look
at
the
shelve
module
shelve
is
a
tool
that
uses
pickle
to
store
python
objects
in
an
access
by
key
filesystem
which
is
beyond
our
scope
here
though
you
will
get
to
see
chapter
tuples
files
and
everything
else
an
example
of
shelve
in
action
in
chapter
and
other
pickle
examples
in
chapters
and
note
that
i
opened
the
file
used
to
store
the
pickled
object
in
binary
mode
binary
mode
is
always
required
in
python
because
the
pickler
creates
and
uses
a
bytes
string
object
and
these
objects
imply
binarymode
files
text
mode
files
imply
str
strings
in
in
earlier
pythons
it
s
ok
to
use
text
mode
files
for
protocol
the
default
which
creates
ascii
text
as
long
as
text
mode
is
used
consistently
higher
protocols
require
binary
mode
files
python
s
default
protocol
is
binary
but
it
creates
bytes
even
for
protocol
see
chapter
python
s
library
manual
or
reference
books
for
more
details
on
this
python
also
has
a
cpickle
module
which
is
an
optimized
version
of
pickle
that
can
be
imported
directly
for
speed
python
renames
this
module
pickle
and
uses
it
automatically
in
pickle
scripts
simply
import
pickle
and
let
python
optimize
itself
storing
and
parsing
packed
binary
data
in
files
one
other
file
related
note
before
we
move
on
some
advanced
applications
also
need
to
deal
with
packed
binary
data
created
perhaps
by
a
c
language
program
python
s
standard
library
includes
a
tool
to
help
in
this
domain
the
struct
module
knows
how
to
both
compose
and
parse
packed
binary
data
in
a
sense
this
is
another
dataconversion
tool
that
interprets
strings
in
files
as
binary
data
to
create
a
packed
binary
data
file
for
example
open
it
in
wb
write
binary
mode
and
pass
struct
a
format
string
and
some
python
objects
the
format
string
used
here
means
pack
as
a
byte
integer
a
character
string
and
a
byte
integer
all
in
bigendian
form
other
format
codes
handle
padding
bytes
floating
point
numbers
and
more
f
open
data
bin
wb
import
struct
data
struct
pack
i
sh
spam
data
b
x
x
x
x
spam
x
x
f
write
data
f
close
open
binary
output
file
make
packed
binary
data
write
byte
string
python
creates
a
binary
bytes
data
string
which
we
write
out
to
the
file
normally
this
one
consists
mostly
of
nonprintable
characters
printed
in
hexadecimal
escapes
and
is
the
same
binary
file
we
met
earlier
to
parse
the
values
out
to
normal
python
objects
we
simply
read
the
string
back
and
unpack
it
using
the
same
format
string
python
extracts
the
values
into
normal
python
objects
integers
and
a
string
f
open
data
bin
rb
data
f
read
data
b
x
x
x
x
spam
x
x
get
packed
binary
data
files
values
struct
unpack
i
sh
data
values
spam
convert
to
python
objects
binary
data
files
are
advanced
and
somewhat
low
level
tools
that
we
won
t
cover
in
more
detail
here
for
more
help
see
chapter
consult
the
python
library
manual
or
import
struct
and
pass
it
to
the
help
function
interactively
also
note
that
the
binary
file
processing
modes
wb
and
rb
can
be
used
to
process
a
simpler
binary
file
such
as
an
image
or
audio
file
as
a
whole
without
having
to
unpack
its
contents
file
context
managers
you
ll
also
want
to
watch
for
chapter
s
discussion
of
the
file
s
context
manager
support
new
in
python
and
though
more
a
feature
of
exception
processing
than
files
themselves
it
allows
us
to
wrap
file
processing
code
in
a
logic
layer
that
ensures
that
the
file
will
be
closed
automatically
on
exit
instead
of
relying
on
the
autoclose
on
garbage
collection
with
open
r
c
misc
data
txt
as
myfile
for
line
in
myfile
use
line
here
see
chapter
for
details
the
try
finally
statement
we
ll
look
at
in
chapter
can
provide
similar
functionality
but
at
some
cost
in
extra
code
three
extra
lines
to
be
precise
though
we
can
often
avoid
both
options
and
let
python
close
files
for
us
automatically
myfile
open
r
c
misc
data
txt
try
for
line
in
myfile
use
line
here
finally
myfile
close
since
both
these
options
require
more
information
than
we
have
yet
obtained
we
ll
postpone
details
until
later
in
this
book
other
file
tools
there
are
additional
more
advanced
file
methods
shown
in
table
and
even
more
that
are
not
in
the
table
for
instance
as
mentioned
earlier
seek
resets
your
current
position
in
a
file
the
next
read
or
write
happens
at
that
position
flush
forces
buffered
output
to
be
written
out
to
disk
by
default
files
are
always
buffered
and
so
on
the
python
standard
library
manual
and
the
reference
books
described
in
the
preface
provide
complete
lists
of
file
methods
for
a
quick
look
run
a
dir
or
help
call
interactively
passing
in
an
open
file
object
in
python
but
not
you
can
pass
in
the
name
file
instead
for
more
file
processing
examples
watch
for
the
sidebar
why
you
will
care
file
scanners
on
page
it
sketches
common
file
scanning
loop
code
patterns
with
statements
we
have
not
covered
enough
yet
to
use
here
chapter
tuples
files
and
everything
else
also
note
that
although
the
open
function
and
the
file
objects
it
returns
are
your
main
interface
to
external
files
in
a
python
script
there
are
additional
file
like
tools
in
the
python
toolset
also
available
to
name
a
few
are
standard
streams
preopened
file
objects
in
the
sys
module
such
as
sys
stdout
see
print
operations
on
page
descriptor
files
in
the
os
module
integer
file
handles
that
support
lower
level
tools
such
as
file
locking
sockets
pipes
and
fifos
file
like
objects
used
to
synchronize
processes
or
communicate
over
networks
access
by
key
files
known
as
shelves
used
to
store
unaltered
python
objects
directly
by
key
used
in
chapter
shell
command
streams
tools
such
as
os
popen
and
subprocess
popen
that
support
spawning
shell
commands
and
reading
and
writing
to
their
standard
streams
the
third
party
open
source
domain
offers
even
more
file
like
tools
including
support
for
communicating
with
serial
ports
in
the
pyserial
extension
and
interactive
programs
in
the
pexpect
system
see
more
advanced
python
texts
and
the
web
at
large
for
additional
information
on
file
like
tools
version
skew
note
in
python
and
earlier
the
built
in
name
open
is
essentially
a
synonym
for
the
name
file
and
files
may
technically
be
opened
by
calling
either
open
or
file
though
open
is
generally
preferred
for
opening
in
python
the
name
file
is
no
longer
available
because
of
its
redundancy
with
open
python
users
may
also
use
the
name
file
as
the
file
object
type
in
order
to
customize
files
with
object
oriented
programming
described
later
in
this
book
in
python
files
have
changed
radically
the
classes
used
to
implement
file
objects
live
in
the
standard
library
module
io
see
this
module
s
documentation
or
code
for
the
classes
it
makes
available
for
customization
and
run
a
type
f
call
on
open
files
f
for
hints
type
categories
revisited
now
that
we
ve
seen
all
of
python
s
core
built
in
types
in
action
let
s
wrap
up
our
object
types
tour
by
reviewing
some
of
the
properties
they
share
table
classifies
all
the
major
types
we
ve
seen
so
far
according
to
the
type
categories
introduced
earlier
here
are
some
points
to
remember
type
categories
revisited
objects
share
operations
according
to
their
category
for
instance
strings
lists
and
tuples
all
share
sequence
operations
such
as
concatenation
length
and
indexing
only
mutable
objects
lists
dictionaries
and
sets
may
be
changed
in
place
you
cannot
change
numbers
strings
or
tuples
in
place
files
export
only
methods
so
mutability
doesn
t
really
apply
to
them
their
state
may
be
changed
when
they
are
processed
but
this
isn
t
quite
the
same
as
python
core
type
mutability
constraints
numbers
in
table
includes
all
number
types
integer
and
the
distinct
long
integer
in
floating
point
complex
decimal
and
fraction
strings
in
table
includes
str
as
well
as
bytes
in
and
unicode
in
the
bytearray
string
type
in
is
mutable
sets
are
something
like
the
keys
of
a
valueless
dictionary
but
they
don
t
map
to
values
and
are
not
ordered
so
sets
are
neither
a
mapping
nor
a
sequence
type
frozenset
is
an
immutable
variant
of
set
in
addition
to
type
category
operations
as
of
python
and
all
the
types
in
table
have
callable
methods
which
are
generally
specific
to
their
type
table
object
classifications
object
type
category
mutable
numbers
all
numeric
no
strings
sequence
no
lists
sequence
yes
dictionaries
mapping
yes
tuples
sequence
no
files
extension
n
a
sets
set
yes
frozenset
set
no
bytearray
sequence
yes
why
you
will
care
operator
overloading
in
part
vi
of
this
book
we
ll
see
that
objects
we
implement
with
classes
can
pick
and
choose
from
these
categories
arbitrarily
for
instance
if
we
want
to
provide
a
new
kind
of
specialized
sequence
object
that
is
consistent
with
built
in
sequences
we
can
code
a
class
that
overloads
things
like
indexing
and
concatenation
class
mysequence
def
getitem
self
index
called
on
self
index
others
def
add
self
other
called
on
self
other
chapter
tuples
files
and
everything
else
and
so
on
we
can
also
make
the
new
object
mutable
or
not
by
selectively
implementing
methods
called
for
in
place
change
operations
e
g
setitem
is
called
on
self
index
value
assignments
although
it
s
beyond
this
book
s
scope
it
s
also
possible
to
implement
new
objects
in
an
external
language
like
c
as
c
extension
types
for
these
we
fill
in
c
function
pointer
slots
to
choose
between
number
sequence
and
mapping
operation
sets
object
flexibility
this
part
of
the
book
introduced
a
number
of
compound
object
types
collections
with
components
in
general
lists
dictionaries
and
tuples
can
hold
any
kind
of
object
lists
dictionaries
and
tuples
can
be
arbitrarily
nested
lists
and
dictionaries
can
dynamically
grow
and
shrink
because
they
support
arbitrary
structures
python
s
compound
object
types
are
good
at
representing
complex
information
in
programs
for
example
values
in
dictionaries
may
be
lists
which
may
contain
tuples
which
may
contain
dictionaries
and
so
on
the
nesting
can
be
as
deep
as
needed
to
model
the
data
to
be
processed
let
s
look
at
an
example
of
nesting
the
following
interaction
defines
a
tree
of
nested
compound
sequence
objects
shown
in
figure
to
access
its
components
you
may
include
as
many
index
operations
as
required
python
evaluates
the
indexes
from
left
to
right
and
fetches
a
reference
to
a
more
deeply
nested
object
at
each
step
figure
may
be
a
pathologically
complicated
data
structure
but
it
illustrates
the
syntax
used
to
access
nested
objects
in
general
l
abc
l
l
l
l
references
versus
copies
chapter
mentioned
that
assignments
always
store
references
to
objects
not
copies
of
those
objects
in
practice
this
is
usually
what
you
want
because
assignments
can
generate
multiple
references
to
the
same
object
though
it
s
important
to
be
aware
that
changing
a
mutable
object
in
place
may
affect
other
references
to
the
same
object
references
versus
copies
figure
a
nested
object
tree
with
the
offsets
of
its
components
created
by
running
the
literal
expression
abc
syntactically
nested
objects
are
internally
represented
as
references
i
e
pointers
to
separate
pieces
of
memory
elsewhere
in
your
program
if
you
don
t
want
such
behavior
you
ll
need
to
tell
python
to
copy
the
object
explicitly
we
studied
this
phenomenon
in
chapter
but
it
can
become
more
subtle
when
larger
objects
come
into
play
for
instance
the
following
example
creates
a
list
assigned
to
x
and
another
list
assigned
to
l
that
embeds
a
reference
back
to
list
x
it
also
creates
a
dictionary
d
that
contains
another
reference
back
to
list
x
x
l
a
x
b
d
x
x
y
embed
references
to
x
s
object
at
this
point
there
are
three
references
to
the
first
list
created
from
the
name
x
from
inside
the
list
assigned
to
l
and
from
inside
the
dictionary
assigned
to
d
the
situation
is
illustrated
in
figure
because
lists
are
mutable
changing
the
shared
list
object
from
any
of
the
three
references
also
changes
what
the
other
two
reference
x
surprise
changes
all
three
references
l
a
surprise
b
d
x
surprise
y
references
are
a
higher
level
analog
of
pointers
in
other
languages
although
you
can
t
grab
hold
of
the
reference
itself
it
s
possible
to
store
the
same
reference
in
more
than
one
place
variables
lists
and
so
on
this
is
a
feature
you
can
pass
a
large
object
chapter
tuples
files
and
everything
else
figure
shared
object
references
because
the
list
referenced
by
variable
x
is
also
referenced
from
within
the
objects
referenced
by
l
and
d
changing
the
shared
list
from
x
makes
it
look
different
from
l
and
d
too
around
a
program
without
generating
expensive
copies
of
it
along
the
way
if
you
really
do
want
copies
however
you
can
request
them
slice
expressions
with
empty
limits
l
copy
sequences
the
dictionary
and
set
copy
method
x
copy
copies
a
dictionary
or
set
some
built
in
functions
such
as
list
make
copies
list
l
the
copy
standard
library
module
makes
full
copies
for
example
say
you
have
a
list
and
a
dictionary
and
you
don
t
want
their
values
to
be
changed
through
other
variables
l
d
a
b
to
prevent
this
simply
assign
copies
to
the
other
variables
not
references
to
the
same
objects
a
l
b
d
copy
instead
of
a
l
or
list
l
instead
of
b
d
ditto
for
sets
this
way
changes
made
from
the
other
variables
will
change
the
copies
not
the
originals
a
ni
b
c
spam
l
d
a
b
a
b
ni
a
c
spam
b
in
terms
of
our
original
example
you
can
avoid
the
reference
side
effects
by
slicing
the
original
list
instead
of
simply
naming
it
references
versus
copies
x
l
a
x
b
d
x
x
y
embed
copies
of
x
s
object
this
changes
the
picture
in
figure
l
and
d
will
now
point
to
different
lists
than
x
the
net
effect
is
that
changes
made
through
x
will
impact
only
x
not
l
and
d
similarly
changes
to
l
or
d
will
not
impact
x
one
final
note
on
copies
empty
limit
slices
and
the
dictionary
copy
method
only
make
top
level
copies
that
is
they
do
not
copy
nested
data
structures
if
any
are
present
if
you
need
a
complete
fully
independent
copy
of
a
deeply
nested
data
structure
use
the
standard
copy
module
include
an
import
copy
statement
and
say
x
copy
deep
copy
y
to
fully
copy
an
arbitrarily
nested
object
y
this
call
recursively
traverses
objects
to
copy
all
their
parts
this
is
a
much
more
rare
case
though
which
is
why
you
have
to
say
more
to
make
it
go
references
are
usually
what
you
will
want
when
they
are
not
slices
and
copy
methods
are
usually
as
much
copying
as
you
ll
need
to
do
comparisons
equality
and
truth
all
python
objects
also
respond
to
comparisons
tests
for
equality
relative
magnitude
and
so
on
python
comparisons
always
inspect
all
parts
of
compound
objects
until
a
result
can
be
determined
in
fact
when
nested
objects
are
present
python
automatically
traverses
data
structures
to
apply
comparisons
recursively
from
left
to
right
and
as
deeply
as
needed
the
first
difference
found
along
the
way
determines
the
comparison
result
for
instance
a
comparison
of
list
objects
compares
all
their
components
automatically
l
l
l
true
a
a
l
l
is
l
false
same
value
unique
objects
equivalent
same
object
here
l
and
l
are
assigned
lists
that
are
equivalent
but
distinct
objects
because
of
the
nature
of
python
references
studied
in
chapter
there
are
two
ways
to
test
for
equality
the
operator
tests
value
equivalence
python
performs
an
equivalence
test
comparing
all
nested
objects
recursively
the
is
operator
tests
object
identity
python
tests
whether
the
two
are
really
the
same
object
i
e
live
at
the
same
address
in
memory
in
the
preceding
example
l
and
l
pass
the
test
they
have
equivalent
values
because
all
their
components
are
equivalent
but
fail
the
is
check
they
reference
two
different
objects
and
hence
two
different
pieces
of
memory
notice
what
happens
for
short
strings
though
s
spam
s
spam
chapter
tuples
files
and
everything
else
s
s
s
is
s
true
true
here
we
should
again
have
two
distinct
objects
that
happen
to
have
the
same
value
should
be
true
and
is
should
be
false
but
because
python
internally
caches
and
reuses
some
strings
as
an
optimization
there
really
is
just
a
single
string
spam
in
memory
shared
by
s
and
s
hence
the
is
identity
test
reports
a
true
result
to
trigger
the
normal
behavior
we
need
to
use
longer
strings
s
s
s
true
a
longer
string
a
longer
string
s
s
is
s
false
of
course
because
strings
are
immutable
the
object
caching
mechanism
is
irrelevant
to
your
code
strings
can
t
be
changed
in
place
regardless
of
how
many
variables
refer
to
them
if
identity
tests
seem
confusing
see
chapter
for
a
refresher
on
object
reference
concepts
as
a
rule
of
thumb
the
operator
is
what
you
will
want
to
use
for
almost
all
equality
checks
is
is
reserved
for
highly
specialized
roles
we
ll
see
cases
where
these
operators
are
put
to
use
later
in
the
book
relative
magnitude
comparisons
are
also
applied
recursively
to
nested
data
structures
l
a
l
a
l
l
l
l
l
l
false
false
true
less
equal
greater
tuple
of
results
here
l
is
greater
than
l
because
the
nested
is
greater
than
the
result
of
the
last
line
is
really
a
tuple
of
three
objects
the
results
of
the
three
expressions
typed
an
example
of
a
tuple
without
its
enclosing
parentheses
in
general
python
compares
types
as
follows
numbers
are
compared
by
relative
magnitude
strings
are
compared
lexicographically
character
by
character
abc
ac
lists
and
tuples
are
compared
by
comparing
each
component
from
left
to
right
dictionaries
compare
as
equal
if
their
sorted
key
value
lists
are
equal
relative
magnitude
comparisons
are
not
supported
for
dictionaries
in
python
but
they
work
in
and
earlier
as
though
comparing
sorted
key
value
lists
nonnumeric
mixed
type
comparisons
e
g
spam
are
errors
in
python
they
are
allowed
in
python
but
use
a
fixed
but
arbitrary
ordering
rule
by
proxy
this
also
applies
to
sorts
which
use
comparisons
internally
nonnumeric
mixed
type
collections
cannot
be
sorted
in
in
general
comparisons
of
structured
objects
proceed
as
though
you
had
written
the
objects
as
literals
and
compared
all
their
parts
one
at
a
time
from
left
to
right
in
later
chapters
we
ll
see
other
object
types
that
can
change
the
way
they
get
compared
comparisons
equality
and
truth
python
dictionary
comparisons
the
second
to
last
point
in
the
preceding
section
merits
illustration
in
python
and
earlier
dictionaries
support
magnitude
comparisons
as
though
you
were
comparing
sorted
key
value
lists
c
misc
c
python
python
d
a
b
d
a
b
d
d
false
d
d
true
in
python
magnitude
comparisons
for
dictionaries
are
removed
because
they
incur
too
much
overhead
when
equality
is
desired
equality
uses
an
optimized
scheme
in
that
doesn
t
literally
compare
sorted
key
value
lists
the
alternative
in
is
to
either
write
loops
to
compare
values
by
key
or
compare
the
sorted
key
value
lists
manually
the
items
dictionary
methods
and
sorted
built
in
suffice
c
misc
c
python
python
d
a
b
d
a
b
d
d
false
d
d
typeerror
unorderable
types
dict
dict
list
d
items
a
b
sorted
d
items
a
b
sorted
d
items
sorted
d
items
true
sorted
d
items
sorted
d
items
false
in
practice
most
programs
requiring
this
behavior
will
develop
more
efficient
ways
to
compare
data
in
dictionaries
than
either
this
workaround
or
the
original
behavior
in
python
the
meaning
of
true
and
false
in
python
notice
that
the
test
results
returned
in
the
last
two
examples
represent
true
and
false
values
they
print
as
the
words
true
and
false
but
now
that
we
re
using
logical
tests
like
these
in
earnest
i
should
be
a
bit
more
formal
about
what
these
names
really
mean
in
python
as
in
most
programming
languages
an
integer
represents
false
and
an
integer
represents
true
in
addition
though
python
recognizes
any
empty
data
structure
as
false
and
any
nonempty
data
structure
as
true
more
generally
the
notions
of
chapter
tuples
files
and
everything
else
true
and
false
are
intrinsic
properties
of
every
object
in
python
each
object
is
either
true
or
false
as
follows
numbers
are
true
if
nonzero
other
objects
are
true
if
nonempty
table
gives
examples
of
true
and
false
objects
in
python
table
example
object
truth
values
object
value
spam
true
false
false
false
true
false
none
false
as
one
application
because
objects
are
true
or
false
themselves
it
s
common
to
see
python
programmers
code
tests
like
if
x
which
assuming
x
is
a
string
is
the
same
as
if
x
in
other
words
you
can
test
the
object
itself
instead
of
comparing
it
to
an
empty
object
more
on
if
statements
in
part
iii
the
none
object
as
shown
in
the
last
item
in
table
python
also
provides
a
special
object
called
none
which
is
always
considered
to
be
false
none
was
introduced
in
chapter
it
is
the
only
value
of
a
special
data
type
in
python
and
typically
serves
as
an
empty
placeholder
much
like
a
null
pointer
in
c
for
example
recall
that
for
lists
you
cannot
assign
to
an
offset
unless
that
offset
already
exists
the
list
does
not
magically
grow
if
you
make
an
out
of
bounds
assignment
to
preallocate
a
item
list
such
that
you
can
add
to
any
of
the
offsets
you
can
fill
it
with
none
objects
l
none
l
none
none
none
none
none
none
none
this
doesn
t
limit
the
size
of
the
list
it
can
still
grow
and
shrink
later
but
simply
presets
an
initial
size
to
allow
for
future
index
assignments
you
could
initialize
a
list
with
zeros
the
same
way
of
course
but
best
practice
dictates
using
none
if
the
list
s
contents
are
not
yet
known
comparisons
equality
and
truth
keep
in
mind
that
none
does
not
mean
undefined
that
is
none
is
something
not
nothing
despite
its
name
it
is
a
real
object
and
piece
of
memory
given
a
built
in
name
by
python
watch
for
other
uses
of
this
special
object
later
in
the
book
it
is
also
the
default
return
value
of
functions
as
we
ll
see
in
part
iv
the
bool
type
also
keep
in
mind
that
the
python
boolean
type
bool
introduced
in
chapter
simply
augments
the
notions
of
true
and
false
in
python
as
we
learned
in
chapter
the
builtin
words
true
and
false
are
just
customized
versions
of
the
integers
and
it
s
as
if
these
two
words
have
been
preassigned
to
and
everywhere
in
python
because
of
the
way
this
new
type
is
implemented
this
is
really
just
a
minor
extension
to
the
notions
of
true
and
false
already
described
designed
to
make
truth
values
more
explicit
when
used
explicitly
in
truth
test
code
the
words
true
and
false
are
equivalent
to
and
but
they
make
the
programmer
s
intent
clearer
results
of
boolean
tests
run
interactively
print
as
the
words
true
and
false
instead
of
as
and
to
make
the
type
of
result
clearer
you
are
not
required
to
use
only
boolean
types
in
logical
statements
such
as
if
all
objects
are
still
inherently
true
or
false
and
all
the
boolean
concepts
mentioned
in
this
chapter
still
work
as
described
if
you
use
other
types
python
also
provides
a
bool
builtin
function
that
can
be
used
to
test
the
boolean
value
of
an
object
i
e
whether
it
is
true
that
is
nonzero
or
nonempty
bool
true
bool
spam
true
bool
false
in
practice
though
you
ll
rarely
notice
the
boolean
type
produced
by
logic
tests
because
boolean
results
are
used
automatically
by
if
statements
and
other
selection
tools
we
ll
explore
booleans
further
when
we
study
logical
statements
in
chapter
python
s
type
hierarchies
figure
summarizes
all
the
built
in
object
types
available
in
python
and
their
relationships
we
ve
looked
at
the
most
prominent
of
these
most
of
the
other
kinds
of
objects
in
figure
correspond
to
program
units
e
g
functions
and
modules
or
exposed
interpreter
internals
e
g
stack
frames
and
compiled
code
the
main
point
to
notice
here
is
that
everything
in
a
python
system
is
an
object
type
and
may
be
processed
by
your
python
programs
for
instance
you
can
pass
a
class
to
a
function
assign
it
to
a
variable
stuff
it
in
a
list
or
dictionary
and
so
on
chapter
tuples
files
and
everything
else
figure
python
s
major
built
in
object
types
organized
by
categories
everything
is
a
type
of
object
in
python
even
the
type
of
an
object
python
s
type
hierarchies
type
objects
in
fact
even
types
themselves
are
an
object
type
in
python
the
type
of
an
object
is
an
object
of
type
type
say
that
three
times
fast
seriously
a
call
to
the
built
in
function
type
x
returns
the
type
object
of
object
x
the
practical
application
of
this
is
that
type
objects
can
be
used
for
manual
type
comparisons
in
python
if
statements
however
for
reasons
introduced
in
chapter
manual
type
testing
is
usually
not
the
right
thing
to
do
in
python
since
it
limits
your
code
s
flexibility
one
note
on
type
names
as
of
python
each
core
type
has
a
new
built
in
name
added
to
support
type
customization
through
object
oriented
subclassing
dict
list
str
tuple
int
float
complex
bytes
type
set
and
more
in
python
but
not
file
is
also
a
type
name
and
a
synonym
for
open
calls
to
these
names
are
really
object
constructor
calls
not
simply
conversion
functions
though
you
can
treat
them
as
simple
functions
for
basic
usage
in
addition
the
types
standard
library
module
in
python
provides
additional
type
names
for
types
that
are
not
available
as
built
ins
e
g
the
type
of
a
function
in
python
but
not
this
module
also
includes
synonyms
for
built
in
type
names
and
it
is
possible
to
do
type
tests
with
the
isinstance
function
for
example
all
of
the
following
type
tests
are
true
type
type
type
list
isinstance
list
type
of
another
list
list
type
name
list
or
customization
thereof
import
types
def
f
pass
type
f
types
functiontype
types
has
names
for
other
types
because
types
can
be
subclassed
in
python
today
the
isinstance
technique
is
generally
recommended
see
chapter
for
more
on
subclassing
built
in
types
in
python
and
later
also
in
chapter
we
will
explore
how
type
x
and
type
testing
in
general
apply
to
instances
of
user
defined
classes
in
short
in
python
and
for
new
style
classes
in
python
the
type
of
a
class
instance
is
the
class
from
which
the
instance
was
made
for
classic
classes
in
python
and
earlier
all
class
instances
are
of
the
type
instance
and
we
must
compare
instance
class
attributes
to
compare
their
types
meaningfully
since
we
re
not
ready
for
classes
yet
we
ll
postpone
the
rest
of
this
story
until
chapter
other
types
in
python
besides
the
core
objects
studied
in
this
part
of
the
book
and
the
program
unit
objects
such
as
functions
modules
and
classes
that
we
ll
meet
later
a
typical
python
installation
has
dozens
of
additional
object
types
available
as
linked
in
c
extensions
or
chapter
tuples
files
and
everything
else
python
classes
regular
expression
objects
dbm
files
gui
widgets
network
sockets
and
so
on
the
main
difference
between
these
extra
tools
and
the
built
in
types
we
ve
seen
so
far
is
that
the
built
ins
provide
special
language
creation
syntax
for
their
objects
e
g
for
an
integer
for
a
list
the
open
function
for
files
and
def
and
lambda
for
functions
other
tools
are
generally
made
available
in
standard
library
modules
that
you
must
first
import
to
use
for
instance
to
make
a
regular
expression
object
you
import
re
and
call
re
compile
see
python
s
library
reference
for
a
comprehensive
guide
to
all
the
tools
available
to
python
programs
built
in
type
gotchas
that
s
the
end
of
our
look
at
core
data
types
we
ll
wrap
up
this
part
of
the
book
with
a
discussion
of
common
problems
that
seem
to
bite
new
users
and
the
occasional
expert
along
with
their
solutions
some
of
this
is
a
review
of
ideas
we
ve
already
covered
but
these
issues
are
important
enough
to
warn
about
again
here
assignment
creates
references
not
copies
because
this
is
such
a
central
concept
i
ll
mention
it
again
you
need
to
understand
what
s
going
on
with
shared
references
in
your
program
for
instance
in
the
following
example
the
list
object
assigned
to
the
name
l
is
referenced
from
l
and
from
inside
the
list
assigned
to
the
name
m
changing
l
in
place
changes
what
m
references
too
l
m
x
l
y
m
x
y
l
m
x
y
embed
a
reference
to
l
changes
m
too
this
effect
usually
becomes
important
only
in
larger
programs
and
shared
references
are
often
exactly
what
you
want
if
they
re
not
you
can
avoid
sharing
objects
by
copying
them
explicitly
for
lists
you
can
always
make
a
top
level
copy
by
using
an
emptylimits
slice
l
m
x
l
y
l
l
m
x
y
embed
a
copy
of
l
changes
only
l
not
m
built
in
type
gotchas
remember
slice
limits
default
to
and
the
length
of
the
sequence
being
sliced
if
both
are
omitted
the
slice
extracts
every
item
in
the
sequence
and
so
makes
a
top
level
copy
a
new
unshared
object
repetition
adds
one
level
deep
repeating
a
sequence
is
like
adding
it
to
itself
a
number
of
times
however
when
mutable
sequences
are
nested
the
effect
might
not
always
be
what
you
expect
for
instance
in
the
following
example
x
is
assigned
to
l
repeated
four
times
whereas
y
is
assigned
to
a
list
containing
l
repeated
four
times
l
x
l
y
l
like
l
l
l
l
x
y
because
l
was
nested
in
the
second
repetition
y
winds
up
embedding
references
back
to
the
original
list
assigned
to
l
and
so
is
open
to
the
same
sorts
of
side
effects
noted
in
the
last
section
l
impacts
y
but
not
x
x
y
the
same
solutions
to
this
problem
apply
here
as
in
the
previous
section
as
this
is
really
just
another
way
to
create
the
shared
mutable
object
reference
case
if
you
remember
that
repetition
concatenation
and
slicing
copy
only
the
top
level
of
their
operand
objects
these
sorts
of
cases
make
much
more
sense
beware
of
cyclic
data
structures
we
actually
encountered
this
concept
in
a
prior
exercise
if
a
collection
object
contains
a
reference
to
itself
it
s
called
a
cyclic
object
python
prints
a
whenever
it
detects
a
cycle
in
the
object
rather
than
getting
stuck
in
an
infinite
loop
l
grail
l
append
l
l
grail
append
reference
to
same
object
generates
cycle
in
object
besides
understanding
that
the
three
dots
in
square
brackets
represent
a
cycle
in
the
object
this
case
is
worth
knowing
about
because
it
can
lead
to
gotchas
cyclic
structures
may
cause
code
of
your
own
to
fall
into
unexpected
loops
if
you
don
t
anticipate
them
for
instance
some
programs
keep
a
list
or
dictionary
of
already
visited
items
and
chapter
tuples
files
and
everything
else
check
it
to
determine
whether
they
re
in
a
cycle
see
the
solutions
to
the
test
your
knowledge
part
i
exercises
in
appendix
b
for
more
on
this
problem
and
check
out
the
reloadall
py
program
in
chapter
for
a
solution
don
t
use
cyclic
references
unless
you
really
need
to
there
are
good
reasons
to
create
cycles
but
unless
you
have
code
that
knows
how
to
handle
them
you
probably
won
t
want
to
make
your
objects
reference
themselves
very
often
in
practice
immutable
types
can
t
be
changed
in
place
you
can
t
change
an
immutable
object
in
place
instead
you
construct
a
new
object
with
slicing
concatenation
and
so
on
and
assign
it
back
to
the
original
reference
if
needed
t
t
error
t
t
ok
that
might
seem
like
extra
coding
work
but
the
upside
is
that
the
previous
gotchas
can
t
happen
when
you
re
using
immutable
objects
such
as
tuples
and
strings
because
they
can
t
be
changed
in
place
they
are
not
open
to
the
sorts
of
side
effects
that
lists
are
chapter
summary
this
chapter
explored
the
last
two
major
core
object
types
the
tuple
and
the
file
we
learned
that
tuples
support
all
the
usual
sequence
operations
have
just
a
few
methods
and
do
not
allow
any
in
place
changes
because
they
are
immutable
we
also
learned
that
files
are
returned
by
the
built
in
open
function
and
provide
methods
for
reading
and
writing
data
we
explored
how
to
translate
python
objects
to
and
from
strings
for
storing
in
files
and
we
looked
at
the
pickle
and
struct
modules
for
advanced
roles
object
serialization
and
binary
data
finally
we
wrapped
up
by
reviewing
some
properties
common
to
all
object
types
e
g
shared
references
and
went
through
a
list
of
common
mistakes
gotchas
in
the
object
type
domain
in
the
next
part
we
ll
shift
gears
turning
to
the
topic
of
statement
syntax
in
python
we
ll
explore
all
of
python
s
basic
procedural
statements
in
the
chapters
that
follow
the
next
chapter
kicks
off
that
part
of
the
book
with
an
introduction
to
python
s
general
syntax
model
which
is
applicable
to
all
statement
types
before
moving
on
though
take
the
chapter
quiz
and
then
work
through
the
end
of
part
lab
exercises
to
review
type
concepts
statements
largely
just
create
and
process
objects
so
make
sure
you
ve
mastered
this
domain
by
working
through
all
the
exercises
before
reading
on
chapter
summary
test
your
knowledge
quiz
how
can
you
determine
how
large
a
tuple
is
why
is
this
tool
located
where
it
is
write
an
expression
that
changes
the
first
item
in
a
tuple
should
become
in
the
process
what
is
the
default
for
the
processing
mode
argument
in
a
file
open
call
what
module
might
you
use
to
store
python
objects
in
a
file
without
converting
them
to
strings
yourself
how
might
you
go
about
copying
all
parts
of
a
nested
structure
at
once
when
does
python
consider
an
object
true
what
is
your
quest
test
your
knowledge
answers
the
built
in
len
function
returns
the
length
number
of
contained
items
for
any
container
object
in
python
including
tuples
it
is
a
built
in
function
instead
of
a
type
method
because
it
applies
to
many
different
types
of
objects
in
general
builtin
functions
and
expressions
may
span
many
object
types
methods
are
specific
to
a
single
object
type
though
some
may
be
available
on
more
than
one
type
index
for
example
works
on
lists
and
tuples
because
they
are
immutable
you
can
t
really
change
tuples
in
place
but
you
can
generate
a
new
tuple
with
the
desired
value
given
t
you
can
change
the
first
item
by
making
a
new
tuple
from
its
parts
by
slicing
and
concatenating
t
t
recall
that
single
item
tuples
require
a
trailing
comma
you
could
also
convert
the
tuple
to
a
list
change
it
in
place
and
convert
it
back
to
a
tuple
but
this
is
more
expensive
and
is
rarely
required
in
practice
simply
use
a
list
if
you
know
that
the
object
will
require
in
place
changes
the
default
for
the
processing
mode
argument
in
a
file
open
call
is
r
for
reading
text
input
for
input
text
files
simply
pass
in
the
external
file
s
name
the
pickle
module
can
be
used
to
store
python
objects
in
a
file
without
explicitly
converting
them
to
strings
the
struct
module
is
related
but
it
assumes
the
data
is
to
be
in
packed
binary
format
in
the
file
import
the
copy
module
and
call
copy
deepcopy
x
if
you
need
to
copy
all
parts
of
a
nested
structure
x
this
is
also
rarely
seen
in
practice
references
are
usually
the
desired
behavior
and
shallow
copies
e
g
alist
adict
copy
usually
suffice
for
most
copies
chapter
tuples
files
and
everything
else
an
object
is
considered
true
if
it
is
either
a
nonzero
number
or
a
nonempty
collection
object
the
built
in
words
true
and
false
are
essentially
predefined
to
have
the
same
meanings
as
integer
and
respectively
acceptable
answers
include
to
learn
python
to
move
on
to
the
next
part
of
the
book
or
to
seek
the
holy
grail
test
your
knowledge
part
ii
exercises
this
session
asks
you
to
get
your
feet
wet
with
built
in
object
fundamentals
as
before
a
few
new
ideas
may
pop
up
along
the
way
so
be
sure
to
flip
to
the
answers
in
appendix
b
when
you
re
done
or
when
you
re
not
if
necessary
if
you
have
limited
time
i
suggest
starting
with
exercises
and
the
most
practical
of
the
bunch
and
then
working
from
first
to
last
as
time
allows
this
is
all
fundamental
material
though
so
try
to
do
as
many
of
these
as
you
can
the
basics
experiment
interactively
with
the
common
type
operations
found
in
the
various
operation
tables
in
this
part
of
the
book
to
get
started
bring
up
the
python
interactive
interpreter
type
each
of
the
following
expressions
and
try
to
explain
what
s
happening
in
each
case
note
that
the
semicolon
in
some
of
these
is
being
used
as
a
statement
separator
to
squeeze
multiple
statements
onto
a
single
line
for
example
x
x
assigns
and
then
prints
a
variable
more
on
statement
syntax
in
the
next
part
of
the
book
also
remember
that
a
comma
between
expressions
usually
builds
a
tuple
even
if
there
are
no
enclosing
parentheses
x
y
z
is
a
three
item
tuple
which
python
prints
back
to
you
in
parentheses
spam
eggs
s
ham
eggs
s
s
s
green
s
and
s
eggs
s
green
and
format
eggs
s
x
x
y
l
l
l
l
l
l
l
l
l
reverse
l
l
sort
l
l
index
a
b
b
d
x
y
z
test
your
knowledge
part
ii
exercises
d
w
d
x
d
w
d
list
d
keys
list
d
values
in
d
none
indexing
and
slicing
at
the
interactive
prompt
define
a
list
named
l
that
contains
four
strings
or
numbers
e
g
l
then
experiment
with
some
boundary
cases
you
may
not
ever
see
these
cases
in
real
programs
but
they
are
intended
to
make
you
think
about
the
underlying
model
and
some
may
be
useful
in
less
artificial
forms
a
what
happens
when
you
try
to
index
out
of
bounds
e
g
l
b
what
about
slicing
out
of
bounds
e
g
l
c
finally
how
does
python
handle
it
if
you
try
to
extract
a
sequence
in
reverse
with
the
lower
bound
greater
than
the
higher
bound
e
g
l
hint
try
assigning
to
this
slice
l
and
see
where
the
value
is
put
do
you
think
this
may
be
the
same
phenomenon
you
saw
when
slicing
out
of
bounds
indexing
slicing
and
del
define
another
list
l
with
four
items
and
assign
an
empty
list
to
one
of
its
offsets
e
g
l
what
happens
then
assign
an
empty
list
to
a
slice
l
what
happens
now
recall
that
slice
assignment
deletes
the
slice
and
inserts
the
new
value
where
it
used
to
be
the
del
statement
deletes
offsets
keys
attributes
and
names
use
it
on
your
list
to
delete
an
item
e
g
del
l
what
happens
if
you
delete
an
entire
slice
del
l
what
happens
when
you
assign
a
nonsequence
to
a
slice
l
tuple
assignment
type
the
following
lines
x
spam
y
eggs
x
y
y
x
what
do
you
think
is
happening
to
x
and
y
when
you
type
this
sequence
dictionary
keys
consider
the
following
code
fragments
d
d
a
d
b
you
ve
learned
that
dictionaries
aren
t
accessed
by
offsets
so
what
s
going
on
here
does
the
following
shed
any
light
on
the
subject
hint
strings
integers
and
tuples
share
which
type
category
d
c
d
a
b
c
chapter
tuples
files
and
everything
else
dictionary
indexing
create
a
dictionary
named
d
with
three
entries
for
keys
a
b
and
c
what
happens
if
you
try
to
index
a
nonexistent
key
d
d
what
does
python
do
if
you
try
to
assign
to
a
nonexistent
key
d
e
g
d
d
spam
how
does
this
compare
to
out
of
bounds
assignments
and
references
for
lists
does
this
sound
like
the
rule
for
variable
names
generic
operations
run
interactive
tests
to
answer
the
following
questions
a
what
happens
when
you
try
to
use
the
operator
on
different
mixed
types
e
g
string
list
list
tuple
b
does
work
when
one
of
the
operands
is
a
dictionary
c
does
the
append
method
work
for
both
lists
and
strings
how
about
using
the
keys
method
on
lists
hint
what
does
append
assume
about
its
subject
object
d
finally
what
type
of
object
do
you
get
back
when
you
slice
or
concatenate
two
lists
or
two
strings
string
indexing
define
a
string
s
of
four
characters
s
spam
then
type
the
following
expression
s
any
clue
as
to
what
s
happening
this
time
hint
recall
that
a
string
is
a
collection
of
characters
but
python
characters
are
one
character
strings
does
this
indexing
expression
still
work
if
you
apply
it
to
a
list
such
as
s
p
a
m
why
immutable
types
define
a
string
s
of
four
characters
again
s
spam
write
an
assignment
that
changes
the
string
to
slam
using
only
slicing
and
concatenation
could
you
perform
the
same
operation
using
just
indexing
and
concatenation
how
about
index
assignment
nesting
write
a
data
structure
that
represents
your
personal
information
name
first
middle
last
age
job
address
email
address
and
phone
number
you
may
build
the
data
structure
with
any
combination
of
built
in
object
types
you
like
lists
tuples
dictionaries
strings
numbers
then
access
the
individual
components
of
your
data
structures
by
indexing
do
some
structures
make
more
sense
than
others
for
this
object
files
write
a
script
that
creates
a
new
output
file
called
myfile
txt
and
writes
the
string
hello
file
world
into
it
then
write
another
script
that
opens
myfile
txt
and
reads
and
prints
its
contents
run
your
two
scripts
from
the
system
command
line
does
the
new
file
show
up
in
the
directory
where
you
ran
your
scripts
what
if
you
add
a
different
directory
path
to
the
filename
passed
to
open
note
file
write
methods
do
not
add
newline
characters
to
your
strings
add
an
explicit
n
at
the
end
of
the
string
if
you
want
to
fully
terminate
the
line
in
the
file
test
your
knowledge
part
ii
exercises
part
iii
statements
and
syntax
chapter
introducing
python
statements
now
that
you
re
familiar
with
python
s
core
built
in
object
types
this
chapter
begins
our
exploration
of
its
fundamental
statement
forms
as
in
the
previous
part
we
ll
begin
here
with
a
general
introduction
to
statement
syntax
and
we
ll
follow
up
with
more
details
about
specific
statements
in
the
next
few
chapters
in
simple
terms
statements
are
the
things
you
write
to
tell
python
what
your
programs
should
do
if
programs
do
things
with
stuff
statements
are
the
way
you
specify
what
sort
of
things
a
program
does
python
is
a
procedural
statement
based
language
by
combining
statements
you
specify
a
procedure
that
python
performs
to
satisfy
a
program
s
goals
python
program
structure
revisited
another
way
to
understand
the
role
of
statements
is
to
revisit
the
concept
hierarchy
introduced
in
chapter
which
talked
about
built
in
objects
and
the
expressions
used
to
manipulate
them
this
chapter
climbs
the
hierarchy
to
the
next
level
programs
are
composed
of
modules
modules
contain
statements
statements
contain
expressions
expressions
create
and
process
objects
at
its
core
python
syntax
is
composed
of
statements
and
expressions
expressions
process
objects
and
are
embedded
in
statements
statements
code
the
larger
logic
of
a
program
s
operation
they
use
and
direct
expressions
to
process
the
objects
we
studied
in
the
preceding
chapters
moreover
statements
are
where
objects
spring
into
existence
e
g
in
expressions
within
assignment
statements
and
some
statements
create
entirely
new
kinds
of
objects
functions
classes
and
so
on
statements
always
exist
in
modules
which
themselves
are
managed
with
statements
python
s
statements
table
summarizes
python
s
statement
set
this
part
of
the
book
deals
with
entries
in
the
table
from
the
top
through
break
and
continue
you
ve
informally
been
introduced
to
a
few
of
the
statements
in
table
already
this
part
of
the
book
will
fill
in
details
that
were
skipped
earlier
introduce
the
rest
of
python
s
procedural
statement
set
and
cover
the
overall
syntax
model
statements
lower
in
table
that
have
to
do
with
larger
program
units
functions
classes
modules
and
exceptions
lead
to
larger
programming
ideas
so
they
will
each
have
a
section
of
their
own
more
focused
statements
like
del
which
deletes
various
components
are
covered
elsewhere
in
the
book
or
in
python
s
standard
manuals
table
python
statements
statement
role
example
assignment
creating
references
a
b
good
bad
ugly
calls
and
other
expressions
running
functions
log
write
spam
ham
print
calls
printing
objects
print
the
killer
joke
if
elif
else
selecting
actions
if
python
in
text
print
text
for
else
sequence
iteration
for
x
in
mylist
print
x
while
else
general
loops
while
x
y
print
hello
pass
empty
placeholder
while
true
pass
break
loop
exit
while
true
if
exittest
break
continue
loop
continue
while
true
if
skiptest
continue
def
functions
and
methods
def
f
a
b
c
d
print
a
b
c
d
return
functions
results
def
f
a
b
c
d
return
a
b
c
d
yield
generator
functions
def
gen
n
for
i
in
n
yield
i
global
namespaces
x
old
def
function
global
x
y
x
new
nonlocal
namespaces
def
outer
x
old
def
function
nonlocal
x
x
new
import
module
access
import
sys
from
attribute
access
from
sys
import
stdin
class
building
objects
class
subclass
superclass
staticdata
def
method
self
pass
chapter
introducing
python
statements
statement
role
example
try
except
finally
catching
exceptions
try
raise
triggering
exceptions
raise
endsearch
location
assert
debugging
checks
assert
x
y
x
too
small
with
as
context
managers
with
open
data
as
myfile
process
myfile
del
deleting
references
del
del
del
del
action
except
print
action
error
data
k
data
i
j
obj
attr
variable
table
reflects
the
statement
forms
in
python
units
of
code
that
each
have
a
specific
syntax
and
purpose
here
are
a
few
fine
points
about
its
content
assignment
statements
come
in
a
variety
of
syntax
flavors
described
in
chapter
basic
sequence
augmented
and
more
print
is
technically
neither
a
reserved
word
nor
a
statement
in
but
a
built
in
function
call
because
it
will
nearly
always
be
run
as
an
expression
statement
though
that
is
on
a
line
by
itself
it
s
generally
thought
of
as
a
statement
type
we
ll
study
print
operations
in
chapter
the
next
chapter
yield
is
actually
an
expression
instead
of
a
statement
too
as
of
like
print
it
s
typically
used
in
a
line
by
itself
and
so
is
included
in
this
table
but
scripts
occasionally
assign
or
otherwise
use
its
result
as
we
ll
see
in
chapter
as
an
expression
yield
is
also
a
reserved
word
unlike
print
most
of
this
table
applies
to
python
too
except
where
it
doesn
t
if
you
are
using
python
or
older
here
are
a
few
notes
for
your
python
too
in
nonlocal
is
not
available
as
we
ll
see
in
chapter
there
are
alternative
ways
to
achieve
this
statement
s
writeable
state
retention
effect
in
print
is
a
statement
instead
of
a
built
in
function
call
with
specific
syntax
covered
in
chapter
in
the
exec
code
execution
built
in
function
is
a
statement
with
specific
syntax
since
it
supports
enclosing
parentheses
though
you
can
generally
use
its
call
form
in
code
in
the
try
except
and
try
finally
statements
were
merged
the
two
were
formerly
separate
statements
but
we
can
now
say
both
except
and
finally
in
the
same
try
statement
in
with
as
is
an
optional
extension
and
it
is
not
available
unless
you
explicitly
turn
it
on
by
running
the
statement
from
future
import
with
statement
see
chapter
python
program
structure
revisited
a
tale
of
two
ifs
before
we
delve
into
the
details
of
any
of
the
concrete
statements
in
table
i
want
to
begin
our
look
at
python
statement
syntax
by
showing
you
what
you
are
not
going
to
type
in
python
code
so
you
can
compare
and
contrast
it
with
other
syntax
models
you
might
have
seen
in
the
past
consider
the
following
if
statement
coded
in
a
c
like
language
if
x
y
x
y
this
might
be
a
statement
in
c
c
java
javascript
or
perl
now
look
at
the
equivalent
statement
in
the
python
language
if
x
y
x
y
the
first
thing
that
may
pop
out
at
you
is
that
the
equivalent
python
statement
is
less
well
cluttered
that
is
there
are
fewer
syntactic
components
this
is
by
design
as
a
scripting
language
one
of
python
s
goals
is
to
make
programmers
lives
easier
by
requiring
less
typing
more
specifically
when
you
compare
the
two
syntax
models
you
ll
notice
that
python
adds
one
new
thing
to
the
mix
and
that
three
items
that
are
present
in
the
c
like
language
are
not
present
in
python
code
what
python
adds
the
one
new
syntax
component
in
python
is
the
colon
character
all
python
compound
statements
i
e
statements
that
have
statements
nested
inside
them
follow
the
same
general
pattern
of
a
header
line
terminated
in
a
colon
followed
by
a
nested
block
of
code
usually
indented
underneath
the
header
line
like
this
header
line
nested
statement
block
the
colon
is
required
and
omitting
it
is
probably
the
most
common
coding
mistake
among
new
python
programmers
it
s
certainly
one
i
ve
witnessed
thousands
of
times
in
python
training
classes
in
fact
if
you
are
new
to
python
you
ll
almost
certainly
forget
the
colon
character
very
soon
most
python
friendly
editors
make
this
mistake
easy
to
spot
and
including
it
eventually
becomes
an
unconscious
habit
so
much
so
that
you
may
start
typing
colons
in
your
c
code
too
generating
many
entertaining
error
messages
from
your
c
compiler
chapter
introducing
python
statements
what
python
removes
although
python
requires
the
extra
colon
character
there
are
three
things
programmers
in
c
like
languages
must
include
that
you
don
t
generally
have
to
in
python
parentheses
are
optional
the
first
of
these
is
the
set
of
parentheses
around
the
tests
at
the
top
of
the
statement
if
x
y
the
parentheses
here
are
required
by
the
syntax
of
many
c
like
languages
in
python
though
they
are
not
we
simply
omit
the
parentheses
and
the
statement
works
the
same
way
if
x
y
technically
speaking
because
every
expression
can
be
enclosed
in
parentheses
including
them
will
not
hurt
in
this
python
code
and
they
are
not
treated
as
an
error
if
present
but
don
t
do
that
you
ll
be
wearing
out
your
keyboard
needlessly
and
broadcasting
to
the
world
that
you
re
an
ex
c
programmer
still
learning
python
i
was
once
too
the
python
way
is
to
simply
omit
the
parentheses
in
these
kinds
of
statements
altogether
end
of
line
is
end
of
statement
the
second
and
more
significant
syntax
component
you
won
t
find
in
python
code
is
the
semicolon
you
don
t
need
to
terminate
statements
with
semicolons
in
python
the
way
you
do
in
c
like
languages
x
in
python
the
general
rule
is
that
the
end
of
a
line
automatically
terminates
the
statement
that
appears
on
that
line
in
other
words
you
can
leave
off
the
semicolons
and
it
works
the
same
way
x
there
are
some
ways
to
work
around
this
rule
as
you
ll
see
in
a
moment
but
in
general
you
write
one
statement
per
line
for
the
vast
majority
of
python
code
and
no
semicolon
is
required
here
too
if
you
are
pining
for
your
c
programming
days
if
such
a
state
is
possible
you
can
continue
to
use
semicolons
at
the
end
of
each
statement
the
language
lets
you
get
away
with
them
if
they
are
present
but
don
t
do
that
either
really
again
doing
so
tells
the
world
that
you
re
still
a
c
programmer
who
hasn
t
quite
made
the
switch
to
python
coding
the
pythonic
style
is
to
leave
off
the
semicolons
altogether
a
tale
of
two
ifs
end
of
indentation
is
end
of
block
the
third
and
final
syntax
component
that
python
removes
and
the
one
that
may
seem
the
most
unusual
to
soon
to
be
ex
c
programmers
until
they
ve
used
it
for
minutes
and
realize
it
s
actually
a
feature
is
that
you
do
not
type
anything
explicit
in
your
code
to
syntactically
mark
the
beginning
and
end
of
a
nested
block
of
code
you
don
t
need
to
include
begin
end
then
endif
or
braces
around
the
nested
block
as
you
do
in
clike
languages
if
x
y
x
y
instead
in
python
we
consistently
indent
all
the
statements
in
a
given
single
nested
block
the
same
distance
to
the
right
and
python
uses
the
statements
physical
indentation
to
determine
where
the
block
starts
and
stops
if
x
y
x
y
by
indentation
i
mean
the
blank
whitespace
all
the
way
to
the
left
of
the
two
nested
statements
here
python
doesn
t
care
how
you
indent
you
may
use
either
spaces
or
tabs
or
how
much
you
indent
you
may
use
any
number
of
spaces
or
tabs
in
fact
the
indentation
of
one
nested
block
can
be
totally
different
from
that
of
another
the
syntax
rule
is
only
that
for
a
given
single
nested
block
all
of
its
statements
must
be
indented
the
same
distance
to
the
right
if
this
is
not
the
case
you
will
get
a
syntax
error
and
your
code
will
not
run
until
you
repair
its
indentation
to
be
consistent
why
indentation
syntax
the
indentation
rule
may
seem
unusual
at
first
glance
to
programmers
accustomed
to
c
like
languages
but
it
is
a
deliberate
feature
of
python
and
it
s
one
of
the
main
ways
that
python
almost
forces
programmers
to
produce
uniform
regular
and
readable
code
it
essentially
means
that
you
must
line
up
your
code
vertically
in
columns
according
to
its
logical
structure
the
net
effect
is
to
make
your
code
more
consistent
and
readable
unlike
much
of
the
code
written
in
c
like
languages
to
put
that
more
strongly
aligning
your
code
according
to
its
logical
structure
is
a
major
part
of
making
it
readable
and
thus
reusable
and
maintainable
by
yourself
and
others
in
fact
even
if
you
never
use
python
after
reading
this
book
you
should
get
into
the
habit
of
aligning
your
code
for
readability
in
any
block
structured
language
python
forces
the
issue
by
making
this
a
part
of
its
syntax
but
it
s
an
important
thing
to
do
in
any
programming
language
and
it
has
a
huge
impact
on
the
usefulness
of
your
code
your
experience
may
vary
but
when
i
was
still
doing
development
on
a
full
time
basis
i
was
mostly
paid
to
work
on
large
old
c
programs
that
had
been
worked
on
by
many
programmers
over
the
years
almost
invariably
each
programmer
had
his
or
her
chapter
introducing
python
statements
own
style
for
indenting
code
for
example
i
d
often
be
asked
to
change
a
while
loop
coded
in
the
c
language
that
began
like
this
while
x
before
we
even
get
into
indentation
there
are
three
or
four
ways
that
programmers
can
arrange
these
braces
in
a
c
like
language
and
organizations
often
have
political
debates
and
write
standards
manuals
to
address
the
options
which
seems
more
than
a
little
off
topic
for
the
problem
to
be
solved
by
programming
ignoring
that
here
s
the
scenario
i
often
encountered
in
c
code
the
first
person
who
worked
on
the
code
indented
the
loop
four
spaces
while
x
that
person
eventually
moved
on
to
management
only
to
be
replaced
by
someone
who
liked
to
indent
further
to
the
right
while
x
that
person
later
moved
on
to
other
opportunities
and
someone
else
picked
up
the
code
who
liked
to
indent
less
while
x
and
so
on
eventually
the
block
is
terminated
by
a
closing
brace
which
of
course
makes
this
block
structured
code
he
says
sarcastically
in
any
block
structured
language
python
or
otherwise
if
nested
blocks
are
not
indented
consistently
they
become
very
difficult
for
the
reader
to
interpret
change
or
reuse
because
the
code
no
longer
visually
reflects
its
logical
meaning
readability
matters
and
indentation
is
a
major
component
of
readability
here
is
another
example
that
may
have
burned
you
in
the
past
if
you
ve
done
much
programming
in
a
c
like
language
consider
the
following
statement
in
c
if
x
if
y
statement
else
statement
a
tale
of
two
ifs
which
if
does
the
else
here
go
with
surprisingly
the
else
is
paired
with
the
nested
if
statement
if
y
even
though
it
looks
visually
as
though
it
is
associated
with
the
outer
if
x
this
is
a
classic
pitfall
in
the
c
language
and
it
can
lead
to
the
reader
completely
misinterpreting
the
code
and
changing
it
incorrectly
in
ways
that
might
not
be
uncovered
until
the
mars
rover
crashes
into
a
giant
rock
this
cannot
happen
in
python
because
indentation
is
significant
the
way
the
code
looks
is
the
way
it
will
work
consider
an
equivalent
python
statement
if
x
if
y
statement
else
statement
in
this
example
the
if
that
the
else
lines
up
with
vertically
is
the
one
it
is
associated
with
logically
the
outer
if
x
in
a
sense
python
is
a
wysiwyg
language
what
you
see
is
what
you
get
because
the
way
code
looks
is
the
way
it
runs
regardless
of
who
coded
it
if
this
still
isn
t
enough
to
underscore
the
benefits
of
python
s
syntax
here
s
another
anecdote
early
in
my
career
i
worked
at
a
successful
company
that
developed
systems
software
in
the
c
language
where
consistent
indentation
is
not
required
even
so
when
we
checked
our
code
into
source
control
at
the
end
of
the
day
this
company
ran
an
automated
script
that
analyzed
the
indentation
used
in
the
code
if
the
script
noticed
that
we
d
indented
our
code
inconsistently
we
received
an
automated
email
about
it
the
next
morning
and
so
did
our
managers
the
point
is
that
even
when
a
language
doesn
t
require
it
good
programmers
know
that
consistent
use
of
indentation
has
a
huge
impact
on
code
readability
and
quality
the
fact
that
python
promotes
this
to
the
level
of
syntax
is
seen
by
most
as
a
feature
of
the
language
also
keep
in
mind
that
nearly
every
programmer
friendly
text
editor
has
built
in
support
for
python
s
syntax
model
in
the
idle
python
gui
for
example
lines
of
code
are
automatically
indented
when
you
are
typing
a
nested
block
pressing
the
backspace
key
backs
up
one
level
of
indentation
and
you
can
customize
how
far
to
the
right
idle
indents
statements
in
a
nested
block
there
is
no
universal
standard
on
this
four
spaces
or
one
tab
per
level
is
common
but
it
s
up
to
you
to
decide
how
and
how
much
you
wish
to
indent
indent
further
to
the
right
for
further
nested
blocks
and
less
to
close
the
prior
block
as
a
rule
of
thumb
you
probably
shouldn
t
mix
tabs
and
spaces
in
the
same
block
in
python
unless
you
do
so
consistently
use
tabs
or
spaces
in
a
given
block
but
not
both
in
fact
python
now
issues
an
error
for
inconsistent
use
of
tabs
and
spaces
as
we
ll
see
in
chapter
but
you
probably
shouldn
t
mix
tabs
or
spaces
in
indentation
in
any
structured
language
such
code
can
cause
major
readability
issues
if
the
next
programmer
has
his
or
her
editor
set
to
display
tabs
differently
than
yours
c
like
languages
chapter
introducing
python
statements
might
let
coders
get
away
with
this
but
they
shouldn
t
the
result
can
be
a
mangled
mess
i
can
t
stress
enough
that
regardless
of
which
language
you
code
in
you
should
be
indenting
consistently
for
readability
in
fact
if
you
weren
t
taught
to
do
this
earlier
in
your
career
your
teachers
did
you
a
disservice
most
programmers
especially
those
who
must
read
others
code
consider
it
a
major
asset
that
python
elevates
this
to
the
level
of
syntax
moreover
generating
tabs
instead
of
braces
is
no
more
difficult
in
practice
for
tools
that
must
output
python
code
in
general
if
you
do
what
you
should
be
doing
in
a
c
like
language
anyhow
but
get
rid
of
the
braces
your
code
will
satisfy
python
s
syntax
rules
a
few
special
cases
as
mentioned
previously
in
python
s
syntax
model
the
end
of
a
line
terminates
the
statement
on
that
line
without
semicolons
nested
statements
are
blocked
and
associated
by
their
physical
indentation
without
braces
those
rules
cover
almost
all
python
code
you
ll
write
or
see
in
practice
however
python
also
provides
some
special
purpose
rules
that
allow
customization
of
both
statements
and
nested
statement
blocks
statement
rule
special
cases
although
statements
normally
appear
one
per
line
it
is
possible
to
squeeze
more
than
one
statement
onto
a
single
line
in
python
by
separating
them
with
semicolons
a
b
print
a
b
three
statements
on
one
line
this
is
the
only
place
in
python
where
semicolons
are
required
as
statement
separators
this
only
works
though
if
the
statements
thus
combined
are
not
themselves
compound
statements
in
other
words
you
can
chain
together
only
simple
statements
like
assignments
prints
and
function
calls
compound
statements
must
still
appear
on
lines
of
their
own
otherwise
you
could
squeeze
an
entire
program
onto
one
line
which
probably
would
not
make
you
very
popular
among
your
coworkers
the
other
special
rule
for
statements
is
essentially
the
inverse
you
can
make
a
single
statement
span
across
multiple
lines
to
make
this
work
you
simply
have
to
enclose
part
of
your
statement
in
a
bracketed
pair
parentheses
square
brackets
or
curly
braces
any
code
enclosed
in
these
constructs
can
cross
multiple
lines
your
statement
doesn
t
end
until
python
reaches
the
line
containing
the
closing
part
of
the
pair
for
instance
to
continue
a
list
literal
mlist
a
tale
of
two
ifs
because
the
code
is
enclosed
in
a
square
brackets
pair
python
simply
drops
down
to
the
next
line
until
it
encounters
the
closing
bracket
the
curly
braces
surrounding
dictionaries
as
well
as
set
literals
and
dictionary
and
set
comprehensions
in
allow
them
to
span
lines
this
way
too
and
parentheses
handle
tuples
function
calls
and
expressions
the
indentation
of
the
continuation
lines
does
not
matter
though
common
sense
dictates
that
the
lines
should
be
aligned
somehow
for
readability
parentheses
are
the
catchall
device
because
any
expression
can
be
wrapped
up
in
them
simply
inserting
a
left
parenthesis
allows
you
to
drop
down
to
the
next
line
and
continue
your
statement
x
a
b
c
d
this
technique
works
with
compound
statements
too
by
the
way
anywhere
you
need
to
code
a
large
expression
simply
wrap
it
in
parentheses
to
continue
it
on
the
next
line
if
a
and
b
and
c
print
spam
an
older
rule
also
allows
for
continuation
lines
when
the
prior
line
ends
in
a
backslash
x
a
b
c
d
an
error
prone
alternative
this
alternative
technique
is
dated
though
and
is
frowned
on
today
because
it
s
difficult
to
notice
and
maintain
the
backslashes
and
it
s
fairly
brittle
there
can
be
no
spaces
after
the
backslash
and
omitting
it
can
have
unexpected
effects
if
the
next
line
is
mistaken
to
be
a
new
statement
it
s
also
another
throwback
to
the
c
language
where
it
is
commonly
used
in
define
macros
again
when
in
pythonland
do
as
pythonistas
do
not
as
c
programmers
do
block
rule
special
case
as
mentioned
previously
statements
in
a
nested
block
of
code
are
normally
associated
by
being
indented
the
same
amount
to
the
right
as
one
special
case
here
the
body
of
a
compound
statement
can
instead
appear
on
the
same
line
as
the
header
in
python
after
the
colon
if
x
y
print
x
this
allows
us
to
code
single
line
if
statements
single
line
loops
and
so
on
here
again
though
this
will
work
only
if
the
body
of
the
compound
statement
itself
does
not
contain
any
compound
statements
that
is
only
simple
statements
assignments
prints
function
calls
and
the
like
are
allowed
after
the
colon
larger
statements
must
still
appear
on
lines
by
themselves
extra
parts
of
compound
statements
such
as
the
else
part
of
an
if
which
we
ll
meet
later
must
also
be
on
separate
lines
of
their
own
the
body
can
consist
of
multiple
simple
statements
separated
by
semicolons
but
this
tends
to
be
frowned
upon
chapter
introducing
python
statements
in
general
even
though
it
s
not
always
required
if
you
keep
all
your
statements
on
individual
lines
and
always
indent
your
nested
blocks
your
code
will
be
easier
to
read
and
change
in
the
future
moreover
some
code
profiling
and
coverage
tools
may
not
be
able
to
distinguish
between
multiple
statements
squeezed
onto
a
single
line
or
the
header
and
body
of
a
one
line
compound
statement
it
is
almost
always
to
your
advantage
to
keep
things
simple
in
python
to
see
a
prime
and
common
exception
to
one
of
these
rules
in
action
however
the
use
of
a
single
line
if
statement
to
break
out
of
a
loop
let
s
move
on
to
the
next
section
and
write
some
real
code
a
quick
example
interactive
loops
we
ll
see
all
these
syntax
rules
in
action
when
we
tour
python
s
specific
compound
statements
in
the
next
few
chapters
but
they
work
the
same
everywhere
in
the
python
language
to
get
started
let
s
work
through
a
brief
realistic
example
that
demonstrates
the
way
that
statement
syntax
and
statement
nesting
come
together
in
practice
and
introduces
a
few
statements
along
the
way
a
simple
interactive
loop
suppose
you
re
asked
to
write
a
python
program
that
interacts
with
a
user
in
a
console
window
maybe
you
re
accepting
inputs
to
send
to
a
database
or
reading
numbers
to
be
used
in
a
calculation
regardless
of
the
purpose
you
need
to
code
a
loop
that
reads
one
or
more
inputs
from
a
user
typing
on
a
keyboard
and
prints
back
a
result
for
each
in
other
words
you
need
to
write
a
classic
read
evaluate
print
loop
program
in
python
typical
boilerplate
code
for
such
an
interactive
loop
might
look
like
this
while
true
reply
input
enter
text
if
reply
stop
break
print
reply
upper
this
code
makes
use
of
a
few
new
ideas
the
code
leverages
the
python
while
loop
python
s
most
general
looping
statement
we
ll
study
the
while
statement
in
more
detail
later
but
in
short
it
consists
of
the
word
while
followed
by
an
expression
that
is
interpreted
as
a
true
or
false
result
followed
by
a
nested
block
of
code
that
is
repeated
while
the
test
at
the
top
is
true
the
word
true
here
is
considered
always
true
the
input
built
in
function
we
met
earlier
in
the
book
is
used
here
for
general
console
input
it
prints
its
optional
argument
string
as
a
prompt
and
returns
the
user
s
typed
reply
as
a
string
a
single
line
if
statement
that
makes
use
of
the
special
rule
for
nested
blocks
also
appears
here
the
body
of
the
if
appears
on
the
header
line
after
the
colon
instead
a
quick
example
interactive
loops
of
being
indented
on
a
new
line
underneath
it
this
would
work
either
way
but
as
it
s
coded
we
ve
saved
an
extra
line
finally
the
python
break
statement
is
used
to
exit
the
loop
immediately
it
simply
jumps
out
of
the
loop
statement
altogether
and
the
program
continues
after
the
loop
without
this
exit
statement
the
while
would
loop
forever
as
its
test
is
always
true
in
effect
this
combination
of
statements
essentially
means
read
a
line
from
the
user
and
print
it
in
uppercase
until
the
user
enters
the
word
stop
there
are
other
ways
to
code
such
a
loop
but
the
form
used
here
is
very
common
in
python
code
notice
that
all
three
lines
nested
under
the
while
header
line
are
indented
the
same
amount
because
they
line
up
vertically
in
a
column
this
way
they
are
the
block
of
code
that
is
associated
with
the
while
test
and
repeated
either
the
end
of
the
source
file
or
a
lesser
indented
statement
will
terminate
the
loop
body
block
when
run
here
is
the
sort
of
interaction
we
get
from
this
code
enter
text
spam
spam
enter
text
enter
text
stop
version
skew
note
this
example
is
coded
for
python
if
you
are
working
in
python
or
earlier
the
code
works
the
same
but
you
should
use
raw
input
instead
of
input
and
you
can
omit
the
outer
parentheses
in
print
statements
in
the
former
was
renamed
and
the
latter
is
a
built
in
function
instead
of
a
statement
more
on
prints
in
the
next
chapter
doing
math
on
user
inputs
our
script
works
but
now
suppose
that
instead
of
converting
a
text
string
to
uppercase
we
want
to
do
some
math
with
numeric
input
squaring
it
for
example
perhaps
in
some
misguided
effort
to
discourage
users
who
happen
to
be
obsessed
with
youth
we
might
try
statements
like
these
to
achieve
the
desired
effect
reply
reply
error
text
omitted
typeerror
unsupported
operand
type
s
for
or
pow
str
and
int
this
won
t
quite
work
in
our
script
though
because
as
discussed
in
the
prior
part
of
the
book
python
won
t
convert
object
types
in
expressions
unless
they
are
all
numeric
and
input
from
a
user
is
always
returned
to
our
script
as
a
string
we
cannot
raise
a
string
of
digits
to
a
power
unless
we
convert
it
manually
to
an
integer
chapter
introducing
python
statements
int
reply
armed
with
this
information
we
can
now
recode
our
loop
to
perform
the
necessary
math
type
the
following
in
a
file
to
test
it
while
true
reply
input
enter
text
if
reply
stop
break
print
int
reply
print
bye
this
script
uses
a
single
line
if
statement
to
exit
on
stop
as
before
but
it
also
converts
inputs
to
perform
the
required
math
this
version
also
adds
an
exit
message
at
the
bottom
because
the
print
statement
in
the
last
line
is
not
indented
as
much
as
the
nested
block
of
code
it
is
not
considered
part
of
the
loop
body
and
will
run
only
once
after
the
loop
is
exited
enter
text
enter
text
enter
text
stop
bye
one
note
here
i
m
assuming
that
this
code
is
stored
in
and
run
from
a
script
file
if
you
are
entering
this
code
interactively
be
sure
to
include
a
blank
line
i
e
press
enter
twice
before
the
final
print
statement
to
terminate
the
loop
the
final
print
doesn
t
quite
make
sense
in
interactive
mode
though
you
ll
have
to
code
it
after
interacting
with
the
loop
handling
errors
by
testing
inputs
so
far
so
good
but
notice
what
happens
when
the
input
is
invalid
enter
text
xxx
error
text
omitted
valueerror
invalid
literal
for
int
with
base
xxx
the
built
in
int
function
raises
an
exception
here
in
the
face
of
a
mistake
if
we
want
our
script
to
be
robust
we
can
check
the
string
s
content
ahead
of
time
with
the
string
object
s
isdigit
method
s
t
xxx
s
isdigit
t
isdigit
true
false
this
also
gives
us
an
excuse
to
further
nest
the
statements
in
our
example
the
following
new
version
of
our
interactive
script
uses
a
full
blown
if
statement
to
work
around
the
exception
on
errors
while
true
reply
input
enter
text
a
quick
example
interactive
loops
if
reply
stop
break
elif
not
reply
isdigit
print
bad
else
print
int
reply
print
bye
we
ll
study
the
if
statement
in
more
detail
in
chapter
but
it
s
a
fairly
lightweight
tool
for
coding
logic
in
scripts
in
its
full
form
it
consists
of
the
word
if
followed
by
a
test
and
an
associated
block
of
code
one
or
more
optional
elif
else
if
tests
and
code
blocks
and
an
optional
else
part
with
an
associated
block
of
code
at
the
bottom
to
serve
as
a
default
python
runs
the
block
of
code
associated
with
the
first
test
that
is
true
working
from
top
to
bottom
or
the
else
part
if
all
tests
are
false
the
if
elif
and
else
parts
in
the
preceding
example
are
associated
as
part
of
the
same
statement
because
they
all
line
up
vertically
i
e
share
the
same
level
of
indentation
the
if
statement
spans
from
the
word
if
to
the
start
of
the
print
statement
on
the
last
line
of
the
script
in
turn
the
entire
if
block
is
part
of
the
while
loop
because
all
of
it
is
indented
under
the
loop
s
header
line
statement
nesting
is
natural
once
you
get
the
hang
of
it
when
we
run
our
new
script
its
code
catches
errors
before
they
occur
and
prints
an
arguably
silly
error
message
to
demonstrate
enter
text
enter
text
xyz
bad
bad
bad
bad
bad
bad
bad
bad
enter
text
enter
text
stop
handling
errors
with
try
statements
the
preceding
solution
works
but
as
you
ll
see
later
in
the
book
the
most
general
way
to
handle
errors
in
python
is
to
catch
and
recover
from
them
completely
using
the
python
try
statement
we
ll
explore
this
statement
in
depth
in
part
vii
of
this
book
but
as
a
preview
using
a
try
here
can
lead
to
code
that
some
would
claim
is
simpler
than
the
prior
version
while
true
reply
input
enter
text
if
reply
stop
break
try
num
int
reply
except
print
bad
else
print
int
reply
print
bye
chapter
introducing
python
statements
this
version
works
exactly
like
the
previous
one
but
we
ve
replaced
the
explicit
error
check
with
code
that
assumes
the
conversion
will
work
and
wraps
it
up
in
an
exception
handler
for
cases
when
it
doesn
t
this
try
statement
is
composed
of
the
word
try
followed
by
the
main
block
of
code
the
action
we
are
trying
to
run
followed
by
an
except
part
that
gives
the
exception
handler
code
and
an
else
part
to
be
run
if
no
exception
is
raised
in
the
try
part
python
first
runs
the
try
part
then
runs
either
the
except
part
if
an
exception
occurs
or
the
else
part
if
no
exception
occurs
in
terms
of
statement
nesting
because
the
words
try
except
and
else
are
all
indented
to
the
same
level
they
are
all
considered
part
of
the
same
single
try
statement
notice
that
the
else
part
is
associated
with
the
try
here
not
the
if
as
we
ve
seen
else
can
appear
in
if
statements
in
python
but
it
can
also
appear
in
try
statements
and
loops
its
indentation
tells
you
what
statement
it
is
a
part
of
in
this
case
the
try
statement
spans
from
the
word
try
through
the
code
indented
under
the
word
else
because
the
else
is
indented
to
the
same
level
as
try
the
if
statement
in
this
code
is
a
one
liner
and
ends
after
the
break
again
we
ll
come
back
to
the
try
statement
later
in
this
book
for
now
be
aware
that
because
try
can
be
used
to
intercept
any
error
it
reduces
the
amount
of
error
checking
code
you
have
to
write
and
it
s
a
very
general
approach
to
dealing
with
unusual
cases
if
we
wanted
to
support
input
of
floating
point
numbers
instead
of
just
integers
for
example
using
try
would
be
much
easier
than
manual
error
testing
we
could
simply
run
a
float
call
and
catch
its
exceptions
instead
of
trying
to
analyze
all
possible
floatingpoint
syntax
nesting
code
three
levels
deep
let
s
look
at
one
last
mutation
of
our
script
nesting
can
take
us
even
further
if
we
need
it
to
we
could
for
example
branch
to
one
of
a
set
of
alternatives
based
on
the
relative
magnitude
of
a
valid
input
while
true
reply
input
enter
text
if
reply
stop
break
elif
not
reply
isdigit
print
bad
else
num
int
reply
if
num
print
low
else
print
num
print
bye
a
quick
example
interactive
loops
this
version
includes
an
if
statement
nested
in
the
else
clause
of
another
if
statement
which
is
in
turn
nested
in
the
while
loop
when
code
is
conditional
or
repeated
like
this
we
simply
indent
it
further
to
the
right
the
net
effect
is
like
that
of
the
prior
versions
but
we
ll
now
print
low
for
numbers
less
than
enter
text
low
enter
text
enter
text
spam
bad
bad
bad
bad
bad
bad
bad
bad
enter
text
stop
bye
chapter
summary
that
concludes
our
quick
look
at
python
statement
syntax
this
chapter
introduced
the
general
rules
for
coding
statements
and
blocks
of
code
as
you
ve
learned
in
python
we
normally
code
one
statement
per
line
and
indent
all
the
statements
in
a
nested
block
the
same
amount
indentation
is
part
of
python
s
syntax
however
we
also
looked
at
a
few
exceptions
to
these
rules
including
continuation
lines
and
single
line
tests
and
loops
finally
we
put
these
ideas
to
work
in
an
interactive
script
that
demonstrated
a
handful
of
statements
and
showed
statement
syntax
in
action
in
the
next
chapter
we
ll
start
to
dig
deeper
by
going
over
each
of
python
s
basic
procedural
statements
in
depth
as
you
ll
see
though
all
statements
follow
the
same
general
rules
introduced
here
test
your
knowledge
quiz
what
three
things
are
required
in
a
c
like
language
but
omitted
in
python
how
is
a
statement
normally
terminated
in
python
how
are
the
statements
in
a
nested
block
of
code
normally
associated
in
python
how
can
you
make
a
single
statement
span
multiple
lines
how
can
you
code
a
compound
statement
on
a
single
line
is
there
any
valid
reason
to
type
a
semicolon
at
the
end
of
a
statement
in
python
what
is
a
try
statement
for
what
is
the
most
common
coding
mistake
among
python
beginners
chapter
introducing
python
statements
test
your
knowledge
answers
c
like
languages
require
parentheses
around
the
tests
in
some
statements
semicolons
at
the
end
of
each
statement
and
braces
around
a
nested
block
of
code
the
end
of
a
line
terminates
the
statement
that
appears
on
that
line
alternatively
if
more
than
one
statement
appears
on
the
same
line
they
can
be
terminated
with
semicolons
similarly
if
a
statement
spans
many
lines
you
must
terminate
it
by
closing
a
bracketed
syntactic
pair
the
statements
in
a
nested
block
are
all
indented
the
same
number
of
tabs
or
spaces
a
statement
can
be
made
to
span
many
lines
by
enclosing
part
of
it
in
parentheses
square
brackets
or
curly
braces
the
statement
ends
when
python
sees
a
line
that
contains
the
closing
part
of
the
pair
the
body
of
a
compound
statement
can
be
moved
to
the
header
line
after
the
colon
but
only
if
the
body
consists
of
only
noncompound
statements
only
when
you
need
to
squeeze
more
than
one
statement
onto
a
single
line
of
code
even
then
this
only
works
if
all
the
statements
are
noncompound
and
it
s
discouraged
because
it
can
lead
to
code
that
is
difficult
to
read
the
try
statement
is
used
to
catch
and
recover
from
exceptions
errors
in
a
python
script
it
s
usually
an
alternative
to
manually
checking
for
errors
in
your
code
forgetting
to
type
the
colon
character
at
the
end
of
the
header
line
in
a
compound
statement
is
the
most
common
beginner
s
mistake
if
you
haven
t
made
it
yet
you
probably
will
soon
test
your
knowledge
answers
chapter
assignments
expressions
and
prints
now
that
we
ve
had
a
quick
introduction
to
python
statement
syntax
this
chapter
begins
our
in
depth
tour
of
specific
python
statements
we
ll
begin
with
the
basics
assignment
statements
expression
statements
and
print
operations
we
ve
already
seen
all
of
these
in
action
but
here
we
ll
fill
in
important
details
we
ve
skipped
so
far
although
they
re
fairly
simple
as
you
ll
see
there
are
optional
variations
for
each
of
these
statement
types
that
will
come
in
handy
once
you
begin
writing
real
python
programs
assignment
statements
we
ve
been
using
the
python
assignment
statement
for
a
while
to
assign
objects
to
names
in
its
basic
form
you
write
the
target
of
an
assignment
on
the
left
of
an
equals
sign
and
the
object
to
be
assigned
on
the
right
the
target
on
the
left
may
be
a
name
or
object
component
and
the
object
on
the
right
can
be
an
arbitrary
expression
that
computes
an
object
for
the
most
part
assignments
are
straightforward
but
here
are
a
few
properties
to
keep
in
mind
assignments
create
object
references
as
discussed
in
chapter
python
assignments
store
references
to
objects
in
names
or
data
structure
components
they
always
create
references
to
objects
instead
of
copying
the
objects
because
of
that
python
variables
are
more
like
pointers
than
data
storage
areas
names
are
created
when
first
assigned
python
creates
a
variable
name
the
first
time
you
assign
it
a
value
i
e
an
object
reference
so
there
s
no
need
to
predeclare
names
ahead
of
time
some
but
not
all
data
structure
slots
are
created
when
assigned
too
e
g
dictionary
entries
some
object
attributes
once
assigned
a
name
is
replaced
with
the
value
it
references
whenever
it
appears
in
an
expression
names
must
be
assigned
before
being
referenced
it
s
an
error
to
use
a
name
to
which
you
haven
t
yet
assigned
a
value
python
raises
an
exception
if
you
try
rather
than
returning
some
sort
of
ambiguous
default
value
if
it
returned
a
default
instead
it
would
be
more
difficult
for
you
to
spot
typos
in
your
code
some
operations
perform
assignments
implicitly
in
this
section
we
re
concerned
with
the
statement
but
assignment
occurs
in
many
contexts
in
python
for
instance
we
ll
see
later
that
module
imports
function
and
class
definitions
for
loop
variables
and
function
arguments
are
all
implicit
assignments
because
assignment
works
the
same
everywhere
it
pops
up
all
these
contexts
simply
bind
names
to
object
references
at
runtime
assignment
statement
forms
although
assignment
is
a
general
and
pervasive
concept
in
python
we
are
primarily
interested
in
assignment
statements
in
this
chapter
table
illustrates
the
different
assignment
statement
forms
in
python
table
assignment
statement
forms
operation
interpretation
spam
spam
basic
form
spam
ham
yum
yum
tuple
assignment
positional
spam
ham
yum
yum
list
assignment
positional
a
b
c
d
spam
sequence
assignment
generalized
a
b
spam
extended
sequence
unpacking
python
spam
ham
lunch
multiple
target
assignment
spams
augmented
assignment
equivalent
to
spams
spams
the
first
form
in
table
is
by
far
the
most
common
binding
a
name
or
data
structure
component
to
a
single
object
in
fact
you
could
get
all
your
work
done
with
this
basic
form
alone
the
other
table
entries
represent
special
forms
that
are
all
optional
but
that
programmers
often
find
convenient
in
practice
tuple
and
list
unpacking
assignments
the
second
and
third
forms
in
the
table
are
related
when
you
code
a
tuple
or
list
on
the
left
side
of
the
python
pairs
objects
on
the
right
side
with
targets
on
the
left
by
position
and
assigns
them
from
left
to
right
for
example
in
the
second
line
of
table
the
name
spam
is
assigned
the
string
yum
and
the
name
ham
is
bound
to
the
string
yum
in
this
case
python
internally
makes
a
tuple
of
the
items
on
the
right
which
is
why
this
is
called
tuple
unpacking
assignment
sequence
assignments
in
recent
versions
of
python
tuple
and
list
assignments
have
been
generalized
into
instances
of
what
we
now
call
sequence
assignment
any
sequence
of
names
can
be
assigned
to
any
sequence
of
values
and
python
assigns
the
items
one
at
a
time
by
position
we
can
even
mix
and
match
the
types
of
the
sequences
involved
the
fourth
line
in
table
for
example
pairs
a
tuple
of
names
with
a
string
of
characters
a
is
assigned
s
b
is
assigned
p
and
so
on
chapter
assignments
expressions
and
prints
extended
sequence
unpacking
in
python
a
new
form
of
sequence
assignment
allows
us
to
be
more
flexible
in
how
we
select
portions
of
a
sequence
to
assign
the
fifth
line
in
table
for
example
matches
a
with
the
first
character
in
the
string
on
the
right
and
b
with
the
rest
a
is
assigned
s
and
b
is
assigned
pam
this
provides
a
simpler
alternative
to
assigning
the
results
of
manual
slicing
operations
multiple
target
assignments
the
sixth
line
in
table
shows
the
multiple
target
form
of
assignment
in
this
form
python
assigns
a
reference
to
the
same
object
the
object
farthest
to
the
right
to
all
the
targets
on
the
left
in
the
table
the
names
spam
and
ham
are
both
assigned
references
to
the
same
string
object
lunch
the
effect
is
the
same
as
if
we
had
coded
ham
lunch
followed
by
spam
ham
as
ham
evaluates
to
the
original
string
object
i
e
not
a
separate
copy
of
that
object
augmented
assignments
the
last
line
in
table
is
an
example
of
augmented
assignment
a
shorthand
that
combines
an
expression
and
an
assignment
in
a
concise
way
saying
spam
for
example
has
the
same
effect
as
spam
spam
but
the
augmented
form
requires
less
typing
and
is
generally
quicker
to
run
in
addition
if
the
subject
is
mutable
and
supports
the
operation
an
augmented
assignment
may
run
even
quicker
by
choosing
an
in
place
update
operation
instead
of
an
object
copy
there
is
one
augmented
assignment
statement
for
every
binary
expression
operator
in
python
sequence
assignments
we
ve
already
used
basic
assignments
in
this
book
here
are
a
few
simple
examples
of
sequence
unpacking
assignments
in
action
python
nudge
wink
a
b
nudge
wink
a
b
c
d
nudge
wink
c
d
tuple
assignment
like
a
nudge
b
wink
list
assignment
notice
that
we
really
are
coding
two
tuples
in
the
third
line
in
this
interaction
we
ve
just
omitted
their
enclosing
parentheses
python
pairs
the
values
in
the
tuple
on
the
right
side
of
the
assignment
operator
with
the
variables
in
the
tuple
on
the
left
side
and
assigns
the
values
one
at
a
time
tuple
assignment
leads
to
a
common
coding
trick
in
python
that
was
introduced
in
a
solution
to
the
exercises
at
the
end
of
part
ii
because
python
creates
a
temporary
tuple
that
saves
the
original
values
of
the
variables
on
the
right
while
the
statement
runs
assignment
statements
unpacking
assignments
are
also
a
way
to
swap
two
variables
values
without
creating
a
temporary
variable
of
your
own
the
tuple
on
the
right
remembers
the
prior
values
of
the
variables
automatically
nudge
wink
nudge
wink
wink
nudge
nudge
wink
tuples
swaps
values
like
t
nudge
nudge
wink
wink
t
in
fact
the
original
tuple
and
list
assignment
forms
in
python
have
been
generalized
to
accept
any
type
of
sequence
on
the
right
as
long
as
it
is
of
the
same
length
as
the
sequence
on
the
left
you
can
assign
a
tuple
of
values
to
a
list
of
variables
a
string
of
characters
to
a
tuple
of
variables
and
so
on
in
all
cases
python
assigns
items
in
the
sequence
on
the
right
to
variables
in
the
sequence
on
the
left
by
position
from
left
to
right
a
b
c
a
c
a
b
c
abc
a
c
a
c
assign
tuple
of
values
to
list
of
names
assign
string
of
characters
to
tuple
technically
speaking
sequence
assignment
actually
supports
any
iterable
object
on
the
right
not
just
any
sequence
this
is
a
more
general
concept
that
we
will
explore
in
chapters
and
advanced
sequence
assignment
patterns
although
we
can
mix
and
match
sequence
types
around
the
symbol
we
must
have
the
same
number
of
items
on
the
right
as
we
have
variables
on
the
left
or
we
ll
get
an
error
python
allows
us
to
be
more
general
with
extended
unpacking
syntax
described
in
the
next
section
but
normally
and
always
in
python
x
the
number
of
items
in
the
assignment
target
and
subject
must
match
string
spam
a
b
c
d
string
a
d
s
m
a
b
c
string
error
text
omitted
valueerror
too
many
values
to
unpack
same
number
on
both
sides
error
if
not
to
be
more
general
we
can
slice
there
are
a
variety
of
ways
to
employ
slicing
to
make
this
last
case
work
a
b
c
string
string
string
a
b
c
s
p
am
index
and
slice
a
b
c
list
string
string
a
b
c
slice
and
concatenate
chapter
assignments
expressions
and
prints
s
p
am
a
b
string
c
string
a
b
c
s
p
am
same
but
simpler
a
b
c
string
string
a
b
c
s
p
am
nested
sequences
as
the
last
example
in
this
interaction
demonstrates
we
can
even
assign
nested
sequences
and
python
unpacks
their
parts
according
to
their
shape
as
expected
in
this
case
we
are
assigning
a
tuple
of
two
items
where
the
first
item
is
a
nested
sequence
a
string
exactly
as
though
we
had
coded
it
this
way
paired
by
shape
and
position
a
b
c
sp
am
a
b
c
s
p
am
python
pairs
the
first
string
on
the
right
sp
with
the
first
tuple
on
the
left
a
b
and
assigns
one
character
at
a
time
before
assigning
the
entire
second
string
am
to
the
variable
c
all
at
once
in
this
event
the
sequence
nesting
shape
of
the
object
on
the
left
must
match
that
of
the
object
on
the
right
nested
sequence
assignment
like
this
is
somewhat
advanced
and
rare
to
see
but
it
can
be
convenient
for
picking
out
the
parts
of
data
structures
with
known
shapes
for
example
we
ll
see
in
chapter
that
this
technique
also
works
in
for
loops
because
loop
items
are
assigned
to
the
target
given
in
the
loop
header
for
a
b
c
in
simple
tuple
assignment
for
a
b
c
in
nested
tuple
assignment
in
a
note
in
chapter
we
ll
also
see
that
this
nested
tuple
really
sequence
unpacking
assignment
form
works
for
function
argument
lists
in
python
though
not
in
because
function
arguments
are
passed
by
assignment
as
well
def
f
a
b
c
f
for
arguments
too
in
python
but
not
sequence
unpacking
assignments
also
give
rise
to
another
common
coding
idiom
in
python
assigning
an
integer
series
to
a
set
of
variables
red
green
blue
range
red
blue
this
initializes
the
three
names
to
the
integer
codes
and
respectively
it
s
python
s
equivalent
of
the
enumerated
data
types
you
may
have
seen
in
other
languages
to
make
sense
of
this
you
need
to
know
that
the
range
built
in
function
generates
a
list
of
successive
integers
assignment
statements
range
use
list
range
in
python
because
range
is
commonly
used
in
for
loops
we
ll
say
more
about
it
in
chapter
another
place
you
may
see
a
tuple
assignment
at
work
is
for
splitting
a
sequence
into
its
front
and
the
rest
in
loops
like
this
l
while
l
front
l
l
l
print
front
l
see
next
section
for
alternative
the
tuple
assignment
in
the
loop
here
could
be
coded
as
the
following
two
lines
instead
but
it
s
often
more
convenient
to
string
them
together
front
l
l
l
notice
that
this
code
is
using
the
list
as
a
sort
of
stack
data
structure
which
can
often
also
be
achieved
with
the
append
and
pop
methods
of
list
objects
here
front
l
pop
would
have
much
the
same
effect
as
the
tuple
assignment
statement
but
it
would
be
an
in
place
change
we
ll
learn
more
about
while
loops
and
other
often
better
ways
to
step
through
a
sequence
with
for
loops
in
chapter
extended
sequence
unpacking
in
python
the
prior
section
demonstrated
how
to
use
manual
slicing
to
make
sequence
assignments
more
general
in
python
but
not
sequence
assignment
has
been
generalized
to
make
this
easier
in
short
a
single
starred
name
x
can
be
used
in
the
assignment
target
in
order
to
specify
a
more
general
matching
against
the
sequence
the
starred
name
is
assigned
a
list
which
collects
all
items
in
the
sequence
not
assigned
to
other
names
this
is
especially
handy
for
common
coding
patterns
such
as
splitting
a
sequence
into
its
front
and
rest
as
in
the
preceding
section
s
last
example
extended
unpacking
in
action
let
s
look
at
an
example
as
we
ve
seen
sequence
assignments
normally
require
exactly
as
many
names
in
the
target
on
the
left
as
there
are
items
in
the
subject
on
the
right
we
get
an
error
if
the
lengths
disagree
unless
we
manually
sliced
on
the
right
as
shown
in
the
prior
section
c
misc
c
python
python
seq
a
b
c
d
seq
print
a
b
c
d
chapter
assignments
expressions
and
prints
a
b
seq
valueerror
too
many
values
to
unpack
in
python
though
we
can
use
a
single
starred
name
in
the
target
to
match
more
generally
in
the
following
continuation
of
our
interactive
session
a
matches
the
first
item
in
the
sequence
and
b
matches
the
rest
a
b
seq
a
b
when
a
starred
name
is
used
the
number
of
items
in
the
target
on
the
left
need
not
match
the
length
of
the
subject
sequence
in
fact
the
starred
name
can
appear
anywhere
in
the
target
for
instance
in
the
next
interaction
b
matches
the
last
item
in
the
sequence
and
a
matches
everything
before
the
last
a
b
seq
a
b
when
the
starred
name
appears
in
the
middle
it
collects
everything
between
the
other
names
listed
thus
in
the
following
interaction
a
and
c
are
assigned
the
first
and
last
items
and
b
gets
everything
in
between
them
a
b
c
seq
a
b
c
more
generally
wherever
the
starred
name
shows
up
it
will
be
assigned
a
list
that
collects
every
unassigned
name
at
that
position
a
b
c
seq
a
b
c
naturally
like
normal
sequence
assignment
extended
sequence
unpacking
syntax
works
for
any
sequence
types
not
just
lists
here
it
is
unpacking
characters
in
a
string
a
b
spam
a
b
s
p
a
m
a
b
c
spam
assignment
statements
a
b
c
s
p
a
m
this
is
similar
in
spirit
to
slicing
but
not
exactly
the
same
a
sequence
unpacking
assignment
always
returns
a
list
for
multiple
matched
items
whereas
slicing
returns
a
sequence
of
the
same
type
as
the
object
sliced
s
spam
s
s
s
pam
slices
are
type
specific
assignment
always
returns
a
list
s
s
s
s
pa
m
given
this
extension
in
as
long
as
we
re
processing
a
list
the
last
example
of
the
prior
section
becomes
even
simpler
since
we
don
t
have
to
manually
slice
to
get
the
first
and
rest
of
the
items
l
while
l
front
l
l
print
front
l
get
first
rest
without
slicing
boundary
cases
although
extended
sequence
unpacking
is
flexible
some
boundary
cases
are
worth
noting
first
the
starred
name
may
match
just
a
single
item
but
is
always
assigned
a
list
seq
a
b
c
d
seq
print
a
b
c
d
second
if
there
is
nothing
left
to
match
the
starred
name
it
is
assigned
an
empty
list
regardless
of
where
it
appears
in
the
following
a
b
c
and
d
have
matched
every
item
in
the
sequence
but
python
assigns
e
an
empty
list
instead
of
treating
this
as
an
error
case
a
b
c
d
e
seq
print
a
b
c
d
e
a
b
e
c
d
seq
print
a
b
c
d
e
chapter
assignments
expressions
and
prints
finally
errors
can
still
be
triggered
if
there
is
more
than
one
starred
name
if
there
are
too
few
values
and
no
star
as
before
and
if
the
starred
name
is
not
itself
coded
inside
a
sequence
a
b
c
d
seq
syntaxerror
two
starred
expressions
in
assignment
a
b
seq
valueerror
too
many
values
to
unpack
a
seq
syntaxerror
starred
assignment
target
must
be
in
a
list
or
tuple
a
seq
a
a
useful
convenience
keep
in
mind
that
extended
sequence
unpacking
assignment
is
just
a
convenience
we
can
usually
achieve
the
same
effects
with
explicit
indexing
and
slicing
and
in
fact
must
in
python
x
but
extended
unpacking
is
simpler
to
code
the
common
first
rest
splitting
coding
pattern
for
example
can
be
coded
either
way
but
slicing
involves
extra
work
seq
a
b
seq
a
b
first
rest
a
b
seq
seq
a
b
first
rest
traditional
the
also
common
rest
last
splitting
pattern
can
similarly
be
coded
either
way
but
the
new
extended
unpacking
syntax
requires
noticeably
fewer
keystrokes
a
b
seq
a
b
rest
last
a
b
seq
seq
a
b
rest
last
traditional
because
it
is
not
only
simpler
but
arguably
more
natural
extended
sequence
unpacking
syntax
will
likely
become
widespread
in
python
code
over
time
assignment
statements
application
to
for
loops
because
the
loop
variable
in
the
for
loop
statement
can
be
any
assignment
target
extended
sequence
assignment
works
here
too
we
met
the
for
loop
iteration
tool
briefly
in
part
ii
and
will
study
it
formally
in
chapter
in
python
extended
assignments
may
show
up
after
the
word
for
where
a
simple
variable
name
is
more
commonly
used
for
a
b
c
in
when
used
in
this
context
on
each
iteration
python
simply
assigns
the
next
tuple
of
values
to
the
tuple
of
names
on
the
first
loop
for
example
it
s
as
if
we
d
run
the
following
assignment
statement
a
b
c
b
gets
the
names
a
b
and
c
can
be
used
within
the
loop
s
code
to
reference
the
extracted
components
in
fact
this
is
really
not
a
special
case
at
all
but
just
an
instance
of
general
assignment
at
work
as
we
saw
earlier
in
this
chapter
we
can
do
the
same
thing
with
simple
tuple
assignment
in
both
python
x
and
x
for
a
b
c
in
a
b
c
and
we
can
always
emulate
s
extended
assignment
behavior
in
by
manually
slicing
for
all
in
a
b
c
all
all
all
since
we
haven
t
learned
enough
to
get
more
detailed
about
the
syntax
of
for
loops
we
ll
return
to
this
topic
in
chapter
multiple
target
assignments
a
multiple
target
assignment
simply
assigns
all
the
given
names
to
the
object
all
the
way
to
the
right
the
following
for
example
assigns
the
three
variables
a
b
and
c
to
the
string
spam
a
b
c
spam
a
b
c
spam
spam
spam
this
form
is
equivalent
to
but
easier
to
code
than
these
three
assignments
c
spam
b
c
a
b
multiple
target
assignment
and
shared
references
keep
in
mind
that
there
is
just
one
object
here
shared
by
all
three
variables
they
all
wind
up
pointing
to
the
same
object
in
memory
this
behavior
is
fine
for
immutable
types
for
example
when
initializing
a
set
of
counters
to
zero
recall
that
variables
chapter
assignments
expressions
and
prints
must
be
assigned
before
they
can
be
used
in
python
so
you
must
initialize
counters
to
zero
before
you
can
start
adding
to
them
a
b
b
b
a
b
here
changing
b
only
changes
b
because
numbers
do
not
support
in
place
changes
as
long
as
the
object
assigned
is
immutable
it
s
irrelevant
if
more
than
one
name
references
it
as
usual
though
we
have
to
be
more
cautious
when
initializing
variables
to
an
empty
mutable
object
such
as
a
list
or
dictionary
a
b
b
append
a
b
this
time
because
a
and
b
reference
the
same
object
appending
to
it
in
place
through
b
will
impact
what
we
see
through
a
as
well
this
is
really
just
another
example
of
the
shared
reference
phenomenon
we
first
met
in
chapter
to
avoid
the
issue
initialize
mutable
objects
in
separate
statements
instead
so
that
each
creates
a
distinct
empty
object
by
running
a
distinct
literal
expression
a
b
b
append
a
b
augmented
assignments
beginning
with
python
the
set
of
additional
assignment
statement
formats
listed
in
table
became
available
known
as
augmented
assignments
and
borrowed
from
the
c
language
these
formats
are
mostly
just
shorthand
they
imply
the
combination
of
a
binary
expression
and
an
assignment
for
instance
the
following
two
formats
are
now
roughly
equivalent
traditional
form
newer
augmented
form
x
x
y
x
y
table
augmented
assignment
statements
x
y
x
y
x
y
x
y
x
y
x
y
x
y
x
y
x
y
x
y
x
y
x
y
augmented
assignment
works
on
any
type
that
supports
the
implied
binary
expression
for
example
here
are
two
ways
to
add
to
a
name
assignment
statements
x
x
x
x
x
x
traditional
augmented
when
applied
to
a
string
the
augmented
form
performs
concatenation
instead
thus
the
second
line
here
is
equivalent
to
typing
the
longer
s
s
spam
s
spam
s
spam
s
spamspam
implied
concatenation
as
shown
in
table
there
are
analogous
augmented
assignment
forms
for
every
python
binary
expression
operator
i
e
each
operator
with
values
on
the
left
and
right
side
for
instance
x
y
multiplies
and
assigns
x
y
shifts
right
and
assigns
and
so
on
x
y
for
floor
division
was
added
in
version
augmented
assignments
have
three
advantages
there
s
less
for
you
to
type
need
i
say
more
the
left
side
only
has
to
be
evaluated
once
in
x
y
x
may
be
a
complicated
object
expression
in
the
augmented
form
it
only
has
to
be
evaluated
once
however
in
the
long
form
x
x
y
x
appears
twice
and
must
be
run
twice
because
of
this
augmented
assignments
usually
run
faster
the
optimal
technique
is
automatically
chosen
that
is
for
objects
that
support
in
place
changes
the
augmented
forms
automatically
perform
in
place
change
operations
instead
of
slower
copies
the
last
point
here
requires
a
bit
more
explanation
for
augmented
assignments
inplace
operations
may
be
applied
for
mutable
objects
as
an
optimization
recall
that
lists
can
be
extended
in
a
variety
of
ways
to
add
a
single
item
to
the
end
of
a
list
we
can
concatenate
or
call
append
l
l
l
l
l
append
l
concatenate
slower
faster
but
in
place
c
c
programmers
take
note
although
python
now
supports
statements
like
x
y
it
still
does
not
have
c
s
auto
increment
decrement
operators
e
g
x
x
these
don
t
quite
map
to
the
python
object
model
because
python
has
no
notion
of
in
place
changes
to
immutable
objects
like
numbers
chapter
assignments
expressions
and
prints
and
to
add
a
set
of
items
to
the
end
we
can
either
concatenate
again
or
call
the
list
extend
method
l
l
l
l
extend
l
concatenate
slower
faster
but
in
place
in
both
cases
concatenation
is
less
prone
to
the
side
effects
of
shared
object
references
but
will
generally
run
slower
than
the
in
place
equivalent
concatenation
operations
must
create
a
new
object
copy
in
the
list
on
the
left
and
then
copy
in
the
list
on
the
right
by
contrast
in
place
method
calls
simply
add
items
at
the
end
of
a
memory
block
when
we
use
augmented
assignment
to
extend
a
list
we
can
forget
these
details
for
example
python
automatically
calls
the
quicker
extend
method
instead
of
using
the
slower
concatenation
operation
implied
by
l
mapped
to
l
extend
l
augmented
assignment
and
shared
references
this
behavior
is
usually
what
we
want
but
notice
that
it
implies
that
the
is
an
inplace
change
for
lists
thus
it
is
not
exactly
like
concatenation
which
always
makes
a
new
object
as
for
all
shared
reference
cases
this
difference
might
matter
if
other
names
reference
the
object
being
changed
l
m
l
l
l
l
m
l
m
l
l
l
m
l
and
m
reference
the
same
object
concatenation
makes
a
new
object
changes
l
but
not
m
but
really
means
extend
m
sees
the
in
place
change
too
this
only
matters
for
mutables
like
lists
and
dictionaries
and
it
is
a
fairly
obscure
case
at
least
until
it
impacts
your
code
as
always
make
copies
of
your
mutable
objects
if
you
need
to
break
the
shared
reference
structure
as
suggested
in
chapter
we
can
also
use
slice
assignment
e
g
l
len
l
but
this
works
roughly
the
same
as
the
simpler
list
extend
method
assignment
statements
variable
name
rules
now
that
we
ve
explored
assignment
statements
it
s
time
to
get
more
formal
about
the
use
of
variable
names
in
python
names
come
into
existence
when
you
assign
values
to
them
but
there
are
a
few
rules
to
follow
when
picking
names
for
things
in
your
programs
syntax
underscore
or
letter
any
number
of
letters
digits
or
underscores
variable
names
must
start
with
an
underscore
or
letter
which
can
be
followed
by
any
number
of
letters
digits
or
underscores
spam
spam
and
spam
are
legal
names
but
spam
spam
and
are
not
case
matters
spam
is
not
the
same
as
spam
python
always
pays
attention
to
case
in
programs
both
in
names
you
create
and
in
reserved
words
for
instance
the
names
x
and
x
refer
to
two
different
variables
for
portability
case
also
matters
in
the
names
of
imported
module
files
even
on
platforms
where
the
filesystems
are
case
insensitive
reserved
words
are
off
limits
names
you
define
cannot
be
the
same
as
words
that
mean
special
things
in
the
python
language
for
instance
if
you
try
to
use
a
variable
name
like
class
python
will
raise
a
syntax
error
but
klass
and
class
work
fine
table
lists
the
words
that
are
currently
reserved
and
hence
off
limits
for
names
of
your
own
in
python
table
python
reserved
words
false
class
finally
is
return
none
continue
for
lambda
try
true
def
from
nonlocal
while
and
del
global
not
with
as
elif
if
or
yield
assert
else
import
pass
break
except
in
raise
table
is
specific
to
python
in
python
the
set
of
reserved
words
differs
slightly
print
is
a
reserved
word
because
printing
is
a
statement
not
a
built
in
more
on
this
later
in
this
chapter
exec
is
a
reserved
word
because
it
is
a
statement
not
a
built
in
function
nonlocal
is
not
a
reserved
word
because
this
statement
is
not
available
in
older
pythons
the
story
is
also
more
or
less
the
same
with
a
few
variations
chapter
assignments
expressions
and
prints
with
and
as
were
not
reserved
until
when
context
managers
were
officially
enabled
yield
was
not
reserved
until
python
when
generator
functions
were
enabled
yield
morphed
from
statement
to
expression
in
but
it
s
still
a
reserved
word
not
a
built
in
function
as
you
can
see
most
of
python
s
reserved
words
are
all
lowercase
they
are
also
all
truly
reserved
unlike
names
in
the
built
in
scope
that
you
will
meet
in
the
next
part
of
this
book
you
cannot
redefine
reserved
words
by
assignment
e
g
and
results
in
a
syntax
error
besides
being
of
mixed
case
the
first
three
entries
in
table
true
false
and
none
are
somewhat
unusual
in
meaning
they
also
appear
in
the
built
in
scope
of
python
described
in
chapter
and
they
are
technically
names
assigned
to
objects
they
are
truly
reserved
in
all
other
senses
though
and
cannot
be
used
for
any
other
purpose
in
your
script
other
than
that
of
the
objects
they
represent
all
the
other
reserved
words
are
hardwired
into
python
s
syntax
and
can
appear
only
in
the
specific
contexts
for
which
they
are
intended
furthermore
because
module
names
in
import
statements
become
variables
in
your
scripts
variable
name
constraints
extend
to
your
module
filenames
too
for
instance
you
can
code
files
called
and
py
and
my
code
py
and
run
them
as
top
level
scripts
but
you
cannot
import
them
their
names
without
the
py
extension
become
variables
in
your
code
and
so
must
follow
all
the
variable
rules
just
outlined
reserved
words
are
off
limits
and
dashes
won
t
work
though
underscores
will
we
ll
revisit
this
idea
in
part
v
of
this
book
python
s
deprecation
protocol
it
is
interesting
to
note
how
reserved
word
changes
are
gradually
phased
into
the
language
when
a
new
feature
might
break
existing
code
python
normally
makes
it
an
option
and
begins
issuing
deprecation
warnings
one
or
more
releases
before
the
feature
is
officially
enabled
the
idea
is
that
you
should
have
ample
time
to
notice
the
warnings
and
update
your
code
before
migrating
to
the
new
release
this
is
not
true
for
major
new
releases
like
which
breaks
existing
code
freely
but
it
is
generally
true
in
other
cases
for
example
yield
was
an
optional
extension
in
python
but
is
a
standard
keyword
as
of
it
is
used
in
conjunction
with
generator
functions
this
was
one
of
a
small
handful
of
instances
where
python
broke
with
backward
compatibility
still
yield
was
phased
in
over
time
it
began
generating
deprecation
warnings
in
and
was
not
enabled
until
in
the
jython
java
based
implementation
of
python
though
user
defined
variable
names
can
sometimes
be
the
same
as
python
reserved
words
see
chapter
for
an
overview
of
the
jython
system
assignment
statements
similarly
in
python
the
words
with
and
as
become
new
reserved
words
for
use
in
context
managers
a
newer
form
of
exception
handling
these
two
words
are
not
reserved
in
unless
the
context
manager
feature
is
turned
on
manually
with
a
from
future
import
discussed
later
in
this
book
when
used
in
with
and
as
generate
warnings
about
the
upcoming
change
except
in
the
version
of
idle
in
python
which
appears
to
have
enabled
this
feature
for
you
that
is
using
these
words
as
variable
names
does
generate
errors
in
but
only
in
its
version
of
the
idle
gui
naming
conventions
besides
these
rules
there
is
also
a
set
of
naming
conventions
rules
that
are
not
required
but
are
followed
in
normal
practice
for
instance
because
names
with
two
leading
and
trailing
underscores
e
g
name
generally
have
special
meaning
to
the
python
interpreter
you
should
avoid
this
pattern
for
your
own
names
here
is
a
list
of
the
conventions
python
follows
names
that
begin
with
a
single
underscore
x
are
not
imported
by
a
from
module
import
statement
described
in
chapter
names
that
have
two
leading
and
trailing
underscores
x
are
system
defined
names
that
have
special
meaning
to
the
interpreter
names
that
begin
with
two
underscores
and
do
not
end
with
two
more
x
are
localized
mangled
to
enclosing
classes
see
the
discussion
of
pseudoprivate
attributes
in
chapter
the
name
that
is
just
a
single
underscore
retains
the
result
of
the
last
expression
when
working
interactively
in
addition
to
these
python
interpreter
conventions
there
are
various
other
conventions
that
python
programmers
usually
follow
for
instance
later
in
the
book
we
ll
see
that
class
names
commonly
start
with
an
uppercase
letter
and
module
names
with
a
lowercase
letter
and
that
the
name
self
though
not
reserved
usually
has
a
special
role
in
classes
in
chapter
we
ll
also
study
another
larger
category
of
names
known
as
the
built
ins
which
are
predefined
but
not
reserved
and
so
can
be
reassigned
open
works
though
sometimes
you
might
wish
it
didn
t
names
have
no
type
but
objects
do
this
is
mostly
review
but
remember
that
it
s
crucial
to
keep
python
s
distinction
between
names
and
objects
clear
as
described
in
chapter
objects
have
a
type
e
g
integer
list
and
may
be
mutable
or
not
names
a
k
a
variables
on
the
other
hand
are
always
just
references
to
objects
they
have
no
notion
of
mutability
and
have
no
associated
type
information
apart
from
the
type
of
the
object
they
happen
to
reference
at
a
given
point
in
time
chapter
assignments
expressions
and
prints
thus
it
s
ok
to
assign
the
same
name
to
different
kinds
of
objects
at
different
times
x
x
hello
x
x
bound
to
an
integer
object
now
it
s
a
string
and
now
it
s
a
list
in
later
examples
you
ll
see
that
this
generic
nature
of
names
can
be
a
decided
advantage
in
python
programming
in
chapter
you
ll
also
learn
that
names
also
live
in
something
called
a
scope
which
defines
where
they
can
be
used
the
place
where
you
assign
a
name
determines
where
it
is
visible
for
additional
naming
suggestions
see
the
previous
section
naming
conventions
of
python
s
semi
official
style
guide
known
as
pep
this
guide
is
available
at
http
www
python
org
dev
peps
pep
or
via
a
web
search
for
python
pep
technically
this
document
formalizes
coding
standards
for
python
library
code
though
useful
the
usual
caveats
about
coding
standards
apply
here
for
one
thing
pep
comes
with
more
detail
than
you
are
probably
ready
for
at
this
point
in
the
book
and
frankly
it
has
become
more
complex
rigid
and
subjective
than
it
needs
to
be
some
of
its
suggestions
are
not
at
all
universally
accepted
or
followed
by
python
programmers
doing
real
work
moreover
some
of
the
most
prominent
companies
using
python
today
have
adopted
coding
standards
of
their
own
that
differ
pep
does
codify
useful
rule
of
thumb
python
knowledge
though
and
it
s
a
great
read
for
python
beginners
as
long
as
you
take
its
recommendations
as
guidelines
not
gospel
expression
statements
in
python
you
can
use
an
expression
as
a
statement
too
that
is
on
a
line
by
itself
but
because
the
result
of
the
expression
won
t
be
saved
it
usually
makes
sense
to
do
so
only
if
the
expression
does
something
useful
as
a
side
effect
expressions
are
commonly
used
as
statements
in
two
situations
for
calls
to
functions
and
methods
some
functions
and
methods
do
lots
of
work
without
returning
a
value
such
functions
are
sometimes
called
procedures
in
other
languages
because
they
don
t
return
values
that
you
might
be
interested
in
retaining
you
can
call
these
functions
with
expression
statements
if
you
ve
used
a
more
restrictive
language
like
c
you
may
be
interested
to
know
that
there
is
no
notion
of
c
s
const
declaration
in
python
certain
objects
may
be
immutable
but
names
can
always
be
assigned
python
also
has
ways
to
hide
names
in
classes
and
modules
but
they
re
not
the
same
as
c
s
declarations
if
hiding
attributes
matters
to
you
see
the
coverage
of
x
module
names
in
chapter
x
class
names
in
chapter
and
the
private
and
public
class
decorators
example
in
chapter
expression
statements
for
printing
values
at
the
interactive
prompt
python
echoes
back
the
results
of
expressions
typed
at
the
interactive
command
line
technically
these
are
expression
statements
too
they
serve
as
a
shorthand
for
typing
print
statements
table
lists
some
common
expression
statement
forms
in
python
calls
to
functions
and
methods
are
coded
with
zero
or
more
argument
objects
really
expressions
that
evaluate
to
objects
in
parentheses
after
the
function
method
name
table
common
python
expression
statements
operation
interpretation
spam
eggs
ham
function
calls
spam
ham
eggs
method
calls
spam
printing
variables
in
the
interactive
interpreter
print
a
b
c
sep
printing
operations
in
python
yield
x
yielding
expression
statements
the
last
two
entries
in
table
are
somewhat
special
cases
as
we
ll
see
later
in
this
chapter
printing
in
python
is
a
function
call
usually
coded
on
a
line
by
itself
and
the
yield
operation
in
generator
functions
discussed
in
chapter
is
often
coded
as
a
statement
as
well
both
are
really
just
instances
of
expression
statements
for
instance
though
you
normally
run
a
print
call
on
a
line
by
itself
as
an
expression
statement
it
returns
a
value
like
any
other
function
call
its
return
value
is
none
the
default
return
value
for
functions
that
don
t
return
anything
meaningful
x
print
spam
spam
print
x
none
print
is
a
function
call
expression
in
but
it
is
coded
as
an
expression
statement
also
keep
in
mind
that
although
expressions
can
appear
as
statements
in
python
statements
cannot
be
used
as
expressions
for
example
python
doesn
t
allow
you
to
embed
assignment
statements
in
other
expressions
the
rationale
for
this
is
that
it
avoids
common
coding
mistakes
you
can
t
accidentally
change
a
variable
by
typing
when
you
really
mean
to
use
the
equality
test
you
ll
see
how
to
code
around
this
when
you
meet
the
python
while
loop
in
chapter
expression
statements
and
in
place
changes
this
brings
up
a
mistake
that
is
common
in
python
work
expression
statements
are
often
used
to
run
list
methods
that
change
a
list
in
place
l
l
append
l
append
is
an
in
place
change
chapter
assignments
expressions
and
prints
however
it
s
not
unusual
for
python
newcomers
to
code
such
an
operation
as
an
assignment
statement
instead
intending
to
assign
l
to
the
larger
list
l
l
append
print
l
none
but
append
returns
none
not
l
so
we
lose
our
list
this
doesn
t
quite
work
though
calling
an
in
place
change
operation
such
as
append
sort
or
reverse
on
a
list
always
changes
the
list
in
place
but
these
methods
do
not
return
the
list
they
have
changed
instead
they
return
the
none
object
thus
if
you
assign
such
an
operation
s
result
back
to
the
variable
name
you
effectively
lose
the
list
and
it
is
probably
garbage
collected
in
the
process
the
moral
of
the
story
is
don
t
do
this
we
ll
revisit
this
phenomenon
in
the
section
common
coding
gotchas
on
page
at
the
end
of
this
part
of
the
book
because
it
can
also
appear
in
the
context
of
some
looping
statements
we
ll
meet
in
later
chapters
print
operations
in
python
print
prints
things
it
s
simply
a
programmer
friendly
interface
to
the
standard
output
stream
technically
printing
converts
one
or
more
objects
to
their
textual
representations
adds
some
minor
formatting
and
sends
the
resulting
text
to
either
standard
output
or
another
file
like
stream
in
a
bit
more
detail
print
is
strongly
bound
up
with
the
notions
of
files
and
streams
in
python
file
object
methods
in
chapter
we
learned
about
file
object
methods
that
write
text
e
g
file
write
str
printing
operations
are
similar
but
more
focused
whereas
file
write
methods
write
strings
to
arbitrary
files
print
writes
objects
to
the
stdout
stream
by
default
with
some
automatic
formatting
added
unlike
with
file
methods
there
is
no
need
to
convert
objects
to
strings
when
using
print
operations
standard
output
stream
the
standard
output
stream
often
known
as
stdout
is
simply
a
default
place
to
send
a
program
s
text
output
along
with
the
standard
input
and
error
streams
it
s
one
of
three
data
connections
created
when
your
script
starts
the
standard
output
stream
is
usually
mapped
to
the
window
where
you
started
your
python
program
unless
it
s
been
redirected
to
a
file
or
pipe
in
your
operating
system
s
shell
because
the
standard
output
stream
is
available
in
python
as
the
stdout
file
object
in
the
built
in
sys
module
i
e
sys
stdout
it
s
possible
to
emulate
print
with
file
write
method
calls
however
print
is
noticeably
easier
to
use
and
makes
it
easy
to
print
text
to
other
files
and
streams
print
operations
printing
is
also
one
of
the
most
visible
places
where
python
and
have
diverged
in
fact
this
divergence
is
usually
the
first
reason
that
most
x
code
won
t
run
unchanged
under
x
specifically
the
way
you
code
print
operations
depends
on
which
version
of
python
you
use
in
python
x
printing
is
a
built
in
function
with
keyword
arguments
for
special
modes
in
python
x
printing
is
a
statement
with
specific
syntax
all
its
own
because
this
book
covers
both
and
we
will
look
at
each
form
in
turn
here
if
you
are
fortunate
enough
to
be
able
to
work
with
code
written
for
just
one
version
of
python
feel
free
to
pick
the
section
that
is
relevant
to
you
however
as
your
circumstances
may
change
it
probably
won
t
hurt
to
be
familiar
with
both
cases
the
python
print
function
strictly
speaking
printing
is
not
a
separate
statement
form
in
instead
it
is
simply
an
instance
of
the
expression
statement
we
studied
in
the
preceding
section
the
print
built
in
function
is
normally
called
on
a
line
of
its
own
because
it
doesn
t
return
any
value
we
care
about
technically
it
returns
none
because
it
is
a
normal
function
though
printing
in
uses
standard
function
call
syntax
rather
than
a
special
statement
form
because
it
provides
special
operation
modes
with
keyword
arguments
this
form
is
both
more
general
and
supports
future
enhancements
better
by
comparison
python
print
statements
have
somewhat
ad
hoc
syntax
to
support
extensions
such
as
end
of
line
suppression
and
target
files
further
the
statement
does
not
support
separator
specification
at
all
in
you
wind
up
building
strings
ahead
of
time
more
often
than
you
do
in
call
format
syntactically
calls
to
the
print
function
have
the
following
form
print
object
sep
end
n
file
sys
stdout
in
this
formal
notation
items
in
square
brackets
are
optional
and
may
be
omitted
in
a
given
call
and
values
after
give
argument
defaults
in
english
this
built
in
function
prints
the
textual
representation
of
one
or
more
objects
separated
by
the
string
sep
and
followed
by
the
string
end
to
the
stream
file
the
sep
end
and
file
parts
if
present
must
be
given
as
keyword
arguments
that
is
you
must
use
a
special
name
value
syntax
to
pass
the
arguments
by
name
instead
of
position
keyword
arguments
are
covered
in
depth
in
chapter
but
they
re
straightforward
to
use
the
keyword
arguments
sent
to
this
call
may
appear
in
any
left
to
right
order
following
the
objects
to
be
printed
and
they
control
the
print
operation
chapter
assignments
expressions
and
prints
sep
is
a
string
inserted
between
each
object
s
text
which
defaults
to
a
single
space
if
not
passed
passing
an
empty
string
suppresses
separators
altogether
end
is
a
string
added
at
the
end
of
the
printed
text
which
defaults
to
a
n
newline
character
if
not
passed
passing
an
empty
string
avoids
dropping
down
to
the
next
output
line
at
the
end
of
the
printed
text
the
next
print
will
keep
adding
to
the
end
of
the
current
output
line
file
specifies
the
file
standard
stream
or
other
file
like
object
to
which
the
text
will
be
sent
it
defaults
to
the
sys
stdout
standard
output
stream
if
not
passed
any
object
with
a
file
like
write
string
method
may
be
passed
but
real
files
should
be
already
opened
for
output
the
textual
representation
of
each
object
to
be
printed
is
obtained
by
passing
the
object
to
the
str
built
in
call
as
we
ve
seen
this
built
in
returns
a
user
friendly
display
string
for
any
object
with
no
arguments
at
all
the
print
function
simply
prints
a
newline
character
to
the
standard
output
stream
which
usually
displays
a
blank
line
the
print
function
in
action
printing
in
is
probably
simpler
than
some
of
its
details
may
imply
to
illustrate
let
s
run
some
quick
examples
the
following
prints
a
variety
of
object
types
to
the
default
standard
output
stream
with
the
default
separator
and
end
of
line
formatting
added
these
are
the
defaults
because
they
are
the
most
common
use
case
c
misc
c
python
python
print
x
spam
y
z
eggs
print
x
y
z
spam
eggs
display
a
blank
line
print
objects
per
defaults
there
s
no
need
to
convert
objects
to
strings
here
as
would
be
required
for
file
write
methods
by
default
print
calls
add
a
space
between
the
objects
printed
to
suppress
this
send
an
empty
string
to
the
sep
keyword
argument
or
send
an
alternative
separator
of
your
choosing
print
x
y
z
sep
spam
eggs
print
x
y
z
sep
spam
eggs
suppress
separator
custom
separator
technically
printing
uses
the
equivalent
of
str
in
the
internal
implementation
of
python
but
the
effect
is
the
same
besides
this
to
string
conversion
role
str
is
also
the
name
of
the
string
data
type
and
can
be
used
to
decode
unicode
strings
from
raw
bytes
with
an
extra
encoding
argument
as
we
ll
learn
in
chapter
this
latter
role
is
an
advanced
usage
that
we
can
safely
ignore
here
print
operations
also
by
default
print
adds
an
end
of
line
character
to
terminate
the
output
line
you
can
suppress
this
and
avoid
the
line
break
altogether
by
passing
an
empty
string
to
the
end
keyword
argument
or
you
can
pass
a
different
terminator
of
your
own
include
a
n
character
to
break
the
line
manually
print
x
y
z
end
spam
eggs
print
x
y
z
end
print
x
y
z
spam
eggs
spam
eggs
print
x
y
z
end
n
spam
eggs
suppress
line
break
two
prints
same
output
line
custom
line
end
you
can
also
combine
keyword
arguments
to
specify
both
separators
and
end
of
line
strings
they
may
appear
in
any
order
but
must
appear
after
all
the
objects
being
printed
print
x
y
z
sep
end
n
spam
eggs
print
x
y
z
end
n
sep
spam
eggs
multiple
keywords
order
doesn
t
matter
here
is
how
the
file
keyword
argument
is
used
it
directs
the
printed
text
to
an
open
output
file
or
other
compatible
object
for
the
duration
of
the
single
print
this
is
really
a
form
of
stream
redirection
a
topic
we
will
revisit
later
in
this
section
print
x
y
z
sep
file
open
data
txt
w
print
x
y
z
spam
eggs
print
open
data
txt
read
spam
eggs
print
to
a
file
back
to
stdout
display
file
text
finally
keep
in
mind
that
the
separator
and
end
of
line
options
provided
by
print
operations
are
just
conveniences
if
you
need
to
display
more
specific
formatting
don
t
print
this
way
instead
build
up
a
more
complex
string
ahead
of
time
or
within
the
print
itself
using
the
string
tools
we
met
in
chapter
and
print
the
string
all
at
once
text
s
f
d
result
print
text
result
print
s
f
d
result
result
as
we
ll
see
in
the
next
section
almost
everything
we
ve
just
seen
about
the
print
function
also
applies
directly
to
print
statements
which
makes
sense
given
that
the
function
was
intended
to
both
emulate
and
improve
upon
printing
support
the
python
print
statement
as
mentioned
earlier
printing
in
python
uses
a
statement
with
unique
and
specific
syntax
rather
than
a
built
in
function
in
practice
though
printing
is
mostly
a
variation
on
a
theme
with
the
exception
of
separator
strings
which
are
supported
in
chapter
assignments
expressions
and
prints
but
not
everything
we
can
do
with
the
print
function
has
a
direct
translation
to
the
print
statement
statement
forms
table
lists
the
print
statement
s
forms
in
python
and
gives
their
python
print
function
equivalents
for
reference
notice
that
the
comma
is
significant
in
print
statements
it
separates
objects
to
be
printed
and
a
trailing
comma
suppresses
the
end
of
line
character
normally
added
at
the
end
of
the
printed
text
not
to
be
confused
with
tuple
syntax
the
syntax
normally
used
as
a
bitwise
right
shift
operation
is
used
here
as
well
to
specify
a
target
output
stream
other
than
the
sys
stdout
default
table
python
print
statement
forms
python
statement
python
equivalent
interpretation
print
x
y
print
x
y
print
objects
textual
forms
to
sys
stdout
add
a
space
between
the
items
and
an
end
of
line
at
the
end
print
x
y
print
x
y
end
same
but
don
t
add
end
of
line
at
end
of
text
print
afile
x
y
print
x
y
file
afile
send
text
to
myfile
write
not
to
sys
stdout
write
the
print
statement
in
action
although
the
print
statement
has
more
unique
syntax
than
the
function
it
s
similarly
easy
to
use
let
s
turn
to
some
basic
examples
again
by
default
the
print
statement
adds
a
space
between
the
items
separated
by
commas
and
adds
a
line
break
at
the
end
of
the
current
output
line
c
misc
c
python
python
x
a
y
b
print
x
y
a
b
this
formatting
is
just
a
default
you
can
choose
to
use
it
or
not
to
suppress
the
line
break
so
you
can
add
more
text
to
the
current
line
later
end
your
print
statement
with
a
comma
as
shown
in
the
second
line
of
table
the
following
is
two
statements
on
one
line
separated
by
a
semicolon
print
x
y
print
x
y
a
b
a
b
print
operations
to
suppress
the
space
between
items
again
don
t
print
this
way
instead
build
up
an
output
string
using
the
string
concatenation
and
formatting
tools
covered
in
chapter
and
print
the
string
all
at
once
print
x
y
ab
print
s
s
x
y
a
b
as
you
can
see
apart
from
their
special
syntax
for
usage
modes
print
statements
are
roughly
as
simple
to
use
as
s
function
the
next
section
uncovers
the
way
that
files
are
specified
in
prints
print
stream
redirection
in
both
python
and
printing
sends
text
to
the
standard
output
stream
by
default
however
it
s
often
useful
to
send
it
elsewhere
to
a
text
file
for
example
to
save
results
for
later
use
or
testing
purposes
although
such
redirection
can
be
accomplished
in
system
shells
outside
python
itself
it
turns
out
to
be
just
as
easy
to
redirect
a
script
s
streams
from
within
the
script
the
python
hello
world
program
let
s
start
off
with
the
usual
and
largely
pointless
language
benchmark
the
hello
world
program
to
print
a
hello
world
message
in
python
simply
print
the
string
per
your
version
s
print
operation
print
hello
world
hello
world
print
a
string
object
in
print
hello
world
hello
world
print
a
string
object
in
because
expression
results
are
echoed
on
the
interactive
command
line
you
often
don
t
even
need
to
use
a
print
statement
there
simply
type
the
expressions
you
d
like
to
have
printed
and
their
results
are
echoed
back
hello
world
hello
world
interactive
echoes
this
code
isn
t
exactly
an
earth
shattering
piece
of
software
mastery
but
it
serves
to
illustrate
printing
behavior
really
the
print
operation
is
just
an
ergonomic
feature
of
python
it
provides
a
simple
interface
to
the
sys
stdout
object
with
a
bit
of
default
formatting
in
fact
if
you
enjoy
working
harder
than
you
must
you
can
also
code
print
operations
this
way
import
sys
sys
stdout
write
hello
world
n
hello
world
chapter
assignments
expressions
and
prints
printing
the
hard
way
this
code
explicitly
calls
the
write
method
of
sys
stdout
an
attribute
preset
when
python
starts
up
to
an
open
file
object
connected
to
the
output
stream
the
print
operation
hides
most
of
those
details
providing
a
simple
tool
for
simple
printing
tasks
manual
stream
redirection
so
why
did
i
just
show
you
the
hard
way
to
print
the
sys
stdout
print
equivalent
turns
out
to
be
the
basis
of
a
common
technique
in
python
in
general
print
and
sys
stdout
are
directly
related
as
follows
this
statement
print
x
y
or
in
print
x
y
is
equivalent
to
the
longer
import
sys
sys
stdout
write
str
x
str
y
n
which
manually
performs
a
string
conversion
with
str
adds
a
separator
and
newline
with
and
calls
the
output
stream
s
write
method
which
would
you
rather
code
he
says
hoping
to
underscore
the
programmer
friendly
nature
of
prints
obviously
the
long
form
isn
t
all
that
useful
for
printing
by
itself
however
it
is
useful
to
know
that
this
is
exactly
what
print
operations
do
because
it
is
possible
to
reassign
sys
stdout
to
something
different
from
the
standard
output
stream
in
other
words
this
equivalence
provides
a
way
of
making
your
print
operations
send
their
text
to
other
places
for
example
import
sys
sys
stdout
open
log
txt
a
print
x
y
x
redirects
prints
to
a
file
shows
up
in
log
txt
here
we
reset
sys
stdout
to
a
manually
opened
file
named
log
txt
located
in
the
script
s
working
directory
and
opened
in
append
mode
so
we
add
to
its
current
content
after
the
reset
every
print
operation
anywhere
in
the
program
will
write
its
text
to
the
end
of
the
file
log
txt
instead
of
to
the
original
output
stream
the
print
operations
are
happy
to
keep
calling
sys
stdout
s
write
method
no
matter
what
sys
stdout
happens
to
refer
to
because
there
is
just
one
sys
module
in
your
process
assigning
sys
stdout
this
way
will
redirect
every
print
anywhere
in
your
program
in
fact
as
this
chapter
s
upcoming
sidebar
about
print
and
stdout
will
explain
you
can
even
reset
sys
stdout
to
an
object
that
isn
t
a
file
at
all
as
long
as
it
has
the
expected
interface
a
method
named
write
to
receive
the
printed
text
string
argument
when
that
object
is
a
class
printed
text
can
be
routed
and
processed
arbitrarily
per
a
write
method
you
code
yourself
this
trick
of
resetting
the
output
stream
is
primarily
useful
for
programs
originally
coded
with
print
statements
if
you
know
that
output
should
go
to
a
file
to
begin
with
you
can
always
call
file
write
methods
instead
to
redirect
the
output
of
a
print
based
print
operations
program
though
resetting
sys
stdout
provides
a
convenient
alternative
to
changing
every
print
statement
or
using
system
shell
based
redirection
syntax
automatic
stream
redirection
this
technique
of
redirecting
printed
text
by
assigning
sys
stdout
is
commonly
used
in
practice
one
potential
problem
with
the
last
section
s
code
though
is
that
there
is
no
direct
way
to
restore
the
original
output
stream
should
you
need
to
switch
back
after
printing
to
a
file
because
sys
stdout
is
just
a
normal
file
object
you
can
always
save
it
and
restore
it
if
needed
c
misc
c
python
python
import
sys
temp
sys
stdout
sys
stdout
open
log
txt
a
print
spam
print
sys
stdout
close
sys
stdout
temp
print
back
here
back
here
print
open
log
txt
read
spam
save
for
restoring
later
redirect
prints
to
a
file
prints
go
to
file
not
here
flush
output
to
disk
restore
original
stream
prints
show
up
here
again
result
of
earlier
prints
as
you
can
see
though
manual
saving
and
restoring
of
the
original
output
stream
like
this
involves
quite
a
bit
of
extra
work
because
this
crops
up
fairly
often
a
print
extension
is
available
to
make
it
unnecessary
in
the
file
keyword
allows
a
single
print
call
to
send
its
text
to
a
file
s
write
method
without
actually
resetting
sys
stdout
because
the
redirection
is
temporary
normal
print
calls
keep
printing
to
the
original
output
stream
in
a
print
statement
that
begins
with
a
followed
by
an
output
file
object
or
other
compatible
object
has
the
same
effect
for
example
the
following
again
sends
printed
text
to
a
file
named
log
txt
log
open
log
txt
a
print
x
y
z
file
log
print
a
b
c
print
to
a
file
like
object
print
to
original
stdout
log
open
log
txt
a
print
log
x
y
z
print
a
b
c
print
to
a
file
like
object
print
to
original
stdout
these
redirected
forms
of
print
are
handy
if
you
need
to
print
to
both
files
and
the
standard
output
stream
in
the
same
program
if
you
use
these
forms
however
be
sure
in
both
and
you
may
also
be
able
to
use
the
stdout
attribute
in
the
sys
module
which
refers
to
the
original
value
sys
stdout
had
at
program
startup
time
you
still
need
to
restore
sys
stdout
to
sys
stdout
to
go
back
to
this
original
stream
value
though
see
the
sys
module
documentation
for
more
details
chapter
assignments
expressions
and
prints
to
give
them
a
file
object
or
an
object
that
has
the
same
write
method
as
a
file
object
not
a
file
s
name
string
here
is
the
technique
in
action
c
misc
c
python
python
log
open
log
txt
w
print
file
log
print
file
log
log
close
print
print
open
log
txt
read
print
log
print
these
extended
forms
of
print
are
also
commonly
used
to
print
error
messages
to
the
standard
error
stream
available
to
your
script
as
the
preopened
file
object
sys
stderr
you
can
either
use
its
file
write
methods
and
format
the
output
manually
or
print
with
redirection
syntax
import
sys
sys
stderr
write
bad
n
bad
bad
bad
bad
bad
bad
bad
bad
print
bad
file
sys
stderr
bad
bad
bad
bad
bad
bad
bad
bad
print
sys
stderr
bad
now
that
you
know
all
about
print
redirections
the
equivalence
between
printing
and
file
write
methods
should
be
fairly
obvious
the
following
interaction
prints
both
ways
in
then
redirects
the
output
to
an
external
file
to
verify
that
the
same
text
is
printed
x
y
print
x
y
b
b
open
temp
w
write
str
x
str
y
n
send
to
file
manually
print
the
easy
way
import
sys
sys
stdout
write
str
x
str
y
n
print
the
hard
way
print
x
y
file
open
temp
w
redirect
text
to
file
print
open
temp
rb
read
r
n
print
open
temp
rb
read
r
n
binary
mode
for
bytes
as
you
can
see
unless
you
happen
to
enjoy
typing
print
operations
are
usually
the
best
option
for
displaying
text
for
another
example
of
the
equivalence
between
prints
and
file
writes
watch
for
a
print
function
emulation
example
in
chapter
it
uses
this
code
pattern
to
provide
a
general
print
function
equivalent
for
use
in
python
print
operations
version
neutral
printing
finally
if
you
cannot
restrict
your
work
to
python
but
still
want
your
prints
to
be
compatible
with
you
have
some
options
for
one
you
can
code
print
statements
and
let
s
to
conversion
script
translate
them
to
function
calls
automatically
see
the
python
documentation
for
more
details
about
this
script
it
attempts
to
translate
x
code
to
run
under
alternatively
you
can
code
print
function
calls
in
your
code
by
enabling
the
function
call
variant
with
a
statement
like
the
following
from
future
import
print
function
this
statement
changes
to
support
s
print
functions
exactly
this
way
you
can
use
print
features
and
won
t
have
to
change
your
prints
if
you
later
migrate
to
also
keep
in
mind
that
simple
prints
like
those
in
the
first
row
of
table
work
in
either
version
of
python
because
any
expression
may
be
enclosed
in
parentheses
we
can
always
pretend
to
be
calling
a
print
function
in
by
adding
outer
parentheses
the
only
downside
to
this
is
that
it
makes
a
tuple
out
of
your
printed
objects
if
there
are
more
than
one
they
will
print
with
extra
enclosing
parentheses
in
for
example
any
number
of
objects
may
be
listed
in
the
call
s
parentheses
c
misc
c
python
python
print
spam
spam
print
spam
ham
eggs
spam
ham
eggs
print
function
call
syntax
these
are
mutiple
argments
the
first
of
these
works
the
same
in
but
the
second
generates
a
tuple
in
the
output
c
misc
c
python
python
print
spam
spam
print
spam
ham
eggs
spam
ham
eggs
print
statement
enclosing
parens
this
is
really
a
tuple
object
to
be
truly
portable
you
can
format
the
print
string
as
a
single
object
using
the
string
formatting
expression
or
method
call
or
other
string
tools
that
we
studied
in
chapter
print
s
s
s
spam
ham
eggs
spam
ham
eggs
print
format
spam
ham
eggs
spam
ham
eggs
of
course
if
you
can
use
exclusively
you
can
forget
such
mappings
entirely
but
many
python
programmers
will
at
least
encounter
if
not
write
x
code
and
systems
for
some
time
to
come
chapter
assignments
expressions
and
prints
i
use
python
print
function
calls
throughout
this
book
i
ll
usually
warn
you
that
the
results
may
have
extra
enclosing
parentheses
in
because
multiple
items
are
a
tuple
but
i
sometimes
don
t
so
please
consider
this
note
a
blanket
warning
if
you
see
extra
parentheses
in
your
printed
text
in
either
drop
the
parentheses
in
your
print
statements
recode
your
prints
using
the
version
neutral
scheme
outlined
here
or
learn
to
love
superfluous
text
why
you
will
care
print
and
stdout
the
equivalence
between
the
print
operation
and
writing
to
sys
stdout
is
important
it
makes
it
possible
to
reassign
sys
stdout
to
any
user
defined
object
that
provides
the
same
write
method
as
files
because
the
print
statement
just
sends
text
to
the
sys
stdout
write
method
you
can
capture
printed
text
in
your
programs
by
assigning
sys
stdout
to
an
object
whose
write
method
processes
the
text
in
arbitrary
ways
for
instance
you
can
send
printed
text
to
a
gui
window
or
tee
it
off
to
multiple
destinations
by
defining
an
object
with
a
write
method
that
does
the
required
routing
you
ll
see
an
example
of
this
trick
when
we
study
classes
in
part
vi
of
this
book
but
abstractly
it
looks
like
this
class
filefaker
def
write
self
string
do
something
with
printed
text
in
string
import
sys
sys
stdout
filefaker
print
someobjects
sends
to
class
write
method
this
works
because
print
is
what
we
will
call
in
the
next
part
of
this
book
a
polymorphic
operation
it
doesn
t
care
what
sys
stdout
is
only
that
it
has
a
method
i
e
interface
called
write
this
redirection
to
objects
is
made
even
simpler
with
the
file
keyword
argument
in
and
the
extended
form
of
print
in
because
we
don
t
need
to
reset
sys
stdout
explicitly
normal
prints
will
still
be
routed
to
the
stdout
stream
myobj
filefaker
redirect
to
object
for
one
print
print
someobjects
file
myobj
does
not
reset
sys
stdout
myobj
filefaker
print
myobj
someobjects
same
effect
does
not
reset
sys
stdout
python
s
built
in
input
function
reads
from
the
sys
stdin
file
so
you
can
intercept
read
requests
in
a
similar
way
using
classes
that
implement
file
like
read
methods
instead
see
the
input
and
while
loop
example
in
chapter
for
more
background
on
this
notice
that
because
printed
text
goes
to
the
stdout
stream
it
s
the
way
to
print
html
in
cgi
scripts
used
on
the
web
it
also
enables
you
to
redirect
python
script
input
and
output
at
the
operating
system
s
shell
command
line
as
usual
print
operations
python
script
py
inputfile
outputfile
python
script
py
filterprogram
python
s
print
operation
redirection
tools
are
essentially
pure
python
alternatives
to
these
shell
syntax
forms
chapter
summary
in
this
chapter
we
began
our
in
depth
look
at
python
statements
by
exploring
assignments
expressions
and
print
operations
although
these
are
generally
simple
to
use
they
have
some
alternative
forms
that
while
optional
are
often
convenient
in
practice
augmented
assignment
statements
and
the
redirection
form
of
print
operations
for
example
allow
us
to
avoid
some
manual
coding
work
along
the
way
we
also
studied
the
syntax
of
variable
names
stream
redirection
techniques
and
a
variety
of
common
mistakes
to
avoid
such
as
assigning
the
result
of
an
append
method
call
back
to
a
variable
in
the
next
chapter
we
ll
continue
our
statement
tour
by
filling
in
details
about
the
if
statement
python
s
main
selection
tool
there
we
ll
also
revisit
python
s
syntax
model
in
more
depth
and
look
at
the
behavior
of
boolean
expressions
before
we
move
on
though
the
end
of
chapter
quiz
will
test
your
knowledge
of
what
you
ve
learned
here
test
your
knowledge
quiz
name
three
ways
that
you
can
assign
three
variables
to
the
same
value
why
might
you
need
to
care
when
assigning
three
variables
to
a
mutable
object
what
s
wrong
with
saying
l
l
sort
how
might
you
use
the
print
operation
to
send
text
to
an
external
file
test
your
knowledge
answers
you
can
use
multiple
target
assignments
a
b
c
sequence
assignment
a
b
c
or
multiple
assignment
statements
on
three
separate
lines
a
b
and
c
with
the
latter
technique
as
introduced
in
chapter
you
can
also
string
the
three
separate
statements
together
on
the
same
line
by
separating
them
with
semicolons
a
b
c
chapter
assignments
expressions
and
prints
if
you
assign
them
this
way
a
b
c
all
three
names
reference
the
same
object
so
changing
it
in
place
from
one
e
g
a
append
will
affect
the
others
this
is
true
only
for
in
place
changes
to
mu
table
objects
like
lists
and
dictionaries
for
immutable
objects
such
as
numbers
and
strings
this
issue
is
irrelevant
the
list
sort
method
is
like
append
in
that
it
makes
an
in
place
change
to
the
subject
list
it
returns
none
not
the
list
it
changes
the
assignment
back
to
l
sets
l
to
none
not
to
the
sorted
list
as
we
ll
see
later
in
this
part
of
the
book
a
newer
builtin
function
sorted
sorts
any
sequence
and
returns
a
new
list
with
the
sorting
result
because
this
is
not
an
in
place
change
its
result
can
be
meaningfully
assigned
to
a
name
to
print
to
a
file
for
a
single
print
operation
you
can
use
s
print
x
file
f
call
form
use
s
extended
print
file
x
statement
form
or
assign
sys
stdout
to
a
manually
opened
file
before
the
print
and
restore
the
original
after
you
can
also
redirect
all
of
a
program
s
printed
text
to
a
file
with
special
syntax
in
the
system
shell
but
this
is
outside
python
s
scope
test
your
knowledge
answers
chapter
if
tests
and
syntax
rules
this
chapter
presents
the
python
if
statement
which
is
the
main
statement
used
for
selecting
from
alternative
actions
based
on
test
results
because
this
is
our
first
in
depth
look
at
compound
statements
statements
that
embed
other
statements
we
will
also
explore
the
general
concepts
behind
the
python
statement
syntax
model
here
in
more
detail
than
we
did
in
the
introduction
in
chapter
because
the
if
statement
introduces
the
notion
of
tests
this
chapter
will
also
deal
with
boolean
expressions
and
fill
in
some
details
on
truth
tests
in
general
if
statements
in
simple
terms
the
python
if
statement
selects
actions
to
perform
it
s
the
primary
selection
tool
in
python
and
represents
much
of
the
logic
a
python
program
possesses
it
s
also
our
first
compound
statement
like
all
compound
python
statements
the
if
statement
may
contain
other
statements
including
other
ifs
in
fact
python
lets
you
combine
statements
in
a
program
sequentially
so
that
they
execute
one
after
another
and
in
an
arbitrarily
nested
fashion
so
that
they
execute
only
under
certain
conditions
general
format
the
python
if
statement
is
typical
of
if
statements
in
most
procedural
languages
it
takes
the
form
of
an
if
test
followed
by
one
or
more
optional
elif
else
if
tests
and
a
final
optional
else
block
the
tests
and
the
else
part
each
have
an
associated
block
of
nested
statements
indented
under
a
header
line
when
the
if
statement
runs
python
executes
the
block
of
code
associated
with
the
first
test
that
evaluates
to
true
or
the
else
block
if
all
tests
prove
false
the
general
form
of
an
if
statement
looks
like
this
if
test
statements
elif
test
statements
else
statements
if
test
associated
block
optional
elifs
optional
else
basic
examples
to
demonstrate
let
s
look
at
a
few
simple
examples
of
the
if
statement
at
work
all
parts
are
optional
except
the
initial
if
test
and
its
associated
statements
thus
in
the
simplest
case
the
other
parts
are
omitted
if
print
true
true
notice
how
the
prompt
changes
to
for
continuation
lines
when
typing
interactively
in
the
basic
interface
used
here
in
idle
you
ll
simply
drop
down
to
an
indented
line
instead
hit
backspace
to
back
up
a
blank
line
which
you
can
get
by
pressing
enter
twice
terminates
and
runs
the
entire
statement
remember
that
is
boolean
true
so
this
statement
s
test
always
succeeds
to
handle
a
false
result
code
the
else
if
not
print
true
else
print
false
false
multiway
branching
now
here
s
an
example
of
a
more
complex
if
statement
with
all
its
optional
parts
present
run
x
killer
rabbit
if
x
roger
print
how
s
jessica
elif
x
bugs
print
what
s
up
doc
else
print
run
away
run
away
away
run
away
this
multiline
statement
extends
from
the
if
line
through
the
else
block
when
it
s
run
python
executes
the
statements
nested
under
the
first
test
that
is
true
or
the
else
part
if
all
tests
are
false
in
this
example
they
are
in
practice
both
the
elif
and
else
parts
may
be
omitted
and
there
may
be
more
than
one
statement
nested
in
each
section
note
that
the
words
if
elif
and
else
are
associated
by
the
fact
that
they
line
up
vertically
with
the
same
indentation
if
you
ve
used
languages
like
c
or
pascal
you
might
be
interested
to
know
that
there
is
no
switch
or
case
statement
in
python
that
selects
an
action
based
on
a
variable
s
value
instead
multiway
branching
is
coded
either
as
a
series
of
if
elif
tests
as
in
the
prior
example
or
by
indexing
dictionaries
or
searching
lists
because
dictionaries
and
lists
can
be
built
at
runtime
they
re
sometimes
more
flexible
than
hardcoded
if
logic
chapter
if
tests
and
syntax
rules
choice
ham
print
spam
ham
eggs
bacon
a
dictionary
based
switch
use
has
key
or
get
for
default
choice
although
it
may
take
a
few
moments
for
this
to
sink
in
the
first
time
you
see
it
this
dictionary
is
a
multiway
branch
indexing
on
the
key
choice
branches
to
one
of
a
set
of
values
much
like
a
switch
in
c
an
almost
equivalent
but
more
verbose
python
if
statement
might
look
like
this
if
choice
spam
print
elif
choice
ham
print
elif
choice
eggs
print
elif
choice
bacon
print
else
print
bad
choice
notice
the
else
clause
on
the
if
here
to
handle
the
default
case
when
no
key
matches
as
we
saw
in
chapter
dictionary
defaults
can
be
coded
with
in
expressions
get
method
calls
or
exception
catching
all
of
the
same
techniques
can
be
used
here
to
code
a
default
action
in
a
dictionary
based
multiway
branch
here
s
the
get
scheme
at
work
with
defaults
branch
spam
ham
eggs
print
branch
get
spam
bad
choice
print
branch
get
bacon
bad
choice
bad
choice
an
in
membership
test
in
an
if
statement
can
have
the
same
default
effect
bad
choice
bacon
if
choice
in
branch
print
branch
choice
else
print
bad
choice
choice
dictionaries
are
good
for
associating
values
with
keys
but
what
about
the
more
complicated
actions
you
can
code
in
the
statement
blocks
associated
with
if
statements
in
part
iv
you
ll
learn
that
dictionaries
can
also
contain
functions
to
represent
more
complex
branch
actions
and
implement
general
jump
tables
such
functions
appear
as
if
statements
dictionary
values
may
be
coded
as
function
names
or
lambdas
and
are
called
by
adding
parentheses
to
trigger
their
actions
stay
tuned
for
more
on
this
topic
in
chapter
although
dictionary
based
multiway
branching
is
useful
in
programs
that
deal
with
more
dynamic
data
most
programmers
will
probably
find
that
coding
an
if
statement
is
the
most
straightforward
way
to
perform
multiway
branching
as
a
rule
of
thumb
in
coding
when
in
doubt
err
on
the
side
of
simplicity
and
readability
it
s
the
pythonic
way
python
syntax
rules
i
introduced
python
s
syntax
model
in
chapter
now
that
we
re
stepping
up
to
larger
statements
like
the
if
this
section
reviews
and
expands
on
the
syntax
ideas
introduced
earlier
in
general
python
has
a
simple
statement
based
syntax
however
there
are
a
few
properties
you
need
to
know
about
statements
execute
one
after
another
until
you
say
otherwise
python
normally
runs
statements
in
a
file
or
nested
block
in
order
from
first
to
last
but
statements
like
if
and
as
you
ll
see
loops
cause
the
interpreter
to
jump
around
in
your
code
because
python
s
path
through
a
program
is
called
the
control
flow
statements
such
as
if
that
affect
it
are
often
called
control
flow
statements
block
and
statement
boundaries
are
detected
automatically
as
we
ve
seen
there
are
no
braces
or
begin
end
delimiters
around
blocks
of
code
in
python
instead
python
uses
the
indentation
of
statements
under
a
header
to
group
the
statements
in
a
nested
block
similarly
python
statements
are
not
normally
terminated
with
semicolons
rather
the
end
of
a
line
usually
marks
the
end
of
the
statement
coded
on
that
line
compound
statements
header
indented
statements
all
compound
statements
in
python
follow
the
same
pattern
a
header
line
terminated
with
a
colon
followed
by
one
or
more
nested
statements
usually
indented
under
the
header
the
indented
statements
are
called
a
block
or
sometimes
a
suite
in
the
if
statement
the
elif
and
else
clauses
are
part
of
the
if
but
they
are
also
header
lines
with
nested
blocks
of
their
own
blank
lines
spaces
and
comments
are
usually
ignored
blank
lines
are
ignored
in
files
but
not
at
the
interactive
prompt
when
they
terminate
compound
statements
spaces
inside
statements
and
expressions
are
almost
always
ignored
except
in
string
literals
and
when
used
for
indentation
comments
are
always
ignored
they
start
with
a
character
not
inside
a
string
literal
and
extend
to
the
end
of
the
current
line
docstrings
are
ignored
but
are
saved
and
displayed
by
tools
python
supports
an
additional
comment
form
called
documentation
strings
docstrings
for
short
which
unlike
comments
are
retained
at
runtime
for
inspection
docstrings
are
simply
strings
that
show
up
at
the
top
of
program
files
and
some
statements
python
chapter
if
tests
and
syntax
rules
ignores
their
contents
but
they
are
automatically
attached
to
objects
at
runtime
and
may
be
displayed
with
documentation
tools
docstrings
are
part
of
python
s
larger
documentation
strategy
and
are
covered
in
the
last
chapter
in
this
part
of
the
book
as
you
ve
seen
there
are
no
variable
type
declarations
in
python
this
fact
alone
makes
for
a
much
simpler
language
syntax
than
what
you
may
be
used
to
however
for
most
new
users
the
lack
of
the
braces
and
semicolons
used
to
mark
blocks
and
statements
in
many
other
languages
seems
to
be
the
most
novel
syntactic
feature
of
python
so
let
s
explore
what
this
means
in
more
detail
block
delimiters
indentation
rules
python
detects
block
boundaries
automatically
by
line
indentation
that
is
the
empty
space
to
the
left
of
your
code
all
statements
indented
the
same
distance
to
the
right
belong
to
the
same
block
of
code
in
other
words
the
statements
within
a
block
line
up
vertically
as
in
a
column
the
block
ends
when
the
end
of
the
file
or
a
lesser
indented
line
is
encountered
and
more
deeply
nested
blocks
are
simply
indented
further
to
the
right
than
the
statements
in
the
enclosing
block
for
instance
figure
demonstrates
the
block
structure
of
the
following
code
x
if
x
y
if
y
print
block
print
block
print
block
figure
nested
blocks
of
code
a
nested
block
starts
with
a
statement
indented
further
to
the
right
and
ends
with
either
a
statement
that
is
indented
less
or
the
end
of
the
file
python
syntax
rules
this
code
contains
three
blocks
the
first
the
top
level
code
of
the
file
is
not
indented
at
all
the
second
within
the
outer
if
statement
is
indented
four
spaces
and
the
third
the
print
statement
under
the
nested
if
is
indented
eight
spaces
in
general
top
level
unnested
code
must
start
in
column
nested
blocks
can
start
in
any
column
indentation
may
consist
of
any
number
of
spaces
and
tabs
as
long
as
it
s
the
same
for
all
the
statements
in
a
given
single
block
that
is
python
doesn
t
care
how
you
indent
your
code
it
only
cares
that
it
s
done
consistently
four
spaces
or
one
tab
per
indentation
level
are
common
conventions
but
there
is
no
absolute
standard
in
the
python
world
indenting
code
is
quite
natural
in
practice
for
example
the
following
arguably
silly
code
snippet
demonstrates
common
indentation
errors
in
python
code
x
spam
if
rubbery
in
shrubbery
print
x
x
ni
if
x
endswith
ni
x
print
x
error
first
line
indented
error
unexpected
indentation
error
inconsistent
indentation
the
properly
indented
version
of
this
code
looks
like
the
following
even
for
an
artificial
example
like
this
proper
indentation
makes
the
code
s
intent
much
more
apparent
x
spam
if
rubbery
in
shrubbery
print
x
x
ni
if
x
endswith
ni
x
print
x
prints
spamnispamni
it
s
important
to
know
that
the
only
major
place
in
python
where
whitespace
matters
is
where
it
s
used
to
the
left
of
your
code
for
indentation
in
most
other
contexts
space
can
be
coded
or
not
however
indentation
is
really
part
of
python
syntax
not
just
a
stylistic
suggestion
all
the
statements
within
any
given
single
block
must
be
indented
to
the
same
level
or
python
reports
a
syntax
error
this
is
intentional
because
you
don
t
need
to
explicitly
mark
the
start
and
end
of
a
nested
block
of
code
some
of
the
syntactic
clutter
found
in
other
languages
is
unnecessary
in
python
as
described
in
chapter
making
indentation
part
of
the
syntax
model
also
enforces
consistency
a
crucial
component
of
readability
in
structured
programming
languages
like
python
python
s
syntax
is
sometimes
described
as
what
you
see
is
what
you
get
the
indentation
of
each
line
of
code
unambiguously
tells
readers
what
it
is
associated
with
this
uniform
and
consistent
appearance
makes
python
code
easier
to
maintain
and
reuse
chapter
if
tests
and
syntax
rules
indentation
is
more
natural
than
the
details
might
imply
and
it
makes
your
code
reflect
its
logical
structure
consistently
indented
code
always
satisfies
python
s
rules
moreover
most
text
editors
including
idle
make
it
easy
to
follow
python
s
indentation
model
by
automatically
indenting
code
as
you
type
it
avoid
mixing
tabs
and
spaces
new
error
checking
in
one
rule
of
thumb
although
you
can
use
spaces
or
tabs
to
indent
it
s
usually
not
a
good
idea
to
mix
the
two
within
a
block
use
one
or
the
other
technically
tabs
count
for
enough
spaces
to
move
the
current
column
number
up
to
a
multiple
of
and
your
code
will
work
if
you
mix
tabs
and
spaces
consistently
however
such
code
can
be
difficult
to
change
worse
mixing
tabs
and
spaces
makes
your
code
difficult
to
read
tabs
may
look
very
different
in
the
next
programmer
s
editor
than
they
do
in
yours
in
fact
python
now
issues
an
error
for
these
very
reasons
when
a
script
mixes
tabs
and
spaces
for
indentation
inconsistently
within
a
block
that
is
in
a
way
that
makes
it
dependent
on
a
tab
s
equivalent
in
spaces
python
allows
such
scripts
to
run
but
it
has
a
t
command
line
flag
that
will
warn
you
about
inconsistent
tab
usage
and
a
tt
flag
that
will
issue
errors
for
such
code
you
can
use
these
switches
in
a
command
line
like
python
t
main
py
in
a
system
shell
window
python
s
error
case
is
equivalent
to
s
tt
switch
statement
delimiters
lines
and
continuations
a
statement
in
python
normally
ends
at
the
end
of
the
line
on
which
it
appears
when
a
statement
is
too
long
to
fit
on
a
single
line
though
a
few
special
rules
may
be
used
to
make
it
span
multiple
lines
statements
may
span
multiple
lines
if
you
re
continuing
an
open
syntactic
pair
python
lets
you
continue
typing
a
statement
on
the
next
line
if
you
re
coding
something
enclosed
in
a
or
pair
for
instance
expressions
in
parentheses
and
dictionary
and
list
literals
can
span
any
number
of
lines
your
statement
doesn
t
end
until
the
python
interpreter
reaches
the
line
on
which
you
type
the
closing
part
of
the
pair
a
or
continuation
lines
lines
and
beyond
of
the
statement
can
start
at
any
indentation
level
you
like
but
you
should
try
to
make
them
align
vertically
for
readability
if
possible
this
open
pairs
rule
also
covers
set
and
dictionary
comprehensions
in
python
statements
may
span
multiple
lines
if
they
end
in
a
backslash
this
is
a
somewhat
outdated
feature
but
if
a
statement
needs
to
span
multiple
lines
you
can
also
add
a
backslash
a
not
embedded
in
a
string
literal
or
comment
at
the
end
of
the
prior
line
to
indicate
you
re
continuing
on
the
next
line
because
you
can
also
continue
by
adding
parentheses
around
most
constructs
backslashes
are
almost
never
used
this
approach
is
error
prone
accidentally
forgetting
a
usually
generates
a
syntax
error
and
might
even
cause
the
next
line
to
be
silently
mistaken
to
be
a
new
statement
with
unexpected
results
python
syntax
rules
special
rules
for
string
literals
as
we
learned
in
chapter
triple
quoted
string
blocks
are
designed
to
span
multiple
lines
normally
we
also
learned
in
chapter
that
adjacent
string
literals
are
implicitly
concatenated
when
used
in
conjunction
with
the
open
pairs
rule
mentioned
earlier
wrapping
this
construct
in
parentheses
allows
it
to
span
multiple
lines
other
rules
there
are
a
few
other
points
to
mention
with
regard
to
statement
delimiters
although
uncommon
you
can
terminate
a
statement
with
a
semicolon
this
convention
is
sometimes
used
to
squeeze
more
than
one
simple
noncompound
statement
onto
a
single
line
also
comments
and
blank
lines
can
appear
anywhere
in
a
file
comments
which
begin
with
a
character
terminate
at
the
end
of
the
line
on
which
they
appear
a
few
special
cases
here
s
what
a
continuation
line
looks
like
using
the
open
syntactic
pairs
rule
delimited
constructs
such
as
lists
in
square
brackets
can
span
across
any
number
of
lines
l
good
bad
ugly
open
pairs
may
span
lines
this
also
works
for
anything
in
parentheses
expressions
function
arguments
function
headers
tuples
and
generator
expressions
as
well
as
anything
in
curly
braces
dictionaries
and
in
set
literals
and
set
and
dictionary
comprehensions
some
of
these
are
tools
we
ll
study
in
later
chapters
but
this
rule
naturally
covers
most
constructs
that
span
lines
in
practice
if
you
like
using
backslashes
to
continue
lines
you
can
but
it
s
not
common
practice
in
python
if
a
b
and
c
d
and
d
e
and
f
g
print
olde
backslashes
allow
continuations
because
any
expression
can
be
enclosed
in
parentheses
you
can
usually
use
the
open
pairs
technique
instead
if
you
need
your
code
to
span
multiple
lines
simply
wrap
a
part
of
your
statement
in
parentheses
if
a
b
and
c
d
and
d
e
and
e
f
print
new
but
parentheses
usually
do
too
in
fact
backslashes
are
frowned
on
because
they
re
too
easy
to
not
notice
and
too
easy
to
omit
altogether
in
the
following
x
is
assigned
with
the
backslash
as
intended
if
the
backslash
is
accidentally
omitted
though
x
is
assigned
instead
and
no
error
is
reported
the
is
a
valid
expression
statement
by
itself
chapter
if
tests
and
syntax
rules
in
a
real
program
with
a
more
complex
assignment
this
could
be
the
source
of
a
very
nasty
bug
x
omitting
the
makes
this
very
different
as
another
special
case
python
allows
you
to
write
more
than
one
noncompound
statement
i
e
statements
without
nested
statements
on
the
same
line
separated
by
semicolons
some
coders
use
this
form
to
save
program
file
real
estate
but
it
usually
makes
for
more
readable
code
if
you
stick
to
one
statement
per
line
for
most
of
your
work
x
y
print
x
more
than
one
simple
statement
as
we
learned
in
chapter
triple
quoted
string
literals
span
lines
too
in
addition
if
two
string
literals
appear
next
to
each
other
they
are
concatenated
as
if
a
had
been
added
between
them
when
used
in
conjunction
with
the
open
pairs
rule
wrapping
in
parentheses
allows
this
form
to
span
multiple
lines
for
example
the
first
of
the
following
inserts
newline
characters
at
line
breaks
and
assigns
s
to
naaaa
nbbbb
ncccc
and
the
second
implicitly
concatenates
and
assigns
s
to
aaaabbbbcccc
comments
are
ignored
in
the
second
form
but
included
in
the
string
in
the
first
s
aaaa
bbbb
cccc
s
aaaa
bbbb
cccc
comments
here
are
ignored
finally
python
lets
you
move
a
compound
statement
s
body
up
to
the
header
line
provided
the
body
is
just
a
simple
noncompound
statement
you
ll
most
often
see
this
used
for
simple
if
statements
with
a
single
test
and
action
if
print
hello
simple
statement
on
header
line
you
can
combine
some
of
these
special
cases
to
write
code
that
is
difficult
to
read
but
i
don
t
recommend
it
as
a
rule
of
thumb
try
to
keep
each
statement
on
a
line
of
its
own
and
indent
all
but
the
simplest
of
blocks
six
months
down
the
road
you
ll
be
happy
you
did
frankly
it
s
surprising
that
this
wasn
t
removed
in
python
given
some
of
its
other
changes
see
table
p
of
the
preface
for
a
list
of
removals
some
seem
fairly
innocuous
in
comparison
with
the
dangers
inherent
in
backslash
continuations
then
again
this
book
s
goal
is
python
instruction
not
populist
outrage
so
the
best
advice
i
can
give
is
simply
don
t
do
this
python
syntax
rules
truth
tests
the
notions
of
comparison
equality
and
truth
values
were
introduced
in
chapter
because
the
if
statement
is
the
first
statement
we
ve
looked
at
that
actually
uses
test
results
we
ll
expand
on
some
of
these
ideas
here
in
particular
python
s
boolean
operators
are
a
bit
different
from
their
counterparts
in
languages
like
c
in
python
any
nonzero
number
or
nonempty
object
is
true
zero
numbers
empty
objects
and
the
special
object
none
are
considered
false
comparisons
and
equality
tests
are
applied
recursively
to
data
structures
comparisons
and
equality
tests
return
true
or
false
custom
versions
of
and
boolean
and
and
or
operators
return
a
true
or
false
operand
object
in
short
boolean
operators
are
used
to
combine
the
results
of
other
tests
there
are
three
boolean
expression
operators
in
python
x
and
y
is
true
if
both
x
and
y
are
true
x
or
y
is
true
if
either
x
or
y
is
true
not
x
is
true
if
x
is
false
the
expression
returns
true
or
false
here
x
and
y
may
be
any
truth
value
or
any
expression
that
returns
a
truth
value
e
g
an
equality
test
range
comparison
and
so
on
boolean
operators
are
typed
out
as
words
in
python
instead
of
c
s
and
also
boolean
and
and
or
operators
return
a
true
or
false
object
in
python
not
the
values
true
or
false
let
s
look
at
a
few
examples
to
see
how
this
works
true
false
less
than
return
true
or
false
or
magnitude
comparisons
such
as
these
return
true
or
false
as
their
truth
results
which
as
we
learned
in
chapters
and
are
really
just
custom
versions
of
the
integers
and
they
print
themselves
differently
but
are
otherwise
the
same
on
the
other
hand
the
and
and
or
operators
always
return
an
object
either
the
object
on
the
left
side
of
the
operator
or
the
object
on
the
right
if
we
test
their
results
in
if
or
other
statements
they
will
be
as
expected
remember
every
object
is
inherently
true
or
false
but
we
won
t
get
back
a
simple
true
or
false
chapter
if
tests
and
syntax
rules
for
or
tests
python
evaluates
the
operand
objects
from
left
to
right
and
returns
the
first
one
that
is
true
moreover
python
stops
at
the
first
true
operand
it
finds
this
is
usually
called
short
circuit
evaluation
as
determining
a
result
short
circuits
terminates
the
rest
of
the
expression
or
or
or
return
left
operand
if
true
else
return
right
operand
true
or
false
or
in
the
first
line
of
the
preceding
example
both
operands
and
are
true
i
e
are
nonzero
so
python
always
stops
and
returns
the
one
on
the
left
in
the
other
two
tests
the
left
operand
is
false
an
empty
object
so
python
simply
evaluates
and
returns
the
object
on
the
right
which
may
happen
to
have
either
a
true
or
a
false
value
when
tested
and
operations
also
stop
as
soon
as
the
result
is
known
however
in
this
case
python
evaluates
the
operands
from
left
to
right
and
stops
at
the
first
false
object
and
and
and
return
left
operand
if
false
else
return
right
operand
true
or
false
and
here
both
operands
are
true
in
the
first
line
so
python
evaluates
both
sides
and
returns
the
object
on
the
right
in
the
second
test
the
left
operand
is
false
so
python
stops
and
returns
it
as
the
test
result
in
the
last
test
the
left
side
is
true
so
python
evaluates
and
returns
the
object
on
the
right
which
happens
to
be
a
false
the
end
result
of
all
this
is
the
same
as
in
c
and
most
other
languages
you
get
a
value
that
is
logically
true
or
false
if
tested
in
an
if
or
while
however
in
python
booleans
return
either
the
left
or
the
right
object
not
a
simple
integer
flag
this
behavior
of
and
and
or
may
seem
esoteric
at
first
glance
but
see
this
chapter
s
sidebar
why
you
will
care
booleans
on
page
for
examples
of
how
it
is
sometimes
used
to
advantage
in
coding
by
python
programmers
the
next
section
also
shows
a
common
way
to
leverage
this
behavior
and
its
replacement
in
more
recent
versions
of
python
the
if
else
ternary
expression
one
common
role
for
the
prior
section
s
boolean
operators
is
to
code
an
expression
that
runs
the
same
as
an
if
statement
consider
the
following
statement
which
sets
a
to
either
y
or
z
based
on
the
truth
value
of
x
the
if
else
ternary
expression
if
x
a
y
else
a
z
sometimes
though
the
items
involved
in
such
a
statement
are
so
simple
that
it
seems
like
overkill
to
spread
them
across
four
lines
at
other
times
we
may
want
to
nest
such
a
construct
in
a
larger
statement
instead
of
assigning
its
result
to
a
variable
for
these
reasons
and
frankly
because
the
c
language
has
a
similar
tool
python
introduced
a
new
expression
format
that
allows
us
to
say
the
same
thing
in
one
expression
a
y
if
x
else
z
this
expression
has
the
exact
same
effect
as
the
preceding
four
line
if
statement
but
it
s
simpler
to
code
as
in
the
statement
equivalent
python
runs
expression
y
only
if
x
turns
out
to
be
true
and
runs
expression
z
only
if
x
turns
out
to
be
false
that
is
it
short
circuits
just
like
the
boolean
operators
described
in
the
prior
section
here
are
some
examples
of
it
in
action
t
f
a
t
if
spam
else
f
a
nonempty
is
true
a
t
if
else
f
a
prior
to
python
and
after
if
you
insist
the
same
effect
can
often
be
achieved
by
a
careful
combination
of
the
and
and
or
operators
because
they
return
either
the
object
on
the
left
side
or
the
object
on
the
right
a
x
and
y
or
z
this
works
but
there
is
a
catch
you
have
to
be
able
to
assume
that
y
will
be
boolean
true
if
that
is
the
case
the
effect
is
the
same
the
and
runs
first
and
returns
y
if
x
is
true
if
it
s
not
the
or
simply
returns
z
in
other
words
we
get
if
x
then
y
else
z
this
and
or
combination
also
seems
to
require
a
moment
of
great
clarity
to
understand
the
first
time
you
see
it
and
it
s
no
longer
required
as
of
use
the
equivalent
and
more
robust
and
mnemonic
y
if
x
else
z
instead
if
you
need
this
as
an
expression
or
use
a
full
if
statement
if
the
parts
are
nontrivial
as
a
side
note
using
the
following
expression
in
python
is
similar
because
the
bool
function
will
translate
x
into
the
equivalent
of
integer
or
which
can
then
be
used
to
pick
true
and
false
values
from
a
list
a
z
y
bool
x
in
fact
python
s
x
if
y
else
z
has
a
slightly
different
order
than
c
s
y
x
z
this
was
reportedly
done
in
response
to
analysis
of
common
use
patterns
in
python
code
according
to
rumor
this
order
was
also
chosen
in
part
to
discourage
ex
c
programmers
from
overusing
it
remember
simple
is
better
than
complex
in
python
and
elsewhere
chapter
if
tests
and
syntax
rules
for
example
f
t
bool
f
f
t
bool
spam
t
however
this
isn
t
exactly
the
same
because
python
will
not
short
circuit
it
will
always
run
both
z
and
y
regardless
of
the
value
of
x
because
of
such
complexities
you
re
better
off
using
the
simpler
and
more
easily
understood
if
else
expression
as
of
python
and
later
again
though
you
should
use
even
that
sparingly
and
only
if
its
parts
are
all
fairly
simple
otherwise
you
re
better
off
coding
the
full
if
statement
form
to
make
changes
easier
in
the
future
your
coworkers
will
be
happy
you
did
still
you
may
see
the
and
or
version
in
code
written
prior
to
and
in
code
written
by
c
programmers
who
haven
t
quite
let
go
of
their
dark
coding
pasts
why
you
will
care
booleans
one
common
way
to
use
the
somewhat
unusual
behavior
of
python
boolean
operators
is
to
select
from
a
set
of
objects
with
an
or
a
statement
such
as
this
x
a
or
b
or
c
or
none
sets
x
to
the
first
nonempty
that
is
true
object
among
a
b
and
c
or
to
none
if
all
of
them
are
empty
this
works
because
the
or
operator
returns
one
of
its
two
objects
and
it
turns
out
to
be
a
fairly
common
coding
paradigm
in
python
to
select
a
nonempty
object
from
among
a
fixed
size
set
simply
string
them
together
in
an
or
expression
in
simpler
form
this
is
also
commonly
used
to
designate
a
default
the
following
sets
x
to
a
if
a
is
true
or
nonempty
and
to
default
otherwise
x
a
or
default
it
s
also
important
to
understand
short
circuit
evaluation
because
expressions
on
the
right
of
a
boolean
operator
might
call
functions
that
perform
substantial
or
important
work
or
have
side
effects
that
won
t
happen
if
the
short
circuit
rule
takes
effect
if
f
or
f
here
if
f
returns
a
true
or
nonempty
value
python
will
never
run
f
to
guarantee
that
both
functions
will
be
run
call
them
before
the
or
tmp
tmp
f
f
if
tmp
or
tmp
you
ve
already
seen
another
application
of
this
behavior
in
this
chapter
because
of
the
way
booleans
work
the
expression
a
and
b
or
c
can
be
used
to
emulate
an
if
else
statement
almost
see
this
chapter
s
discussion
of
this
form
for
details
we
met
additional
boolean
use
cases
in
prior
chapters
as
we
saw
in
chapter
because
all
objects
are
inherently
true
or
false
it
s
common
and
easier
in
python
to
test
an
object
directly
if
x
than
to
compare
it
to
an
empty
value
if
x
for
a
string
the
two
tests
are
equivalent
as
we
also
saw
in
chapter
the
preset
booleans
values
true
and
false
are
the
same
as
the
integers
and
and
are
useful
for
initializing
variables
the
if
else
ternary
expression
x
false
for
loop
tests
while
true
and
for
displaying
results
at
the
interactive
prompt
also
watch
for
the
discussion
of
operator
overloading
in
part
vi
when
we
define
new
object
types
with
classes
we
can
specify
their
boolean
nature
with
either
the
bool
or
len
methods
bool
is
named
nonzero
in
the
latter
of
these
is
tried
if
the
former
is
absent
and
designates
false
by
returning
a
length
of
zero
an
empty
object
is
considered
false
chapter
summary
in
this
chapter
we
studied
the
python
if
statement
additionally
because
this
was
our
first
compound
and
logical
statement
we
reviewed
python
s
general
syntax
rules
and
explored
the
operation
of
truth
tests
in
more
depth
than
we
were
able
to
previously
along
the
way
we
also
looked
at
how
to
code
multiway
branching
in
python
and
learned
about
the
if
else
expression
introduced
in
python
the
next
chapter
continues
our
look
at
procedural
statements
by
expanding
on
the
while
and
for
loops
there
we
ll
learn
about
alternative
ways
to
code
loops
in
python
some
of
which
may
be
better
than
others
before
that
though
here
is
the
usual
chapter
quiz
test
your
knowledge
quiz
how
might
you
code
a
multiway
branch
in
python
how
can
you
code
an
if
else
statement
as
an
expression
in
python
how
can
you
make
a
single
statement
span
many
lines
what
do
the
words
true
and
false
mean
test
your
knowledge
answers
an
if
statement
with
multiple
elif
clauses
is
often
the
most
straightforward
way
to
code
a
multiway
branch
though
not
necessarily
the
most
concise
dictionary
indexing
can
often
achieve
the
same
result
especially
if
the
dictionary
contains
callable
functions
coded
with
def
statements
or
lambda
expressions
in
python
and
later
the
expression
form
y
if
x
else
z
returns
y
if
x
is
true
or
z
otherwise
it
s
the
same
as
a
four
line
if
statement
the
and
or
combination
x
and
y
or
z
can
work
the
same
way
but
it
s
more
obscure
and
requires
that
the
y
part
be
true
chapter
if
tests
and
syntax
rules
wrap
up
the
statement
in
an
open
syntactic
pair
or
and
it
can
span
as
many
lines
as
you
like
the
statement
ends
when
python
sees
the
closing
right
half
of
the
pair
and
lines
and
beyond
of
the
statement
can
begin
at
any
indentation
level
true
and
false
are
just
custom
versions
of
the
integers
and
respectively
they
always
stand
for
boolean
true
and
false
values
in
python
they
re
available
for
use
in
truth
tests
and
variable
initialization
and
are
printed
for
expression
results
at
the
interactive
prompt
test
your
knowledge
answers
chapter
while
and
for
loops
this
chapter
concludes
our
tour
of
python
procedural
statements
by
presenting
the
language
s
two
main
looping
constructs
statements
that
repeat
an
action
over
and
over
the
first
of
these
the
while
statement
provides
a
way
to
code
general
loops
the
second
the
for
statement
is
designed
for
stepping
through
the
items
in
a
sequence
object
and
running
a
block
of
code
for
each
we
ve
seen
both
of
these
informally
already
but
we
ll
fill
in
additional
usage
details
here
while
we
re
at
it
we
ll
also
study
a
few
less
prominent
statements
used
within
loops
such
as
break
and
continue
and
cover
some
built
ins
commonly
used
with
loops
such
as
range
zip
and
map
although
the
while
and
for
statements
covered
here
are
the
primary
syntax
provided
for
coding
repeated
actions
there
are
additional
looping
operations
and
concepts
in
python
because
of
that
the
iteration
story
is
continued
in
the
next
chapter
where
we
ll
explore
the
related
ideas
of
python
s
iteration
protocol
used
by
the
for
loop
and
list
comprehensions
a
close
cousin
to
the
for
loop
later
chapters
explore
even
more
exotic
iteration
tools
such
as
generators
filter
and
reduce
for
now
though
let
s
keep
things
simple
while
loops
python
s
while
statement
is
the
most
general
iteration
construct
in
the
language
in
simple
terms
it
repeatedly
executes
a
block
of
normally
indented
statements
as
long
as
a
test
at
the
top
keeps
evaluating
to
a
true
value
it
is
called
a
loop
because
control
keeps
looping
back
to
the
start
of
the
statement
until
the
test
becomes
false
when
the
test
becomes
false
control
passes
to
the
statement
that
follows
the
while
block
the
net
effect
is
that
the
loop
s
body
is
executed
repeatedly
while
the
test
at
the
top
is
true
if
the
test
is
false
to
begin
with
the
body
never
runs
general
format
in
its
most
complex
form
the
while
statement
consists
of
a
header
line
with
a
test
expression
a
body
of
one
or
more
indented
statements
and
an
optional
else
part
that
is
executed
if
control
exits
the
loop
without
a
break
statement
being
encountered
python
keeps
evaluating
the
test
at
the
top
and
executing
the
statements
nested
in
the
loop
body
until
the
test
returns
a
false
value
while
test
statements
else
statements
loop
test
loop
body
optional
else
run
if
didn
t
exit
loop
with
break
examples
to
illustrate
let
s
look
at
a
few
simple
while
loops
in
action
the
first
which
consists
of
a
print
statement
nested
in
a
while
loop
just
prints
a
message
forever
recall
that
true
is
just
a
custom
version
of
the
integer
and
always
stands
for
a
boolean
true
value
because
the
test
is
always
true
python
keeps
executing
the
body
forever
or
until
you
stop
its
execution
this
sort
of
behavior
is
usually
called
an
infinite
loop
while
true
print
type
ctrl
c
to
stop
me
the
next
example
keeps
slicing
off
the
first
character
of
a
string
until
the
string
is
empty
and
hence
false
it
s
typical
to
test
an
object
directly
like
this
instead
of
using
the
more
verbose
equivalent
while
x
later
in
this
chapter
we
ll
see
other
ways
to
step
more
directly
through
the
items
in
a
string
with
a
for
loop
x
spam
while
x
print
x
end
x
x
spam
pam
am
m
while
x
is
not
empty
strip
first
character
off
x
note
the
end
keyword
argument
used
here
to
place
all
outputs
on
the
same
line
separated
by
a
space
see
chapter
if
you
ve
forgotten
why
this
works
as
it
does
the
following
code
counts
from
the
value
of
a
up
to
but
not
including
b
we
ll
see
an
easier
way
to
do
this
with
a
python
for
loop
and
the
built
in
range
function
later
a
b
while
a
b
print
a
end
a
one
way
to
code
counter
loops
or
a
a
finally
notice
that
python
doesn
t
have
what
some
languages
call
a
do
until
loop
statement
however
we
can
simulate
one
with
a
test
and
break
at
the
bottom
of
the
loop
body
chapter
while
and
for
loops
while
true
loop
body
if
exittest
break
to
fully
understand
how
this
structure
works
we
need
to
move
on
to
the
next
section
and
learn
more
about
the
break
statement
break
continue
pass
and
the
loop
else
now
that
we
ve
seen
a
few
python
loops
in
action
it
s
time
to
take
a
look
at
two
simple
statements
that
have
a
purpose
only
when
nested
inside
loops
the
break
and
continue
statements
while
we
re
looking
at
oddballs
we
will
also
study
the
loop
else
clause
here
because
it
is
intertwined
with
break
and
python
s
empty
placeholder
statement
the
pass
which
is
not
tied
to
loops
per
se
but
falls
into
the
general
category
of
simple
one
word
statements
in
python
break
jumps
out
of
the
closest
enclosing
loop
past
the
entire
loop
statement
continue
jumps
to
the
top
of
the
closest
enclosing
loop
to
the
loop
s
header
line
pass
does
nothing
at
all
it
s
an
empty
statement
placeholder
loop
else
block
runs
if
and
only
if
the
loop
is
exited
normally
i
e
without
hitting
a
break
general
loop
format
factoring
in
break
and
continue
statements
the
general
format
of
the
while
loop
looks
like
this
while
test
statements
if
test
break
if
test
continue
else
statements
exit
loop
now
skip
else
go
to
top
of
loop
now
to
test
run
if
we
didn
t
hit
a
break
break
and
continue
statements
can
appear
anywhere
inside
the
while
or
for
loop
s
body
but
they
are
usually
coded
further
nested
in
an
if
test
to
take
action
in
response
to
some
condition
let
s
turn
to
a
few
simple
examples
to
see
how
these
statements
come
together
in
practice
break
continue
pass
and
the
loop
else
pass
simple
things
first
the
pass
statement
is
a
no
operation
placeholder
that
is
used
when
the
syntax
requires
a
statement
but
you
have
nothing
useful
to
say
it
is
often
used
to
code
an
empty
body
for
a
compound
statement
for
instance
if
you
want
to
code
an
infinite
loop
that
does
nothing
each
time
through
do
it
with
a
pass
while
true
pass
type
ctrl
c
to
stop
me
because
the
body
is
just
an
empty
statement
python
gets
stuck
in
this
loop
pass
is
roughly
to
statements
as
none
is
to
objects
an
explicit
nothing
notice
that
here
the
while
loop
s
body
is
on
the
same
line
as
the
header
after
the
colon
as
with
if
statements
this
only
works
if
the
body
isn
t
a
compound
statement
this
example
does
nothing
forever
it
probably
isn
t
the
most
useful
python
program
ever
written
unless
you
want
to
warm
up
your
laptop
computer
on
a
cold
winter
s
day
frankly
though
i
couldn
t
think
of
a
better
pass
example
at
this
point
in
the
book
we
ll
see
other
places
where
pass
makes
more
sense
later
for
instance
to
ignore
exceptions
caught
by
try
statements
and
to
define
empty
class
objects
with
attributes
that
behave
like
structs
and
records
in
other
languages
a
pass
is
also
sometime
coded
to
mean
to
be
filled
in
later
to
stub
out
the
bodies
of
functions
temporarily
def
func
pass
add
real
code
here
later
def
func
pass
we
can
t
leave
the
body
empty
without
getting
a
syntax
error
so
we
say
pass
instead
version
skew
note
python
but
not
allows
ellipses
coded
as
literally
three
consecutive
dots
to
appear
any
place
an
expression
can
because
ellipses
do
nothing
by
themselves
this
can
serve
as
an
alternative
to
the
pass
statement
especially
for
code
to
be
filled
in
later
a
sort
of
python
tbd
def
func
alternative
to
pass
def
func
func
does
nothing
if
called
ellipses
can
also
appear
on
the
same
line
as
a
statement
header
and
may
be
used
to
initialize
variable
names
if
no
specific
type
is
required
def
func
def
func
works
on
same
line
too
x
alternative
to
none
chapter
while
and
for
loops
x
ellipsis
this
notation
is
new
in
python
and
goes
well
beyond
the
original
intent
of
in
slicing
extensions
so
time
will
tell
if
it
becomes
widespread
enough
to
challenge
pass
and
none
in
these
roles
continue
the
continue
statement
causes
an
immediate
jump
to
the
top
of
a
loop
it
also
sometimes
lets
you
avoid
statement
nesting
the
next
example
uses
continue
to
skip
odd
numbers
this
code
prints
all
even
numbers
less
than
and
greater
than
or
equal
to
remember
means
false
and
is
the
remainder
of
division
operator
so
this
loop
counts
down
to
skipping
numbers
that
aren
t
multiples
of
it
prints
x
while
x
x
x
if
x
continue
print
x
end
or
x
odd
skip
print
because
continue
jumps
to
the
top
of
the
loop
you
don
t
need
to
nest
the
print
statement
inside
an
if
test
the
print
is
only
reached
if
the
continue
is
not
run
if
this
sounds
similar
to
a
goto
in
other
languages
it
should
python
has
no
goto
statement
but
because
continue
lets
you
jump
about
in
a
program
many
of
the
warnings
about
readability
and
maintainability
you
may
have
heard
about
goto
apply
continue
should
probably
be
used
sparingly
especially
when
you
re
first
getting
started
with
python
for
instance
the
last
example
might
be
clearer
if
the
print
were
nested
under
the
if
x
while
x
x
x
if
x
print
x
end
even
print
break
the
break
statement
causes
an
immediate
exit
from
a
loop
because
the
code
that
follows
it
in
the
loop
is
not
executed
if
the
break
is
reached
you
can
also
sometimes
avoid
nesting
by
including
a
break
for
example
here
is
a
simple
interactive
loop
a
variant
of
a
larger
example
we
studied
in
chapter
that
inputs
data
with
input
known
as
raw
input
in
python
and
exits
when
the
user
enters
stop
for
the
name
request
while
true
name
input
enter
name
if
name
stop
break
age
input
enter
age
print
hello
name
int
age
enter
name
mel
enter
age
break
continue
pass
and
the
loop
else
hello
enter
enter
hello
enter
mel
name
bob
age
bob
name
stop
notice
how
this
code
converts
the
age
input
to
an
integer
with
int
before
raising
it
to
the
second
power
as
you
ll
recall
this
is
necessary
because
input
returns
user
input
as
a
string
in
chapter
you
ll
see
that
input
also
raises
an
exception
at
end
of
file
e
g
if
the
user
types
ctrl
z
or
ctrl
d
if
this
matters
wrap
input
in
try
statements
loop
else
when
combined
with
the
loop
else
clause
the
break
statement
can
often
eliminate
the
need
for
the
search
status
flags
used
in
other
languages
for
instance
the
following
piece
of
code
determines
whether
a
positive
integer
y
is
prime
by
searching
for
factors
greater
than
x
y
while
x
if
y
x
print
y
has
factor
x
break
x
else
print
y
is
prime
for
some
y
remainder
skip
else
normal
exit
rather
than
setting
a
flag
to
be
tested
when
the
loop
is
exited
it
inserts
a
break
where
a
factor
is
found
this
way
the
loop
else
clause
can
assume
that
it
will
be
executed
only
if
no
factor
is
found
if
you
don
t
hit
the
break
the
number
is
prime
the
loop
else
clause
is
also
run
if
the
body
of
the
loop
is
never
executed
as
you
don
t
run
a
break
in
that
event
either
in
a
while
loop
this
happens
if
the
test
in
the
header
is
false
to
begin
with
thus
in
the
preceding
example
you
still
get
the
is
prime
message
if
x
is
initially
less
than
or
equal
to
for
instance
if
y
is
this
example
determines
primes
but
only
informally
so
numbers
less
than
are
not
considered
prime
by
the
strict
mathematical
definition
to
be
really
picky
this
code
also
fails
for
negative
numbers
and
succeeds
for
floating
point
numbers
with
no
decimal
digits
also
note
that
its
code
must
use
instead
of
in
python
because
of
the
migration
of
to
true
division
as
described
in
chapter
we
need
the
initial
division
to
truncate
remainders
not
retain
them
if
you
want
to
experiment
with
this
code
be
sure
to
see
the
exercise
at
the
end
of
part
iv
which
wraps
it
in
a
function
for
reuse
chapter
while
and
for
loops
more
on
the
loop
else
because
the
loop
else
clause
is
unique
to
python
it
tends
to
perplex
some
newcomers
in
general
terms
the
loop
else
provides
explicit
syntax
for
a
common
coding
scenario
it
is
a
coding
structure
that
lets
us
catch
the
other
way
out
of
a
loop
without
setting
and
checking
flags
or
conditions
suppose
for
instance
that
we
are
writing
a
loop
to
search
a
list
for
a
value
and
we
need
to
know
whether
the
value
was
found
after
we
exit
the
loop
we
might
code
such
a
task
this
way
found
false
while
x
and
not
found
if
match
x
print
ni
found
true
else
x
x
if
not
found
print
not
found
value
at
front
slice
off
front
and
repeat
here
we
initialize
set
and
later
test
a
flag
to
determine
whether
the
search
succeeded
or
not
this
is
valid
python
code
and
it
does
work
however
this
is
exactly
the
sort
of
structure
that
the
loop
else
clause
is
there
to
handle
here
s
an
else
equivalent
while
x
if
match
x
print
ni
break
x
x
else
print
not
found
exit
when
x
empty
exit
go
around
else
only
here
if
exhausted
x
this
version
is
more
concise
the
flag
is
gone
and
we
ve
replaced
the
if
test
at
the
loop
end
with
an
else
lined
up
vertically
with
the
word
while
because
the
break
inside
the
main
part
of
the
while
exits
the
loop
and
goes
around
the
else
this
serves
as
a
more
structured
way
to
catch
the
search
failure
case
some
readers
might
have
noticed
that
the
prior
example
s
else
clause
could
be
replaced
with
a
test
for
an
empty
x
after
the
loop
e
g
if
not
x
although
that
s
true
in
this
example
the
else
provides
explicit
syntax
for
this
coding
pattern
it
s
more
obviously
a
search
failure
clause
here
and
such
an
explicit
empty
test
may
not
apply
in
some
cases
the
loop
else
becomes
even
more
useful
when
used
in
conjunction
with
the
for
loop
the
topic
of
the
next
section
because
sequence
iteration
is
not
under
your
control
break
continue
pass
and
the
loop
else
why
you
will
care
emulating
c
while
loops
the
section
on
expression
statements
in
chapter
stated
that
python
doesn
t
allow
statements
such
as
assignments
to
appear
in
places
where
it
expects
an
expression
that
means
this
common
c
language
coding
pattern
won
t
work
in
python
while
x
next
null
process
x
c
assignments
return
the
value
assigned
but
python
assignments
are
just
statements
not
expressions
this
eliminates
a
notorious
class
of
c
errors
you
can
t
accidentally
type
in
python
when
you
mean
if
you
need
similar
behavior
though
there
are
at
least
three
ways
to
get
the
same
effect
in
python
while
loops
without
embedding
assignments
in
loop
tests
you
can
move
the
assignment
into
the
loop
body
with
a
break
while
true
x
next
if
not
x
break
process
x
or
move
the
assignment
into
the
loop
with
tests
x
true
while
x
x
next
if
x
process
x
or
move
the
first
assignment
outside
the
loop
x
next
while
x
process
x
x
next
of
these
three
coding
patterns
the
first
may
be
considered
by
some
to
be
the
least
structured
but
it
also
seems
to
be
the
simplest
and
is
the
most
commonly
used
a
simple
python
for
loop
may
replace
some
c
loops
as
well
for
loops
the
for
loop
is
a
generic
sequence
iterator
in
python
it
can
step
through
the
items
in
any
ordered
sequence
object
the
for
statement
works
on
strings
lists
tuples
other
built
in
iterables
and
new
objects
that
we
ll
see
how
to
create
later
with
classes
we
met
it
in
brief
when
studying
sequence
object
types
let
s
expand
on
its
usage
more
formally
here
general
format
the
python
for
loop
begins
with
a
header
line
that
specifies
an
assignment
target
or
targets
along
with
the
object
you
want
to
step
through
the
header
is
followed
by
a
block
of
normally
indented
statements
that
you
want
to
repeat
chapter
while
and
for
loops
for
target
in
object
statements
else
statements
assign
object
items
to
target
repeated
loop
body
use
target
if
we
didn
t
hit
a
break
when
python
runs
a
for
loop
it
assigns
the
items
in
the
sequence
object
to
the
target
one
by
one
and
executes
the
loop
body
for
each
the
loop
body
typically
uses
the
assignment
target
to
refer
to
the
current
item
in
the
sequence
as
though
it
were
a
cursor
stepping
through
the
sequence
the
name
used
as
the
assignment
target
in
a
for
header
line
is
usually
a
possibly
new
variable
in
the
scope
where
the
for
statement
is
coded
there
s
not
much
special
about
it
it
can
even
be
changed
inside
the
loop
s
body
but
it
will
automatically
be
set
to
the
next
item
in
the
sequence
when
control
returns
to
the
top
of
the
loop
again
after
the
loop
this
variable
normally
still
refers
to
the
last
item
visited
which
is
the
last
item
in
the
sequence
unless
the
loop
exits
with
a
break
statement
the
for
statement
also
supports
an
optional
else
block
which
works
exactly
as
it
does
in
a
while
loop
it
s
executed
if
the
loop
exits
without
running
into
a
break
statement
i
e
if
all
items
in
the
sequence
have
been
visited
the
break
and
continue
statements
introduced
earlier
also
work
the
same
in
a
for
loop
as
they
do
in
a
while
the
for
loop
s
complete
format
can
be
described
this
way
for
target
in
object
statements
if
test
break
if
test
continue
else
statements
assign
object
items
to
target
exit
loop
now
skip
else
go
to
top
of
loop
now
if
we
didn
t
hit
a
break
examples
let
s
type
a
few
for
loops
interactively
now
so
you
can
see
how
they
are
used
in
practice
basic
usage
as
mentioned
earlier
a
for
loop
can
step
across
any
kind
of
sequence
object
in
our
first
example
for
instance
we
ll
assign
the
name
x
to
each
of
the
three
items
in
a
list
in
turn
from
left
to
right
and
the
print
statement
will
be
executed
for
each
inside
the
print
statement
the
loop
body
the
name
x
refers
to
the
current
item
in
the
list
for
x
in
spam
eggs
ham
print
x
end
spam
eggs
ham
the
next
two
examples
compute
the
sum
and
product
of
all
the
items
in
a
list
later
in
this
chapter
and
later
in
the
book
we
ll
meet
tools
that
apply
operations
such
as
and
to
items
in
a
list
automatically
but
it
s
usually
just
as
easy
to
use
a
for
for
loops
sum
for
x
in
sum
sum
x
sum
prod
for
item
in
prod
item
prod
other
data
types
any
sequence
works
in
a
for
as
it
s
a
generic
tool
for
example
for
loops
work
on
strings
and
tuples
s
lumberjack
t
and
i
m
okay
for
x
in
s
print
x
end
l
u
m
b
e
r
j
a
c
k
iterate
over
a
string
for
x
in
t
print
x
end
and
i
m
okay
iterate
over
a
tuple
in
fact
as
we
ll
in
the
next
chapter
when
we
explore
the
notion
of
iterables
for
loops
can
even
work
on
some
objects
that
are
not
sequences
files
and
dictionaries
work
too
tuple
assignment
in
for
loops
if
you
re
iterating
through
a
sequence
of
tuples
the
loop
target
itself
can
actually
be
a
tuple
of
targets
this
is
just
another
case
of
the
tuple
unpacking
assignment
we
studied
in
chapter
at
work
remember
the
for
loop
assigns
items
in
the
sequence
object
to
the
target
and
assignment
works
the
same
everywhere
t
for
a
b
in
t
print
a
b
tuple
assignment
at
work
here
the
first
time
through
the
loop
is
like
writing
a
b
the
second
time
is
like
writing
a
b
and
so
on
the
net
effect
is
to
automatically
unpack
the
current
tuple
on
each
iteration
this
form
is
commonly
used
in
conjunction
with
the
zip
call
we
ll
meet
later
in
this
chapter
to
implement
parallel
traversals
it
also
makes
regular
appearances
in
conjunction
with
sql
databases
in
python
where
query
result
tables
are
returned
as
sequences
chapter
while
and
for
loops
of
sequences
like
the
list
used
here
the
outer
list
is
the
database
table
the
nested
tuples
are
the
rows
within
the
table
and
tuple
assignment
extracts
columns
tuples
in
for
loops
also
come
in
handy
to
iterate
through
both
keys
and
values
in
dictionaries
using
the
items
method
rather
than
looping
through
the
keys
and
indexing
to
fetch
the
values
manually
d
a
b
c
for
key
in
d
print
key
d
key
a
c
b
use
dict
keys
iterator
and
index
list
d
items
a
c
b
for
key
value
in
d
items
print
key
value
a
c
b
iterate
over
both
keys
and
values
it
s
important
to
note
that
tuple
assignment
in
for
loops
isn
t
a
special
case
any
assignment
target
works
syntactically
after
the
word
for
although
we
can
always
assign
manually
within
the
loop
to
unpack
t
for
both
in
t
a
b
both
print
a
b
manual
assignment
equivalent
tuples
in
the
loop
header
save
us
an
extra
step
when
iterating
through
sequences
of
sequences
as
suggested
in
chapter
even
nested
structures
may
be
automatically
unpacked
this
way
in
a
for
a
b
c
a
b
c
nested
sequences
work
too
for
a
b
c
in
print
a
b
c
for
loops
but
this
is
no
special
case
the
for
loop
simply
runs
the
sort
of
assignment
we
ran
just
before
it
on
each
iteration
any
nested
sequence
structure
may
be
unpacked
this
way
just
because
sequence
assignment
is
so
generic
for
a
b
c
in
xy
print
a
b
c
x
y
python
extended
sequence
assignment
in
for
loops
in
fact
because
the
loop
variable
in
a
for
loop
can
really
be
any
assignment
target
we
can
also
use
python
s
extended
sequence
unpacking
assignment
syntax
here
to
extract
items
and
sections
of
sequences
within
sequences
really
this
isn
t
a
special
case
either
but
simply
a
new
assignment
form
in
as
discussed
in
chapter
because
it
works
in
assignment
statements
it
automatically
works
in
for
loops
consider
the
tuple
assignment
form
introduced
in
the
prior
section
a
tuple
of
values
is
assigned
to
a
tuple
of
names
on
each
iteration
exactly
like
a
simple
assignment
statement
a
b
c
a
b
c
tuple
assignment
for
a
b
c
in
print
a
b
c
used
in
for
loop
in
python
because
a
sequence
can
be
assigned
to
a
more
general
set
of
names
with
a
starred
name
to
collect
multiple
items
we
can
use
the
same
syntax
to
extract
parts
of
nested
sequences
in
the
for
loop
a
b
c
a
b
c
extended
seq
assignment
for
a
b
c
in
print
a
b
c
in
practice
this
approach
might
be
used
to
pick
out
multiple
columns
from
rows
of
data
represented
as
nested
sequences
in
python
x
starred
names
aren
t
allowed
but
you
can
achieve
similar
effects
by
slicing
the
only
difference
is
that
slicing
returns
a
type
specific
result
whereas
starred
names
always
are
assigned
lists
for
all
in
a
b
c
all
all
all
print
a
b
c
chapter
while
and
for
loops
manual
slicing
in
see
chapter
for
more
on
this
assignment
form
nested
for
loops
now
let
s
look
at
a
for
loop
that
s
a
bit
more
sophisticated
than
those
we
ve
seen
so
far
the
next
example
illustrates
statement
nesting
and
the
loop
else
clause
in
a
for
given
a
list
of
objects
items
and
a
list
of
keys
tests
this
code
searches
for
each
key
in
the
objects
list
and
reports
on
the
search
s
outcome
items
aaa
tests
for
key
in
tests
for
item
in
items
if
item
key
print
key
was
found
break
else
print
key
not
found
was
found
not
found
a
set
of
objects
keys
to
search
for
for
all
keys
for
all
items
check
for
match
because
the
nested
if
runs
a
break
when
a
match
is
found
the
loop
else
clause
can
assume
that
if
it
is
reached
the
search
has
failed
notice
the
nesting
here
when
this
code
runs
there
are
two
loops
going
at
the
same
time
the
outer
loop
scans
the
keys
list
and
the
inner
loop
scans
the
items
list
for
each
key
the
nesting
of
the
loop
else
clause
is
critical
it
s
indented
to
the
same
level
as
the
header
line
of
the
inner
for
loop
so
it
s
associated
with
the
inner
loop
not
the
if
or
the
outer
for
note
that
this
example
is
easier
to
code
if
we
employ
the
in
operator
to
test
membership
because
in
implicitly
scans
an
object
looking
for
a
match
at
least
logically
it
replaces
the
inner
loop
for
key
in
tests
if
key
in
items
print
key
was
found
else
print
key
not
found
was
found
not
found
for
all
keys
let
python
check
for
a
match
in
general
it
s
a
good
idea
to
let
python
do
as
much
of
the
work
as
possible
as
in
this
solution
for
the
sake
of
brevity
and
performance
the
next
example
performs
a
typical
data
structure
task
with
a
for
collecting
common
items
in
two
sequences
strings
it
s
roughly
a
simple
set
intersection
routine
after
the
loop
runs
res
refers
to
a
list
that
contains
all
the
items
found
in
seq
and
seq
for
loops
seq
spam
seq
scam
res
for
x
in
seq
if
x
in
seq
res
append
x
res
s
a
m
start
empty
scan
first
sequence
common
item
add
to
result
end
unfortunately
this
code
is
equipped
to
work
only
on
two
specific
variables
seq
and
seq
it
would
be
nice
if
this
loop
could
somehow
be
generalized
into
a
tool
you
could
use
more
than
once
as
you
ll
see
that
simple
idea
leads
us
to
functions
the
topic
of
the
next
part
of
the
book
why
you
will
care
file
scanners
in
general
loops
come
in
handy
anywhere
you
need
to
repeat
an
operation
or
process
something
more
than
once
because
files
contain
multiple
characters
and
lines
they
are
one
of
the
more
typical
use
cases
for
loops
to
load
a
file
s
contents
into
a
string
all
at
once
you
simply
call
the
file
object
s
read
method
file
open
test
txt
r
print
file
read
read
contents
into
a
string
but
to
load
a
file
in
smaller
pieces
it
s
common
to
code
either
a
while
loop
with
breaks
on
end
of
file
or
a
for
loop
to
read
by
characters
either
of
the
following
codings
will
suffice
file
open
test
txt
while
true
char
file
read
if
not
char
break
print
char
read
by
character
for
char
in
open
test
txt
read
print
char
the
for
loop
here
also
processes
each
character
but
it
loads
the
file
into
memory
all
at
once
and
assumes
it
fits
to
read
by
lines
or
blocks
instead
you
can
use
while
loop
code
like
this
file
open
test
txt
while
true
line
file
readline
if
not
line
break
print
line
end
read
line
by
line
file
open
test
txt
rb
while
true
chunk
file
read
if
not
chunk
break
print
chunk
read
byte
chunks
up
to
bytes
chapter
while
and
for
loops
line
already
has
a
n
you
typically
read
binary
data
in
blocks
to
read
text
files
line
by
line
though
the
for
loop
tends
to
be
easiest
to
code
and
the
quickest
to
run
for
line
in
open
test
txt
readlines
print
line
end
for
line
in
open
test
txt
print
line
end
use
iterators
best
text
input
mode
the
file
readlines
method
loads
a
file
all
at
once
into
a
line
string
list
and
the
last
example
here
relies
on
file
iterators
to
automatically
read
one
line
on
each
loop
iteration
iterators
are
covered
in
detail
in
chapter
see
the
library
manual
for
more
on
the
calls
used
here
the
last
example
here
is
generally
the
best
option
for
text
files
besides
its
simplicity
it
works
for
arbitrarily
large
files
and
doesn
t
load
the
entire
file
into
memory
all
at
once
the
iterator
version
may
be
the
quickest
but
i
o
performance
is
less
clear
cut
in
python
in
some
x
python
code
you
may
also
see
the
name
open
replaced
with
file
and
the
file
object
s
older
xreadlines
method
used
to
achieve
the
same
effect
as
the
file
s
automatic
line
iterator
it
s
like
readlines
but
doesn
t
load
the
file
into
memory
all
at
once
both
file
and
xreadlines
are
removed
in
python
because
they
are
redundant
you
shouldn
t
use
them
in
either
but
they
may
pop
up
in
older
code
and
resources
watch
for
more
on
reading
files
in
chapter
as
we
ll
see
there
text
and
binary
files
have
slightly
different
semantics
in
loop
coding
techniques
the
for
loop
subsumes
most
counter
style
loops
it
s
generally
simpler
to
code
and
quicker
to
run
than
a
while
so
it
s
the
first
tool
you
should
reach
for
whenever
you
need
to
step
through
a
sequence
but
there
are
also
situations
where
you
will
need
to
iterate
in
more
specialized
ways
for
example
what
if
you
need
to
visit
every
second
or
third
item
in
a
list
or
change
the
list
along
the
way
how
about
traversing
more
than
one
sequence
in
parallel
in
the
same
for
loop
you
can
always
code
such
unique
iterations
with
a
while
loop
and
manual
indexing
but
python
provides
two
built
ins
that
allow
you
to
specialize
the
iteration
in
a
for
the
built
in
range
function
produces
a
series
of
successively
higher
integers
which
can
be
used
as
indexes
in
a
for
the
built
in
zip
function
returns
a
series
of
parallel
item
tuples
which
can
be
used
to
traverse
multiple
sequences
in
a
for
because
for
loops
typically
run
quicker
than
while
based
counter
loops
it
s
to
your
advantage
to
use
tools
like
these
that
allow
you
to
use
for
when
possible
let
s
look
at
each
of
these
built
ins
in
turn
loop
coding
techniques
counter
loops
while
and
range
the
range
function
is
really
a
general
tool
that
can
be
used
in
a
variety
of
contexts
although
it
s
used
most
often
to
generate
indexes
in
a
for
you
can
use
it
anywhere
you
need
a
list
of
integers
in
python
range
is
an
iterator
that
generates
items
on
demand
so
we
need
to
wrap
it
in
a
list
call
to
display
its
results
all
at
once
more
on
iterators
in
chapter
list
range
list
range
list
range
with
one
argument
range
generates
a
list
of
integers
from
zero
up
to
but
not
including
the
argument
s
value
if
you
pass
in
two
arguments
the
first
is
taken
as
the
lower
bound
an
optional
third
argument
can
give
a
step
if
it
is
used
python
adds
the
step
to
each
successive
integer
in
the
result
the
step
defaults
to
ranges
can
also
be
nonpositive
and
nonascending
if
you
want
them
to
be
list
range
list
range
although
such
range
results
may
be
useful
all
by
themselves
they
tend
to
come
in
most
handy
within
for
loops
for
one
thing
they
provide
a
simple
way
to
repeat
an
action
a
specific
number
of
times
to
print
three
lines
for
example
use
a
range
to
generate
the
appropriate
number
of
integers
for
loops
force
results
from
range
automatically
in
so
we
don
t
need
list
here
for
i
in
range
print
i
pythons
pythons
pythons
pythons
range
is
also
commonly
used
to
iterate
over
a
sequence
indirectly
the
easiest
and
fastest
way
to
step
through
a
sequence
exhaustively
is
always
with
a
simple
for
as
python
handles
most
of
the
details
for
you
x
spam
for
item
in
x
print
item
end
s
p
a
m
simple
iteration
internally
the
for
loop
handles
the
details
of
the
iteration
automatically
when
used
this
way
if
you
really
need
to
take
over
the
indexing
logic
explicitly
you
can
do
it
with
a
while
loop
i
while
i
len
x
print
x
i
end
i
chapter
while
and
for
loops
while
loop
iteration
s
p
a
m
you
can
also
do
manual
indexing
with
a
for
though
if
you
use
range
to
generate
a
list
of
indexes
to
iterate
through
it
s
a
multistep
process
but
it
s
sufficient
to
generate
offsets
rather
than
the
items
at
those
offsets
x
spam
len
x
length
of
string
list
range
len
x
all
legal
offsets
into
x
for
i
in
range
len
x
print
x
i
end
manual
for
indexing
s
p
a
m
note
that
because
this
example
is
stepping
over
a
list
of
offsets
into
x
not
the
actual
items
of
x
we
need
to
index
back
into
x
within
the
loop
to
fetch
each
item
nonexhaustive
traversals
range
and
slices
the
last
example
in
the
prior
section
works
but
it
s
not
the
fastest
option
it
s
also
more
work
than
we
need
to
do
unless
you
have
a
special
indexing
requirement
you
re
always
better
off
using
the
simple
for
loop
form
in
python
as
a
general
rule
use
for
instead
of
while
whenever
possible
and
don
t
use
range
calls
in
for
loops
except
as
a
last
resort
this
simpler
solution
is
better
for
item
in
x
print
item
simple
iteration
however
the
coding
pattern
used
in
the
prior
example
does
allow
us
to
do
more
specialized
sorts
of
traversals
for
instance
we
can
skip
items
as
we
go
s
abcdefghijk
list
range
len
s
for
i
in
range
len
s
print
s
i
end
a
c
e
g
i
k
here
we
visit
every
second
item
in
the
string
s
by
stepping
over
the
generated
range
list
to
visit
every
third
item
change
the
third
range
argument
to
be
and
so
on
in
effect
using
range
this
way
lets
you
skip
items
in
loops
while
still
retaining
the
simplicity
of
the
for
loop
construct
still
this
is
probably
not
the
ideal
best
practice
technique
in
python
today
if
you
really
want
to
skip
items
in
a
sequence
the
extended
three
limit
form
of
the
slice
expression
presented
in
chapter
provides
a
simpler
route
to
the
same
goal
to
visit
every
second
character
in
s
for
example
slice
with
a
stride
of
loop
coding
techniques
s
abcdefghijk
for
c
in
s
print
c
end
a
c
e
g
i
k
the
result
is
the
same
but
substantially
easier
for
you
to
write
and
for
others
to
read
the
only
real
advantage
to
using
range
here
instead
is
that
it
does
not
copy
the
string
and
does
not
create
a
list
in
for
very
large
strings
it
may
save
memory
changing
lists
range
another
common
place
where
you
may
use
the
range
and
for
combination
is
in
loops
that
change
a
list
as
it
is
being
traversed
suppose
for
example
that
you
need
to
add
to
every
item
in
a
list
you
can
try
this
with
a
simple
for
loop
but
the
result
probably
won
t
be
exactly
what
you
want
l
for
x
in
l
x
l
x
this
doesn
t
quite
work
it
changes
the
loop
variable
x
not
the
list
l
the
reason
is
somewhat
subtle
each
time
through
the
loop
x
refers
to
the
next
integer
already
pulled
out
of
the
list
in
the
first
iteration
for
example
x
is
integer
in
the
next
iteration
the
loop
body
sets
x
to
a
different
object
integer
but
it
does
not
update
the
list
where
originally
came
from
to
really
change
the
list
as
we
march
across
it
we
need
to
use
indexes
so
we
can
assign
an
updated
value
to
each
position
as
we
go
the
range
len
combination
can
produce
the
required
indexes
for
us
l
for
i
in
range
len
l
l
i
l
add
one
to
each
item
in
l
or
l
i
l
i
when
coded
this
way
the
list
is
changed
as
we
proceed
through
the
loop
there
is
no
way
to
do
the
same
with
a
simple
for
x
in
l
style
loop
because
such
a
loop
iterates
through
actual
items
not
list
positions
but
what
about
the
equivalent
while
loop
such
a
loop
requires
a
bit
more
work
on
our
part
and
likely
runs
more
slowly
i
while
i
len
l
l
i
chapter
while
and
for
loops
i
l
here
again
though
the
range
solution
may
not
be
ideal
either
a
list
comprehension
expression
of
the
form
x
for
x
in
l
would
do
similar
work
albeit
without
changing
the
original
list
in
place
we
could
assign
the
expression
s
new
list
object
result
back
to
l
but
this
would
not
update
any
other
references
to
the
original
list
because
this
is
such
a
central
looping
concept
we
ll
save
a
complete
exploration
of
list
comprehensions
for
the
next
chapter
parallel
traversals
zip
and
map
as
we
ve
seen
the
range
built
in
allows
us
to
traverse
sequences
with
for
in
a
nonexhaustive
fashion
in
the
same
spirit
the
built
in
zip
function
allows
us
to
use
for
loops
to
visit
multiple
sequences
in
parallel
in
basic
operation
zip
takes
one
or
more
sequences
as
arguments
and
returns
a
series
of
tuples
that
pair
up
parallel
items
taken
from
those
sequences
for
example
suppose
we
re
working
with
two
lists
l
l
to
combine
the
items
in
these
lists
we
can
use
zip
to
create
a
list
of
tuple
pairs
like
range
zip
is
an
iterable
object
in
so
we
must
wrap
it
in
a
list
call
to
display
all
its
results
at
once
more
on
iterators
in
the
next
chapter
zip
l
l
zip
object
at
x
c
list
zip
l
l
list
required
in
not
such
a
result
may
be
useful
in
other
contexts
as
well
but
when
wedded
with
the
for
loop
it
supports
parallel
iterations
for
x
y
in
zip
l
l
print
x
y
x
y
here
we
step
over
the
result
of
the
zip
call
that
is
the
pairs
of
items
pulled
from
the
two
lists
notice
that
this
for
loop
again
uses
the
tuple
assignment
form
we
met
earlier
to
unpack
each
tuple
in
the
zip
result
the
first
time
through
it
s
as
though
we
ran
the
assignment
statement
x
y
loop
coding
techniques
the
net
effect
is
that
we
scan
both
l
and
l
in
our
loop
we
could
achieve
a
similar
effect
with
a
while
loop
that
handles
indexing
manually
but
it
would
require
more
typing
and
would
likely
run
more
slowly
than
the
for
zip
approach
strictly
speaking
the
zip
function
is
more
general
than
this
example
suggests
for
instance
it
accepts
any
type
of
sequence
really
any
iterable
object
including
files
and
it
accepts
more
than
two
arguments
with
three
arguments
as
in
the
following
example
it
builds
a
list
of
three
item
tuples
with
items
from
each
sequence
essentially
projecting
by
columns
technically
we
get
an
n
ary
tuple
for
n
arguments
t
t
t
t
list
zip
t
t
t
moreover
zip
truncates
result
tuples
at
the
length
of
the
shortest
sequence
when
the
argument
lengths
differ
in
the
following
we
zip
together
two
strings
to
pick
out
characters
in
parallel
but
the
result
has
only
as
many
tuples
as
the
length
of
the
shortest
sequence
s
abc
s
xyz
list
zip
s
s
a
x
b
y
c
z
map
equivalence
in
python
in
python
x
the
related
built
in
map
function
pairs
items
from
sequences
in
a
similar
fashion
but
it
pads
shorter
sequences
with
none
if
the
argument
lengths
differ
instead
of
truncating
to
the
shortest
length
s
abc
s
xyz
map
none
s
s
x
only
a
x
b
y
c
z
none
none
none
this
example
is
using
a
degenerate
form
of
the
map
built
in
which
is
no
longer
supported
in
normally
map
takes
a
function
and
one
or
more
sequence
arguments
and
collects
the
results
of
calling
the
function
with
parallel
items
taken
from
the
sequence
s
we
ll
study
map
in
detail
in
chapters
and
but
as
a
brief
example
the
following
maps
the
built
in
ord
function
across
each
item
in
a
string
and
collects
the
results
like
zip
map
is
a
value
generator
in
and
so
must
be
passed
to
list
to
collect
all
its
results
at
once
list
map
ord
spam
chapter
while
and
for
loops
this
works
the
same
as
the
following
loop
statement
but
is
often
quicker
res
for
c
in
spam
res
append
ord
c
res
version
skew
note
the
degenerate
form
of
map
using
a
function
argument
of
none
is
no
longer
supported
in
python
because
it
largely
overlaps
with
zip
and
was
frankly
a
bit
at
odds
with
map
s
functionapplication
purpose
in
either
use
zip
or
write
loop
code
to
pad
results
yourself
we
ll
see
how
to
do
this
in
chapter
after
we
ve
had
a
chance
to
study
some
additional
iteration
concepts
dictionary
construction
with
zip
in
chapter
i
suggested
that
the
zip
call
used
here
can
also
be
handy
for
generating
dictionaries
when
the
sets
of
keys
and
values
must
be
computed
at
runtime
now
that
we
re
becoming
proficient
with
zip
i
ll
explain
how
it
relates
to
dictionary
construction
as
you
ve
learned
you
can
always
create
a
dictionary
by
coding
a
dictionary
literal
or
by
assigning
to
keys
over
time
d
spam
eggs
toast
d
toast
eggs
spam
d
d
spam
d
eggs
d
toast
what
to
do
though
if
your
program
obtains
dictionary
keys
and
values
in
lists
at
runtime
after
you
ve
coded
your
script
for
example
say
you
had
the
following
keys
and
values
lists
keys
spam
eggs
toast
vals
one
solution
for
turning
those
lists
into
a
dictionary
would
be
to
zip
the
lists
and
step
through
them
in
parallel
with
a
for
loop
list
zip
keys
vals
spam
eggs
toast
d
for
k
v
in
zip
keys
vals
d
k
v
d
toast
eggs
spam
loop
coding
techniques
it
turns
out
though
that
in
python
and
later
you
can
skip
the
for
loop
altogether
and
simply
pass
the
zipped
keys
values
lists
to
the
built
in
dict
constructor
call
keys
spam
eggs
toast
vals
d
dict
zip
keys
vals
d
toast
eggs
spam
the
built
in
name
dict
is
really
a
type
name
in
python
you
ll
learn
more
about
type
names
and
subclassing
them
in
chapter
calling
it
achieves
something
like
a
listto
dictionary
conversion
but
it
s
really
an
object
construction
request
in
the
next
chapter
we
ll
explore
a
related
but
richer
concept
the
list
comprehension
which
builds
lists
in
a
single
expression
we
ll
also
revisit
dictionary
comprehensions
an
alternative
to
the
dict
cal
for
zipped
key
value
pairs
generating
both
offsets
and
items
enumerate
earlier
we
discussed
using
range
to
generate
the
offsets
of
items
in
a
string
rather
than
the
items
at
those
offsets
in
some
programs
though
we
need
both
the
item
to
use
plus
an
offset
as
we
go
traditionally
this
was
coded
with
a
simple
for
loop
that
also
kept
a
counter
of
the
current
offset
s
spam
offset
for
item
in
s
print
item
offset
s
appears
at
offset
p
appears
at
offset
a
appears
at
offset
m
appears
at
offset
appears
at
offset
offset
this
works
but
in
recent
python
releases
a
new
built
in
named
enumerate
does
the
job
for
us
s
spam
for
offset
item
in
enumerate
s
print
item
appears
at
offset
offset
s
appears
at
offset
p
appears
at
offset
a
appears
at
offset
m
appears
at
offset
the
enumerate
function
returns
a
generator
object
a
kind
of
object
that
supports
the
iteration
protocol
that
we
will
study
in
the
next
chapter
and
will
discuss
in
more
detail
in
the
next
part
of
the
book
in
short
it
has
a
next
method
called
by
the
next
builtin
function
which
returns
an
index
value
tuple
each
time
through
the
loop
we
can
unpack
these
tuples
with
tuple
assignment
in
the
for
loop
much
like
using
zip
chapter
while
and
for
loops
e
enumerate
s
e
enumerate
object
at
x
aa
next
e
s
next
e
p
next
e
a
as
usual
we
don
t
normally
see
this
machinery
because
iteration
contexts
including
list
comprehensions
the
subject
of
chapter
run
the
iteration
protocol
automatically
c
i
for
i
c
in
enumerate
s
p
aa
mmm
to
fully
understand
iteration
concepts
like
enumerate
zip
and
list
comprehensions
we
need
to
move
on
to
the
next
chapter
for
a
more
formal
dissection
chapter
summary
in
this
chapter
we
explored
python
s
looping
statements
as
well
as
some
concepts
related
to
looping
in
python
we
looked
at
the
while
and
for
loop
statements
in
depth
and
we
learned
about
their
associated
else
clauses
we
also
studied
the
break
and
continue
statements
which
have
meaning
only
inside
loops
and
met
several
built
in
tools
commonly
used
in
for
loops
including
range
zip
map
and
enumerate
although
their
roles
as
iterators
in
python
won
t
be
fully
uncovered
until
the
next
chapter
in
the
next
chapter
we
continue
the
iteration
story
by
discussing
list
comprehensions
and
the
iteration
protocol
in
python
concepts
strongly
related
to
for
loops
there
we
ll
also
explain
some
of
the
subtleties
of
iterable
tools
we
met
here
such
as
range
and
zip
as
always
though
before
moving
on
let
s
exercise
what
you
ve
picked
up
here
with
a
quiz
test
your
knowledge
quiz
what
are
the
main
functional
differences
between
a
while
and
a
for
what
s
the
difference
between
break
and
continue
when
is
a
loop
s
else
clause
executed
how
can
you
code
a
counter
based
loop
in
python
what
can
a
range
be
used
for
in
a
for
loop
test
your
knowledge
quiz
test
your
knowledge
answers
the
while
loop
is
a
general
looping
statement
but
the
for
is
designed
to
iterate
across
items
in
a
sequence
really
iterable
although
the
while
can
imitate
the
for
with
counter
loops
it
takes
more
code
and
might
run
slower
the
break
statement
exits
a
loop
immediately
you
wind
up
below
the
entire
while
or
for
loop
statement
and
continue
jumps
back
to
the
top
of
the
loop
you
wind
up
positioned
just
before
the
test
in
while
or
the
next
item
fetch
in
for
the
else
clause
in
a
while
or
for
loop
will
be
run
once
as
the
loop
is
exiting
if
the
loop
exits
normally
without
running
into
a
break
statement
a
break
exits
the
loop
immediately
skipping
the
else
part
on
the
way
out
if
there
is
one
counter
loops
can
be
coded
with
a
while
statement
that
keeps
track
of
the
index
manually
or
with
a
for
loop
that
uses
the
range
built
in
function
to
generate
successive
integer
offsets
neither
is
the
preferred
way
to
work
in
python
if
you
need
to
simply
step
across
all
the
items
in
a
sequence
instead
use
a
simple
for
loop
instead
without
range
or
counters
whenever
possible
it
will
be
easier
to
code
and
usually
quicker
to
run
the
range
built
in
can
be
used
in
a
for
to
implement
a
fixed
number
of
repetitions
to
scan
by
offsets
instead
of
items
at
offsets
to
skip
successive
items
as
you
go
and
to
change
a
list
while
stepping
across
it
none
of
these
roles
requires
range
and
most
have
alternatives
scanning
actual
items
three
limit
slices
and
list
comprehensions
are
often
better
solutions
today
despite
the
natural
inclinations
of
ex
c
programmers
to
want
to
count
things
chapter
while
and
for
loops
chapter
iterations
and
comprehensions
part
in
the
prior
chapter
we
met
python
s
two
looping
statements
while
and
for
although
they
can
handle
most
repetitive
tasks
programs
need
to
perform
the
need
to
iterate
over
sequences
is
so
common
and
pervasive
that
python
provides
additional
tools
to
make
it
simpler
and
more
efficient
this
chapter
begins
our
exploration
of
these
tools
specifically
it
presents
the
related
concepts
of
python
s
iteration
protocol
a
methodcall
model
used
by
the
for
loop
and
fills
in
some
details
on
list
comprehensions
a
close
cousin
to
the
for
loop
that
applies
an
expression
to
items
in
an
iterable
because
both
of
these
tools
are
related
to
both
the
for
loop
and
functions
we
ll
take
a
two
pass
approach
to
covering
them
in
this
book
this
chapter
introduces
the
basics
in
the
context
of
looping
tools
serving
as
something
of
continuation
of
the
prior
chapter
and
a
later
chapter
chapter
revisits
them
in
the
context
of
function
based
tools
in
this
chapter
we
ll
also
sample
additional
iteration
tools
in
python
and
touch
on
the
new
iterators
available
in
python
one
note
up
front
some
of
the
concepts
presented
in
these
chapters
may
seem
advanced
at
first
glance
with
practice
though
you
ll
find
that
these
tools
are
useful
and
powerful
although
never
strictly
required
because
they
ve
become
commonplace
in
python
code
a
basic
understanding
can
also
help
if
you
must
read
programs
written
by
others
iterators
a
first
look
in
the
preceding
chapter
i
mentioned
that
the
for
loop
can
work
on
any
sequence
type
in
python
including
lists
tuples
and
strings
like
this
for
x
in
print
x
end
for
x
in
print
x
end
for
x
in
spam
print
x
end
ss
pp
aa
mm
actually
the
for
loop
turns
out
to
be
even
more
generic
than
this
it
works
on
any
iterable
object
in
fact
this
is
true
of
all
iteration
tools
that
scan
objects
from
left
to
right
in
python
including
for
loops
the
list
comprehensions
we
ll
study
in
this
chapter
in
membership
tests
the
map
built
in
function
and
more
the
concept
of
iterable
objects
is
relatively
recent
in
python
but
it
has
come
to
permeate
the
language
s
design
it
s
essentially
a
generalization
of
the
notion
of
sequences
an
object
is
considered
iterable
if
it
is
either
a
physically
stored
sequence
or
an
object
that
produces
one
result
at
a
time
in
the
context
of
an
iteration
tool
like
a
for
loop
in
a
sense
iterable
objects
include
both
physical
sequences
and
virtual
sequences
computed
on
demand
the
iteration
protocol
file
iterators
one
of
the
easiest
ways
to
understand
what
this
means
is
to
look
at
how
it
works
with
a
built
in
type
such
as
the
file
recall
from
chapter
that
open
file
objects
have
a
method
called
readline
which
reads
one
line
of
text
from
a
file
at
a
time
each
time
we
call
the
readline
method
we
advance
to
the
next
line
at
the
end
of
the
file
an
empty
string
is
returned
which
we
can
detect
to
break
out
of
the
loop
f
open
script
py
f
readline
import
sys
n
f
readline
print
sys
path
n
f
readline
x
n
f
readline
print
n
f
readline
read
a
line
script
file
in
this
directory
readline
loads
one
line
on
each
call
returns
empty
string
at
end
of
file
however
files
also
have
a
method
named
next
that
has
a
nearly
identical
effect
it
returns
the
next
line
from
a
file
each
time
it
is
called
the
only
noticeable
difference
is
that
next
raises
a
built
in
stopiteration
exception
at
end
of
file
instead
of
returning
an
empty
string
f
open
script
py
f
next
import
sys
n
f
next
print
sys
path
n
next
loads
one
line
on
each
call
too
but
raises
an
exception
at
end
of
file
terminology
in
this
topic
tends
to
be
a
bit
loose
this
text
uses
the
terms
iterable
and
iterator
interchangeably
to
refer
to
an
object
that
supports
iteration
in
general
sometimes
the
term
iterable
refers
to
an
object
that
supports
iter
and
iterator
refers
to
an
object
return
by
iter
that
supports
next
i
but
that
convention
is
not
universal
in
either
the
python
world
or
this
book
chapter
iterations
and
comprehensions
part
f
next
x
n
f
next
print
n
f
next
traceback
most
recent
call
last
more
exception
text
omitted
stopiteration
this
interface
is
exactly
what
we
call
the
iteration
protocol
in
python
any
object
with
a
next
method
to
advance
to
a
next
result
which
raises
stopiteration
at
the
end
of
the
series
of
results
is
considered
iterable
in
python
any
such
object
may
also
be
stepped
through
with
a
for
loop
or
other
iteration
tool
because
all
iteration
tools
normally
work
internally
by
calling
next
on
each
iteration
and
catching
the
stopiteration
exception
to
determine
when
to
exit
the
net
effect
of
this
magic
is
that
as
mentioned
in
chapter
the
best
way
to
read
a
text
file
line
by
line
today
is
to
not
read
it
at
all
instead
allow
the
for
loop
to
automatically
call
next
to
advance
to
the
next
line
on
each
iteration
the
file
object
s
iterator
will
do
the
work
of
automatically
loading
lines
as
you
go
the
following
for
example
reads
a
file
line
by
line
printing
the
uppercase
version
of
each
line
along
the
way
without
ever
explicitly
reading
from
the
file
at
all
for
line
in
open
script
py
print
line
upper
end
import
sys
print
sys
path
x
print
use
file
iterators
to
read
by
lines
calls
next
catches
stopiteration
notice
that
the
print
uses
end
here
to
suppress
adding
a
n
because
line
strings
already
have
one
without
this
our
output
would
be
double
spaced
this
is
considered
the
best
way
to
read
text
files
line
by
line
today
for
three
reasons
it
s
the
simplest
to
code
might
be
the
quickest
to
run
and
is
the
best
in
terms
of
memory
usage
the
older
original
way
to
achieve
the
same
effect
with
a
for
loop
is
to
call
the
file
readlines
method
to
load
the
file
s
content
into
memory
as
a
list
of
line
strings
for
line
in
open
script
py
readlines
print
line
upper
end
import
sys
print
sys
path
x
print
this
readlines
technique
still
works
but
it
is
not
considered
the
best
practice
today
and
performs
poorly
in
terms
of
memory
usage
in
fact
because
this
version
really
does
load
the
entire
file
into
memory
all
at
once
it
will
not
even
work
for
files
too
big
to
fit
into
the
memory
space
available
on
your
computer
by
contrast
because
it
reads
one
line
at
a
time
the
iterator
based
version
is
immune
to
such
memory
explosion
issues
iterators
a
first
look
the
iterator
version
might
run
quicker
too
though
this
can
vary
per
release
python
made
this
advantage
less
clear
cut
by
rewriting
i
o
libraries
to
support
unicode
text
and
be
less
system
dependent
as
mentioned
in
the
prior
chapter
s
sidebar
why
you
will
care
file
scanners
on
page
it
s
also
possible
to
read
a
file
line
by
line
with
a
while
loop
f
open
script
py
while
true
line
f
readline
if
not
line
break
print
line
upper
end
same
output
however
this
may
run
slower
than
the
iterator
based
for
loop
version
because
iterators
run
at
c
language
speed
inside
python
whereas
the
while
loop
version
runs
python
byte
code
through
the
python
virtual
machine
any
time
we
trade
python
code
for
c
code
speed
tends
to
increase
this
is
not
an
absolute
truth
though
especially
in
python
we
ll
see
timing
techniques
later
in
this
book
for
measuring
the
relative
speed
of
alternatives
like
these
manual
iteration
iter
and
next
to
support
manual
iteration
code
with
less
typing
python
also
provides
a
builtin
function
next
that
automatically
calls
an
object
s
next
method
given
an
iterable
object
x
the
call
next
x
is
the
same
as
x
next
but
noticeably
simpler
with
files
for
instance
either
form
may
be
used
f
open
script
py
f
next
import
sys
n
f
next
print
sys
path
n
f
open
script
py
next
f
import
sys
n
next
f
print
sys
path
n
call
iteration
method
directly
next
built
in
calls
next
technically
there
is
one
more
piece
to
the
iteration
protocol
when
the
for
loop
begins
it
obtains
an
iterator
from
the
iterable
object
by
passing
it
to
the
iter
built
in
function
the
object
returned
by
iter
has
the
required
next
method
this
becomes
obvious
if
we
look
at
how
for
loops
internally
process
built
in
sequence
types
such
as
lists
l
i
iter
l
i
next
obtain
an
iterator
object
call
next
to
advance
to
next
item
i
next
chapter
iterations
and
comprehensions
part
i
next
i
next
traceback
most
recent
call
last
more
omitted
stopiteration
this
initial
step
is
not
required
for
files
because
a
file
object
is
its
own
iterator
that
is
files
have
their
own
next
method
and
so
do
not
need
to
return
a
different
object
that
does
f
open
script
py
iter
f
is
f
true
f
next
import
sys
n
lists
and
many
other
built
in
objects
are
not
their
own
iterators
because
they
support
multiple
open
iterations
for
such
objects
we
must
call
iter
to
start
iterating
l
iter
l
is
l
false
l
next
attributeerror
list
object
has
no
attribute
next
i
iter
l
i
next
next
i
same
as
i
next
although
python
iteration
tools
call
these
functions
automatically
we
can
use
them
to
apply
the
iteration
protocol
manually
too
the
following
interaction
demonstrates
the
equivalence
between
automatic
and
manual
iteration
l
for
x
in
l
print
x
end
automatic
iteration
obtains
iter
calls
next
catches
exceptions
i
iter
l
manual
iteration
what
for
loops
usually
do
technically
speaking
the
for
loop
calls
the
internal
equivalent
of
i
next
instead
of
the
next
i
used
here
there
is
rarely
any
difference
between
the
two
but
as
we
ll
see
in
the
next
section
there
are
some
builtin
objects
in
such
as
os
popen
results
that
support
the
former
and
not
the
latter
but
may
be
still
be
iterated
across
in
for
loops
your
manual
iterations
can
generally
use
either
call
scheme
if
you
care
for
the
full
story
in
os
popen
results
have
been
reimplemented
with
the
subprocess
module
and
a
wrapper
class
whose
getattr
method
is
no
longer
called
in
for
implicit
next
fetches
made
by
the
next
built
in
but
is
called
for
explicit
fetches
by
name
a
change
issue
we
ll
confront
in
chapters
and
which
apparently
burns
some
standard
library
code
too
also
in
the
related
calls
os
popen
are
no
longer
available
use
subprocess
popen
with
appropriate
arguments
instead
see
the
python
library
manual
for
the
new
required
code
iterators
a
first
look
while
true
try
x
next
i
except
stopiteration
break
print
x
end
try
statement
catches
exceptions
or
call
i
next
to
understand
this
code
you
need
to
know
that
try
statements
run
an
action
and
catch
exceptions
that
occur
while
the
action
runs
we
ll
explore
exceptions
in
depth
in
part
vii
i
should
also
note
that
for
loops
and
other
iteration
contexts
can
sometimes
work
differently
for
user
defined
classes
repeatedly
indexing
an
object
instead
of
running
the
iteration
protocol
we
ll
defer
that
story
until
we
study
class
operator
overloading
in
chapter
version
skew
note
in
python
the
iteration
method
is
named
x
next
instead
of
x
next
for
portability
the
next
x
built
in
function
is
available
in
python
too
but
not
earlier
and
calls
s
x
next
instead
of
s
x
next
iteration
works
the
same
in
in
all
other
ways
though
simply
use
x
next
or
next
x
for
manual
iterations
instead
of
s
x
next
prior
to
use
manual
x
next
calls
instead
of
next
x
other
built
in
type
iterators
besides
files
and
physical
sequences
like
lists
other
types
have
useful
iterators
as
well
the
classic
way
to
step
through
the
keys
of
a
dictionary
for
example
is
to
request
its
keys
list
explicitly
d
a
b
c
for
key
in
d
keys
print
key
d
key
a
c
b
in
recent
versions
of
python
though
dictionaries
have
an
iterator
that
automatically
returns
one
key
at
a
time
in
an
iteration
context
i
iter
d
next
i
a
next
i
c
next
i
b
next
i
traceback
most
recent
call
last
chapter
iterations
and
comprehensions
part
more
omitted
stopiteration
the
net
effect
is
that
we
no
longer
need
to
call
the
keys
method
to
step
through
dictionary
keys
the
for
loop
will
use
the
iteration
protocol
to
grab
one
key
each
time
through
for
key
in
d
print
key
d
key
a
c
b
we
can
t
delve
into
their
details
here
but
other
python
object
types
also
support
the
iterator
protocol
and
thus
may
be
used
in
for
loops
too
for
instance
shelves
an
accessby
key
filesystem
for
python
objects
and
the
results
from
os
popen
a
tool
for
reading
the
output
of
shell
commands
are
iterable
as
well
import
os
p
os
popen
dir
p
next
volume
in
drive
c
is
sq
v
n
p
next
volume
serial
number
is
be
cd
n
next
p
typeerror
wrap
close
object
is
not
an
iterator
notice
that
popen
objects
support
a
p
next
method
in
python
in
they
support
the
p
next
method
but
not
the
next
p
built
in
since
the
latter
is
defined
to
call
the
former
it
s
not
clear
if
this
behavior
will
endure
in
future
releases
as
described
in
an
earlier
footnote
this
appears
to
be
an
implementation
issue
this
is
only
an
issue
for
manual
iteration
though
if
you
iterate
over
these
objects
automatically
with
for
loops
and
other
iteration
contexts
described
in
the
next
sections
they
return
successive
lines
in
either
python
version
the
iteration
protocol
also
is
the
reason
that
we
ve
had
to
wrap
some
results
in
a
list
call
to
see
their
values
all
at
once
objects
that
are
iterable
return
results
one
at
a
time
not
in
a
physical
list
r
range
r
range
i
iter
r
next
i
next
i
list
range
ranges
are
iterables
in
use
iteration
protocol
to
produce
results
or
use
list
to
collect
all
results
at
once
iterators
a
first
look
now
that
you
have
a
better
understanding
of
this
protocol
you
should
be
able
to
see
how
it
explains
why
the
enumerate
tool
introduced
in
the
prior
chapter
works
the
way
it
does
e
enumerate
spam
enumerate
is
an
iterable
too
e
enumerate
object
at
x
f
i
iter
e
next
i
generate
results
with
iteration
protocol
s
next
i
or
use
list
to
force
generation
to
run
p
list
enumerate
spam
s
p
a
m
we
don
t
normally
see
this
machinery
because
for
loops
run
it
for
us
automatically
to
step
through
results
in
fact
everything
that
scans
left
to
right
in
python
employs
the
iteration
protocol
in
the
same
way
including
the
topic
of
the
next
section
list
comprehensions
a
first
look
now
that
we
ve
seen
how
the
iteration
protocol
works
let
s
turn
to
a
very
common
use
case
together
with
for
loops
list
comprehensions
are
one
of
the
most
prominent
contexts
in
which
the
iteration
protocol
is
applied
in
the
previous
chapter
we
learned
how
to
use
range
to
change
a
list
as
we
step
across
it
l
for
i
in
range
len
l
l
i
l
this
works
but
as
i
mentioned
there
it
may
not
be
the
optimal
best
practice
approach
in
python
today
the
list
comprehension
expression
makes
many
such
prior
use
cases
obsolete
here
for
example
we
can
replace
the
loop
with
a
single
expression
that
produces
the
desired
result
list
l
x
for
x
in
l
l
the
net
result
is
the
same
but
it
requires
less
coding
on
our
part
and
is
likely
to
run
substantially
faster
the
list
comprehension
isn
t
exactly
the
same
as
the
for
loop
statement
version
because
it
makes
a
new
list
object
which
might
matter
if
there
are
multiple
references
to
the
original
list
but
it
s
close
enough
for
most
applications
and
is
a
common
and
convenient
enough
approach
to
merit
a
closer
look
here
chapter
iterations
and
comprehensions
part
list
comprehension
basics
we
met
the
list
comprehension
briefly
in
chapter
syntactically
its
syntax
is
derived
from
a
construct
in
set
theory
notation
that
applies
an
operation
to
each
item
in
a
set
but
you
don
t
have
to
know
set
theory
to
use
this
tool
in
python
most
people
find
that
a
list
comprehension
simply
looks
like
a
backward
for
loop
to
get
a
handle
on
the
syntax
let
s
dissect
the
prior
section
s
example
in
more
detail
l
x
for
x
in
l
list
comprehensions
are
written
in
square
brackets
because
they
are
ultimately
a
way
to
construct
a
new
list
they
begin
with
an
arbitrary
expression
that
we
make
up
which
uses
a
loop
variable
that
we
make
up
x
that
is
followed
by
what
you
should
now
recognize
as
the
header
of
a
for
loop
which
names
the
loop
variable
and
an
iterable
object
for
x
in
l
to
run
the
expression
python
executes
an
iteration
across
l
inside
the
interpreter
assigning
x
to
each
item
in
turn
and
collects
the
results
of
running
the
items
through
the
expression
on
the
left
side
the
result
list
we
get
back
is
exactly
what
the
list
comprehension
says
a
new
list
containing
x
for
every
x
in
l
technically
speaking
list
comprehensions
are
never
really
required
because
we
can
always
build
up
a
list
of
expression
results
manually
with
for
loops
that
append
results
as
we
go
res
for
x
in
l
res
append
x
res
in
fact
this
is
exactly
what
the
list
comprehension
does
internally
however
list
comprehensions
are
more
concise
to
write
and
because
this
code
pattern
of
building
up
result
lists
is
so
common
in
python
work
they
turn
out
to
be
very
handy
in
many
contexts
moreover
list
comprehensions
can
run
much
faster
than
manual
for
loop
statements
often
roughly
twice
as
fast
because
their
iterations
are
performed
at
c
language
speed
inside
the
interpreter
rather
than
with
manual
python
code
especially
for
larger
data
sets
there
is
a
major
performance
advantage
to
using
them
using
list
comprehensions
on
files
let
s
work
through
another
common
use
case
for
list
comprehensions
to
explore
them
in
more
detail
recall
that
the
file
object
has
a
readlines
method
that
loads
the
file
into
a
list
of
line
strings
all
at
once
f
open
script
py
lines
f
readlines
list
comprehensions
a
first
look
lines
import
sys
n
print
sys
path
n
x
n
print
n
this
works
but
the
lines
in
the
result
all
include
the
newline
character
n
at
the
end
for
many
programs
the
newline
character
gets
in
the
way
we
have
to
be
careful
to
avoid
double
spacing
when
printing
and
so
on
it
would
be
nice
if
we
could
get
rid
of
these
newlines
all
at
once
wouldn
t
it
any
time
we
start
thinking
about
performing
an
operation
on
each
item
in
a
sequence
we
re
in
the
realm
of
list
comprehensions
for
example
assuming
the
variable
lines
is
as
it
was
in
the
prior
interaction
the
following
code
does
the
job
by
running
each
line
in
the
list
through
the
string
rstrip
method
to
remove
whitespace
on
the
right
side
a
line
slice
would
work
too
but
only
if
we
can
be
sure
all
lines
are
properly
terminated
lines
line
rstrip
for
line
in
lines
lines
import
sys
print
sys
path
x
print
this
works
as
planned
because
list
comprehensions
are
an
iteration
context
just
like
for
loop
statements
though
we
don
t
even
have
to
open
the
file
ahead
of
time
if
we
open
it
inside
the
expression
the
list
comprehension
will
automatically
use
the
iteration
protocol
we
met
earlier
in
this
chapter
that
is
it
will
read
one
line
from
the
file
at
a
time
by
calling
the
file
s
next
method
run
the
line
through
the
rstrip
expression
and
add
it
to
the
result
list
again
we
get
what
we
ask
for
the
rstrip
result
of
a
line
for
every
line
in
the
file
lines
line
rstrip
for
line
in
open
script
py
lines
import
sys
print
sys
path
x
print
this
expression
does
a
lot
implicitly
but
we
re
getting
a
lot
of
work
for
free
here
python
scans
the
file
and
builds
a
list
of
operation
results
automatically
it
s
also
an
efficient
way
to
code
this
operation
because
most
of
this
work
is
done
inside
the
python
interpreter
it
is
likely
much
faster
than
an
equivalent
for
statement
again
especially
for
large
files
the
speed
advantages
of
list
comprehensions
can
be
significant
besides
their
efficiency
list
comprehensions
are
also
remarkably
expressive
in
our
example
we
can
run
any
string
operation
on
a
file
s
lines
as
we
iterate
here
s
the
list
comprehension
equivalent
to
the
file
iterator
uppercase
example
we
met
earlier
along
with
a
few
others
the
method
chaining
in
the
second
of
these
examples
works
because
string
methods
return
a
new
string
to
which
we
can
apply
another
string
method
line
upper
for
line
in
open
script
py
import
sys
n
print
sys
path
n
x
n
print
n
line
rstrip
upper
for
line
in
open
script
py
import
sys
print
sys
path
x
print
line
split
for
line
in
open
script
py
import
sys
print
sys
path
x
print
chapter
iterations
and
comprehensions
part
line
replace
for
line
in
open
script
py
import
sys
n
print
sys
path
n
x
n
print
n
sys
in
line
line
for
line
in
open
script
py
true
i
true
p
false
x
false
p
extended
list
comprehension
syntax
in
fact
list
comprehensions
can
be
even
more
advanced
in
practice
as
one
particularly
useful
extension
the
for
loop
nested
in
the
expression
can
have
an
associated
if
clause
to
filter
out
of
the
result
items
for
which
the
test
is
not
true
for
example
suppose
we
want
to
repeat
the
prior
section
s
file
scanning
example
but
we
need
to
collect
only
lines
that
begin
with
the
letter
p
perhaps
the
first
character
on
each
line
is
an
action
code
of
some
sort
adding
an
if
filter
clause
to
our
expression
does
the
trick
lines
line
rstrip
for
line
in
open
script
py
if
line
p
lines
print
sys
path
print
here
the
if
clause
checks
each
line
read
from
the
file
to
see
whether
its
first
character
is
p
if
not
the
line
is
omitted
from
the
result
list
this
is
a
fairly
big
expression
but
it
s
easy
to
understand
if
we
translate
it
to
its
simple
for
loop
statement
equivalent
in
general
we
can
always
translate
a
list
comprehension
to
a
for
statement
by
appending
as
we
go
and
further
indenting
each
successive
part
res
for
line
in
open
script
py
if
line
p
res
append
line
rstrip
res
print
sys
path
print
this
for
statement
equivalent
works
but
it
takes
up
four
lines
instead
of
one
and
probably
runs
substantially
slower
list
comprehensions
can
become
even
more
complex
if
we
need
them
to
for
instance
they
may
contain
nested
loops
coded
as
a
series
of
for
clauses
in
fact
their
full
syntax
allows
for
any
number
of
for
clauses
each
of
which
can
have
an
optional
associated
if
clause
we
ll
be
more
formal
about
their
syntax
in
chapter
for
example
the
following
builds
a
list
of
the
concatenation
of
x
y
for
every
x
in
one
string
and
every
y
in
another
it
effectively
collects
the
permutation
of
the
characters
in
two
strings
x
y
for
x
in
abc
for
y
in
lmn
al
am
an
bl
bm
bn
cl
cm
cn
list
comprehensions
a
first
look
again
one
way
to
understand
this
expression
is
to
convert
it
to
statement
form
by
indenting
its
parts
the
following
is
an
equivalent
but
likely
slower
alternative
way
to
achieve
the
same
effect
res
for
x
in
abc
for
y
in
lmn
res
append
x
y
res
al
am
an
bl
bm
bn
cl
cm
cn
beyond
this
complexity
level
though
list
comprehension
expressions
can
often
become
too
compact
for
their
own
good
in
general
they
are
intended
for
simple
types
of
iterations
for
more
involved
work
a
simpler
for
statement
structure
will
probably
be
easier
to
understand
and
modify
in
the
future
as
usual
in
programming
if
something
is
difficult
for
you
to
understand
it
s
probably
not
a
good
idea
we
ll
revisit
list
comprehensions
in
chapter
in
the
context
of
functional
programming
tools
as
we
ll
see
they
turn
out
to
be
just
as
related
to
functions
as
they
are
to
looping
statements
other
iteration
contexts
later
in
the
book
we
ll
see
that
user
defined
classes
can
implement
the
iteration
protocol
too
because
of
this
it
s
sometimes
important
to
know
which
built
in
tools
make
use
of
it
any
tool
that
employs
the
iteration
protocol
will
automatically
work
on
any
built
in
type
or
user
defined
class
that
provides
it
so
far
i
ve
been
demonstrating
iterators
in
the
context
of
the
for
loop
statement
because
this
part
of
the
book
is
focused
on
statements
keep
in
mind
though
that
every
tool
that
scans
from
left
to
right
across
objects
uses
the
iteration
protocol
this
includes
the
for
loops
we
ve
seen
for
line
in
open
script
py
print
line
upper
end
import
sys
print
sys
path
x
print
use
file
iterators
however
list
comprehensions
the
in
membership
test
the
map
built
in
function
and
other
built
ins
such
as
the
sorted
and
zip
calls
also
leverage
the
iteration
protocol
when
applied
to
a
file
all
of
these
use
the
file
object
s
iterator
automatically
to
scan
line
by
line
uppers
line
upper
for
line
in
open
script
py
uppers
import
sys
n
print
sys
path
n
x
n
print
n
chapter
iterations
and
comprehensions
part
map
str
upper
open
script
py
map
object
at
x
map
is
an
iterable
in
list
map
str
upper
open
script
py
import
sys
n
print
sys
path
n
x
n
print
n
y
n
in
open
script
py
false
x
n
in
open
script
py
true
we
introduced
the
map
call
used
here
in
the
preceding
chapter
it
s
a
built
in
that
applies
a
function
call
to
each
item
in
the
passed
in
iterable
object
map
is
similar
to
a
list
comprehension
but
is
more
limited
because
it
requires
a
function
instead
of
an
arbitrary
expression
it
also
returns
an
iterable
object
itself
in
python
so
we
must
wrap
it
in
a
list
call
to
force
it
to
give
us
all
its
values
at
once
more
on
this
change
later
in
this
chapter
because
map
like
the
list
comprehension
is
related
to
both
for
loops
and
functions
we
ll
also
explore
both
again
in
chapters
and
python
includes
various
additional
built
ins
that
process
iterables
too
sorted
sorts
items
in
an
iterable
zip
combines
items
from
iterables
enumerate
pairs
items
in
an
iterable
with
relative
positions
filter
selects
items
for
which
a
function
is
true
and
reduce
runs
pairs
of
items
in
an
iterable
through
a
function
all
of
these
accept
iterables
and
zip
enumerate
and
filter
also
return
an
iterable
in
python
like
map
here
they
are
in
action
running
the
file
s
iterator
automatically
to
scan
line
by
line
sorted
open
script
py
import
sys
n
print
n
print
sys
path
n
x
n
list
zip
open
script
py
open
script
py
import
sys
n
import
sys
n
print
sys
path
n
print
sys
path
n
x
n
x
n
print
n
print
n
list
enumerate
open
script
py
import
sys
n
print
sys
path
n
x
n
print
n
list
filter
bool
open
script
py
import
sys
n
print
sys
path
n
x
n
print
n
import
functools
operator
functools
reduce
operator
add
open
script
py
import
sys
nprint
sys
path
nx
nprint
n
all
of
these
are
iteration
tools
but
they
have
unique
roles
we
met
zip
and
enumerate
in
the
prior
chapter
filter
and
reduce
are
in
chapter
s
functional
programming
domain
so
we
ll
defer
details
for
now
we
first
saw
the
sorted
function
used
here
at
work
in
chapter
and
we
used
it
for
dictionaries
in
chapter
sorted
is
a
built
in
that
employs
the
iteration
protocol
it
s
like
the
original
list
sort
method
but
it
returns
the
new
sorted
list
as
a
result
and
runs
other
iteration
contexts
on
any
iterable
object
notice
that
unlike
map
and
others
sorted
returns
an
actual
list
in
python
instead
of
an
iterable
other
built
in
functions
support
the
iteration
protocol
as
well
but
frankly
are
harder
to
cast
in
interesting
examples
related
to
files
for
example
the
sum
call
computes
the
sum
of
all
the
numbers
in
any
iterable
the
any
and
all
built
ins
return
true
if
any
or
all
items
in
an
iterable
are
true
respectively
and
max
and
min
return
the
largest
and
smallest
item
in
an
iterable
respectively
like
reduce
all
of
the
tools
in
the
following
examples
accept
any
iterable
as
an
argument
and
use
the
iteration
protocol
to
scan
it
but
return
a
single
result
sum
any
spam
true
all
spam
false
max
min
sum
expects
numbers
only
ni
ni
strictly
speaking
the
max
and
min
functions
can
be
applied
to
files
as
well
they
automatically
use
the
iteration
protocol
to
scan
the
file
and
pick
out
the
lines
with
the
highest
and
lowest
string
values
respectively
though
i
ll
leave
valid
use
cases
to
your
imagination
max
open
script
py
x
n
min
open
script
py
import
sys
n
line
with
max
min
string
value
interestingly
the
iteration
protocol
is
even
more
pervasive
in
python
today
than
the
examples
so
far
have
demonstrated
everything
in
python
s
built
in
toolset
that
scans
an
object
from
left
to
right
is
defined
to
use
the
iteration
protocol
on
the
subject
object
this
even
includes
more
esoteric
tools
such
as
the
list
and
tuple
built
in
functions
which
build
new
objects
from
iterables
the
string
join
method
which
puts
a
substring
between
strings
contained
in
an
iterable
and
even
sequence
assignments
consequently
all
of
these
will
also
work
on
an
open
file
and
automatically
read
one
line
at
a
time
list
open
script
py
import
sys
n
print
sys
path
n
x
n
print
n
tuple
open
script
py
import
sys
n
print
sys
path
n
x
n
print
n
join
open
script
py
import
sys
n
print
sys
path
n
x
n
print
n
a
b
c
d
open
script
py
a
d
chapter
iterations
and
comprehensions
part
import
sys
n
print
n
a
b
open
script
py
extended
form
a
b
import
sys
n
print
sys
path
n
x
n
print
n
earlier
we
saw
that
the
built
in
dict
call
accepts
an
iterable
zip
result
too
for
that
matter
so
does
the
set
call
as
well
as
the
new
set
and
dictionary
comprehension
expressions
in
python
which
we
met
in
chapters
and
set
open
script
py
print
sys
path
n
x
n
print
n
import
sys
n
line
for
line
in
open
script
py
print
sys
path
n
x
n
print
n
import
sys
n
ix
line
for
ix
line
in
enumerate
open
script
py
import
sys
n
print
sys
path
n
x
n
print
n
in
fact
both
set
and
dictionary
comprehensions
support
the
extended
syntax
of
list
comprehensions
we
met
earlier
in
this
chapter
including
if
tests
line
for
line
in
open
script
py
if
line
p
print
sys
path
n
print
n
ix
line
for
ix
line
in
enumerate
open
script
py
if
line
p
print
sys
path
n
print
n
like
the
list
comprehension
both
of
these
scan
the
file
line
by
line
and
pick
out
lines
that
begin
with
the
letter
p
they
also
happen
to
build
sets
and
dictionaries
in
the
end
but
we
get
a
lot
of
work
for
free
by
combining
file
iteration
and
comprehension
syntax
there
s
one
last
iteration
context
that
s
worth
mentioning
although
it
s
a
bit
of
a
preview
in
chapter
we
ll
learn
that
a
special
arg
form
can
be
used
in
function
calls
to
unpack
a
collection
of
values
into
individual
arguments
as
you
can
probably
predict
by
now
this
accepts
any
iterable
too
including
files
see
chapter
for
more
details
on
the
call
syntax
def
f
a
b
c
d
print
a
b
c
d
sep
f
f
unpacks
into
arguments
f
open
script
py
import
sys
print
sys
path
x
print
iterates
by
lines
too
in
fact
because
this
argument
unpacking
syntax
in
calls
accepts
iterables
it
s
also
possible
to
use
the
zip
built
in
to
unzip
zipped
tuples
by
making
prior
or
nested
zip
results
other
iteration
contexts
arguments
for
another
zip
call
warning
you
probably
shouldn
t
read
the
following
example
if
you
plan
to
operate
heavy
machinery
anytime
soon
x
y
list
zip
x
y
a
b
zip
zip
x
y
a
b
zip
tuples
returns
an
iterable
unzip
a
zip
still
other
tools
in
python
such
as
the
range
built
in
and
dictionary
view
objects
return
iterables
instead
of
processing
them
to
see
how
these
have
been
absorbed
into
the
iteration
protocol
in
python
as
well
we
need
to
move
on
to
the
next
section
new
iterables
in
python
one
of
the
fundamental
changes
in
python
is
that
it
has
a
stronger
emphasis
on
iterators
than
x
in
addition
to
the
iterators
associated
with
built
in
types
such
as
files
and
dictionaries
the
dictionary
methods
keys
values
and
items
return
iterable
objects
in
python
as
do
the
built
in
functions
range
map
zip
and
filter
as
shown
in
the
prior
section
the
last
three
of
these
functions
both
return
iterators
and
process
them
all
of
these
tools
produce
results
on
demand
in
python
instead
of
constructing
result
lists
as
they
do
in
although
this
saves
memory
space
it
can
impact
your
coding
styles
in
some
contexts
in
various
places
in
this
book
so
far
for
example
we
ve
had
to
wrap
up
various
function
and
method
call
results
in
a
list
call
in
order
to
force
them
to
produce
all
their
results
at
once
zip
abc
xyz
zip
object
at
x
e
an
iterable
in
python
a
list
in
list
zip
abc
xyz
a
x
b
y
c
z
force
list
of
results
in
to
display
this
isn
t
required
in
because
functions
like
zip
return
lists
of
results
in
though
they
return
iterable
objects
producing
results
on
demand
this
means
extra
typing
is
required
to
display
the
results
at
the
interactive
prompt
and
possibly
in
some
other
contexts
but
it
s
an
asset
in
larger
programs
delayed
evaluation
like
this
conserves
memory
and
avoids
pauses
while
large
result
lists
are
computed
let
s
take
a
quick
look
at
some
of
the
new
iterables
in
action
chapter
iterations
and
comprehensions
part
the
range
iterator
we
studied
the
range
built
in
s
basic
behavior
in
the
prior
chapter
in
it
returns
an
iterator
that
generates
numbers
in
the
range
on
demand
instead
of
building
the
result
list
in
memory
this
subsumes
the
older
x
xrange
see
the
upcoming
version
skew
note
and
you
must
use
list
range
to
force
an
actual
range
list
if
one
is
needed
e
g
to
display
results
c
misc
c
python
python
r
range
r
range
i
iter
r
next
i
range
returns
an
iterator
not
a
list
make
an
iterator
from
the
range
advance
to
next
result
what
happens
in
for
loops
comprehensions
etc
next
i
next
i
list
range
to
force
a
list
if
required
unlike
the
list
returned
by
this
call
in
x
range
objects
in
support
only
iteration
indexing
and
the
len
function
they
do
not
support
any
other
sequence
operations
use
list
if
you
require
more
list
tools
len
r
r
r
range
also
does
len
and
indexing
but
no
others
next
i
i
next
continue
taking
from
iterator
where
left
off
next
becomes
next
but
use
new
next
version
skew
note
python
x
also
has
a
built
in
called
xrange
which
is
like
range
but
produces
items
on
demand
instead
of
building
a
list
of
results
in
memory
all
at
once
since
this
is
exactly
what
the
new
iteratorbased
range
does
in
python
xrange
is
no
longer
available
in
it
has
been
subsumed
you
may
still
see
it
in
x
code
though
especially
since
range
builds
result
lists
there
and
so
is
not
as
efficient
in
its
memory
usage
as
noted
in
a
sidebar
in
the
prior
chapter
the
file
xread
lines
method
used
to
minimize
memory
use
in
x
has
been
dropped
in
python
for
similar
reasons
in
favor
of
file
iterators
new
iterables
in
python
the
map
zip
and
filter
iterators
like
range
the
map
zip
and
filter
built
ins
also
become
iterators
in
to
conserve
space
rather
than
producing
a
result
list
all
at
once
in
memory
all
three
not
only
process
iterables
as
in
x
but
also
return
iterable
results
in
unlike
range
though
they
are
their
own
iterators
after
you
step
through
their
results
once
they
are
exhausted
in
other
words
you
can
t
have
multiple
iterators
on
their
results
that
maintain
different
positions
in
those
results
here
is
the
case
for
the
map
built
in
we
met
in
the
prior
chapter
as
with
other
iterators
you
can
force
a
list
with
list
if
you
really
need
one
but
the
default
behavior
can
save
substantial
space
in
memory
for
large
result
sets
m
map
abs
m
map
object
at
x
b
next
m
next
m
next
m
next
m
stopiteration
map
returns
an
iterator
not
a
list
for
x
in
m
print
x
map
iterator
is
now
empty
one
pass
only
m
map
abs
for
x
in
m
print
x
make
a
new
iterator
to
scan
again
iteration
contexts
auto
call
next
list
map
abs
can
force
a
real
list
if
needed
use
iterator
manually
exhausts
results
these
do
not
support
len
or
indexing
the
zip
built
in
introduced
in
the
prior
chapter
returns
iterators
that
work
the
same
way
z
zip
z
zip
object
at
x
ee
zip
is
the
same
a
one
pass
iterator
list
z
for
pair
in
z
print
pair
z
zip
for
pair
in
z
print
pair
chapter
iterations
and
comprehensions
part
exhausted
after
one
pass
iterator
used
automatically
or
manually
z
zip
next
z
next
z
the
filter
built
in
which
we
ll
study
in
the
next
part
of
this
book
is
also
analogous
it
returns
items
in
an
iterable
for
which
a
passed
in
function
returns
true
as
we
ve
learned
in
python
true
includes
nonempty
objects
filter
bool
spam
ni
filter
object
at
x
c
d
list
filter
bool
spam
ni
spam
ni
like
most
of
the
tools
discussed
in
this
section
filter
both
accepts
an
iterable
to
process
and
returns
an
iterable
to
generate
results
in
multiple
versus
single
iterators
it
s
interesting
to
see
how
the
range
object
differs
from
the
built
ins
described
in
this
section
it
supports
len
and
indexing
it
is
not
its
own
iterator
you
make
one
with
iter
when
iterating
manually
and
it
supports
multiple
iterators
over
its
result
that
remember
their
positions
independently
r
range
range
allows
multiple
iterators
next
r
typeerror
range
object
is
not
an
iterator
i
iter
r
next
i
next
i
i
iter
r
next
i
two
iterators
on
one
range
next
i
i
is
at
a
different
spot
than
i
by
contrast
zip
map
and
filter
do
not
support
multiple
active
iterators
on
the
same
result
z
zip
i
iter
z
i
iter
z
next
i
next
i
next
i
two
iterators
on
one
zip
i
is
at
same
spot
as
i
new
iterables
in
python
m
map
abs
i
iter
m
i
iter
m
print
next
i
next
i
next
i
next
i
stopiteration
ditto
for
map
and
filter
r
range
i
i
iter
r
iter
r
next
i
next
i
next
i
next
i
but
range
allows
many
iterators
when
we
code
our
own
iterable
objects
with
classes
later
in
the
book
chapter
we
ll
see
that
multiple
iterators
are
usually
supported
by
returning
new
objects
for
the
iter
call
a
single
iterator
generally
means
an
object
returns
itself
in
chapter
we
ll
also
find
that
generator
functions
and
expressions
behave
like
map
and
zip
instead
of
range
in
this
regard
supporting
a
single
active
iteration
in
that
chapter
we
ll
see
some
subtle
implications
of
one
shot
iterators
in
loops
that
attempt
to
scan
multiple
times
dictionary
view
iterators
as
we
saw
briefly
in
chapter
in
python
the
dictionary
keys
values
and
items
methods
return
iterable
view
objects
that
generate
result
items
one
at
a
time
instead
of
producing
result
lists
all
at
once
in
memory
view
items
maintain
the
same
physical
ordering
as
that
of
the
dictionary
and
reflect
changes
made
to
the
underlying
dictionary
now
that
we
know
more
about
iterators
here
s
the
rest
of
the
story
d
dict
a
b
c
d
a
c
b
k
d
keys
k
dict
keys
object
at
x
d
c
a
view
object
in
not
a
list
next
k
views
are
not
iterators
themselves
typeerror
dict
keys
object
is
not
an
iterator
i
iter
k
next
i
a
next
i
c
views
have
an
iterator
which
can
be
used
manually
but
does
not
support
len
index
for
k
in
d
keys
print
k
end
a
c
b
all
iteration
contexts
use
auto
chapter
iterations
and
comprehensions
part
as
for
all
iterators
you
can
always
force
a
dictionary
view
to
build
a
real
list
by
passing
it
to
the
list
built
in
however
this
usually
isn
t
required
except
to
display
results
interactively
or
to
apply
list
operations
like
indexing
k
d
keys
list
k
a
c
b
v
d
values
v
dict
values
object
at
x
d
list
v
can
still
force
a
real
list
if
needed
ditto
for
values
and
items
views
list
d
items
a
c
b
for
k
v
in
d
items
print
k
v
end
a
c
b
in
addition
dictionaries
still
have
iterators
themselves
which
return
successive
keys
thus
it
s
not
often
necessary
to
call
keys
directly
in
this
context
d
a
c
b
i
iter
d
next
i
a
next
i
c
dictionaries
still
have
own
iterator
returns
next
key
on
each
iteration
for
key
in
d
print
key
end
a
c
b
still
no
need
to
call
keys
to
iterate
but
keys
is
an
iterator
in
too
finally
remember
again
that
because
keys
no
longer
returns
a
list
the
traditional
coding
pattern
for
scanning
a
dictionary
by
sorted
keys
won
t
work
in
instead
convert
keys
views
first
with
a
list
call
or
use
the
sorted
call
on
either
a
keys
view
or
the
dictionary
itself
as
follows
d
a
c
b
for
k
in
sorted
d
keys
print
k
d
k
end
a
b
c
d
a
c
b
for
k
in
sorted
d
print
k
d
k
end
a
b
c
best
practice
key
sorting
new
iterables
in
python
other
iterator
topics
we
ll
learn
more
about
both
list
comprehensions
and
iterators
in
chapter
in
conjunction
with
functions
and
again
in
chapter
when
we
study
classes
as
you
ll
see
later
user
defined
functions
can
be
turned
into
iterable
generator
functions
with
yield
statements
list
comprehensions
morph
into
iterable
generator
expressions
when
coded
in
parentheses
user
defined
classes
are
made
iterable
with
iter
or
getitem
operator
overloading
in
particular
user
defined
iterators
defined
with
classes
allow
arbitrary
objects
and
operations
to
be
used
in
any
of
the
iteration
contexts
we
ve
met
here
chapter
summary
in
this
chapter
we
explored
concepts
related
to
looping
in
python
we
took
our
first
substantial
look
at
the
iteration
protocol
in
python
a
way
for
nonsequence
objects
to
take
part
in
iteration
loops
and
at
list
comprehensions
as
we
saw
a
list
comprehension
is
an
expression
similar
to
a
for
loop
that
applies
another
expression
to
all
the
items
in
any
iterable
object
along
the
way
we
also
saw
other
built
in
iteration
tools
at
work
and
studied
recent
iteration
additions
in
python
this
wraps
up
our
tour
of
specific
procedural
statements
and
related
tools
the
next
chapter
closes
out
this
part
of
the
book
by
discussing
documentation
options
for
python
code
documentation
is
also
part
of
the
general
syntax
model
and
it
s
an
important
component
of
well
written
programs
in
the
next
chapter
we
ll
also
dig
into
a
set
of
exercises
for
this
part
of
the
book
before
we
turn
our
attention
to
larger
structures
such
as
functions
as
usual
though
let
s
first
exercise
what
we
ve
learned
here
with
a
quiz
test
your
knowledge
quiz
how
are
for
loops
and
iterators
related
how
are
for
loops
and
list
comprehensions
related
name
four
iteration
contexts
in
the
python
language
what
is
the
best
way
to
read
line
by
line
from
a
text
file
today
what
sort
of
weapons
would
you
expect
to
see
employed
by
the
spanish
inquisition
chapter
iterations
and
comprehensions
part
test
your
knowledge
answers
the
for
loop
uses
the
iteration
protocol
to
step
through
items
in
the
object
across
which
it
is
iterating
it
calls
the
object
s
next
method
run
by
the
next
built
in
on
each
iteration
and
catches
the
stopiteration
exception
to
determine
when
to
stop
looping
any
object
that
supports
this
model
works
in
a
for
loop
and
in
other
iteration
contexts
both
are
iteration
tools
list
comprehensions
are
a
concise
and
efficient
way
to
perform
a
common
for
loop
task
collecting
the
results
of
applying
an
expression
to
all
items
in
an
iterable
object
it
s
always
possible
to
translate
a
list
comprehension
to
a
for
loop
and
part
of
the
list
comprehension
expression
looks
like
the
header
of
a
for
loop
syntactically
iteration
contexts
in
python
include
the
for
loop
list
comprehensions
the
map
built
in
function
the
in
membership
test
expression
and
the
built
in
functions
sorted
sum
any
and
all
this
category
also
includes
the
list
and
tuple
built
ins
string
join
methods
and
sequence
assignments
all
of
which
use
the
iteration
protocol
the
next
method
to
step
across
iterable
objects
one
item
at
a
time
the
best
way
to
read
lines
from
a
text
file
today
is
to
not
read
it
explicitly
at
all
instead
open
the
file
within
an
iteration
context
such
as
a
for
loop
or
list
comprehension
and
let
the
iteration
tool
automatically
scan
one
line
at
a
time
by
running
the
file
s
next
method
on
each
iteration
this
approach
is
generally
best
in
terms
of
coding
simplicity
execution
speed
and
memory
space
requirements
i
ll
accept
any
of
the
following
as
correct
answers
fear
intimidation
nice
red
uniforms
a
comfy
chair
and
soft
pillows
test
your
knowledge
answers
chapter
the
documentation
interlude
this
part
of
the
book
concludes
with
a
look
at
techniques
and
tools
used
for
documenting
python
code
although
python
code
is
designed
to
be
readable
a
few
well
placed
human
readable
comments
can
do
much
to
help
others
understand
the
workings
of
your
programs
python
includes
syntax
and
tools
to
make
documentation
easier
although
this
is
something
of
a
tools
related
concept
the
topic
is
presented
here
partly
because
it
involves
python
s
syntax
model
and
partly
as
a
resource
for
readers
struggling
to
understand
python
s
toolset
for
the
latter
purpose
i
ll
expand
here
on
documentation
pointers
first
given
in
chapter
as
usual
in
addition
to
the
chapter
quiz
this
concluding
chapter
ends
with
some
warnings
about
common
pitfalls
and
a
set
of
exercises
for
this
part
of
the
text
python
documentation
sources
by
this
point
in
the
book
you
re
probably
starting
to
realize
that
python
comes
with
an
amazing
amount
of
prebuilt
functionality
built
in
functions
and
exceptions
predefined
object
attributes
and
methods
standard
library
modules
and
more
and
we
ve
really
only
scratched
the
surface
of
each
of
these
categories
one
of
the
first
questions
that
bewildered
beginners
often
ask
is
how
do
i
find
information
on
all
the
built
in
tools
this
section
provides
hints
on
the
various
documentation
sources
available
in
python
it
also
presents
documentation
strings
docstrings
and
the
pydoc
system
that
makes
use
of
them
these
topics
are
somewhat
peripheral
to
the
core
language
itself
but
they
become
essential
knowledge
as
soon
as
your
code
reaches
the
level
of
the
examples
and
exercises
in
this
part
of
the
book
as
summarized
in
table
there
are
a
variety
of
places
to
look
for
information
on
python
with
generally
increasing
verbosity
because
documentation
is
such
a
crucial
tool
in
practical
programming
we
ll
explore
each
of
these
categories
in
the
sections
that
follow
table
python
documentation
sources
form
role
comments
in
file
documentation
the
dir
function
lists
of
attributes
available
in
objects
docstrings
doc
in
file
documentation
attached
to
objects
pydoc
the
help
function
interactive
help
for
objects
pydoc
html
reports
module
documentation
in
a
browser
the
standard
manual
set
official
language
and
library
descriptions
web
resources
online
tutorials
examples
and
so
on
published
books
commercially
available
reference
texts
comments
hash
mark
comments
are
the
most
basic
way
to
document
your
code
python
simply
ignores
all
the
text
following
a
as
long
as
it
s
not
inside
a
string
literal
so
you
can
follow
this
character
with
words
and
descriptions
meaningful
to
programmers
such
comments
are
accessible
only
in
your
source
files
though
to
code
comments
that
are
more
widely
available
you
ll
need
to
use
docstrings
in
fact
current
best
practice
generally
dictates
that
docstrings
are
best
for
larger
functional
documentation
e
g
my
file
does
this
and
comments
are
best
limited
to
smaller
code
documentation
e
g
this
strange
expression
does
that
more
on
docstrings
in
a
moment
the
dir
function
the
built
in
dir
function
is
an
easy
way
to
grab
a
list
of
all
the
attributes
available
inside
an
object
i
e
its
methods
and
simpler
data
items
it
can
be
called
on
any
object
that
has
attributes
for
example
to
find
out
what
s
available
in
the
standard
library
s
sys
module
import
it
and
pass
it
to
dir
these
results
are
from
python
they
might
vary
slightly
on
import
sys
dir
sys
displayhook
doc
excepthook
name
package
stderr
stdin
stdout
clear
type
cache
current
frames
getframe
api
version
argv
builtin
module
names
byteorder
call
tracing
callstats
copyright
displayhook
dllhandle
dont
write
bytecode
exc
info
excepthook
exec
prefix
executable
exit
flags
float
info
getcheckinterval
getdefaultencoding
more
names
omitted
only
some
of
the
many
names
are
displayed
here
run
these
statements
on
your
machine
to
see
the
full
list
chapter
the
documentation
interlude
to
find
out
what
attributes
are
provided
in
built
in
object
types
run
dir
on
a
literal
or
existing
instance
of
the
desired
type
for
example
to
see
list
and
string
attributes
you
can
pass
empty
objects
dir
add
class
contains
more
append
count
extend
index
insert
pop
remove
reverse
sort
dir
add
class
contains
more
capitalize
center
count
encode
endswith
expandtabs
find
format
index
isalnum
isalpha
isdecimal
isdigit
isidentifier
islower
isnumeric
isprintable
isspace
istitle
isupper
join
ljust
lower
lstrip
maketrans
partition
replace
rfind
rindex
rjust
more
names
omitted
dir
results
for
any
built
in
type
include
a
set
of
attributes
that
are
related
to
the
imple
mentation
of
that
type
technically
operator
overloading
methods
they
all
begin
and
end
with
double
underscores
to
make
them
distinct
and
you
can
safely
ignore
them
at
this
point
in
the
book
incidentally
you
can
achieve
the
same
effect
by
passing
a
type
name
to
dir
instead
of
a
literal
dir
str
dir
true
dir
list
dir
true
same
result
as
prior
example
this
works
because
names
like
str
and
list
that
were
once
type
converter
functions
are
actually
names
of
types
in
python
today
calling
one
of
these
invokes
its
constructor
to
generate
an
instance
of
that
type
i
ll
have
more
to
say
about
constructors
and
operator
overloading
methods
when
we
discuss
classes
in
part
vi
the
dir
function
serves
as
a
sort
of
memory
jogger
it
provides
a
list
of
attribute
names
but
it
does
not
tell
you
anything
about
what
those
names
mean
for
such
extra
information
we
need
to
move
on
to
the
next
documentation
source
docstrings
doc
besides
comments
python
supports
documentation
that
is
automatically
attached
to
objects
and
retained
at
runtime
for
inspection
syntactically
such
comments
are
coded
as
strings
at
the
tops
of
module
files
and
function
and
class
statements
before
any
other
executable
code
comments
are
ok
before
them
python
automatically
stuffs
the
strings
known
as
docstrings
into
the
doc
attributes
of
the
corresponding
objects
python
documentation
sources
user
defined
docstrings
for
example
consider
the
following
file
docstrings
py
its
docstrings
appear
at
the
beginning
of
the
file
and
at
the
start
of
a
function
and
a
class
within
it
here
i
ve
used
triple
quoted
block
strings
for
multiline
comments
in
the
file
and
the
function
but
any
sort
of
string
will
work
we
haven
t
studied
the
def
or
class
statements
in
detail
yet
so
ignore
everything
about
them
except
the
strings
at
their
tops
module
documentation
words
go
here
spam
def
square
x
function
documentation
can
we
have
your
liver
then
return
x
square
class
employee
class
documentation
pass
print
square
print
square
doc
the
whole
point
of
this
documentation
protocol
is
that
your
comments
are
retained
for
inspection
in
doc
attributes
after
the
file
is
imported
thus
to
display
the
docstrings
associated
with
the
module
and
its
objects
we
simply
import
the
file
and
print
their
doc
attributes
where
python
has
saved
the
text
import
docstrings
function
documentation
can
we
have
your
liver
then
print
docstrings
doc
module
documentation
words
go
here
print
docstrings
square
doc
function
documentation
can
we
have
your
liver
then
print
docstrings
employee
doc
class
documentation
chapter
the
documentation
interlude
note
that
you
will
generally
want
to
use
print
to
print
docstrings
otherwise
you
ll
get
a
single
string
with
embedded
newline
characters
you
can
also
attach
docstrings
to
methods
of
classes
covered
in
part
vi
but
because
these
are
just
def
statements
nested
in
class
statements
they
re
not
a
special
case
to
fetch
the
docstring
of
a
method
function
inside
a
class
within
a
module
you
would
simply
extend
the
path
to
go
through
the
class
module
class
method
doc
we
ll
see
an
example
of
method
docstrings
in
chapter
docstring
standards
there
is
no
broad
standard
about
what
should
go
into
the
text
of
a
docstring
although
some
companies
have
internal
standards
there
have
been
various
markup
language
and
template
proposals
e
g
html
or
xml
but
they
don
t
seem
to
have
caught
on
in
the
python
world
and
frankly
convincing
python
programmers
to
document
their
code
using
handcoded
html
is
probably
not
going
to
happen
in
our
lifetimes
documentation
tends
to
have
a
low
priority
amongst
programmers
in
general
usually
if
you
get
any
comments
in
a
file
at
all
you
count
yourself
lucky
i
strongly
encourage
you
to
document
your
code
liberally
though
it
really
is
an
important
part
of
wellwritten
programs
the
point
here
is
that
there
is
presently
no
standard
on
the
structure
of
docstrings
if
you
want
to
use
them
anything
goes
today
built
in
docstrings
as
it
turns
out
built
in
modules
and
objects
in
python
use
similar
techniques
to
attach
documentation
above
and
beyond
the
attribute
lists
returned
by
dir
for
example
to
see
an
actual
human
readable
description
of
a
built
in
module
import
it
and
print
its
doc
string
import
sys
print
sys
doc
this
module
provides
access
to
some
objects
used
or
maintained
by
the
interpreter
and
to
functions
that
interact
strongly
with
the
interpreter
dynamic
objects
argv
path
modules
more
command
line
arguments
argv
is
the
script
pathname
if
known
module
search
path
path
is
the
script
directory
else
dictionary
of
loaded
modules
text
omitted
functions
classes
and
methods
within
built
in
modules
have
attached
descriptions
in
their
doc
attributes
as
well
print
sys
getrefcount
doc
getrefcount
object
integer
return
the
reference
count
of
object
the
count
returned
is
generally
one
higher
than
you
might
expect
because
it
includes
the
temporary
more
text
omitted
python
documentation
sources
you
can
also
read
about
built
in
functions
via
their
docstrings
print
int
doc
int
x
base
integer
convert
a
string
or
number
to
an
integer
if
possible
a
floating
point
argument
will
be
truncated
towards
zero
this
does
not
include
a
more
text
omitted
print
map
doc
map
func
iterables
map
object
make
an
iterator
that
computes
the
function
using
arguments
from
each
of
the
iterables
stops
when
the
shortest
iterable
is
exhausted
you
can
get
a
wealth
of
information
about
built
in
tools
by
inspecting
their
docstrings
this
way
but
you
don
t
have
to
the
help
function
the
topic
of
the
next
section
does
this
automatically
for
you
pydoc
the
help
function
the
docstring
technique
proved
to
be
so
useful
that
python
now
ships
with
a
tool
that
makes
docstrings
even
easier
to
display
the
standard
pydoc
tool
is
python
code
that
knows
how
to
extract
docstrings
and
associated
structural
information
and
format
them
into
nicely
arranged
reports
of
various
types
additional
tools
for
extracting
and
formatting
docstrings
are
available
in
the
open
source
domain
including
tools
that
may
support
structured
text
search
the
web
for
pointers
but
python
ships
with
pydoc
in
its
standard
library
there
are
a
variety
of
ways
to
launch
pydoc
including
command
line
script
options
see
the
python
library
manual
for
details
perhaps
the
two
most
prominent
pydoc
interfaces
are
the
built
in
help
function
and
the
pydoc
gui
html
interface
the
help
function
invokes
pydoc
to
generate
a
simple
textual
report
which
looks
much
like
a
manpage
on
unix
like
systems
import
sys
help
sys
getrefcount
help
on
built
in
function
getrefcount
in
module
sys
getrefcount
getrefcount
object
integer
return
the
reference
count
of
object
the
count
returned
is
generally
one
higher
than
you
might
expect
because
it
includes
the
temporary
more
omitted
note
that
you
do
not
have
to
import
sys
in
order
to
call
help
but
you
do
have
to
import
sys
to
get
help
on
sys
it
expects
an
object
reference
to
be
passed
in
for
larger
objects
such
as
modules
and
classes
the
help
display
is
broken
down
into
multiple
sections
a
few
of
which
are
shown
here
run
this
interactively
to
see
the
full
report
chapter
the
documentation
interlude
help
sys
help
on
built
in
module
sys
name
sys
file
built
in
module
docs
http
docs
python
org
library
sys
description
this
module
provides
access
to
some
objects
used
or
maintained
by
the
interpreter
and
to
functions
that
interact
strongly
with
the
interpreter
more
omitted
functions
displayhook
displayhook
displayhook
object
none
print
an
object
to
sys
stdout
and
also
save
it
in
builtins
more
omitted
data
stderr
io
textiowrapper
object
at
x
e
stdin
io
textiowrapper
object
at
x
stdout
io
textiowrapper
object
at
x
e
more
omitted
some
of
the
information
in
this
report
is
docstrings
and
some
of
it
e
g
function
call
patterns
is
structural
information
that
pydoc
gleans
automatically
by
inspecting
objects
internals
when
available
you
can
also
use
help
on
built
in
functions
methods
and
types
to
get
help
for
a
built
in
type
use
the
type
name
e
g
dict
for
dictionary
str
for
string
list
for
list
you
ll
get
a
large
display
that
describes
all
the
methods
available
for
that
type
help
dict
help
on
class
dict
in
module
builtins
class
dict
object
dict
new
empty
dictionary
dict
mapping
new
dictionary
initialized
from
a
mapping
object
s
more
omitted
help
str
replace
help
on
method
descriptor
replace
s
replace
old
new
count
str
return
a
copy
of
s
with
all
occurrences
of
substring
more
omitted
help
ord
python
documentation
sources
help
on
built
in
function
ord
in
module
builtins
ord
ord
c
integer
return
the
integer
ordinal
of
a
one
character
string
finally
the
help
function
works
just
as
well
on
your
modules
as
it
does
on
built
ins
here
it
is
reporting
on
the
docstrings
py
file
we
coded
earlier
again
some
of
this
is
docstrings
and
some
is
information
automatically
extracted
by
inspecting
objects
structures
import
docstrings
help
docstrings
square
help
on
function
square
in
module
docstrings
square
x
function
documentation
can
we
have
your
liver
then
help
docstrings
employee
help
on
class
employee
in
module
docstrings
class
employee
builtins
object
class
documentation
data
descriptors
defined
here
more
omitted
help
docstrings
help
on
module
docstrings
name
docstrings
file
c
misc
docstrings
py
description
module
documentation
words
go
here
classes
builtins
object
employee
class
employee
builtins
object
class
documentation
data
descriptors
defined
here
more
omitted
functions
square
x
function
documentation
chapter
the
documentation
interlude
can
we
have
your
liver
then
data
spam
pydoc
html
reports
the
help
function
is
nice
for
grabbing
documentation
when
working
interactively
for
a
more
grandiose
display
however
pydoc
also
provides
a
gui
interface
a
simple
but
portable
python
tkinter
script
and
can
render
its
report
in
html
page
format
viewable
in
any
web
browser
in
this
mode
pydoc
can
run
locally
or
as
a
remote
server
in
client
server
mode
reports
contain
automatically
created
hyperlinks
that
allow
you
to
click
your
way
through
the
documentation
of
related
components
in
your
application
to
start
pydoc
in
this
mode
you
generally
first
launch
the
search
engine
gui
captured
in
figure
you
can
start
this
either
by
selecting
the
module
docs
item
in
python
s
start
button
menu
on
windows
or
by
launching
the
pydoc
py
script
in
python
s
standard
library
directory
lib
on
windows
run
pydoc
py
with
a
g
command
line
argument
enter
the
name
of
a
module
you
re
interested
in
and
press
the
enter
key
pydoc
will
march
down
your
module
import
search
path
sys
path
looking
for
references
to
the
requested
module
figure
the
pydoc
top
level
search
engine
gui
type
the
name
of
a
module
you
want
documentation
for
press
enter
select
the
module
and
then
press
go
to
selected
or
omit
the
module
name
and
press
open
browser
to
see
all
available
modules
once
you
ve
found
a
promising
entry
select
it
and
click
go
to
selected
pydoc
will
spawn
a
web
browser
on
your
machine
to
display
the
report
rendered
in
html
format
figure
shows
the
information
pydoc
displays
for
the
built
in
glob
module
notice
the
hyperlinks
in
the
modules
section
of
this
page
you
can
click
these
to
jump
to
the
pydoc
pages
for
related
imported
modules
for
larger
pages
pydoc
also
generates
hyperlinks
to
sections
within
the
page
python
documentation
sources
figure
when
you
find
a
module
in
the
figure
gui
such
as
this
built
in
standard
library
module
and
press
go
to
selected
the
module
s
documentation
is
rendered
in
html
and
displayed
in
a
web
browser
window
like
this
one
like
the
help
function
interface
the
gui
interface
works
on
user
defined
modules
as
well
as
built
ins
figure
shows
the
page
generated
for
our
docstrings
py
module
file
pydoc
can
be
customized
and
launched
in
various
ways
we
won
t
cover
here
see
its
entry
in
python
s
standard
library
manual
for
more
details
the
main
thing
to
take
away
from
this
section
is
that
pydoc
essentially
gives
you
implementation
reports
for
free
if
you
are
good
about
using
docstrings
in
your
files
pydoc
does
all
the
work
of
collecting
and
formatting
them
for
display
pydoc
only
helps
for
objects
like
functions
and
modules
but
it
provides
an
easy
way
to
access
a
middle
level
of
documentation
for
such
tools
its
reports
are
more
useful
than
raw
attribute
lists
and
less
exhaustive
than
the
standard
manuals
cool
pydoc
trick
of
the
day
if
you
leave
the
module
name
empty
in
the
top
input
field
of
the
window
in
figure
and
press
the
open
browser
button
pydoc
will
produce
a
web
page
containing
a
hyperlink
to
every
module
you
can
possibly
import
on
your
computer
this
includes
python
standard
library
modules
modules
of
third
party
chapter
the
documentation
interlude
figure
pydoc
can
serve
up
documentation
pages
for
both
built
in
and
user
coded
modules
here
is
the
page
for
a
user
defined
module
showing
all
its
documentation
strings
docstrings
extracted
from
the
source
file
extensions
you
may
have
installed
user
defined
modules
on
your
import
search
path
and
even
statically
or
dynamically
linked
in
c
coded
modules
such
information
is
hard
to
come
by
otherwise
without
writing
code
that
inspects
a
set
of
module
sources
pydoc
can
also
be
run
to
save
the
html
documentation
for
a
module
in
a
file
for
later
viewing
or
printing
see
its
documentation
for
pointers
also
note
that
pydoc
might
not
work
well
if
run
on
scripts
that
read
from
standard
input
pydoc
imports
the
target
module
to
inspect
its
contents
and
there
may
be
no
connection
for
standard
input
text
when
it
is
run
in
gui
mode
modules
that
can
be
imported
without
immediate
input
requirements
will
always
work
under
pydoc
though
python
documentation
sources
the
standard
manual
set
for
the
complete
and
most
up
to
date
description
of
the
language
and
its
toolset
python
s
standard
manuals
stand
ready
to
serve
python
s
manuals
ship
in
html
and
other
formats
and
they
are
installed
with
the
python
system
on
windows
they
are
available
in
your
start
button
s
menu
for
python
and
they
can
also
be
opened
from
the
help
menu
within
idle
you
can
also
fetch
the
manual
set
separately
from
http
www
python
org
in
a
variety
of
formats
or
read
them
online
at
that
site
follow
the
documentation
link
on
windows
the
manuals
are
a
compiled
help
file
to
support
searches
and
the
online
versions
at
the
python
website
include
a
web
based
search
page
when
opened
the
windows
format
of
the
manuals
displays
a
root
page
like
that
in
figure
the
two
most
important
entries
here
are
most
likely
the
library
reference
which
documents
built
in
types
functions
exceptions
and
standard
library
modules
and
the
language
reference
which
provides
a
formal
description
of
language
level
details
the
tutorial
listed
on
this
page
also
provides
a
brief
introduction
for
newcomers
figure
python
s
standard
manual
set
available
online
at
http
www
python
org
from
idle
s
help
menu
and
in
the
windows
start
button
menu
it
s
a
searchable
help
file
on
windows
and
there
is
a
search
engine
for
the
online
version
of
these
the
library
reference
is
the
one
you
ll
want
to
use
most
of
the
time
chapter
the
documentation
interlude
web
resources
at
the
official
python
website
http
www
python
org
you
ll
find
links
to
various
python
resources
some
of
which
cover
special
topics
or
domains
click
the
documentation
link
to
access
an
online
tutorial
and
the
beginners
guide
to
python
the
site
also
lists
non
english
python
resources
you
will
find
numerous
python
wikis
blogs
websites
and
a
host
of
other
resources
on
the
web
today
to
sample
the
online
community
try
searching
for
a
term
like
python
programming
in
google
published
books
as
a
final
resource
you
can
choose
from
a
large
collection
of
reference
books
for
python
bear
in
mind
that
books
tend
to
lag
behind
the
cutting
edge
of
python
changes
partly
because
of
the
work
involved
in
writing
and
partly
because
of
the
natural
delays
built
into
the
publishing
cycle
usually
by
the
time
a
book
comes
out
it
s
three
or
more
months
behind
the
current
python
state
unlike
standard
manuals
books
are
also
generally
not
free
still
for
many
the
convenience
and
quality
of
a
professionally
published
text
is
worth
the
cost
moreover
python
changes
so
slowly
that
books
are
usually
still
relevant
years
after
they
are
published
especially
if
their
authors
post
updates
on
the
web
see
the
preface
for
pointers
to
other
python
books
common
coding
gotchas
before
the
programming
exercises
for
this
part
of
the
book
let
s
run
through
some
of
the
most
common
mistakes
beginners
make
when
coding
python
statements
and
programs
many
of
these
are
warnings
i
ve
thrown
out
earlier
in
this
part
of
the
book
collected
here
for
ease
of
reference
you
ll
learn
to
avoid
these
pitfalls
once
you
ve
gained
a
bit
of
python
coding
experience
but
a
few
words
now
might
help
you
avoid
falling
into
some
of
these
traps
initially
don
t
forget
the
colons
always
remember
to
type
a
at
the
end
of
compound
statement
headers
the
first
line
of
an
if
while
for
etc
you
ll
probably
forget
at
first
i
did
and
so
have
most
of
my
python
students
over
the
years
but
you
can
take
some
comfort
from
the
fact
that
it
will
soon
become
an
unconscious
habit
start
in
column
be
sure
to
start
top
level
unnested
code
in
column
that
includes
unnested
code
typed
into
module
files
as
well
as
unnested
code
typed
at
the
interactive
prompt
common
coding
gotchas
blank
lines
matter
at
the
interactive
prompt
blank
lines
in
compound
statements
are
always
ignored
in
module
files
but
when
you
re
typing
code
at
the
interactive
prompt
they
end
the
statement
in
other
words
blank
lines
tell
the
interactive
command
line
that
you
ve
finished
a
compound
statement
if
you
want
to
continue
don
t
hit
the
enter
key
at
the
prompt
or
in
idle
until
you
re
really
done
indent
consistently
avoid
mixing
tabs
and
spaces
in
the
indentation
of
a
block
unless
you
know
what
your
text
editor
does
with
tabs
otherwise
what
you
see
in
your
editor
may
not
be
what
python
sees
when
it
counts
tabs
as
a
number
of
spaces
this
is
true
in
any
block
structured
language
not
just
python
if
the
next
programmer
has
her
tabs
set
differently
she
will
not
understand
the
structure
of
your
code
it
s
safer
to
use
all
tabs
or
all
spaces
for
each
block
don
t
code
c
in
python
a
reminder
for
c
c
programmers
you
don
t
need
to
type
parentheses
around
tests
in
if
and
while
headers
e
g
if
x
you
can
if
you
like
any
expression
can
be
enclosed
in
parentheses
but
they
are
fully
superfluous
in
this
context
also
do
not
terminate
all
your
statements
with
semicolons
it
s
technically
legal
to
do
this
in
python
as
well
but
it
s
totally
useless
unless
you
re
placing
more
than
one
statement
on
a
single
line
the
end
of
a
line
normally
terminates
a
statement
and
remember
don
t
embed
assignment
statements
in
while
loop
tests
and
don
t
use
around
blocks
indent
your
nested
code
blocks
consistently
instead
use
simple
for
loops
instead
of
while
or
range
another
reminder
a
simple
for
loop
e
g
for
x
in
seq
is
almost
always
simpler
to
code
and
quicker
to
run
than
a
while
or
range
based
counter
loop
because
python
handles
indexing
internally
for
a
simple
for
it
can
sometimes
be
twice
as
fast
as
the
equivalent
while
avoid
the
temptation
to
count
things
in
python
beware
of
mutables
in
assignments
i
mentioned
this
in
chapter
you
need
to
be
careful
about
using
mutables
in
a
multiple
target
assignment
a
b
as
well
as
in
an
augmented
assignment
a
in
both
cases
in
place
changes
may
impact
other
variables
see
chapter
for
details
don
t
expect
results
from
functions
that
change
objects
in
place
we
encountered
this
one
earlier
too
in
place
change
operations
like
the
list
append
and
list
sort
methods
introduced
in
chapter
do
not
return
values
other
than
none
so
you
should
call
them
without
assigning
the
result
it
s
not
uncommon
for
beginners
to
say
something
like
mylist
mylist
append
x
to
try
to
get
the
result
of
an
append
but
what
this
actually
does
is
assign
mylist
to
none
not
to
the
modified
list
in
fact
you
ll
lose
your
reference
to
the
list
altogether
a
more
devious
example
of
this
pops
up
in
python
x
code
when
trying
to
step
through
dictionary
items
in
a
sorted
fashion
it
s
fairly
common
to
see
code
like
for
k
in
d
keys
sort
this
almost
works
the
keys
method
builds
a
keys
list
and
the
sort
method
orders
it
but
because
the
sort
method
returns
none
the
loop
fails
because
it
is
ultimately
a
loop
over
none
a
nonsequence
this
fails
even
chapter
the
documentation
interlude
sooner
in
python
because
dictionary
keys
are
views
not
lists
to
code
this
correctly
either
use
the
newer
sorted
built
in
function
which
returns
the
sorted
list
or
split
the
method
calls
out
to
statements
ks
list
d
keys
then
ks
sort
and
finally
for
k
in
ks
this
by
the
way
is
one
case
where
you
ll
still
want
to
call
the
keys
method
explicitly
for
looping
instead
of
relying
on
the
dictionary
iterators
iterators
do
not
sort
always
use
parentheses
to
call
a
function
you
must
add
parentheses
after
a
function
name
to
call
it
whether
it
takes
arguments
or
not
e
g
use
function
not
function
in
part
iv
we
ll
see
that
functions
are
simply
objects
that
have
a
special
operation
a
call
that
you
trigger
with
the
parentheses
in
classes
this
problem
seems
to
occur
most
often
with
files
it
s
common
to
see
beginners
type
file
close
to
close
a
file
rather
than
file
close
because
it
s
legal
to
reference
a
function
without
calling
it
the
first
version
with
no
parentheses
succeeds
silently
but
it
does
not
close
the
file
don
t
use
extensions
or
paths
in
imports
and
reloads
omit
directory
paths
and
file
suffixes
in
import
statements
e
g
say
import
mod
not
import
mod
py
we
discussed
module
basics
in
chapter
and
will
continue
studying
modules
in
part
v
because
modules
may
have
other
suffixes
besides
py
pyc
for
instance
hardcoding
a
particular
suffix
is
not
only
illegal
syntax
but
doesn
t
make
sense
any
platform
specific
directory
path
syntax
comes
from
module
search
path
settings
not
the
import
statement
chapter
summary
this
chapter
took
us
on
a
tour
of
program
documentation
both
documentation
we
write
ourselves
for
our
own
programs
and
documentation
available
for
built
in
tools
we
met
docstrings
explored
the
online
and
manual
resources
for
python
reference
and
learned
how
pydoc
s
help
function
and
web
page
interface
provide
extra
sources
of
documentation
because
this
is
the
last
chapter
in
this
part
of
the
book
we
also
reviewed
common
coding
mistakes
to
help
you
avoid
them
in
the
next
part
of
this
book
we
ll
start
applying
what
we
already
know
to
larger
program
constructs
functions
before
moving
on
however
be
sure
to
work
through
the
set
of
lab
exercises
for
this
part
of
the
book
that
appear
at
the
end
of
this
chapter
and
even
before
that
let
s
run
through
this
chapter
s
quiz
test
your
knowledge
quiz
when
should
you
use
documentation
strings
instead
of
hash
mark
comments
name
three
ways
you
can
view
documentation
strings
test
your
knowledge
quiz
how
can
you
obtain
a
list
of
the
available
attributes
in
an
object
how
can
you
get
a
list
of
all
available
modules
on
your
computer
which
python
book
should
you
purchase
after
this
one
test
your
knowledge
answers
documentation
strings
docstrings
are
considered
best
for
larger
functional
documentation
describing
the
use
of
modules
functions
classes
and
methods
in
your
code
hash
mark
comments
are
today
best
limited
to
micro
documentation
about
arcane
expressions
or
statements
this
is
partly
because
docstrings
are
easier
to
find
in
a
source
file
but
also
because
they
can
be
extracted
and
displayed
by
the
pydoc
system
you
can
see
docstrings
by
printing
an
object
s
doc
attribute
by
passing
it
to
pydoc
s
help
function
and
by
selecting
modules
in
pydoc
s
gui
search
engine
in
client
server
mode
additionally
pydoc
can
be
run
to
save
a
module
s
documentation
in
an
html
file
for
later
viewing
or
printing
the
built
in
dir
x
function
returns
a
list
of
all
the
attributes
attached
to
any
object
run
the
pydoc
gui
interface
leave
the
module
name
blank
and
select
open
browser
this
opens
a
web
page
containing
a
link
to
every
module
available
to
your
programs
mine
of
course
seriously
the
preface
lists
a
few
recommended
follow
up
books
both
for
reference
and
for
application
tutorials
test
your
knowledge
part
iii
exercises
now
that
you
know
how
to
code
basic
program
logic
the
following
exercises
will
ask
you
to
implement
some
simple
tasks
with
statements
most
of
the
work
is
in
exercise
which
lets
you
explore
coding
alternatives
there
are
always
many
ways
to
arrange
statements
and
part
of
learning
python
is
learning
which
arrangements
work
better
than
others
see
part
iii
in
appendix
b
for
the
solutions
coding
basic
loops
a
write
a
for
loop
that
prints
the
ascii
code
of
each
character
in
a
string
named
s
use
the
built
in
function
ord
character
to
convert
each
character
to
an
ascii
integer
test
it
interactively
to
see
how
it
works
b
next
change
your
loop
to
compute
the
sum
of
the
ascii
codes
of
all
the
characters
in
a
string
chapter
the
documentation
interlude
c
finally
modify
your
code
again
to
return
a
new
list
that
contains
the
ascii
codes
of
each
character
in
the
string
does
the
expression
map
ord
s
have
a
similar
effect
hint
see
chapter
backslash
characters
what
happens
on
your
machine
when
you
type
the
following
code
interactively
for
i
in
range
print
hello
d
n
a
i
beware
that
if
it
s
run
outside
of
the
idle
interface
this
example
may
beep
at
you
so
you
may
not
want
to
run
it
in
a
crowded
lab
idle
prints
odd
characters
instead
of
beeping
see
the
backslash
escape
characters
in
table
sorting
dictionaries
in
chapter
we
saw
that
dictionaries
are
unordered
collections
write
a
for
loop
that
prints
a
dictionary
s
items
in
sorted
ascending
order
hint
use
the
dictionary
keys
and
list
sort
methods
or
the
newer
sorted
built
in
function
program
logic
alternatives
consider
the
following
code
which
uses
a
while
loop
and
found
flag
to
search
a
list
of
powers
of
for
the
value
of
raised
to
the
fifth
power
it
s
stored
in
a
module
file
called
power
py
l
x
found
false
i
while
not
found
and
i
len
l
if
x
l
i
found
true
else
i
i
if
found
print
at
index
i
else
print
x
not
found
c
book
tests
python
power
py
at
index
as
is
the
example
doesn
t
follow
normal
python
coding
techniques
follow
the
steps
outlined
here
to
improve
it
for
all
the
transformations
you
may
either
type
your
code
interactively
or
store
it
in
a
script
file
run
from
the
system
command
line
using
a
file
makes
this
exercise
much
easier
a
first
rewrite
this
code
with
a
while
loop
else
clause
to
eliminate
the
found
flag
and
final
if
statement
b
next
rewrite
the
example
to
use
a
for
loop
with
an
else
clause
to
eliminate
the
explicit
list
indexing
logic
hint
to
get
the
index
of
an
item
use
the
list
index
method
l
index
x
returns
the
offset
of
the
first
x
in
list
l
test
your
knowledge
part
iii
exercises
c
next
remove
the
loop
completely
by
rewriting
the
example
with
a
simple
in
operator
membership
expression
see
chapter
for
more
details
or
type
this
to
test
in
d
finally
use
a
for
loop
and
the
list
append
method
to
generate
the
powers
of
list
l
instead
of
hardcoding
a
list
literal
deeper
thoughts
e
do
you
think
it
would
improve
performance
to
move
the
x
expression
outside
the
loops
how
would
you
code
that
f
as
we
saw
in
exercise
python
includes
a
map
function
list
tool
that
can
generate
a
powers
of
list
too
map
lambda
x
x
range
try
typing
this
code
interactively
we
ll
meet
lambda
more
formally
in
chapter
chapter
the
documentation
interlude
part
iv
functions
chapter
function
basics
in
part
iii
we
looked
at
basic
procedural
statements
in
python
here
we
ll
move
on
to
explore
a
set
of
additional
statements
that
we
can
use
to
create
functions
of
our
own
in
simple
terms
a
function
is
a
device
that
groups
a
set
of
statements
so
they
can
be
run
more
than
once
in
a
program
functions
also
can
compute
a
result
value
and
let
us
specify
parameters
that
serve
as
function
inputs
which
may
differ
each
time
the
code
is
run
coding
an
operation
as
a
function
makes
it
a
generally
useful
tool
which
we
can
use
in
a
variety
of
contexts
more
fundamentally
functions
are
the
alternative
to
programming
by
cutting
and
pasting
rather
than
having
multiple
redundant
copies
of
an
operation
s
code
we
can
factor
it
into
a
single
function
in
so
doing
we
reduce
our
future
work
radically
if
the
operation
must
be
changed
later
we
only
have
one
copy
to
update
not
many
functions
are
the
most
basic
program
structure
python
provides
for
maximizing
code
reuse
and
minimizing
code
redundancy
as
we
ll
see
functions
are
also
a
design
tool
that
lets
us
split
complex
systems
into
manageable
parts
table
summarizes
the
primary
function
related
tools
we
ll
study
in
this
part
of
the
book
table
function
related
statements
and
expressions
statement
examples
calls
myfunc
spam
eggs
meat
ham
def
return
def
adder
a
b
c
return
a
b
c
global
def
changer
global
x
x
new
nonlocal
def
changer
nonlocal
x
x
new
yield
def
squares
x
for
i
in
range
x
yield
i
lambda
funcs
lambda
x
x
lambda
x
x
why
use
functions
before
we
get
into
the
details
let
s
establish
a
clear
picture
of
what
functions
are
all
about
functions
are
a
nearly
universal
program
structuring
device
you
may
have
come
across
them
before
in
other
languages
where
they
may
have
been
called
subroutines
or
procedures
as
a
brief
introduction
functions
serve
two
primary
development
roles
maximizing
code
reuse
and
minimizing
redundancy
as
in
most
programming
languages
python
functions
are
the
simplest
way
to
package
logic
you
may
wish
to
use
in
more
than
one
place
and
more
than
one
time
up
until
now
all
the
code
we
ve
been
writing
has
run
immediately
functions
allow
us
to
group
and
generalize
code
to
be
used
arbitrarily
many
times
later
because
they
allow
us
to
code
an
operation
in
a
single
place
and
use
it
in
many
places
python
functions
are
the
most
basic
factoring
tool
in
the
language
they
allow
us
to
reduce
code
redundancy
in
our
programs
and
thereby
reduce
maintenance
effort
procedural
decomposition
functions
also
provide
a
tool
for
splitting
systems
into
pieces
that
have
well
defined
roles
for
instance
to
make
a
pizza
from
scratch
you
would
start
by
mixing
the
dough
rolling
it
out
adding
toppings
baking
it
and
so
on
if
you
were
programming
a
pizza
making
robot
functions
would
help
you
divide
the
overall
make
pizza
task
into
chunks
one
function
for
each
subtask
in
the
process
it
s
easier
to
implement
the
smaller
tasks
in
isolation
than
it
is
to
implement
the
entire
process
at
once
in
general
functions
are
about
procedure
how
to
do
something
rather
than
what
you
re
doing
it
to
we
ll
see
why
this
distinction
matters
in
part
vi
when
we
start
making
new
object
with
classes
in
this
part
of
the
book
we
ll
explore
the
tools
used
to
code
functions
in
python
function
basics
scope
rules
and
argument
passing
along
with
a
few
related
concepts
such
as
generators
and
functional
tools
because
its
importance
begins
to
become
more
apparent
at
this
level
of
coding
we
ll
also
revisit
the
notion
of
polymorphism
introduced
earlier
in
the
book
as
you
ll
see
functions
don
t
imply
much
new
syntax
but
they
do
lead
us
to
some
bigger
programming
ideas
coding
functions
although
it
wasn
t
made
very
formal
we
ve
already
used
some
functions
in
earlier
chapters
for
instance
to
make
a
file
object
we
called
the
built
in
open
function
similarly
we
used
the
len
built
in
function
to
ask
for
the
number
of
items
in
a
collection
object
in
this
chapter
we
will
explore
how
to
write
new
functions
in
python
functions
we
write
behave
the
same
way
as
the
built
ins
we
ve
already
seen
they
are
called
in
chapter
function
basics
expressions
are
passed
values
and
return
results
but
writing
new
functions
requires
the
application
of
a
few
additional
ideas
that
haven
t
yet
been
introduced
moreover
functions
behave
very
differently
in
python
than
they
do
in
compiled
languages
like
c
here
is
a
brief
introduction
to
the
main
concepts
behind
python
functions
all
of
which
we
will
study
in
this
part
of
the
book
def
is
executable
code
python
functions
are
written
with
a
new
statement
the
def
unlike
functions
in
compiled
languages
such
as
c
def
is
an
executable
statement
your
function
does
not
exist
until
python
reaches
and
runs
the
def
in
fact
it
s
legal
and
even
occasionally
useful
to
nest
def
statements
inside
if
statements
while
loops
and
even
other
defs
in
typical
operation
def
statements
are
coded
in
module
files
and
are
naturally
run
to
generate
functions
when
a
module
file
is
first
imported
def
creates
an
object
and
assigns
it
to
a
name
when
python
reaches
and
runs
a
def
statement
it
generates
a
new
function
object
and
assigns
it
to
the
function
s
name
as
with
all
assignments
the
function
name
becomes
a
reference
to
the
function
object
there
s
nothing
magic
about
the
name
of
a
function
as
you
ll
see
the
function
object
can
be
assigned
to
other
names
stored
in
a
list
and
so
on
function
objects
may
also
have
arbitrary
user
defined
attributes
attached
to
them
to
record
data
lambda
creates
an
object
but
returns
it
as
a
result
functions
may
also
be
created
with
the
lambda
expression
a
feature
that
allows
us
to
in
line
function
definitions
in
places
where
a
def
statement
won
t
work
syntactically
this
is
a
more
advanced
concept
that
we
ll
defer
until
chapter
return
sends
a
result
object
back
to
the
caller
when
a
function
is
called
the
caller
stops
until
the
function
finishes
its
work
and
returns
control
to
the
caller
functions
that
compute
a
value
send
it
back
to
the
caller
with
a
return
statement
the
returned
value
becomes
the
result
of
the
function
call
yield
sends
a
result
object
back
to
the
caller
but
remembers
where
it
left
off
functions
known
as
generators
may
also
use
the
yield
statement
to
send
back
a
value
and
suspend
their
state
such
that
they
may
be
resumed
later
to
produce
a
series
of
results
over
time
this
is
another
advanced
topic
covered
later
in
this
part
of
the
book
global
declares
module
level
variables
that
are
to
be
assigned
by
default
all
names
assigned
in
a
function
are
local
to
that
function
and
exist
only
while
the
function
runs
to
assign
a
name
in
the
enclosing
module
functions
need
to
list
it
in
a
global
statement
more
generally
names
are
always
looked
up
in
scopes
places
where
variables
are
stored
and
assignments
bind
names
to
scopes
nonlocal
declares
enclosing
function
variables
that
are
to
be
assigned
similarly
the
nonlocal
statement
added
in
python
allows
a
function
to
assign
a
name
that
exists
in
the
scope
of
a
syntactically
enclosing
def
statement
this
allows
coding
functions
enclosing
functions
to
serve
as
a
place
to
retain
state
information
remembered
when
a
function
is
called
without
using
shared
global
names
arguments
are
passed
by
assignment
object
reference
in
python
arguments
are
passed
to
functions
by
assignment
which
as
we
ve
learned
means
by
object
reference
as
you
ll
see
in
python
s
model
the
caller
and
function
share
objects
by
references
but
there
is
no
name
aliasing
changing
an
argument
name
within
a
function
does
not
also
change
the
corresponding
name
in
the
caller
but
changing
passed
in
mutable
objects
can
change
objects
shared
by
the
caller
arguments
return
values
and
variables
are
not
declared
as
with
everything
in
python
there
are
no
type
constraints
on
functions
in
fact
nothing
about
a
function
needs
to
be
declared
ahead
of
time
you
can
pass
in
arguments
of
any
type
return
any
kind
of
object
and
so
on
as
one
consequence
a
single
function
can
often
be
applied
to
a
variety
of
object
types
any
objects
that
sport
a
compatible
interface
methods
and
expressions
will
do
regardless
of
their
specific
types
if
some
of
the
preceding
words
didn
t
sink
in
don
t
worry
we
ll
explore
all
of
these
concepts
with
real
code
in
this
part
of
the
book
let
s
get
started
by
expanding
on
some
of
these
ideas
and
looking
at
a
few
examples
def
statements
the
def
statement
creates
a
function
object
and
assigns
it
to
a
name
its
general
format
is
as
follows
def
name
arg
arg
argn
statements
as
with
all
compound
python
statements
def
consists
of
a
header
line
followed
by
a
block
of
statements
usually
indented
or
a
simple
statement
after
the
colon
the
statement
block
becomes
the
function
s
body
that
is
the
code
python
executes
each
time
the
function
is
called
the
def
header
line
specifies
a
function
name
that
is
assigned
the
function
object
along
with
a
list
of
zero
or
more
arguments
sometimes
called
parameters
in
parentheses
the
argument
names
in
the
header
are
assigned
to
the
objects
passed
in
parentheses
at
the
point
of
call
function
bodies
often
contain
a
return
statement
def
name
arg
arg
argn
return
value
the
python
return
statement
can
show
up
anywhere
in
a
function
body
it
ends
the
function
call
and
sends
a
result
back
to
the
caller
the
return
statement
consists
of
an
object
expression
that
gives
the
function
s
result
the
return
statement
is
optional
if
it
s
not
present
the
function
exits
when
the
control
flow
falls
off
the
end
of
the
function
chapter
function
basics
body
technically
a
function
without
a
return
statement
returns
the
none
object
automatically
but
this
return
value
is
usually
ignored
functions
may
also
contain
yield
statements
which
are
designed
to
produce
a
series
of
values
over
time
but
we
ll
defer
discussion
of
these
until
we
survey
generator
topics
in
chapter
def
executes
at
runtime
the
python
def
is
a
true
executable
statement
when
it
runs
it
creates
a
new
function
object
and
assigns
it
to
a
name
remember
all
we
have
in
python
is
runtime
there
is
no
such
thing
as
a
separate
compile
time
because
it
s
a
statement
a
def
can
appear
anywhere
a
statement
can
even
nested
in
other
statements
for
instance
although
defs
normally
are
run
when
the
module
enclosing
them
is
imported
it
s
also
completely
legal
to
nest
a
function
def
inside
an
if
statement
to
select
between
alternative
definitions
if
test
def
func
else
def
func
func
define
func
this
way
or
else
this
way
call
the
version
selected
and
built
one
way
to
understand
this
code
is
to
realize
that
the
def
is
much
like
an
statement
it
simply
assigns
a
name
at
runtime
unlike
in
compiled
languages
such
as
c
python
functions
do
not
need
to
be
fully
defined
before
the
program
runs
more
generally
defs
are
not
evaluated
until
they
are
reached
and
run
and
the
code
inside
defs
is
not
evaluated
until
the
functions
are
later
called
because
function
definition
happens
at
runtime
there
s
nothing
special
about
the
function
name
what
s
important
is
the
object
to
which
it
refers
othername
func
othername
assign
function
object
call
func
again
here
the
function
was
assigned
to
a
different
name
and
called
through
the
new
name
like
everything
else
in
python
functions
are
just
objects
they
are
recorded
explicitly
in
memory
at
program
execution
time
in
fact
besides
calls
functions
allow
arbitrary
attributes
to
be
attached
to
record
information
for
later
use
def
func
func
func
attr
value
create
function
object
call
object
attach
attributes
coding
functions
a
first
example
definitions
and
calls
apart
from
such
runtime
concepts
which
tend
to
seem
most
unique
to
programmers
with
backgrounds
in
traditional
compiled
languages
python
functions
are
straightforward
to
use
let
s
code
a
first
real
example
to
demonstrate
the
basics
as
you
ll
see
there
are
two
sides
to
the
function
picture
a
definition
the
def
that
creates
a
function
and
a
call
an
expression
that
tells
python
to
run
the
function
s
body
definition
here
s
a
definition
typed
interactively
that
defines
a
function
called
times
which
returns
the
product
of
its
two
arguments
def
times
x
y
return
x
y
create
and
assign
function
body
executed
when
called
when
python
reaches
and
runs
this
def
it
creates
a
new
function
object
that
packages
the
function
s
code
and
assigns
the
object
to
the
name
times
typically
such
a
statement
is
coded
in
a
module
file
and
runs
when
the
enclosing
file
is
imported
for
something
this
small
though
the
interactive
prompt
suffices
calls
after
the
def
has
run
you
can
call
run
the
function
in
your
program
by
adding
parentheses
after
the
function
s
name
the
parentheses
may
optionally
contain
one
or
more
object
arguments
to
be
passed
assigned
to
the
names
in
the
function
s
header
times
arguments
in
parentheses
this
expression
passes
two
arguments
to
times
as
mentioned
previously
arguments
are
passed
by
assignment
so
in
this
case
the
name
x
in
the
function
header
is
assigned
the
value
y
is
assigned
the
value
and
the
function
s
body
is
run
for
this
function
the
body
is
just
a
return
statement
that
sends
back
the
result
as
the
value
of
the
call
expression
the
returned
object
was
printed
here
interactively
as
in
most
languages
is
in
python
but
if
we
needed
to
use
it
later
we
could
instead
assign
it
to
a
variable
for
example
x
times
x
save
the
result
object
now
watch
what
happens
when
the
function
is
called
a
third
time
with
very
different
kinds
of
objects
passed
in
times
ni
nininini
chapter
function
basics
functions
are
typeless
this
time
our
function
means
something
completely
different
monty
python
reference
again
intended
in
this
third
call
a
string
and
an
integer
are
passed
to
x
and
y
instead
of
two
numbers
recall
that
works
on
both
numbers
and
sequences
because
we
never
declare
the
types
of
variables
arguments
or
return
values
in
python
we
can
use
times
to
either
multiply
numbers
or
repeat
sequences
in
other
words
what
our
times
function
means
and
does
depends
on
what
we
pass
into
it
this
is
a
core
idea
in
python
and
perhaps
the
key
to
using
the
language
well
which
we
ll
explore
in
the
next
section
polymorphism
in
python
as
we
just
saw
the
very
meaning
of
the
expression
x
y
in
our
simple
times
function
depends
completely
upon
the
kinds
of
objects
that
x
and
y
are
thus
the
same
function
can
perform
multiplication
in
one
instance
and
repetition
in
another
python
leaves
it
up
to
the
objects
to
do
something
reasonable
for
the
syntax
really
is
just
a
dispatch
mechanism
that
routes
control
to
the
objects
being
processed
this
sort
of
type
dependent
behavior
is
known
as
polymorphism
a
term
we
first
met
in
chapter
that
essentially
means
that
the
meaning
of
an
operation
depends
on
the
objects
being
operated
upon
because
it
s
a
dynamically
typed
language
polymorphism
runs
rampant
in
python
in
fact
every
operation
is
a
polymorphic
operation
in
python
printing
indexing
the
operator
and
much
more
this
is
deliberate
and
it
accounts
for
much
of
the
language
s
conciseness
and
flexibility
a
single
function
for
instance
can
generally
be
applied
to
a
whole
category
of
object
types
automatically
as
long
as
those
objects
support
the
expected
interface
a
k
a
protocol
the
function
can
process
them
that
is
if
the
objects
passed
into
a
function
have
the
expected
methods
and
expression
operators
they
are
plug
and
play
compatible
with
the
function
s
logic
even
in
our
simple
times
function
this
means
that
any
two
objects
that
support
a
will
work
no
matter
what
they
may
be
and
no
matter
when
they
are
coded
this
function
will
work
on
two
numbers
performing
multiplication
or
a
string
and
a
number
performing
repetition
or
any
other
combination
of
objects
supporting
the
expected
interface
even
class
based
objects
we
have
not
even
coded
yet
moreover
if
the
objects
passed
in
do
not
support
this
expected
interface
python
will
detect
the
error
when
the
expression
is
run
and
raise
an
exception
automatically
it
s
therefore
pointless
to
code
error
checking
ourselves
in
fact
doing
so
would
limit
our
function
s
utility
as
it
would
be
restricted
to
work
only
on
objects
whose
types
we
test
for
this
turns
out
to
be
a
crucial
philosophical
difference
between
python
and
statically
typed
languages
like
c
and
java
in
python
your
code
is
not
supposed
to
care
about
specific
data
types
if
it
does
it
will
be
limited
to
working
on
just
the
types
you
anticipated
when
you
wrote
it
and
it
will
not
support
other
compatible
object
types
that
a
first
example
definitions
and
calls
may
be
coded
in
the
future
although
it
is
possible
to
test
for
types
with
tools
like
the
type
built
in
function
doing
so
breaks
your
code
s
flexibility
by
and
large
we
code
to
object
interfaces
in
python
not
data
types
of
course
this
polymorphic
model
of
programming
means
we
have
to
test
our
code
to
detect
errors
rather
than
providing
type
declarations
a
compiler
can
use
to
detect
some
types
of
errors
for
us
ahead
of
time
in
exchange
for
an
initial
bit
of
testing
though
we
radically
reduce
the
amount
of
code
we
have
to
write
and
radically
increase
our
code
s
flexibility
as
you
ll
learn
it
s
a
net
win
in
practice
a
second
example
intersecting
sequences
let
s
look
at
a
second
function
example
that
does
something
a
bit
more
useful
than
multiplying
arguments
and
further
illustrates
function
basics
in
chapter
we
coded
a
for
loop
that
collected
items
held
in
common
in
two
strings
we
noted
there
that
the
code
wasn
t
as
useful
as
it
could
be
because
it
was
set
up
to
work
only
on
specific
variables
and
could
not
be
rerun
later
of
course
we
could
copy
the
code
and
paste
it
into
each
place
where
it
needs
to
be
run
but
this
solution
is
neither
good
nor
general
we
d
still
have
to
edit
each
copy
to
support
different
sequence
names
and
changing
the
algorithm
would
then
require
changing
multiple
copies
definition
by
now
you
can
probably
guess
that
the
solution
to
this
dilemma
is
to
package
the
for
loop
inside
a
function
doing
so
offers
a
number
of
advantages
putting
the
code
in
a
function
makes
it
a
tool
that
you
can
run
as
many
times
as
you
like
because
callers
can
pass
in
arbitrary
arguments
functions
are
general
enough
to
work
on
any
two
sequences
or
other
iterables
you
wish
to
intersect
when
the
logic
is
packaged
in
a
function
you
only
have
to
change
code
in
one
place
if
you
ever
need
to
change
the
way
the
intersection
works
coding
the
function
in
a
module
file
means
it
can
be
imported
and
reused
by
any
program
run
on
your
machine
in
effect
wrapping
the
code
in
a
function
makes
it
a
general
intersection
utility
def
intersect
seq
seq
res
for
x
in
seq
if
x
in
seq
res
append
x
return
res
start
empty
scan
seq
common
item
add
to
end
the
transformation
from
the
simple
code
of
chapter
to
this
function
is
straightforward
we
ve
just
nested
the
original
logic
under
a
def
header
and
made
the
objects
on
chapter
function
basics
which
it
operates
passed
in
parameter
names
because
this
function
computes
a
result
we
ve
also
added
a
return
statement
to
send
a
result
object
back
to
the
caller
calls
before
you
can
call
a
function
you
have
to
make
it
to
do
this
run
its
def
statement
either
by
typing
it
interactively
or
by
coding
it
in
a
module
file
and
importing
the
file
once
you
ve
run
the
def
you
can
call
the
function
by
passing
any
two
sequence
objects
in
parentheses
s
spam
s
scam
intersect
s
s
s
a
m
strings
here
we
ve
passed
in
two
strings
and
we
get
back
a
list
containing
the
characters
in
common
the
algorithm
the
function
uses
is
simple
for
every
item
in
the
first
argument
if
that
item
is
also
in
the
second
argument
append
the
item
to
the
result
it
s
a
little
shorter
to
say
that
in
python
than
in
english
but
it
works
out
the
same
to
be
fair
our
intersect
function
is
fairly
slow
it
executes
nested
loops
isn
t
really
mathematical
intersection
there
may
be
duplicates
in
the
result
and
isn
t
required
at
all
as
we
ve
seen
python
s
set
data
type
provides
a
built
in
intersection
operation
indeed
the
function
could
be
replaced
with
a
single
list
comprehension
expression
as
it
exhibits
the
classic
loop
collector
code
pattern
x
for
x
in
s
if
x
in
s
s
a
m
as
a
function
basics
example
though
it
does
the
job
this
single
piece
of
code
can
apply
to
an
entire
range
of
object
types
as
the
next
section
explains
polymorphism
revisited
like
all
functions
in
python
intersect
is
polymorphic
that
is
it
works
on
arbitrary
types
as
long
as
they
support
the
expected
object
interface
x
intersect
x
mixed
types
saved
result
object
this
time
we
passed
in
different
types
of
objects
to
our
function
a
list
and
a
tuple
mixed
types
and
it
still
picked
out
the
common
items
because
you
don
t
have
to
specify
the
types
of
arguments
ahead
of
time
the
intersect
function
happily
iterates
through
any
kind
of
sequence
objects
you
send
it
as
long
as
they
support
the
expected
interfaces
for
intersect
this
means
that
the
first
argument
has
to
support
the
for
loop
and
the
second
has
to
support
the
in
membership
test
any
two
such
objects
will
work
regardless
of
their
specific
types
that
includes
physically
stored
sequences
like
strings
a
second
example
intersecting
sequences
and
lists
all
the
iterable
objects
we
met
in
chapter
including
files
and
dictionaries
and
even
any
class
based
objects
we
code
that
apply
operator
overloading
techniques
we
ll
discuss
these
later
in
the
book
here
again
if
we
pass
in
objects
that
do
not
support
these
interfaces
e
g
numbers
python
will
automatically
detect
the
mismatch
and
raise
an
exception
for
us
which
is
exactly
what
we
want
and
the
best
we
could
do
on
our
own
if
we
coded
explicit
type
tests
by
not
coding
type
tests
and
allowing
python
to
detect
the
mismatches
for
us
we
both
reduce
the
amount
of
code
we
need
to
write
and
increase
our
code
s
flexibility
local
variables
probably
the
most
interesting
part
of
this
example
is
its
names
it
turns
out
that
the
variable
res
inside
intersect
is
what
in
python
is
called
a
local
variable
a
name
that
is
visible
only
to
code
inside
the
function
def
and
that
exists
only
while
the
function
runs
in
fact
because
all
names
assigned
in
any
way
inside
a
function
are
classified
as
local
variables
by
default
nearly
all
the
names
in
intersect
are
local
variables
res
is
obviously
assigned
so
it
is
a
local
variable
arguments
are
passed
by
assignment
so
seq
and
seq
are
too
the
for
loop
assigns
items
to
a
variable
so
the
name
x
is
also
local
all
these
local
variables
appear
when
the
function
is
called
and
disappear
when
the
function
exits
the
return
statement
at
the
end
of
intersect
sends
back
the
result
object
but
the
name
res
goes
away
to
fully
explore
the
notion
of
locals
though
we
need
to
move
on
to
chapter
chapter
summary
this
chapter
introduced
the
core
ideas
behind
function
definition
the
syntax
and
operation
of
the
def
and
return
statements
the
behavior
of
function
call
expressions
and
the
notion
and
benefits
of
polymorphism
in
python
functions
as
we
saw
a
def
statement
is
executable
code
that
creates
a
function
object
at
runtime
when
the
function
is
later
called
objects
are
passed
into
it
by
assignment
recall
that
assignment
means
object
reference
in
python
which
as
we
learned
in
chapter
really
means
pointer
internally
and
computed
values
are
sent
back
by
return
we
also
began
this
code
will
always
work
if
we
intersect
files
contents
obtained
with
file
readlines
it
may
not
work
to
intersect
lines
in
open
input
files
directly
though
depending
on
the
file
object
s
implementation
of
the
in
operator
or
general
iteration
files
must
generally
be
rewound
e
g
with
a
file
seek
or
another
open
after
they
have
been
read
to
end
of
file
once
as
we
ll
see
in
chapter
when
we
study
operator
overloading
classes
implement
the
in
operator
either
by
providing
the
specific
contains
method
or
by
supporting
the
general
iteration
protocol
with
the
iter
or
older
getitem
methods
if
coded
classes
can
define
what
iteration
means
for
their
data
chapter
function
basics
exploring
the
concepts
of
local
variables
and
scopes
in
this
chapter
but
we
ll
save
all
the
details
on
those
topics
for
chapter
first
though
a
quick
quiz
test
your
knowledge
quiz
what
is
the
point
of
coding
functions
at
what
time
does
python
create
a
function
what
does
a
function
return
if
it
has
no
return
statement
in
it
when
does
the
code
nested
inside
the
function
definition
statement
run
what
s
wrong
with
checking
the
types
of
objects
passed
into
a
function
test
your
knowledge
answers
functions
are
the
most
basic
way
of
avoiding
code
redundancy
in
python
factoring
code
into
functions
means
that
we
have
only
one
copy
of
an
operation
s
code
to
update
in
the
future
functions
are
also
the
basic
unit
of
code
reuse
in
python
wrapping
code
in
functions
makes
it
a
reusable
tool
callable
in
a
variety
of
programs
finally
functions
allow
us
to
divide
a
complex
system
into
manageable
parts
each
of
which
may
be
developed
individually
a
function
is
created
when
python
reaches
and
runs
the
def
statement
this
statement
creates
a
function
object
and
assigns
it
the
function
s
name
this
normally
happens
when
the
enclosing
module
file
is
imported
by
another
module
recall
that
imports
run
the
code
in
a
file
from
top
to
bottom
including
any
defs
but
it
can
also
occur
when
a
def
is
typed
interactively
or
nested
in
other
statements
such
as
ifs
a
function
returns
the
none
object
by
default
if
the
control
flow
falls
off
the
end
of
the
function
body
without
running
into
a
return
statement
such
functions
are
usually
called
with
expression
statements
as
assigning
their
none
results
to
variables
is
generally
pointless
the
function
body
the
code
nested
inside
the
function
definition
statement
is
run
when
the
function
is
later
called
with
a
call
expression
the
body
runs
anew
each
time
the
function
is
called
checking
the
types
of
objects
passed
into
a
function
effectively
breaks
the
function
s
flexibility
constraining
the
function
to
work
on
specific
types
only
without
such
checks
the
function
would
likely
be
able
to
process
an
entire
range
of
object
types
any
objects
that
support
the
interface
expected
by
the
function
will
work
the
term
interface
means
the
set
of
methods
and
expression
operators
the
function
s
code
runs
test
your
knowledge
answers
chapter
scopes
chapter
introduced
basic
function
definitions
and
calls
as
we
saw
python
s
basic
function
model
is
simple
to
use
but
even
simple
function
examples
quickly
led
us
to
questions
about
the
meaning
of
variables
in
our
code
this
chapter
moves
on
to
present
the
details
behind
python
s
scopes
the
places
where
variables
are
defined
and
looked
up
as
we
ll
see
the
place
where
a
name
is
assigned
in
our
code
is
crucial
to
determining
what
the
name
means
we
ll
also
find
that
scope
usage
can
have
a
major
impact
on
program
maintenance
effort
overuse
of
globals
for
example
is
a
generally
bad
thing
python
scope
basics
now
that
you
re
ready
to
start
writing
your
own
functions
we
need
to
get
more
formal
about
what
names
mean
in
python
when
you
use
a
name
in
a
program
python
creates
changes
or
looks
up
the
name
in
what
is
known
as
a
namespace
a
place
where
names
live
when
we
talk
about
the
search
for
a
name
s
value
in
relation
to
code
the
term
scope
refers
to
a
namespace
that
is
the
location
of
a
name
s
assignment
in
your
code
determines
the
scope
of
the
name
s
visibility
to
your
code
just
about
everything
related
to
names
including
scope
classification
happens
at
assignment
time
in
python
as
we
ve
seen
names
in
python
spring
into
existence
when
they
are
first
assigned
values
and
they
must
be
assigned
before
they
are
used
because
names
are
not
declared
ahead
of
time
python
uses
the
location
of
the
assignment
of
a
name
to
associate
it
with
i
e
bind
it
to
a
particular
namespace
in
other
words
the
place
where
you
assign
a
name
in
your
source
code
determines
the
namespace
it
will
live
in
and
hence
its
scope
of
visibility
besides
packaging
code
functions
add
an
extra
namespace
layer
to
your
programs
by
default
all
names
assigned
inside
a
function
are
associated
with
that
function
s
namespace
and
no
other
this
means
that
names
defined
inside
a
def
can
only
be
seen
by
the
code
within
that
def
you
cannot
even
refer
to
such
names
from
outside
the
function
names
defined
inside
a
def
do
not
clash
with
variables
outside
the
def
even
if
the
same
names
are
used
elsewhere
a
name
x
assigned
outside
a
given
def
i
e
in
a
different
def
or
at
the
top
level
of
a
module
file
is
a
completely
different
variable
from
a
name
x
assigned
inside
that
def
in
all
cases
the
scope
of
a
variable
where
it
can
be
used
is
always
determined
by
where
it
is
assigned
in
your
source
code
and
has
nothing
to
do
with
which
functions
call
which
in
fact
as
we
ll
learn
in
this
chapter
variables
may
be
assigned
in
three
different
places
corresponding
to
three
different
scopes
if
a
variable
is
assigned
inside
a
def
it
is
local
to
that
function
if
a
variable
is
assigned
in
an
enclosing
def
it
is
nonlocal
to
nested
functions
if
a
variable
is
assigned
outside
all
defs
it
is
global
to
the
entire
file
we
call
this
lexical
scoping
because
variable
scopes
are
determined
entirely
by
the
locations
of
the
variables
in
the
source
code
of
your
program
files
not
by
function
calls
for
example
in
the
following
module
file
the
x
assignment
creates
a
global
variable
named
x
visible
everywhere
in
this
file
but
the
x
assignment
creates
a
local
variable
x
visible
only
within
the
def
statement
x
def
func
x
even
though
both
variables
are
named
x
their
scopes
make
them
different
the
net
effect
is
that
function
scopes
help
to
avoid
name
clashes
in
your
programs
and
help
to
make
functions
more
self
contained
program
units
scope
rules
before
we
started
writing
functions
all
the
code
we
wrote
was
at
the
top
level
of
a
module
i
e
not
nested
in
a
def
so
the
names
we
used
either
lived
in
the
module
itself
or
were
built
ins
predefined
by
python
e
g
open
functions
provide
nested
namespaces
scopes
that
localize
the
names
they
use
such
that
names
inside
a
function
won
t
clash
with
those
outside
it
in
a
module
or
another
function
again
functions
define
a
local
scope
and
modules
define
a
global
scope
the
two
scopes
are
related
as
follows
the
enclosing
module
is
a
global
scope
each
module
is
a
global
scope
that
is
a
namespace
in
which
variables
created
assigned
at
the
top
level
of
the
module
file
live
global
variables
become
attributes
of
a
module
object
to
the
outside
world
but
can
be
used
as
simple
variables
within
a
module
file
the
global
scope
spans
a
single
file
only
don
t
be
fooled
by
the
word
global
here
names
at
the
top
level
of
a
file
are
only
global
to
code
within
that
single
file
there
is
really
no
notion
of
a
single
all
encompassing
global
file
based
scope
in
chapter
scopes
python
instead
names
are
partitioned
into
modules
and
you
must
always
import
a
module
explicitly
if
you
want
to
be
able
to
use
the
names
its
file
defines
when
you
hear
global
in
python
think
module
each
call
to
a
function
creates
a
new
local
scope
every
time
you
call
a
function
you
create
a
new
local
scope
that
is
a
namespace
in
which
the
names
created
inside
that
function
will
usually
live
you
can
think
of
each
def
statement
and
lambda
expression
as
defining
a
new
local
scope
but
because
python
allows
functions
to
call
themselves
to
loop
an
advanced
technique
known
as
recursion
the
local
scope
in
fact
technically
corresponds
to
a
function
call
in
other
words
each
call
creates
a
new
local
namespace
recursion
is
useful
when
processing
structures
whose
shapes
can
t
be
predicted
ahead
of
time
assigned
names
are
local
unless
declared
global
or
nonlocal
by
default
all
the
names
assigned
inside
a
function
definition
are
put
in
the
local
scope
the
namespace
associated
with
the
function
call
if
you
need
to
assign
a
name
that
lives
at
the
top
level
of
the
module
enclosing
the
function
you
can
do
so
by
declaring
it
in
a
global
statement
inside
the
function
if
you
need
to
assign
a
name
that
lives
in
an
enclosing
def
as
of
python
you
can
do
so
by
declaring
it
in
a
nonlocal
statement
all
other
names
are
enclosing
function
locals
globals
or
built
ins
names
not
assigned
a
value
in
the
function
definition
are
assumed
to
be
enclosing
scope
locals
in
an
enclosing
def
globals
in
the
enclosing
module
s
namespace
or
builtins
in
the
predefined
builtin
module
python
provides
there
are
a
few
subtleties
to
note
here
first
keep
in
mind
that
code
typed
at
the
interactive
command
prompt
follows
these
same
rules
you
may
not
know
it
yet
but
code
run
interactively
is
really
entered
into
a
built
in
module
called
main
this
module
works
just
like
a
module
file
but
results
are
echoed
as
you
go
because
of
this
interactively
created
names
live
in
a
module
too
and
thus
follow
the
normal
scope
rules
they
are
global
to
the
interactive
session
you
ll
learn
more
about
modules
in
the
next
part
of
this
book
also
note
that
any
type
of
assignment
within
a
function
classifies
a
name
as
local
this
includes
statements
module
names
in
import
function
names
in
def
function
argument
names
and
so
on
if
you
assign
a
name
in
any
way
within
a
def
it
will
become
a
local
to
that
function
conversely
in
place
changes
to
objects
do
not
classify
names
as
locals
only
actual
name
assignments
do
for
instance
if
the
name
l
is
assigned
to
a
list
at
the
top
level
of
a
module
a
statement
l
x
within
a
function
will
classify
l
as
a
local
but
l
append
x
will
not
in
the
latter
case
we
are
changing
the
list
object
that
l
references
not
l
itself
l
is
found
in
the
global
scope
as
usual
and
python
happily
modifies
it
without
requiring
a
global
or
nonlocal
declaration
as
usual
it
helps
to
keep
the
distinction
between
names
and
objects
clear
changing
an
object
is
not
an
assignment
to
a
name
python
scope
basics
name
resolution
the
legb
rule
if
the
prior
section
sounds
confusing
it
really
boils
down
to
three
simple
rules
with
a
def
statement
name
references
search
at
most
four
scopes
local
then
enclosing
functions
if
any
then
global
then
built
in
name
assignments
create
or
change
local
names
by
default
global
and
nonlocal
declarations
map
assigned
names
to
enclosing
module
and
function
scopes
in
other
words
all
names
assigned
inside
a
function
def
statement
or
a
lambda
an
expression
we
ll
meet
later
are
locals
by
default
functions
can
freely
use
names
assigned
in
syntactically
enclosing
functions
and
the
global
scope
but
they
must
declare
such
nonlocals
and
globals
in
order
to
change
them
python
s
name
resolution
scheme
is
sometimes
called
the
legb
rule
after
the
scope
names
when
you
use
an
unqualified
name
inside
a
function
python
searches
up
to
four
scopes
the
local
l
scope
then
the
local
scopes
of
any
enclosing
e
defs
and
lambdas
then
the
global
g
scope
and
then
the
built
in
b
scope
and
stops
at
the
first
place
the
name
is
found
if
the
name
is
not
found
during
this
search
python
reports
an
error
as
we
learned
in
chapter
names
must
be
assigned
before
they
can
be
used
when
you
assign
a
name
in
a
function
instead
of
just
referring
to
it
in
an
expression
python
always
creates
or
changes
the
name
in
the
local
scope
unless
it
s
declared
to
be
global
or
nonlocal
in
that
function
when
you
assign
a
name
outside
any
function
i
e
at
the
top
level
of
a
module
file
or
at
the
interactive
prompt
the
local
scope
is
the
same
as
the
global
scope
the
module
s
namespace
figure
illustrates
python
s
four
scopes
note
that
the
second
scope
lookup
layer
e
the
scopes
of
enclosing
defs
or
lambdas
can
technically
correspond
to
more
than
one
lookup
layer
this
case
only
comes
into
play
when
you
nest
functions
within
functions
and
it
is
addressed
by
the
nonlocal
statement
also
keep
in
mind
that
these
rules
apply
only
to
simple
variable
names
e
g
spam
in
parts
v
and
vi
we
ll
see
that
qualified
attribute
names
e
g
object
spam
live
in
particular
objects
and
follow
a
completely
different
set
of
lookup
rules
than
those
the
scope
lookup
rule
was
called
the
lgb
rule
in
the
first
edition
of
this
book
the
enclosing
def
e
layer
was
added
later
in
python
to
obviate
the
task
of
passing
in
enclosing
scope
names
explicitly
with
default
arguments
a
topic
usually
of
marginal
interest
to
python
beginners
that
we
ll
defer
until
later
in
this
chapter
since
this
scope
is
addressed
by
the
nonlocal
statement
in
python
i
suppose
the
lookup
rule
might
now
be
better
named
lngb
but
backward
compatibility
matters
in
books
too
chapter
scopes
figure
the
legb
scope
lookup
rule
when
a
variable
is
referenced
python
searches
for
it
in
this
order
in
the
local
scope
in
any
enclosing
functions
local
scopes
in
the
global
scope
and
finally
in
the
built
in
scope
the
first
occurrence
wins
the
place
in
your
code
where
a
variable
is
assigned
usually
determines
its
scope
in
python
nonlocal
declarations
can
also
force
names
to
be
mapped
to
enclosing
function
scopes
whether
assigned
or
not
covered
here
references
to
attribute
names
following
periods
search
one
or
more
objects
not
scopes
and
may
invoke
something
called
inheritance
more
on
this
in
part
vi
of
this
book
scope
example
let
s
look
at
a
larger
example
that
demonstrates
scope
ideas
suppose
we
wrote
the
following
code
in
a
module
file
global
scope
x
x
and
func
assigned
in
module
global
def
func
y
local
scope
z
x
y
return
z
y
and
z
assigned
in
function
locals
func
func
in
module
result
x
is
a
global
this
module
and
the
function
it
contains
use
a
number
of
names
to
do
their
business
using
python
s
scope
rules
we
can
classify
the
names
as
follows
global
names
x
func
x
is
global
because
it
s
assigned
at
the
top
level
of
the
module
file
it
can
be
referenced
inside
the
function
without
being
declared
global
func
is
global
for
the
same
reason
the
def
statement
assigns
a
function
object
to
the
name
func
at
the
top
level
of
the
module
python
scope
basics
local
names
y
z
y
and
z
are
local
to
the
function
and
exist
only
while
the
function
runs
because
they
are
both
assigned
values
in
the
function
definition
z
by
virtue
of
the
statement
and
y
because
arguments
are
always
passed
by
assignment
the
whole
point
behind
this
name
segregation
scheme
is
that
local
variables
serve
as
temporary
names
that
you
need
only
while
a
function
is
running
for
instance
in
the
preceding
example
the
argument
y
and
the
addition
result
z
exist
only
inside
the
function
these
names
don
t
interfere
with
the
enclosing
module
s
namespace
or
any
other
function
for
that
matter
the
local
global
distinction
also
makes
functions
easier
to
understand
as
most
of
the
names
a
function
uses
appear
in
the
function
itself
not
at
some
arbitrary
place
in
a
module
also
because
you
can
be
sure
that
local
names
will
not
be
changed
by
some
remote
function
in
your
program
they
tend
to
make
programs
easier
to
debug
and
modify
the
built
in
scope
we
ve
been
talking
about
the
built
in
scope
in
the
abstract
but
it
s
a
bit
simpler
than
you
may
think
really
the
built
in
scope
is
just
a
built
in
module
called
builtins
but
you
have
to
import
builtins
to
query
built
ins
because
the
name
builtins
is
not
itself
built
in
no
i
m
serious
the
built
in
scope
is
implemented
as
a
standard
library
module
named
builtins
but
that
name
itself
is
not
placed
in
the
built
in
scope
so
you
have
to
import
it
in
order
to
inspect
it
once
you
do
you
can
run
a
dir
call
to
see
which
names
are
predefined
in
python
import
builtins
dir
builtins
arithmeticerror
assertionerror
attributeerror
baseexception
buffererror
byteswarning
deprecationwarning
eoferror
ellipsis
many
more
names
omitted
print
property
quit
range
repr
reversed
round
set
setattr
slice
sorted
staticmethod
str
sum
super
tuple
type
vars
zip
the
names
in
this
list
constitute
the
built
in
scope
in
python
roughly
the
first
half
are
built
in
exceptions
and
the
second
half
are
built
in
functions
also
in
this
list
are
the
special
names
none
true
and
false
though
they
are
treated
as
reserved
words
because
python
automatically
searches
this
module
last
in
its
legb
lookup
you
get
all
the
names
in
this
list
for
free
that
is
you
can
use
them
without
importing
any
modules
thus
there
are
really
two
ways
to
refer
to
a
built
in
function
by
taking
advantage
of
the
legb
rule
or
by
manually
importing
the
builtins
module
zip
class
zip
chapter
scopes
the
normal
way
import
builtins
builtins
zip
class
zip
the
hard
way
the
second
of
these
approaches
is
sometimes
useful
in
advanced
work
the
careful
reader
might
also
notice
that
because
the
legb
lookup
procedure
takes
the
first
occurrence
of
a
name
that
it
finds
names
in
the
local
scope
may
override
variables
of
the
same
name
in
both
the
global
and
built
in
scopes
and
global
names
may
override
builtins
a
function
can
for
instance
create
a
local
variable
called
open
by
assigning
to
it
def
hider
open
spam
open
data
txt
local
variable
hides
built
in
this
won
t
open
a
file
now
in
this
scope
however
this
will
hide
the
built
in
function
called
open
that
lives
in
the
built
in
outer
scope
it
s
also
usually
a
bug
and
a
nasty
one
at
that
because
python
will
not
issue
a
warning
message
about
it
there
are
times
in
advanced
programming
where
you
may
really
want
to
replace
a
built
in
name
by
redefining
it
in
your
code
functions
can
similarly
hide
global
variables
of
the
same
name
with
locals
x
global
x
def
func
x
local
x
hides
global
func
print
x
prints
unchanged
here
the
assignment
within
the
function
creates
a
local
x
that
is
a
completely
different
variable
from
the
global
x
in
the
module
outside
the
function
because
of
this
there
is
no
way
to
change
a
name
outside
a
function
without
adding
a
global
or
nonlocal
declaration
to
the
def
as
described
in
the
next
section
version
skew
note
actually
the
tongue
twisting
gets
a
bit
worse
the
python
builtins
module
used
here
is
named
builtin
in
python
and
just
for
fun
the
name
builtins
with
the
s
is
preset
in
most
global
scopes
including
the
interactive
session
to
reference
the
module
known
as
builtins
a
k
a
builtin
in
that
is
after
importing
builtins
builtins
is
builtins
is
true
in
and
builtins
is
builtin
is
true
in
the
net
effect
is
that
we
can
inspect
the
built
in
scope
by
simply
running
dir
builtins
with
no
import
in
both
and
but
we
are
advised
to
use
builtins
for
real
work
in
who
said
documenting
this
stuff
was
easy
python
scope
basics
breaking
the
universe
in
python
here
s
another
thing
you
can
do
in
python
that
you
probably
shouldn
t
because
the
names
true
and
false
in
are
just
variables
in
the
built
in
scope
and
are
not
reserved
it
s
possible
to
reassign
them
with
a
statement
like
true
false
don
t
worry
you
won
t
actually
break
the
logical
consistency
of
the
universe
in
so
doing
this
statement
merely
redefines
the
word
true
for
the
single
scope
in
which
it
appears
all
other
scopes
still
find
the
originals
in
the
built
in
scope
for
more
fun
though
in
python
you
could
say
builtin
true
false
to
reset
true
to
false
for
the
entire
python
process
alas
this
type
of
assignment
has
been
disallowed
in
python
because
true
and
false
are
treated
as
actual
reserved
words
just
like
none
in
though
it
sends
idle
into
a
strange
panic
state
that
resets
the
user
code
process
this
technique
can
be
useful
however
both
to
illustrate
the
underlying
namespace
model
and
for
tool
writers
who
must
change
built
ins
such
as
open
to
customized
functions
also
note
that
third
party
tools
such
as
pychecker
will
warn
about
common
programming
mistakes
including
accidental
assignment
to
built
in
names
this
is
known
as
shadowing
a
built
in
in
pychecker
the
global
statement
the
global
statement
and
its
nonlocal
cousin
are
the
only
things
that
are
remotely
like
declaration
statements
in
python
they
are
not
type
or
size
declarations
though
they
are
namespace
declarations
the
global
statement
tells
python
that
a
function
plans
to
change
one
or
more
global
names
i
e
names
that
live
in
the
enclosing
module
s
scope
namespace
we
ve
talked
about
global
in
passing
already
here
s
a
summary
global
names
are
variables
assigned
at
the
top
level
of
the
enclosing
module
file
global
names
must
be
declared
only
if
they
are
assigned
within
a
function
global
names
may
be
referenced
within
a
function
without
being
declared
in
other
words
global
allows
us
to
change
names
that
live
outside
a
def
at
the
top
level
of
a
module
file
as
we
ll
see
later
the
nonlocal
statement
is
almost
identical
but
applies
to
names
in
the
enclosing
def
s
local
scope
rather
than
names
in
the
enclosing
module
the
global
statement
consists
of
the
keyword
global
followed
by
one
or
more
names
separated
by
commas
all
the
listed
names
will
be
mapped
to
the
enclosing
module
s
scope
when
assigned
or
referenced
within
the
function
body
for
instance
x
global
x
def
func
global
x
x
global
x
outside
def
chapter
scopes
func
print
x
prints
we
ve
added
a
global
declaration
to
the
example
here
such
that
the
x
inside
the
def
now
refers
to
the
x
outside
the
def
they
are
the
same
variable
this
time
here
is
a
slightly
more
involved
example
of
global
at
work
y
z
def
all
global
global
x
x
y
z
global
variables
in
module
declare
globals
assigned
no
need
to
declare
y
z
legb
rule
here
x
y
and
z
are
all
globals
inside
the
function
all
global
y
and
z
are
global
because
they
aren
t
assigned
in
the
function
x
is
global
because
it
was
listed
in
a
global
statement
to
map
it
to
the
module
s
scope
explicitly
without
the
global
here
x
would
be
considered
local
by
virtue
of
the
assignment
notice
that
y
and
z
are
not
declared
global
python
s
legb
lookup
rule
finds
them
in
the
module
automatically
also
notice
that
x
might
not
exist
in
the
enclosing
module
before
the
function
runs
in
this
case
the
assignment
in
the
function
creates
x
in
the
module
minimize
global
variables
by
default
names
assigned
in
functions
are
locals
so
if
you
want
to
change
names
outside
functions
you
have
to
write
extra
code
e
g
global
statements
this
is
by
design
as
is
common
in
python
you
have
to
say
more
to
do
the
potentially
wrong
thing
although
there
are
times
when
globals
are
useful
variables
assigned
in
a
def
are
local
by
default
because
that
is
normally
the
best
policy
changing
globals
can
lead
to
well
known
software
engineering
problems
because
the
variables
values
are
dependent
on
the
order
of
calls
to
arbitrarily
distant
functions
programs
can
become
difficult
to
debug
consider
this
module
file
for
example
x
def
func
global
x
x
def
func
global
x
x
now
imagine
that
it
is
your
job
to
modify
or
reuse
this
module
file
what
will
the
value
of
x
be
here
really
that
question
has
no
meaning
unless
it
s
qualified
with
a
point
of
reference
in
time
the
value
of
x
is
timing
dependent
as
it
depends
on
which
function
was
called
last
something
we
can
t
tell
from
this
file
alone
the
global
statement
the
net
effect
is
that
to
understand
this
code
you
have
to
trace
the
flow
of
control
through
the
entire
program
and
if
you
need
to
reuse
or
modify
the
code
you
have
to
keep
the
entire
program
in
your
head
all
at
once
in
this
case
you
can
t
really
use
one
of
these
functions
without
bringing
along
the
other
they
are
dependent
on
that
is
coupled
with
the
global
variable
this
is
the
problem
with
globals
they
generally
make
code
more
difficult
to
understand
and
use
than
code
consisting
of
self
contained
functions
that
rely
on
locals
on
the
other
hand
short
of
using
object
oriented
programming
and
classes
global
variables
are
probably
the
most
straightforward
way
to
retain
shared
state
information
information
that
a
function
needs
to
remember
for
use
the
next
time
it
is
called
in
python
local
variables
disappear
when
the
function
returns
but
globals
do
not
other
techniques
such
as
default
mutable
arguments
and
enclosing
function
scopes
can
achieve
this
too
but
they
are
more
complex
than
pushing
values
out
to
the
global
scope
for
retention
some
programs
designate
a
single
module
to
collect
globals
as
long
as
this
is
expected
it
is
not
as
harmful
in
addition
programs
that
use
multithreading
to
do
parallel
processing
in
python
commonly
depend
on
global
variables
they
become
shared
memory
between
functions
running
in
parallel
threads
and
so
act
as
a
communication
device
for
now
though
especially
if
you
are
relatively
new
to
programming
avoid
the
temptation
to
use
globals
whenever
you
can
try
to
communicate
with
passed
in
arguments
and
return
values
instead
six
months
from
now
both
you
and
your
coworkers
will
be
happy
you
did
minimize
cross
file
changes
here
s
another
scope
related
issue
although
we
can
change
variables
in
another
file
directly
we
usually
shouldn
t
module
files
were
introduced
in
chapter
and
are
covered
in
more
depth
in
the
next
part
of
this
book
to
illustrate
their
relationship
to
scopes
consider
these
two
module
files
first
py
x
this
code
doesn
t
know
about
second
py
second
py
import
first
print
first
x
first
x
okay
references
a
name
in
another
file
but
changing
it
can
be
too
subtle
and
implicit
multithreading
runs
function
calls
in
parallel
with
the
rest
of
the
program
and
is
supported
by
python
s
standard
library
modules
thread
threading
and
queue
thread
threading
and
queue
in
python
because
all
threaded
functions
run
in
the
same
process
global
scopes
often
serve
as
shared
memory
between
them
threading
is
commonly
used
for
long
running
tasks
in
guis
to
implement
nonblocking
operations
in
general
and
to
leverage
cpu
capacity
it
is
also
beyond
this
book
s
scope
see
the
python
library
manual
as
well
as
the
follow
up
texts
listed
in
the
preface
such
as
o
reilly
s
programming
python
for
more
details
chapter
scopes
the
first
defines
a
variable
x
which
the
second
prints
and
then
changes
by
assignment
notice
that
we
must
import
the
first
module
into
the
second
file
to
get
to
its
variable
at
all
as
we
ve
learned
each
module
is
a
self
contained
namespace
package
of
variables
and
we
must
import
one
module
to
see
inside
it
from
another
that
s
the
main
point
about
modules
by
segregating
variables
on
a
per
file
basis
they
avoid
name
collisions
across
files
really
though
in
terms
of
this
chapter
s
topic
the
global
scope
of
a
module
file
becomes
the
attribute
namespace
of
the
module
object
once
it
is
imported
importers
automatically
have
access
to
all
of
the
file
s
global
variables
because
a
file
s
global
scope
morphs
into
an
object
s
attribute
namespace
when
it
is
imported
after
importing
the
first
module
the
second
module
prints
its
variable
and
then
assigns
it
a
new
value
referencing
the
module
s
variable
to
print
it
is
fine
this
is
how
modules
are
linked
together
into
a
larger
system
normally
the
problem
with
the
assignment
however
is
that
it
is
far
too
implicit
whoever
s
charged
with
maintaining
or
reusing
the
first
module
probably
has
no
clue
that
some
arbitrarily
far
removed
module
on
the
import
chain
can
change
x
out
from
under
him
at
runtime
in
fact
the
second
module
may
be
in
a
completely
different
directory
and
so
difficult
to
notice
at
all
although
such
cross
file
variable
changes
are
always
possible
in
python
they
are
usually
much
more
subtle
than
you
will
want
again
this
sets
up
too
strong
a
coupling
between
the
two
files
because
they
are
both
dependent
on
the
value
of
the
variable
x
it
s
difficult
to
understand
or
reuse
one
file
without
the
other
such
implicit
cross
file
dependencies
can
lead
to
inflexible
code
at
best
and
outright
bugs
at
worst
here
again
the
best
prescription
is
generally
to
not
do
this
the
best
way
to
communicate
across
file
boundaries
is
to
call
functions
passing
in
arguments
and
getting
back
return
values
in
this
specific
case
we
would
probably
be
better
off
coding
an
accessor
function
to
manage
the
change
first
py
x
def
setx
new
global
x
x
new
second
py
import
first
first
setx
this
requires
more
code
and
may
seem
like
a
trivial
change
but
it
makes
a
huge
difference
in
terms
of
readability
and
maintainability
when
a
person
reading
the
first
module
by
itself
sees
a
function
that
person
will
know
that
it
is
a
point
of
interface
and
will
expect
the
change
to
the
x
in
other
words
it
removes
the
element
of
surprise
that
is
rarely
a
good
thing
in
software
projects
although
we
cannot
prevent
cross
file
changes
from
happening
common
sense
dictates
that
they
should
be
minimized
unless
widely
accepted
across
the
program
the
global
statement
other
ways
to
access
globals
interestingly
because
global
scope
variables
morph
into
the
attributes
of
a
loaded
module
object
we
can
emulate
the
global
statement
by
importing
the
enclosing
module
and
assigning
to
its
attributes
as
in
the
following
example
module
file
code
in
this
file
imports
the
enclosing
module
first
by
name
and
then
by
indexing
the
sys
modules
loaded
modules
table
more
on
this
table
in
chapter
thismod
py
var
global
variable
module
attribute
def
local
var
change
local
var
def
glob
global
var
var
declare
global
normal
change
global
var
def
glob
var
import
thismod
thismod
var
change
local
var
import
myself
change
global
var
def
glob
var
import
sys
glob
sys
modules
thismod
glob
var
change
local
var
import
system
table
get
module
object
or
use
name
change
global
var
def
test
print
var
local
glob
glob
glob
print
var
when
run
this
adds
to
the
global
variable
only
the
first
function
does
not
impact
it
import
thismod
thismod
test
thismod
var
this
works
and
it
illustrates
the
equivalence
of
globals
to
module
attributes
but
it
s
much
more
work
than
using
the
global
statement
to
make
your
intentions
explicit
as
we
ve
seen
global
allows
us
to
change
names
in
a
module
outside
a
function
it
has
a
cousin
named
nonlocal
that
can
be
used
to
change
names
in
enclosing
functions
too
but
to
understand
how
that
can
be
useful
we
first
need
to
explore
enclosing
functions
in
general
chapter
scopes
scopes
and
nested
functions
so
far
i
ve
omitted
one
part
of
python
s
scope
rules
on
purpose
because
it
s
relatively
rare
to
encounter
it
in
practice
however
it
s
time
to
take
a
deeper
look
at
the
letter
e
in
the
legb
lookup
rule
the
e
layer
is
fairly
new
it
was
added
in
python
it
takes
the
form
of
the
local
scopes
of
any
and
all
enclosing
function
defs
enclosing
scopes
are
sometimes
also
called
statically
nested
scopes
really
the
nesting
is
a
lexical
one
nested
scopes
correspond
to
physically
and
syntactically
nested
code
structures
in
your
program
s
source
code
nested
scope
details
with
the
addition
of
nested
function
scopes
variable
lookup
rules
become
slightly
more
complex
within
a
function
a
reference
x
looks
for
the
name
x
first
in
the
current
local
scope
function
then
in
the
local
scopes
of
any
lexically
enclosing
functions
in
your
source
code
from
inner
to
outer
then
in
the
current
global
scope
the
module
file
and
finally
in
the
built
in
scope
the
module
builtins
global
declarations
make
the
search
begin
in
the
global
module
file
scope
instead
an
assignment
x
value
creates
or
changes
the
name
x
in
the
current
local
scope
by
default
if
x
is
declared
global
within
the
function
the
assignment
creates
or
changes
the
name
x
in
the
enclosing
module
s
scope
instead
if
on
the
other
hand
x
is
declared
nonlocal
within
the
function
the
assignment
changes
the
name
x
in
the
closest
enclosing
function
s
local
scope
notice
that
the
global
declaration
still
maps
variables
to
the
enclosing
module
when
nested
functions
are
present
variables
in
enclosing
functions
may
be
referenced
but
they
require
nonlocal
declarations
to
be
changed
nested
scope
examples
to
clarify
the
prior
section
s
points
let
s
illustrate
with
some
real
code
here
is
what
an
enclosing
function
scope
looks
like
x
def
f
x
def
f
print
x
f
f
global
scope
name
not
used
enclosing
def
local
reference
made
in
nested
def
prints
enclosing
def
local
first
off
this
is
legal
python
code
the
def
is
simply
an
executable
statement
which
can
appear
anywhere
any
other
statement
can
including
nested
in
another
def
here
the
scopes
and
nested
functions
nested
def
runs
while
a
call
to
the
function
f
is
running
it
generates
a
function
and
assigns
it
to
the
name
f
a
local
variable
within
f
s
local
scope
in
a
sense
f
is
a
temporary
function
that
lives
only
during
the
execution
of
and
is
visible
only
to
code
in
the
enclosing
f
but
notice
what
happens
inside
f
when
it
prints
the
variable
x
it
refers
to
the
x
that
lives
in
the
enclosing
f
function
s
local
scope
because
functions
can
access
names
in
all
physically
enclosing
def
statements
the
x
in
f
is
automatically
mapped
to
the
x
in
f
by
the
legb
lookup
rule
this
enclosing
scope
lookup
works
even
if
the
enclosing
function
has
already
returned
for
example
the
following
code
defines
a
function
that
makes
and
returns
another
function
def
f
x
def
f
print
x
return
f
remembers
x
in
enclosing
def
scope
return
f
but
don
t
call
it
action
f
action
make
return
function
call
it
now
prints
in
this
code
the
call
to
action
is
really
running
the
function
we
named
f
when
f
ran
f
remembers
the
enclosing
scope
s
x
in
f
even
though
f
is
no
longer
active
factory
functions
depending
on
whom
you
ask
this
sort
of
behavior
is
also
sometimes
called
a
closure
or
factory
function
these
terms
refer
to
a
function
object
that
remembers
values
in
enclosing
scopes
regardless
of
whether
those
scopes
are
still
present
in
memory
although
classes
described
in
part
vi
of
this
book
are
usually
best
at
remembering
state
because
they
make
it
explicit
with
attribute
assignments
such
functions
provide
an
alternative
for
instance
factory
functions
are
sometimes
used
by
programs
that
need
to
generate
event
handlers
on
the
fly
in
response
to
conditions
at
runtime
e
g
user
inputs
that
cannot
be
anticipated
look
at
the
following
function
for
example
def
maker
n
def
action
x
return
x
n
return
action
make
and
return
action
action
retains
n
from
enclosing
scope
this
defines
an
outer
function
that
simply
generates
and
returns
a
nested
function
without
calling
it
if
we
call
the
outer
function
f
maker
f
function
action
at
x
b
chapter
scopes
pass
to
n
what
we
get
back
is
a
reference
to
the
generated
nested
function
the
one
created
by
running
the
nested
def
if
we
now
call
what
we
got
back
from
the
outer
function
f
f
pass
to
x
n
remembers
it
invokes
the
nested
function
the
one
called
action
within
maker
the
most
unusual
part
of
this
is
that
the
nested
function
remembers
integer
the
value
of
the
variable
n
in
maker
even
though
maker
has
returned
and
exited
by
the
time
we
call
action
in
effect
n
from
the
enclosing
local
scope
is
retained
as
state
information
attached
to
action
and
we
get
back
its
argument
squared
if
we
now
call
the
outer
function
again
we
get
back
a
new
nested
function
with
different
state
information
attached
that
is
we
get
the
argument
cubed
instead
of
squared
but
the
original
still
squares
as
before
g
maker
g
f
g
remembers
f
remembers
this
works
because
each
call
to
a
factory
function
like
this
gets
its
own
set
of
state
information
in
our
case
the
function
we
assign
to
name
g
remembers
and
f
remembers
because
each
has
its
own
state
information
retained
by
the
variable
n
in
maker
this
is
an
advanced
technique
that
you
re
unlikely
to
see
very
often
in
most
code
except
among
programmers
with
backgrounds
in
functional
programming
languages
on
the
other
hand
enclosing
scopes
are
often
employed
by
lambda
function
creation
expressions
discussed
later
in
this
chapter
because
they
are
expressions
they
are
almost
always
nested
within
a
def
moreover
function
nesting
is
commonly
used
for
decorators
explored
in
chapter
in
some
cases
it
s
the
most
reasonable
coding
pattern
as
a
general
rule
classes
are
better
at
memory
like
this
because
they
make
the
state
retention
explicit
in
attributes
short
of
using
classes
though
globals
enclosing
scope
references
like
these
and
default
arguments
are
the
main
ways
that
python
functions
can
retain
state
information
to
see
how
they
compete
chapter
provides
complete
coverage
of
defaults
but
the
next
section
gives
enough
of
an
introduction
to
get
us
started
retaining
enclosing
scopes
state
with
defaults
in
earlier
versions
of
python
the
sort
of
code
in
the
prior
section
failed
because
nested
defs
did
not
do
anything
about
scopes
a
reference
to
a
variable
within
f
would
search
only
the
local
f
then
global
the
code
outside
f
and
then
built
in
scopes
because
it
skipped
the
scopes
of
enclosing
functions
an
error
would
result
to
work
around
this
programmers
typically
used
default
argument
values
to
pass
in
and
remember
the
objects
in
an
enclosing
scope
scopes
and
nested
functions
def
f
x
def
f
x
x
print
x
f
remember
enclosing
scope
x
with
defaults
f
prints
this
code
works
in
all
python
releases
and
you
ll
still
see
this
pattern
in
some
existing
python
code
in
short
the
syntax
arg
val
in
a
def
header
means
that
the
argument
arg
will
default
to
the
value
val
if
no
real
value
is
passed
to
arg
in
a
call
in
the
modified
f
here
the
x
x
means
that
the
argument
x
will
default
to
the
value
of
x
in
the
enclosing
scope
because
the
second
x
is
evaluated
before
python
steps
into
the
nested
def
it
still
refers
to
the
x
in
f
in
effect
the
default
remembers
what
x
was
in
f
i
e
the
object
that
s
fairly
complex
and
it
depends
entirely
on
the
timing
of
default
value
evaluations
in
fact
the
nested
scope
lookup
rule
was
added
to
python
to
make
defaults
unnecessary
for
this
role
today
python
automatically
remembers
any
values
required
in
the
enclosing
scope
for
use
in
nested
defs
of
course
the
best
prescription
for
most
code
is
simply
to
avoid
nesting
defs
within
defs
as
it
will
make
your
programs
much
simpler
the
following
is
an
equivalent
of
the
prior
example
that
banishes
the
notion
of
nesting
notice
the
forward
reference
in
this
code
it
s
ok
to
call
a
function
defined
after
the
function
that
calls
it
as
long
as
the
second
def
runs
before
the
first
function
is
actually
called
code
inside
a
def
is
never
evaluated
until
the
function
is
actually
called
def
f
x
f
x
def
f
x
print
x
f
pass
x
along
instead
of
nesting
forward
reference
okay
if
you
avoid
nesting
this
way
you
can
almost
forget
about
the
nested
scopes
concept
in
python
unless
you
need
to
code
in
the
factory
function
style
discussed
earlier
at
least
for
def
statements
lambdas
which
almost
naturally
appear
nested
in
defs
often
rely
on
nested
scopes
as
the
next
section
explains
nested
scopes
and
lambdas
while
they
re
rarely
used
in
practice
for
defs
themselves
you
are
more
likely
to
care
about
nested
function
scopes
when
you
start
coding
lambda
expressions
we
won
t
cover
lambda
in
depth
until
chapter
but
in
short
it
s
an
expression
that
generates
a
new
function
to
be
called
later
much
like
a
def
statement
because
it
s
an
expression
chapter
scopes
though
it
can
be
used
in
places
that
def
cannot
such
as
within
list
and
dictionary
literals
like
a
def
a
lambda
expression
introduces
a
new
local
scope
for
the
function
it
creates
thanks
to
the
enclosing
scopes
lookup
layer
lambdas
can
see
all
the
variables
that
live
in
the
functions
in
which
they
are
coded
thus
the
following
code
works
but
only
because
the
nested
scope
rules
are
applied
def
func
x
action
lambda
n
x
n
return
action
x
func
print
x
x
remembered
from
enclosing
def
prints
prior
to
the
introduction
of
nested
function
scopes
programmers
used
defaults
to
pass
values
from
an
enclosing
scope
into
lambdas
just
as
for
defs
for
instance
the
following
works
on
all
python
releases
def
func
x
action
lambda
n
x
x
x
n
return
action
pass
x
in
manually
because
lambdas
are
expressions
they
naturally
and
even
normally
nest
inside
enclosing
defs
hence
they
are
perhaps
the
biggest
beneficiaries
of
the
addition
of
enclosing
function
scopes
in
the
lookup
rules
in
most
cases
it
is
no
longer
necessary
to
pass
values
into
lambdas
with
defaults
scopes
versus
defaults
with
loop
variables
there
is
one
notable
exception
to
the
rule
i
just
gave
if
a
lambda
or
def
defined
within
a
function
is
nested
inside
a
loop
and
the
nested
function
references
an
enclosing
scope
variable
that
is
changed
by
that
loop
all
functions
generated
within
the
loop
will
have
the
same
value
the
value
the
referenced
variable
had
in
the
last
loop
iteration
for
instance
the
following
attempts
to
build
up
a
list
of
functions
that
each
remember
the
current
variable
i
from
the
enclosing
scope
def
makeactions
acts
for
i
in
range
acts
append
lambda
x
i
x
return
acts
acts
makeactions
acts
function
lambda
at
x
b
b
tries
to
remember
each
i
all
remember
same
last
i
this
doesn
t
quite
work
though
because
the
enclosing
scope
variable
is
looked
up
when
the
nested
functions
are
later
called
they
all
effectively
remember
the
same
value
scopes
and
nested
functions
the
value
the
loop
variable
had
on
the
last
loop
iteration
that
is
we
get
back
to
the
power
of
for
each
function
in
the
list
because
i
is
the
same
in
all
of
them
all
are
value
of
last
i
acts
acts
acts
this
should
be
this
should
be
this
is
the
one
case
where
we
still
have
to
explicitly
retain
enclosing
scope
values
with
default
arguments
rather
than
enclosing
scope
references
that
is
to
make
this
sort
of
code
work
we
must
pass
in
the
current
value
of
the
enclosing
scope
s
variable
with
a
default
because
defaults
are
evaluated
when
the
nested
function
is
created
not
when
it
s
later
called
each
remembers
its
own
value
for
i
def
makeactions
acts
for
i
in
range
acts
append
lambda
x
i
i
i
x
return
acts
use
defaults
instead
remember
current
i
acts
makeactions
acts
acts
acts
this
is
a
fairly
obscure
case
but
it
can
come
up
in
practice
especially
in
code
that
generates
callback
handler
functions
for
a
number
of
widgets
in
a
gui
e
g
buttonpress
handlers
we
ll
talk
more
about
defaults
in
chapter
and
lambdas
in
chapter
so
you
may
want
to
return
and
review
this
section
later
arbitrary
scope
nesting
before
ending
this
discussion
i
should
note
that
scopes
may
nest
arbitrarily
but
only
enclosing
function
def
statements
not
classes
described
in
part
vi
are
searched
def
f
x
def
f
def
f
print
x
f
found
in
f
s
local
scope
in
the
section
function
gotchas
on
page
at
the
end
of
this
part
of
the
book
we
ll
also
see
that
there
is
an
issue
with
using
mutable
objects
like
lists
and
dictionaries
for
default
arguments
e
g
def
f
a
because
defaults
are
implemented
as
single
objects
attached
to
functions
mutable
defaults
retain
state
from
call
to
call
rather
then
being
initialized
anew
on
each
call
depending
on
whom
you
ask
this
is
either
considered
a
feature
that
supports
state
retention
or
a
strange
wart
on
the
language
more
on
this
at
the
end
of
chapter
chapter
scopes
f
f
python
will
search
the
local
scopes
of
all
enclosing
defs
from
inner
to
outer
after
the
referencing
function
s
local
scope
and
before
the
module
s
global
scope
or
built
ins
however
this
sort
of
code
is
even
less
likely
to
pop
up
in
practice
in
python
we
say
flat
is
better
than
nested
except
in
very
limited
contexts
your
life
and
the
lives
of
your
coworkers
will
generally
be
better
if
you
minimize
nested
function
definitions
the
nonlocal
statement
in
the
prior
section
we
explored
the
way
that
nested
functions
can
reference
variables
in
an
enclosing
function
s
scope
even
if
that
function
has
already
returned
it
turns
out
that
as
of
python
we
can
also
change
such
enclosing
scope
variables
as
long
as
we
declare
them
in
nonlocal
statements
with
this
statement
nested
defs
can
have
both
read
and
write
access
to
names
in
enclosing
functions
the
nonlocal
statement
is
a
close
cousin
to
global
covered
earlier
like
global
nonlocal
declares
that
a
name
will
be
changed
in
an
enclosing
scope
unlike
global
though
nonlocal
applies
to
a
name
in
an
enclosing
function
s
scope
not
the
global
module
scope
outside
all
defs
also
unlike
global
nonlocal
names
must
already
exist
in
the
enclosing
function
s
scope
when
declared
they
can
exist
only
in
enclosing
functions
and
cannot
be
created
by
a
first
assignment
in
a
nested
def
in
other
words
nonlocal
both
allows
assignment
to
names
in
enclosing
function
scopes
and
limits
scope
lookups
for
such
names
to
enclosing
defs
the
net
effect
is
a
more
direct
and
reliable
implementation
of
changeable
scope
information
for
programs
that
do
not
desire
or
need
classes
with
attributes
nonlocal
basics
python
introduces
a
new
nonlocal
statement
which
has
meaning
only
inside
a
function
def
func
nonlocal
name
name
this
statement
allows
a
nested
function
to
change
one
or
more
names
defined
in
a
syntactically
enclosing
function
s
scope
in
python
x
including
when
one
function
def
is
nested
in
another
the
nested
function
can
reference
any
of
the
names
defined
by
assignment
in
the
enclosing
def
s
scope
but
it
cannot
change
them
in
declaring
the
enclosing
scopes
names
in
a
nonlocal
statement
enables
nested
functions
to
assign
and
thus
change
such
names
as
well
this
provides
a
way
for
enclosing
functions
to
provide
writeable
state
information
remembered
when
the
nested
function
is
later
called
allowing
the
state
to
change
the
nonlocal
statement
makes
it
more
useful
to
the
nested
function
imagine
a
counter
in
the
enclosing
scope
for
instance
in
x
programmers
usually
achieve
similar
goals
by
using
classes
or
other
schemes
because
nested
functions
have
become
a
more
common
coding
pattern
for
state
retention
though
nonlocal
makes
it
more
generally
applicable
besides
allowing
names
in
enclosing
defs
to
be
changed
the
nonlocal
statement
also
forces
the
issue
for
references
just
like
the
global
statement
nonlocal
causes
searches
for
the
names
listed
in
the
statement
to
begin
in
the
enclosing
defs
scopes
not
in
the
local
scope
of
the
declaring
function
that
is
nonlocal
also
means
skip
my
local
scope
entirely
in
fact
the
names
listed
in
a
nonlocal
must
have
been
previously
defined
in
an
enclosing
def
when
the
nonlocal
is
reached
or
an
error
is
raised
the
net
effect
is
much
like
global
global
means
the
names
reside
in
the
enclosing
module
and
nonlocal
means
they
reside
in
an
enclosing
def
nonlocal
is
even
more
strict
though
scope
search
is
restricted
to
only
enclosing
defs
that
is
nonlocal
names
can
appear
only
in
enclosing
defs
not
in
the
module
s
global
scope
or
built
in
scopes
outside
the
defs
the
addition
of
nonlocal
does
not
alter
name
reference
scope
rules
in
general
they
still
work
as
before
per
the
legb
rule
described
earlier
the
nonlocal
statement
mostly
serves
to
allow
names
in
enclosing
scopes
to
be
changed
rather
than
just
referenced
however
global
and
nonlocal
statements
do
both
restrict
the
lookup
rules
somewhat
when
coded
in
a
function
global
makes
scope
lookup
begin
in
the
enclosing
module
s
scope
and
allows
names
there
to
be
assigned
scope
lookup
continues
on
to
the
built
in
scope
if
the
name
does
not
exist
in
the
module
but
assignments
to
global
names
always
create
or
change
them
in
the
module
s
scope
nonlocal
restricts
scope
lookup
to
just
enclosing
defs
requires
that
the
names
already
exist
there
and
allows
them
to
be
assigned
scope
lookup
does
not
continue
on
to
the
global
or
built
in
scopes
in
python
references
to
enclosing
def
scope
names
are
allowed
but
not
assignment
however
you
can
still
use
classes
with
explicit
attributes
to
achieve
the
same
changeable
state
information
effect
as
nonlocals
and
you
may
be
better
off
doing
so
in
some
contexts
globals
and
function
attributes
can
sometimes
accomplish
similar
goals
as
well
more
on
this
in
a
moment
first
let
s
turn
to
some
working
code
to
make
this
more
concrete
nonlocal
in
action
on
to
some
examples
all
run
in
references
to
enclosing
def
scopes
work
as
they
do
in
in
the
following
tester
builds
and
returns
the
function
nested
to
be
called
later
and
the
state
reference
in
nested
maps
the
local
scope
of
tester
using
the
normal
scope
lookup
rules
chapter
scopes
c
misc
c
python
python
def
tester
start
state
start
def
nested
label
print
label
state
return
nested
f
tester
f
spam
spam
f
ham
ham
referencing
nonlocals
works
normally
remembers
state
in
enclosing
scope
changing
a
name
in
an
enclosing
def
s
scope
is
not
allowed
by
default
though
this
is
the
normal
case
in
as
well
def
tester
start
state
start
def
nested
label
print
label
state
state
cannot
change
by
default
or
in
return
nested
f
tester
f
spam
unboundlocalerror
local
variable
state
referenced
before
assignment
using
nonlocal
for
changes
now
under
if
we
declare
state
in
the
tester
scope
as
nonlocal
within
nested
we
get
to
change
it
inside
the
nested
function
too
this
works
even
though
tester
has
returned
and
exited
by
the
time
we
call
the
returned
nested
function
through
the
name
f
def
tester
start
state
start
def
nested
label
nonlocal
state
print
label
state
state
return
nested
f
tester
f
spam
spam
f
ham
ham
f
eggs
eggs
each
call
gets
its
own
state
remembers
state
in
enclosing
scope
allowed
to
change
it
if
nonlocal
increments
state
on
each
call
as
usual
with
enclosing
scope
references
we
can
call
the
tester
factory
function
multiple
times
to
get
multiple
copies
of
its
state
in
memory
the
state
object
in
the
enclosing
scope
is
essentially
attached
to
the
nested
function
object
returned
each
call
makes
a
the
nonlocal
statement
new
distinct
state
object
such
that
updating
one
function
s
state
won
t
impact
the
other
the
following
continues
the
prior
listing
s
interaction
g
tester
g
spam
spam
make
a
new
tester
that
starts
at
g
eggs
eggs
my
state
information
updated
to
f
bacon
bacon
but
f
s
is
where
it
left
off
at
each
call
has
different
state
information
boundary
cases
there
are
a
few
things
to
watch
out
for
first
unlike
the
global
statement
nonlocal
names
really
must
have
previously
been
assigned
in
an
enclosing
def
s
scope
when
a
nonlocal
is
evaluated
or
else
you
ll
get
an
error
you
cannot
create
them
dynamically
by
assigning
them
anew
in
the
enclosing
scope
def
tester
start
def
nested
label
nonlocal
state
nonlocals
must
already
exist
in
enclosing
def
state
print
label
state
return
nested
syntaxerror
no
binding
for
nonlocal
state
found
abc
def
tester
start
def
nested
label
global
state
state
print
label
state
return
nested
globals
don
t
have
to
exist
yet
when
declared
this
creates
the
name
in
the
module
now
f
tester
f
abc
state
second
nonlocal
restricts
the
scope
lookup
to
just
enclosing
defs
nonlocals
are
not
looked
up
in
the
enclosing
module
s
global
scope
or
the
built
in
scope
outside
all
defs
even
if
they
are
already
there
spam
def
tester
def
nested
nonlocal
spam
must
be
in
a
def
not
the
module
print
current
spam
spam
return
nested
syntaxerror
no
binding
for
nonlocal
spam
found
chapter
scopes
these
restrictions
make
sense
once
you
realize
that
python
would
not
otherwise
generally
know
which
enclosing
scope
to
create
a
brand
new
name
in
in
the
prior
listing
should
spam
be
assigned
in
tester
or
the
module
outside
because
this
is
ambiguous
python
must
resolve
nonlocals
at
function
creation
time
not
function
call
time
why
nonlocal
given
the
extra
complexity
of
nested
functions
you
might
wonder
what
the
fuss
is
about
although
it
s
difficult
to
see
in
our
small
examples
state
information
becomes
crucial
in
many
programs
there
are
a
variety
of
ways
to
remember
information
across
function
and
method
calls
in
python
while
there
are
tradeoffs
for
all
nonlocal
does
improve
this
story
for
enclosing
scope
references
the
nonlocal
statement
allows
multiple
copies
of
changeable
state
to
be
retained
in
memory
and
addresses
simple
state
retention
needs
where
classes
may
not
be
warranted
as
we
saw
in
the
prior
section
the
following
code
allows
state
to
be
retained
and
modified
in
an
enclosing
scope
each
call
to
tester
creates
a
little
self
contained
package
of
changeable
information
whose
names
do
not
clash
with
any
other
part
of
the
program
def
tester
start
state
start
def
nested
label
nonlocal
state
print
label
state
state
return
nested
each
call
gets
its
own
state
remembers
state
in
enclosing
scope
allowed
to
change
it
if
nonlocal
f
tester
f
spam
unfortunately
this
code
only
works
in
python
if
you
are
using
python
other
options
are
available
depending
on
your
goals
the
next
two
sections
present
some
alternatives
shared
state
with
globals
one
usual
prescription
for
achieving
the
nonlocal
effect
in
and
earlier
is
to
simply
move
the
state
out
to
the
global
scope
the
enclosing
module
def
tester
start
global
state
state
start
def
nested
label
global
state
print
label
state
state
return
nested
f
tester
f
spam
move
it
out
to
the
module
to
change
it
global
allows
changes
in
module
scope
each
call
increments
shared
global
state
the
nonlocal
statement
spam
f
eggs
eggs
this
works
in
this
case
but
it
requires
global
declarations
in
both
functions
and
is
prone
to
name
collisions
in
the
global
scope
what
if
state
is
already
being
used
a
worse
and
more
subtle
problem
is
that
it
only
allows
for
a
single
shared
copy
of
the
state
information
in
the
module
scope
if
we
call
tester
again
we
ll
wind
up
resetting
the
module
s
state
variable
such
that
prior
calls
will
see
their
state
overwritten
g
tester
g
toast
toast
resets
state
s
single
copy
in
global
scope
g
bacon
bacon
f
ham
ham
oops
my
counter
has
been
overwritten
as
shown
earlier
when
using
nonlocal
instead
of
global
each
call
to
tester
remembers
its
own
unique
copy
of
the
state
object
state
with
classes
preview
the
other
prescription
for
changeable
state
information
in
and
earlier
is
to
use
classes
with
attributes
to
make
state
information
access
more
explicit
than
the
implicit
magic
of
scope
lookup
rules
as
an
added
benefit
each
instance
of
a
class
gets
a
fresh
copy
of
the
state
information
as
a
natural
byproduct
of
python
s
object
model
we
haven
t
explored
classes
in
detail
yet
but
as
a
brief
preview
here
is
a
reformulation
of
the
tester
nested
functions
used
earlier
as
a
class
state
is
recorded
in
objects
explicitly
as
they
are
created
to
make
sense
of
this
code
you
need
to
know
that
a
def
within
a
class
like
this
works
exactly
like
a
def
outside
of
a
class
except
that
the
function
s
self
argument
automatically
receives
the
implied
subject
of
the
call
an
instance
object
created
by
calling
the
class
itself
class
tester
def
init
self
start
self
state
start
def
nested
self
label
print
label
self
state
self
state
f
tester
f
nested
spam
spam
f
nested
ham
ham
class
based
alternative
see
part
vi
on
object
construction
save
state
explicitly
in
new
object
g
tester
g
nested
toast
toast
each
instance
gets
new
copy
of
state
changing
one
does
not
impact
others
chapter
scopes
reference
state
explicitly
changes
are
always
allowed
create
instance
invoke
init
f
is
passed
to
self
g
nested
bacon
bacon
f
nested
eggs
eggs
f
state
f
s
state
is
where
it
left
off
state
may
be
accessed
outside
class
with
just
slightly
more
magic
which
we
ll
delve
into
later
in
this
book
we
could
also
make
our
class
look
like
a
callable
function
using
operator
overloading
call
intercepts
direct
calls
on
an
instance
so
we
don
t
need
to
call
a
named
method
class
tester
def
init
self
start
self
state
start
def
call
self
label
print
label
self
state
self
state
h
tester
h
juice
juice
h
pancakes
pancakes
intercept
direct
instance
calls
so
nested
not
required
invokes
call
don
t
sweat
the
details
in
this
code
too
much
at
this
point
in
the
book
we
ll
explore
classes
in
depth
in
part
vi
and
will
look
at
specific
operator
overloading
tools
like
call
in
chapter
so
you
may
wish
to
file
this
code
away
for
future
reference
the
point
here
is
that
classes
can
make
state
information
more
obvious
by
leveraging
explicit
attribute
assignment
instead
of
scope
lookups
while
using
classes
for
state
information
is
generally
a
good
rule
of
thumb
to
follow
they
might
be
overkill
in
cases
like
this
where
state
is
a
single
counter
such
trivial
state
cases
are
more
common
than
you
might
think
in
such
contexts
nested
defs
are
sometimes
more
lightweight
than
coding
classes
especially
if
you
re
not
familiar
with
oop
yet
moreover
there
are
some
scenarios
in
which
nested
defs
may
actually
work
better
than
classes
see
the
description
of
method
decorators
in
chapter
for
an
example
that
is
far
beyond
this
chapter
s
scope
state
with
function
attributes
as
a
final
state
retention
option
we
can
also
sometimes
achieve
the
same
effect
as
nonlocals
with
function
attributes
user
defined
names
attached
to
functions
directly
here
s
a
final
version
of
our
example
based
on
this
technique
it
replaces
a
nonlocal
with
an
attribute
attached
to
the
nested
function
although
this
scheme
may
not
be
as
intuitive
to
some
it
also
allows
the
state
variable
to
be
accessed
outside
the
nested
function
with
nonlocals
we
can
only
see
state
variables
within
the
nested
def
def
tester
start
def
nested
label
print
label
nested
state
nested
state
nested
is
in
enclosing
scope
change
attr
not
nested
itself
the
nonlocal
statement
nested
state
start
return
nested
f
tester
f
spam
spam
f
ham
ham
f
state
g
tester
g
eggs
eggs
f
ham
ham
initial
state
after
func
defined
f
is
a
nested
with
state
attached
can
access
state
outside
functions
too
g
has
own
state
doesn
t
overwrite
f
s
this
code
relies
on
the
fact
that
the
function
name
nested
is
a
local
variable
in
the
tester
scope
enclosing
nested
as
such
it
can
be
referenced
freely
inside
nested
this
code
also
relies
on
the
fact
that
changing
an
object
in
place
is
not
an
assignment
to
a
name
when
it
increments
nested
state
it
is
changing
part
of
the
object
nested
references
not
the
name
nested
itself
because
we
re
not
really
assigning
a
name
in
the
enclosing
scope
no
nonlocal
is
needed
as
you
can
see
globals
nonlocals
classes
and
function
attributes
all
offer
state
retention
options
globals
only
support
shared
data
classes
require
a
basic
knowledge
of
oop
and
both
classes
and
function
attributes
allow
state
to
be
accessed
outside
the
nested
function
itself
as
usual
the
best
tool
for
your
program
depends
upon
your
program
s
goals
chapter
summary
in
this
chapter
we
studied
one
of
two
key
concepts
related
to
functions
scopes
how
variables
are
looked
up
when
they
are
used
as
we
learned
variables
are
considered
local
to
the
function
definitions
in
which
they
are
assigned
unless
they
are
specifically
declared
to
be
global
or
nonlocal
we
also
studied
some
more
advanced
scope
concepts
here
including
nested
function
scopes
and
function
attributes
finally
we
looked
at
some
general
design
ideas
such
as
the
need
to
avoid
globals
and
cross
file
changes
in
the
next
chapter
we
re
going
to
continue
our
function
tour
with
the
second
key
function
related
concept
argument
passing
as
we
ll
find
arguments
are
passed
into
a
function
by
assignment
but
python
also
provides
tools
that
allow
functions
to
be
flexible
in
how
items
are
passed
before
we
move
on
let
s
take
this
chapter
s
quiz
to
review
the
scope
concepts
we
ve
covered
here
chapter
scopes
test
your
knowledge
quiz
what
is
the
output
of
the
following
code
and
why
x
spam
def
func
print
x
func
what
is
the
output
of
this
code
and
why
x
spam
def
func
x
ni
func
print
x
what
does
this
code
print
and
why
x
spam
def
func
x
ni
print
x
func
print
x
what
output
does
this
code
produce
why
x
spam
def
func
global
x
x
ni
func
print
x
what
about
this
code
what
s
the
output
and
why
x
spam
def
func
x
ni
def
nested
print
x
nested
func
x
test
your
knowledge
quiz
how
about
this
example
what
is
its
output
in
python
and
why
def
func
x
ni
def
nested
nonlocal
x
x
spam
nested
print
x
func
name
three
or
more
ways
to
retain
state
information
in
a
python
function
test
your
knowledge
answers
the
output
here
is
spam
because
the
function
references
a
global
variable
in
the
enclosing
module
because
it
is
not
assigned
in
the
function
it
is
considered
global
the
output
here
is
spam
again
because
assigning
the
variable
inside
the
function
makes
it
a
local
and
effectively
hides
the
global
of
the
same
name
the
print
statement
finds
the
variable
unchanged
in
the
global
module
scope
it
prints
ni
on
one
line
and
spam
on
another
because
the
reference
to
the
variable
within
the
function
finds
the
assigned
local
and
the
reference
in
the
print
statement
finds
the
global
this
time
it
just
prints
ni
because
the
global
declaration
forces
the
variable
assigned
inside
the
function
to
refer
to
the
variable
in
the
enclosing
global
scope
the
output
in
this
case
is
again
ni
on
one
line
and
spam
on
another
because
the
print
statement
in
the
nested
function
finds
the
name
in
the
enclosing
function
s
local
scope
and
the
print
at
the
end
finds
the
variable
in
the
global
scope
this
example
prints
spam
because
the
nonlocal
statement
available
in
python
but
not
means
that
the
assignment
to
x
inside
the
nested
function
changes
x
in
the
enclosing
function
s
local
scope
without
this
statement
this
assignment
would
classify
x
as
local
to
the
nested
function
making
it
a
different
variable
the
code
would
then
print
ni
instead
although
the
values
of
local
variables
go
away
when
a
function
returns
you
can
make
a
python
function
retain
state
information
by
using
shared
global
variables
enclosing
function
scope
references
within
nested
functions
or
using
default
argument
values
function
attributes
can
sometimes
allow
state
to
be
attached
to
the
function
itself
instead
of
looked
up
in
scopes
another
alternative
using
oop
with
classes
sometimes
supports
state
retention
better
than
any
of
the
scope
based
techniques
because
it
makes
it
explicit
with
attribute
assignments
we
ll
explore
this
option
in
part
vi
chapter
scopes
chapter
arguments
chapter
explored
the
details
behind
python
s
scopes
the
places
where
variables
are
defined
and
looked
up
as
we
learned
the
place
where
a
name
is
defined
in
our
code
determines
much
of
its
meaning
this
chapter
continues
the
function
story
by
studying
the
concepts
in
python
argument
passing
the
way
that
objects
are
sent
to
functions
as
inputs
as
we
ll
see
arguments
a
k
a
parameters
are
assigned
to
names
in
a
function
but
they
have
more
to
do
with
object
references
than
with
variable
scopes
we
ll
also
find
that
python
provides
extra
tools
such
as
keywords
defaults
and
arbitrary
argument
collectors
that
allow
for
wide
flexibility
in
the
way
arguments
are
sent
to
a
function
argument
passing
basics
earlier
in
this
part
of
the
book
i
noted
that
arguments
are
passed
by
assignment
this
has
a
few
ramifications
that
aren
t
always
obvious
to
beginners
which
i
ll
expand
on
in
this
section
here
is
a
rundown
of
the
key
points
in
passing
arguments
to
functions
arguments
are
passed
by
automatically
assigning
objects
to
local
variable
names
function
arguments
references
to
possibly
shared
objects
sent
by
the
caller
are
just
another
instance
of
python
assignment
at
work
because
references
are
implemented
as
pointers
all
arguments
are
in
effect
passed
by
pointer
objects
passed
as
arguments
are
never
automatically
copied
assigning
to
argument
names
inside
a
function
does
not
affect
the
caller
argument
names
in
the
function
header
become
new
local
names
when
the
function
runs
in
the
scope
of
the
function
there
is
no
aliasing
between
function
argument
names
and
variable
names
in
the
scope
of
the
caller
changing
a
mutable
object
argument
in
a
function
may
impact
the
caller
on
the
other
hand
as
arguments
are
simply
assigned
to
passed
in
objects
functions
can
change
passed
in
mutable
objects
in
place
and
the
results
may
affect
the
caller
mutable
arguments
can
be
input
and
output
for
functions
for
more
details
on
references
see
chapter
everything
we
learned
there
also
applies
to
function
arguments
though
the
assignment
to
argument
names
is
automatic
and
implicit
python
s
pass
by
assignment
scheme
isn
t
quite
the
same
as
c
s
reference
parameters
option
but
it
turns
out
to
be
very
similar
to
the
c
language
s
argument
passing
model
in
practice
immutable
arguments
are
effectively
passed
by
value
objects
such
as
integers
and
strings
are
passed
by
object
reference
instead
of
by
copying
but
because
you
can
t
change
immutable
objects
in
place
anyhow
the
effect
is
much
like
making
a
copy
mutable
arguments
are
effectively
passed
by
pointer
objects
such
as
lists
and
dictionaries
are
also
passed
by
object
reference
which
is
similar
to
the
way
c
passes
arrays
as
pointers
mutable
objects
can
be
changed
in
place
in
the
function
much
like
c
arrays
of
course
if
you
ve
never
used
c
python
s
argument
passing
mode
will
seem
simpler
still
it
involves
just
the
assignment
of
objects
to
names
and
it
works
the
same
whether
the
objects
are
mutable
or
not
arguments
and
shared
references
to
illustrate
argument
passing
properties
at
work
consider
the
following
code
def
f
a
a
a
is
assigned
to
references
passed
object
changes
local
variable
a
only
b
f
b
print
b
a
and
b
both
reference
same
initially
b
is
not
changed
in
this
example
the
variable
a
is
assigned
the
object
at
the
moment
the
function
is
called
with
f
b
but
a
lives
only
within
the
called
function
changing
a
inside
the
function
has
no
effect
on
the
place
where
the
function
is
called
it
simply
resets
the
local
variable
a
to
a
completely
different
object
that
s
what
is
meant
by
a
lack
of
name
aliasing
assignment
to
an
argument
name
inside
a
function
e
g
a
does
not
magically
change
a
variable
like
b
in
the
scope
of
the
function
call
argument
names
may
share
passed
objects
initially
they
are
essentially
pointers
to
those
objects
but
only
temporarily
when
the
function
is
first
called
as
soon
as
an
argument
name
is
reassigned
this
relationship
ends
at
least
that
s
the
case
for
assignment
to
argument
names
themselves
when
arguments
are
passed
mutable
objects
like
lists
and
dictionaries
we
also
need
to
be
aware
that
inplace
changes
to
such
objects
may
live
on
after
a
function
exits
and
hence
impact
callers
here
s
an
example
that
demonstrates
this
behavior
chapter
arguments
def
changer
a
b
a
b
spam
arguments
assigned
references
to
objects
changes
local
name
s
value
only
changes
shared
object
in
place
x
l
changer
x
l
x
l
spam
caller
pass
immutable
and
mutable
objects
x
is
unchanged
l
is
different
in
this
code
the
changer
function
assigns
values
to
argument
a
itself
and
to
a
component
of
the
object
referenced
by
argument
b
these
two
assignments
within
the
function
are
only
slightly
different
in
syntax
but
have
radically
different
results
because
a
is
a
local
variable
name
in
the
function
s
scope
the
first
assignment
has
no
effect
on
the
caller
it
simply
changes
the
local
variable
a
to
reference
a
completely
different
object
and
does
not
change
the
binding
of
the
name
x
in
the
caller
s
scope
this
is
the
same
as
in
the
prior
example
argument
b
is
a
local
variable
name
too
but
it
is
passed
a
mutable
object
the
list
that
l
references
in
the
caller
s
scope
as
the
second
assignment
is
an
in
place
object
change
the
result
of
the
assignment
to
b
in
the
function
impacts
the
value
of
l
after
the
function
returns
really
the
second
assignment
statement
in
changer
doesn
t
change
b
it
changes
part
of
the
object
that
b
currently
references
this
in
place
change
impacts
the
caller
only
because
the
changed
object
outlives
the
function
call
the
name
l
hasn
t
changed
either
it
still
references
the
same
changed
object
but
it
seems
as
though
l
differs
after
the
call
because
the
value
it
references
has
been
modified
within
the
function
figure
illustrates
the
name
object
bindings
that
exist
immediately
after
the
function
has
been
called
and
before
its
code
has
run
if
this
example
is
still
confusing
it
may
help
to
notice
that
the
effect
of
the
automatic
assignments
of
the
passed
in
arguments
is
the
same
as
running
a
series
of
simple
assignment
statements
in
terms
of
the
first
argument
the
assignment
has
no
effect
on
the
caller
x
a
x
a
print
x
they
share
the
same
object
resets
a
only
x
is
still
the
assignment
through
the
second
argument
does
affect
a
variable
at
the
call
though
because
it
is
an
in
place
object
change
l
b
l
b
spam
print
l
spam
they
share
the
same
object
in
place
change
l
sees
the
change
too
argument
passing
basics
figure
references
arguments
because
arguments
are
passed
by
assignment
argument
names
in
the
function
may
share
objects
with
variables
in
the
scope
of
the
call
hence
in
place
changes
to
mutable
arguments
in
a
function
can
impact
the
caller
here
a
and
b
in
the
function
initially
reference
the
objects
referenced
by
variables
x
and
l
when
the
function
is
first
called
changing
the
list
through
variable
b
makes
l
appear
different
after
the
call
returns
if
you
recall
our
discussions
about
shared
mutable
objects
in
chapters
and
you
ll
recognize
the
phenomenon
at
work
changing
a
mutable
object
in
place
can
impact
other
references
to
that
object
here
the
effect
is
to
make
one
of
the
arguments
work
like
both
an
input
and
an
output
of
the
function
avoiding
mutable
argument
changes
this
behavior
of
in
place
changes
to
mutable
arguments
isn
t
a
bug
it
s
simply
the
way
argument
passing
works
in
python
arguments
are
passed
to
functions
by
reference
a
k
a
pointer
by
default
because
that
is
what
we
normally
want
it
means
we
can
pass
large
objects
around
our
programs
without
making
multiple
copies
along
the
way
and
we
can
easily
update
these
objects
as
we
go
in
fact
as
we
ll
see
in
part
vi
python
s
class
model
depends
upon
changing
a
passed
in
self
argument
in
place
to
update
object
state
if
we
don
t
want
in
place
changes
within
functions
to
impact
objects
we
pass
to
them
though
we
can
simply
make
explicit
copies
of
mutable
objects
as
we
learned
in
chapter
for
function
arguments
we
can
always
copy
the
list
at
the
point
of
call
l
changer
x
l
pass
a
copy
so
our
l
does
not
change
we
can
also
copy
within
the
function
itself
if
we
never
want
to
change
passed
in
objects
regardless
of
how
the
function
is
called
def
changer
a
b
b
b
chapter
arguments
copy
input
list
so
we
don
t
impact
caller
a
b
spam
changes
our
list
copy
only
both
of
these
copying
schemes
don
t
stop
the
function
from
changing
the
object
they
just
prevent
those
changes
from
impacting
the
caller
to
really
prevent
changes
we
can
always
convert
to
immutable
objects
to
force
the
issue
tuples
for
example
throw
an
exception
when
changes
are
attempted
l
changer
x
tuple
l
pass
a
tuple
so
changes
are
errors
this
scheme
uses
the
built
in
tuple
function
which
builds
a
new
tuple
out
of
all
the
items
in
a
sequence
really
any
iterable
it
s
also
something
of
an
extreme
because
it
forces
the
function
to
be
written
to
never
change
passed
in
arguments
this
solution
might
impose
more
limitations
on
the
function
than
it
should
and
so
should
generally
be
avoided
you
never
know
when
changing
arguments
might
come
in
handy
for
other
calls
in
the
future
using
this
technique
will
also
make
the
function
lose
the
ability
to
call
any
list
specific
methods
on
the
argument
including
methods
that
do
not
change
the
object
in
place
the
main
point
to
remember
here
is
that
functions
might
update
mutable
objects
like
lists
and
dictionaries
passed
into
them
this
isn
t
necessarily
a
problem
if
it
s
expected
and
often
serves
useful
purposes
moreover
functions
that
change
passed
in
mutable
objects
in
place
are
probably
designed
and
intended
to
do
so
the
change
is
likely
part
of
a
well
defined
api
that
you
shouldn
t
violate
by
making
copies
however
you
do
have
to
be
aware
of
this
property
if
objects
change
out
from
under
you
unexpectedly
check
whether
a
called
function
might
be
responsible
and
make
copies
when
objects
are
passed
if
needed
simulating
output
parameters
we
ve
already
discussed
the
return
statement
and
used
it
in
a
few
examples
here
s
another
way
to
use
this
statement
because
return
can
send
back
any
sort
of
object
it
can
return
multiple
values
by
packaging
them
in
a
tuple
or
other
collection
type
in
fact
although
python
doesn
t
support
what
some
languages
label
call
by
reference
argument
passing
we
can
usually
simulate
it
by
returning
tuples
and
assigning
the
results
back
to
the
original
argument
names
in
the
caller
def
multiple
x
y
x
y
return
x
y
x
l
x
l
multiple
x
l
x
l
changes
local
names
only
return
new
values
in
a
tuple
assign
results
to
caller
s
names
argument
passing
basics
it
looks
like
the
code
is
returning
two
values
here
but
it
s
really
just
one
a
two
item
tuple
with
the
optional
surrounding
parentheses
omitted
after
the
call
returns
we
can
use
tuple
assignment
to
unpack
the
parts
of
the
returned
tuple
if
you
ve
forgotten
why
this
works
flip
back
to
tuples
on
page
in
chapter
chapter
and
assignment
statements
on
page
in
chapter
the
net
effect
of
this
coding
pattern
is
to
simulate
the
output
parameters
of
other
languages
by
explicit
assignments
x
and
l
change
after
the
call
but
only
because
the
code
said
so
unpacking
arguments
in
python
x
the
preceding
example
unpacks
a
tuple
returned
by
the
function
with
tuple
assignment
in
python
it
s
also
possible
to
automatically
unpack
tuples
in
arguments
passed
to
a
function
in
a
function
defined
by
this
header
def
f
a
b
c
can
be
called
with
tuples
that
match
the
expected
structure
f
assigns
a
b
and
c
to
and
respectively
naturally
the
passed
tuple
can
also
be
an
object
created
before
the
call
f
t
this
def
syntax
is
no
longer
supported
in
python
instead
code
this
function
as
def
f
t
a
b
c
t
to
unpack
in
an
explicit
assignment
statement
this
explicit
form
works
in
both
and
argument
unpacking
is
an
obscure
and
rarely
used
feature
in
python
x
moreover
a
function
header
in
supports
only
the
tuple
form
of
sequence
assignment
more
general
sequence
assignments
e
g
def
f
a
b
c
fail
on
syntax
errors
in
as
well
and
require
the
explicit
assignment
form
tuple
unpacking
argument
syntax
is
also
disallowed
by
in
lambda
function
argument
lists
see
the
sidebar
why
you
will
care
list
comprehensions
and
map
on
page
for
an
example
somewhat
asymmetrically
tuple
unpacking
assignment
is
still
automatic
in
for
loops
targets
though
see
chapter
for
examples
special
argument
matching
modes
as
we
ve
just
seen
arguments
are
always
passed
by
assignment
in
python
names
in
the
def
header
are
assigned
to
passed
in
objects
on
top
of
this
model
though
python
provides
additional
tools
that
alter
the
way
the
argument
objects
in
a
call
are
matched
with
argument
names
in
the
header
prior
to
assignment
these
tools
are
all
optional
but
they
allow
us
to
write
functions
that
support
more
flexible
calling
patterns
and
you
may
encounter
some
libraries
that
require
them
chapter
arguments
by
default
arguments
are
matched
by
position
from
left
to
right
and
you
must
pass
exactly
as
many
arguments
as
there
are
argument
names
in
the
function
header
however
you
can
also
specify
matching
by
name
default
values
and
collectors
for
extra
arguments
the
basics
before
we
go
into
the
syntactic
details
i
want
to
stress
that
these
special
modes
are
optional
and
only
have
to
do
with
matching
objects
to
names
the
underlying
passing
mechanism
after
the
matching
takes
place
is
still
assignment
in
fact
some
of
these
tools
are
intended
more
for
people
writing
libraries
than
for
application
developers
but
because
you
may
stumble
across
these
modes
even
if
you
don
t
code
them
yourself
here
s
a
synopsis
of
the
available
tools
positionals
matched
from
left
to
right
the
normal
case
which
we
ve
mostly
been
using
so
far
is
to
match
passed
argument
values
to
argument
names
in
a
function
header
by
position
from
left
to
right
keywords
matched
by
argument
name
alternatively
callers
can
specify
which
argument
in
the
function
is
to
receive
a
value
by
using
the
argument
s
name
in
the
call
with
the
name
value
syntax
defaults
specify
values
for
arguments
that
aren
t
passed
functions
themselves
can
specify
default
values
for
arguments
to
receive
if
the
call
passes
too
few
values
again
using
the
name
value
syntax
varargs
collecting
collect
arbitrarily
many
positional
or
keyword
arguments
functions
can
use
special
arguments
preceded
with
one
or
two
characters
to
collect
an
arbitrary
number
of
extra
arguments
this
feature
is
often
referred
to
as
varargs
after
the
varargs
feature
in
the
c
language
which
also
supports
variablelength
argument
lists
varargs
unpacking
pass
arbitrarily
many
positional
or
keyword
arguments
callers
can
also
use
the
syntax
to
unpack
argument
collections
into
discrete
separate
arguments
this
is
the
inverse
of
a
in
a
function
header
in
the
header
it
means
collect
arbitrarily
many
arguments
while
in
the
call
it
means
pass
arbitrarily
many
arguments
keyword
only
arguments
arguments
that
must
be
passed
by
name
in
python
but
not
functions
can
also
specify
arguments
that
must
be
passed
by
name
with
keyword
arguments
not
by
position
such
arguments
are
typically
used
to
define
configuration
options
in
addition
to
actual
arguments
special
argument
matching
modes
matching
syntax
table
summarizes
the
syntax
that
invokes
the
special
argument
matching
modes
table
function
argument
matching
forms
syntax
location
interpretation
func
value
caller
normal
argument
matched
by
position
func
name
value
caller
keyword
argument
matched
by
name
func
sequence
caller
pass
all
objects
in
sequence
as
individual
positional
arguments
func
dict
caller
pass
all
key
value
pairs
in
dict
as
individual
keyword
arguments
def
func
name
function
normal
argument
matches
any
passed
value
by
position
or
name
def
func
name
value
function
default
argument
value
if
not
passed
in
the
call
def
func
name
function
matches
and
collects
remaining
positional
arguments
in
a
tuple
def
func
name
function
matches
and
collects
remaining
keyword
arguments
in
a
dictionary
def
func
args
name
function
arguments
that
must
be
passed
by
keyword
only
in
calls
def
func
name
value
these
special
matching
modes
break
down
into
function
calls
and
definitions
as
follows
in
a
function
call
the
first
four
rows
of
the
table
simple
values
are
matched
by
position
but
using
the
name
value
form
tells
python
to
match
by
name
to
arguments
instead
these
are
called
keyword
arguments
using
a
sequence
or
dict
in
a
call
allows
us
to
package
up
arbitrarily
many
positional
or
keyword
objects
in
sequences
and
dictionaries
respectively
and
unpack
them
as
separate
individual
arguments
when
they
are
passed
to
the
function
in
a
function
header
the
rest
of
the
table
a
simple
name
is
matched
by
position
or
name
depending
on
how
the
caller
passes
it
but
the
name
value
form
specifies
a
default
value
the
name
form
collects
any
extra
unmatched
positional
arguments
in
a
tuple
and
the
name
form
collects
extra
keyword
arguments
in
a
dictionary
in
python
and
later
any
normal
or
defaulted
argument
names
following
a
name
or
a
bare
are
keyword
only
arguments
and
must
be
passed
by
keyword
in
calls
of
these
keyword
arguments
and
defaults
are
probably
the
most
commonly
used
in
python
code
we
ve
informally
used
both
of
these
earlier
in
this
book
we
ve
already
used
keywords
to
specify
options
to
the
print
function
but
they
are
more
general
keywords
allow
us
to
label
any
argument
with
its
name
to
make
calls
more
informational
chapter
arguments
we
met
defaults
earlier
too
as
a
way
to
pass
in
values
from
the
enclosing
function
s
scope
but
they
are
also
more
general
they
allow
us
to
make
any
argument
optional
providing
its
default
value
in
a
function
definition
as
we
ll
see
the
combination
of
defaults
in
a
function
header
and
keywords
in
a
call
further
allows
us
to
pick
and
choose
which
defaults
to
override
in
short
special
argument
matching
modes
let
you
be
fairly
liberal
about
how
many
arguments
must
be
passed
to
a
function
if
a
function
specifies
defaults
they
are
used
if
you
pass
too
few
arguments
if
a
function
uses
the
variable
argument
list
forms
you
can
pass
too
many
arguments
the
names
collect
the
extra
arguments
in
data
structures
for
processing
in
the
function
the
gritty
details
if
you
choose
to
use
and
combine
the
special
argument
matching
modes
python
will
ask
you
to
follow
these
ordering
rules
in
a
function
call
arguments
must
appear
in
this
order
any
positional
arguments
value
followed
by
a
combination
of
any
keyword
arguments
name
value
and
the
sequence
form
followed
by
the
dict
form
in
a
function
header
arguments
must
appear
in
this
order
any
normal
arguments
name
followed
by
any
default
arguments
name
value
followed
by
the
name
or
in
form
if
present
followed
by
any
name
or
name
value
keyword
only
arguments
in
followed
by
the
name
form
in
both
the
call
and
header
the
arg
form
must
appear
last
if
present
if
you
mix
arguments
in
any
other
order
you
will
get
a
syntax
error
because
the
combinations
can
be
ambiguous
the
steps
that
python
internally
carries
out
to
match
arguments
before
assignment
can
roughly
be
described
as
follows
assign
nonkeyword
arguments
by
position
assign
keyword
arguments
by
matching
names
assign
extra
nonkeyword
arguments
to
name
tuple
assign
extra
keyword
arguments
to
name
dictionary
assign
default
values
to
unassigned
arguments
in
header
after
this
python
checks
to
make
sure
each
argument
is
passed
just
one
value
if
not
an
error
is
raised
when
all
matching
is
complete
python
assigns
argument
names
to
the
objects
passed
to
them
special
argument
matching
modes
the
actual
matching
algorithm
python
uses
is
a
bit
more
complex
it
must
also
account
for
keyword
only
arguments
in
for
instance
so
we
ll
defer
to
python
s
standard
language
manual
for
a
more
exact
description
it
s
not
required
reading
but
tracing
python
s
matching
algorithm
may
help
you
to
understand
some
convoluted
cases
especially
when
modes
are
mixed
in
python
argument
names
in
a
function
header
can
also
have
annotation
values
specified
as
name
value
or
name
value
default
when
defaults
are
present
this
is
simply
additional
syntax
for
arguments
and
does
not
augment
or
change
the
argument
ordering
rules
described
here
the
function
itself
can
also
have
an
annotation
value
given
as
def
f
value
see
the
discussion
of
function
annotation
in
chapter
for
more
details
keyword
and
default
examples
this
is
all
simpler
in
code
than
the
preceding
descriptions
may
imply
if
you
don
t
use
any
special
matching
syntax
python
matches
names
by
position
from
left
to
right
like
most
other
languages
for
instance
if
you
define
a
function
that
requires
three
arguments
you
must
call
it
with
three
arguments
def
f
a
b
c
print
a
b
c
here
we
pass
them
by
position
a
is
matched
to
b
is
matched
to
and
so
on
this
works
the
same
in
python
and
but
extra
tuple
parentheses
are
displayed
in
because
we
re
using
print
calls
f
keywords
in
python
though
you
can
be
more
specific
about
what
goes
where
when
you
call
a
function
keyword
arguments
allow
us
to
match
by
name
instead
of
by
position
f
c
b
a
the
c
in
this
call
for
example
means
send
to
the
argument
named
c
more
formally
python
matches
the
name
c
in
the
call
to
the
argument
named
c
in
the
function
definition
s
header
and
then
passes
the
value
to
that
argument
the
net
effect
of
this
call
is
the
same
as
that
of
the
prior
call
but
notice
that
the
left
to
right
order
of
the
arguments
no
longer
matters
when
keywords
are
used
because
arguments
are
matched
by
name
not
by
position
it
s
even
possible
to
combine
positional
and
keyword
arguments
in
a
single
call
in
this
case
all
positionals
are
matched
first
from
left
to
right
in
the
header
before
keywords
are
matched
by
name
chapter
arguments
f
c
b
when
most
people
see
this
the
first
time
they
wonder
why
one
would
use
such
a
tool
keywords
typically
have
two
roles
in
python
first
they
make
your
calls
a
bit
more
selfdocumenting
assuming
that
you
use
better
argument
names
than
a
b
and
c
for
example
a
call
of
this
form
func
name
bob
age
job
dev
is
much
more
meaningful
than
a
call
with
three
naked
values
separated
by
commas
the
keywords
serve
as
labels
for
the
data
in
the
call
the
second
major
use
of
keywords
occurs
in
conjunction
with
defaults
which
we
turn
to
next
defaults
we
talked
about
defaults
in
brief
earlier
when
discussing
nested
function
scopes
in
short
defaults
allow
us
to
make
selected
function
arguments
optional
if
not
passed
a
value
the
argument
is
assigned
its
default
before
the
function
runs
for
example
here
is
a
function
that
requires
one
argument
and
defaults
two
def
f
a
b
c
print
a
b
c
when
we
call
this
function
we
must
provide
a
value
for
a
either
by
position
or
by
keyword
however
providing
values
for
b
and
c
is
optional
if
we
don
t
pass
values
to
b
and
c
they
default
to
and
respectively
f
f
a
if
we
pass
two
values
only
c
gets
its
default
and
with
three
values
no
defaults
are
used
f
f
finally
here
is
how
the
keyword
and
default
features
interact
because
they
subvert
the
normal
left
to
right
positional
mapping
keywords
allow
us
to
essentially
skip
over
arguments
with
defaults
f
c
here
a
gets
by
position
c
gets
by
keyword
and
b
in
between
defaults
to
be
careful
not
to
confuse
the
special
name
value
syntax
in
a
function
header
and
a
function
call
in
the
call
it
means
a
match
by
name
keyword
argument
while
in
the
header
it
specifies
a
default
for
an
optional
argument
in
both
cases
this
is
not
an
assignment
statement
despite
its
appearance
it
is
special
syntax
for
these
two
contexts
which
modifies
the
default
argument
matching
mechanics
special
argument
matching
modes
combining
keywords
and
defaults
here
is
a
slightly
larger
example
that
demonstrates
keywords
and
defaults
in
action
in
the
following
the
caller
must
always
pass
at
least
two
arguments
to
match
spam
and
eggs
but
the
other
two
are
optional
if
they
are
omitted
python
assigns
toast
and
ham
to
the
defaults
specified
in
the
header
def
func
spam
eggs
toast
ham
print
spam
eggs
toast
ham
first
required
func
func
ham
eggs
func
spam
eggs
func
toast
eggs
spam
func
output
output
output
output
output
notice
again
that
when
keyword
arguments
are
used
in
the
call
the
order
in
which
the
arguments
are
listed
doesn
t
matter
python
matches
by
name
not
by
position
the
caller
must
supply
values
for
spam
and
eggs
but
they
can
be
matched
by
position
or
by
name
again
keep
in
mind
that
the
form
name
value
means
different
things
in
the
call
and
the
def
a
keyword
in
the
call
and
a
default
in
the
header
arbitrary
arguments
examples
the
last
two
matching
extensions
and
are
designed
to
support
functions
that
take
any
number
of
arguments
both
can
appear
in
either
the
function
definition
or
a
function
call
and
they
have
related
purposes
in
the
two
locations
collecting
arguments
the
first
use
in
the
function
definition
collects
unmatched
positional
arguments
into
a
tuple
def
f
args
print
args
when
this
function
is
called
python
collects
all
the
positional
arguments
into
a
new
tuple
and
assigns
the
variable
args
to
that
tuple
because
it
is
a
normal
tuple
object
it
can
be
indexed
stepped
through
with
a
for
loop
and
so
on
f
f
f
the
feature
is
similar
but
it
only
works
for
keyword
arguments
it
collects
them
into
a
new
dictionary
which
can
then
be
processed
with
normal
dictionary
tools
in
a
sense
the
form
allows
you
to
convert
from
keywords
to
dictionaries
which
you
can
then
step
through
with
keys
calls
dictionary
iterators
and
the
like
chapter
arguments
def
f
args
print
args
f
f
a
b
a
b
finally
function
headers
can
combine
normal
arguments
the
and
the
to
implement
wildly
flexible
call
signatures
for
instance
in
the
following
is
passed
to
a
by
position
and
are
collected
into
the
pargs
positional
tuple
and
x
and
y
wind
up
in
the
kargs
keyword
dictionary
def
f
a
pargs
kargs
print
a
pargs
kargs
f
x
y
y
x
in
fact
these
features
can
be
combined
in
even
more
complex
ways
that
may
seem
ambiguous
at
first
glance
an
idea
we
will
revisit
later
in
this
chapter
first
though
let
s
see
what
happens
when
and
are
coded
in
function
calls
instead
of
definitions
unpacking
arguments
in
recent
python
releases
we
can
use
the
syntax
when
we
call
a
function
too
in
this
context
its
meaning
is
the
inverse
of
its
meaning
in
the
function
definition
it
unpacks
a
collection
of
arguments
rather
than
building
a
collection
of
arguments
for
example
we
can
pass
four
arguments
to
a
function
in
a
tuple
and
let
python
unpack
them
into
individual
arguments
def
func
a
b
c
d
print
a
b
c
d
args
args
func
args
similarly
the
syntax
in
a
function
call
unpacks
a
dictionary
of
key
value
pairs
into
separate
keyword
arguments
args
a
b
c
args
d
func
args
again
we
can
combine
normal
positional
and
keyword
arguments
in
the
call
in
very
flexible
ways
func
d
c
func
d
func
c
d
special
argument
matching
modes
func
d
f
c
d
this
sort
of
code
is
convenient
when
you
cannot
predict
the
number
of
arguments
that
will
be
passed
to
a
function
when
you
write
your
script
you
can
build
up
a
collection
of
arguments
at
runtime
instead
and
call
the
function
generically
this
way
again
don
t
confuse
the
syntax
in
the
function
header
and
the
function
call
in
the
header
it
collects
any
number
of
arguments
while
in
the
call
it
unpacks
any
number
of
arguments
as
we
saw
in
chapter
the
pargs
form
in
a
call
is
an
iteration
context
so
technically
it
accepts
any
iterable
object
not
just
tuples
or
other
sequences
as
shown
in
the
examples
here
for
instance
a
file
object
works
after
the
and
unpacks
its
lines
into
individual
arguments
e
g
func
open
fname
this
generality
is
supported
in
both
python
and
but
it
holds
true
only
for
calls
a
pargs
in
a
call
allows
any
iterable
but
the
same
form
in
a
def
header
always
bundles
extra
arguments
into
a
tuple
this
header
behavior
is
similar
in
spirit
and
syntax
to
the
in
python
extended
sequence
unpacking
assignment
forms
we
met
in
chapter
e
g
x
y
z
though
that
feature
always
creates
lists
not
tuples
applying
functions
generically
the
prior
section
s
examples
may
seem
obtuse
but
they
are
used
more
often
than
you
might
expect
some
programs
need
to
call
arbitrary
functions
in
a
generic
fashion
without
knowing
their
names
or
arguments
ahead
of
time
in
fact
the
real
power
of
the
special
varargs
call
syntax
is
that
you
don
t
need
to
know
how
many
arguments
a
function
call
requires
before
you
write
a
script
for
example
you
can
use
if
logic
to
select
from
a
set
of
functions
and
argument
lists
and
call
any
of
them
generically
if
test
action
args
func
else
action
args
func
action
args
call
func
with
arg
in
this
case
call
func
with
args
here
dispatch
generically
more
generally
this
varargs
call
syntax
is
useful
any
time
you
cannot
predict
the
arguments
list
if
your
user
selects
an
arbitrary
function
via
a
user
interface
for
instance
you
may
be
unable
to
hardcode
a
function
call
when
writing
your
script
to
work
around
this
simply
build
up
the
arguments
list
with
sequence
operations
and
call
it
with
starred
names
to
unpack
the
arguments
chapter
arguments
args
args
args
func
args
because
the
arguments
list
is
passed
in
as
a
tuple
here
the
program
can
build
it
at
runtime
this
technique
also
comes
in
handy
for
functions
that
test
or
time
other
functions
for
instance
in
the
following
code
we
support
any
function
with
any
arguments
by
passing
along
whatever
arguments
were
sent
in
def
tracer
func
pargs
kargs
print
calling
func
name
return
func
pargs
kargs
accept
arbitrary
arguments
pass
along
arbitrary
arguments
def
func
a
b
c
d
return
a
b
c
d
print
tracer
func
c
d
when
this
code
is
run
arguments
are
collected
by
the
tracer
and
then
propagated
with
varargs
call
syntax
calling
func
we
ll
see
larger
examples
of
such
roles
later
in
this
book
see
especially
the
sequence
timing
example
in
chapter
and
the
various
decorator
tools
we
will
code
in
chapter
the
defunct
apply
built
in
python
prior
to
python
the
effect
of
the
args
and
args
varargs
call
syntax
could
be
achieved
with
a
built
in
function
named
apply
this
original
technique
has
been
removed
in
because
it
is
now
redundant
cleans
up
many
such
dusty
tools
that
have
been
subsumed
over
the
years
it
s
still
available
in
python
though
and
you
may
come
across
it
in
older
x
code
in
short
the
following
are
equivalent
prior
to
python
func
pargs
kargs
newer
call
syntax
func
sequence
dict
apply
func
pargs
kargs
defunct
built
in
apply
func
sequence
dict
for
example
consider
the
following
function
which
accepts
any
number
of
positional
or
keyword
arguments
def
echo
args
kwargs
print
args
kwargs
echo
a
b
a
b
special
argument
matching
modes
in
python
we
can
call
it
generically
with
apply
or
with
the
call
syntax
that
is
now
required
in
pargs
kargs
a
b
apply
echo
pargs
kargs
a
b
echo
pargs
kargs
a
b
the
unpacking
call
syntax
form
is
newer
than
the
apply
function
is
preferred
in
general
and
is
required
in
apart
from
its
symmetry
with
the
pargs
and
kargs
collector
forms
in
def
headers
and
the
fact
that
it
requires
fewer
keystrokes
overall
the
newer
call
syntax
also
allows
us
to
pass
along
additional
arguments
without
having
to
manually
extend
argument
sequences
or
dictionaries
echo
c
pargs
kargs
a
c
b
normal
keyword
sequence
dictionary
that
is
the
call
syntax
form
is
more
general
since
it
s
required
in
you
should
now
disavow
all
knowledge
of
apply
unless
of
course
it
appears
in
x
code
you
must
use
or
maintain
python
keyword
only
arguments
python
generalizes
the
ordering
rules
in
function
headers
to
allow
us
to
specify
keyword
only
arguments
arguments
that
must
be
passed
by
keyword
only
and
will
never
be
filled
in
by
a
positional
argument
this
is
useful
if
we
want
a
function
to
both
process
any
number
of
arguments
and
accept
possibly
optional
configuration
options
syntactically
keyword
only
arguments
are
coded
as
named
arguments
that
appear
after
args
in
the
arguments
list
all
such
arguments
must
be
passed
using
keyword
syntax
in
the
call
for
example
in
the
following
a
may
be
passed
by
name
or
position
b
collects
any
extra
positional
arguments
and
c
must
be
passed
by
keyword
only
def
kwonly
a
b
c
print
a
b
c
kwonly
c
kwonly
a
c
kwonly
typeerror
kwonly
needs
keyword
only
argument
c
we
can
also
use
a
character
by
itself
in
the
arguments
list
to
indicate
that
a
function
does
not
accept
a
variable
length
argument
list
but
still
expects
all
arguments
following
the
to
be
passed
as
keywords
in
the
next
function
a
may
be
passed
by
position
or
name
again
but
b
and
c
must
be
keywords
and
no
extra
positionals
are
allowed
chapter
arguments
def
kwonly
a
b
c
print
a
b
c
kwonly
c
b
kwonly
c
b
a
kwonly
typeerror
kwonly
takes
exactly
positional
argument
given
kwonly
typeerror
kwonly
needs
keyword
only
argument
b
you
can
still
use
defaults
for
keyword
only
arguments
even
though
they
appear
after
the
in
the
function
header
in
the
following
code
a
may
be
passed
by
name
or
position
and
b
and
c
are
optional
but
must
be
passed
by
keyword
if
used
def
kwonly
a
b
spam
c
ham
print
a
b
c
kwonly
spam
ham
kwonly
c
spam
kwonly
a
spam
ham
kwonly
c
b
a
kwonly
typeerror
kwonly
takes
exactly
positional
argument
given
in
fact
keyword
only
arguments
with
defaults
are
optional
but
those
without
defaults
effectively
become
required
keywords
for
the
function
def
kwonly
a
b
c
spam
print
a
b
c
kwonly
b
eggs
eggs
spam
kwonly
c
eggs
typeerror
kwonly
needs
keyword
only
argument
b
kwonly
typeerror
kwonly
takes
exactly
positional
argument
given
def
kwonly
a
b
c
d
print
a
b
c
d
kwonly
c
kwonly
c
b
kwonly
typeerror
kwonly
needs
keyword
only
argument
c
kwonly
typeerror
kwonly
takes
exactly
positional
argument
given
special
argument
matching
modes
ordering
rules
finally
note
that
keyword
only
arguments
must
be
specified
after
a
single
star
not
two
named
arguments
cannot
appear
after
the
args
arbitrary
keywords
form
and
a
can
t
appear
by
itself
in
the
arguments
list
both
attempts
generate
a
syntax
error
def
kwonly
a
pargs
b
c
syntaxerror
invalid
syntax
def
kwonly
a
b
c
syntaxerror
invalid
syntax
this
means
that
in
a
function
header
keyword
only
arguments
must
be
coded
before
the
args
arbitrary
keywords
form
and
after
the
args
arbitrary
positional
form
when
both
are
present
whenever
an
argument
name
appears
before
args
it
is
a
possibly
default
positional
argument
not
keyword
only
def
f
a
b
d
c
print
a
b
c
d
syntaxerror
invalid
syntax
keyword
only
before
def
f
a
b
c
d
print
a
b
c
d
f
x
y
y
x
collect
args
in
header
f
x
y
c
y
x
override
default
f
c
x
y
y
x
anywhere
in
keywords
def
f
a
c
b
d
print
a
b
c
d
f
x
x
c
is
not
keyword
only
default
used
in
fact
similar
ordering
rules
hold
true
in
function
calls
when
keyword
only
arguments
are
passed
they
must
appear
before
a
args
form
the
keyword
only
argument
can
be
coded
either
before
or
after
the
args
though
and
may
be
included
in
args
def
f
a
b
c
d
print
a
b
c
d
f
dict
x
y
y
x
kw
only
between
and
f
dict
x
y
c
syntaxerror
invalid
syntax
keywords
before
args
f
c
dict
x
y
y
x
override
default
f
c
dict
x
y
y
x
after
or
before
f
dict
x
y
c
y
x
keyword
only
in
chapter
arguments
unpack
args
at
call
trace
through
these
cases
on
your
own
in
conjunction
with
the
general
argumentordering
rules
described
formally
earlier
they
may
appear
to
be
worst
cases
in
the
artificial
examples
here
but
they
can
come
up
in
real
practice
especially
for
people
who
write
libraries
and
tools
for
other
python
programmers
to
use
why
keyword
only
arguments
so
why
care
about
keyword
only
arguments
in
short
they
make
it
easier
to
allow
a
function
to
accept
both
any
number
of
positional
arguments
to
be
processed
and
configuration
options
passed
as
keywords
while
their
use
is
optional
without
keywordonly
arguments
extra
work
may
be
required
to
provide
defaults
for
such
options
and
to
verify
that
no
superfluous
keywords
were
passed
imagine
a
function
that
processes
a
set
of
passed
in
objects
and
allows
a
tracing
flag
to
be
passed
process
x
y
z
process
x
y
notify
true
use
flag
s
default
override
flag
default
without
keyword
only
arguments
we
have
to
use
both
args
and
args
and
manually
inspect
the
keywords
but
with
keyword
only
arguments
less
code
is
required
the
following
guarantees
that
no
positional
argument
will
be
incorrectly
matched
against
notify
and
requires
that
it
be
a
keyword
if
passed
def
process
args
notify
false
since
we
re
going
to
see
a
more
realistic
example
of
this
later
in
this
chapter
in
emulating
the
python
print
function
on
page
i
ll
postpone
the
rest
of
this
story
until
then
for
an
additional
example
of
keyword
only
arguments
in
action
see
the
iteration
options
timing
case
study
in
chapter
and
for
additional
function
definition
enhancements
in
python
stay
tuned
for
the
discussion
of
function
annotation
syntax
in
chapter
the
min
wakeup
call
time
for
something
more
realistic
to
make
this
chapter
s
concepts
more
concrete
let
s
work
through
an
exercise
that
demonstrates
a
practical
application
of
argumentmatching
tools
suppose
you
want
to
code
a
function
that
is
able
to
compute
the
minimum
value
from
an
arbitrary
set
of
arguments
and
an
arbitrary
set
of
object
data
types
that
is
the
function
should
accept
zero
or
more
arguments
as
many
as
you
wish
to
pass
moreover
the
function
should
work
for
all
kinds
of
python
object
types
numbers
strings
lists
lists
of
dictionaries
files
and
even
none
the
first
requirement
provides
a
natural
example
of
how
the
feature
can
be
put
to
good
use
we
can
collect
arguments
into
a
tuple
and
step
over
each
of
them
in
turn
with
a
simple
for
loop
the
second
part
of
the
problem
definition
is
easy
because
every
the
min
wakeup
call
object
type
supports
comparisons
we
don
t
have
to
specialize
the
function
per
type
an
application
of
polymorphism
we
can
simply
compare
objects
blindly
and
let
python
worry
about
what
sort
of
comparison
to
perform
full
credit
the
following
file
shows
three
ways
to
code
this
operation
at
least
one
of
which
was
suggested
by
a
student
in
one
of
my
courses
the
first
function
fetches
the
first
argument
args
is
a
tuple
and
traverses
the
rest
by
slicing
off
the
first
there
s
no
point
in
comparing
an
object
to
itself
especially
if
it
might
be
a
large
structure
the
second
version
lets
python
pick
off
the
first
and
rest
of
the
arguments
automatically
and
so
avoids
an
index
and
slice
the
third
converts
from
a
tuple
to
a
list
with
the
built
in
list
call
and
employs
the
list
sort
method
the
sort
method
is
coded
in
c
so
it
can
be
quicker
than
the
other
approaches
at
times
but
the
linear
scans
of
the
first
two
techniques
will
make
them
faster
most
of
the
time
the
file
mins
py
contains
the
code
for
all
three
solutions
def
min
args
res
args
for
arg
in
args
if
arg
res
res
arg
return
res
def
min
first
rest
for
arg
in
rest
if
arg
first
first
arg
return
first
def
min
args
tmp
list
args
tmp
sort
return
tmp
or
in
python
return
sorted
args
print
min
actually
this
is
fairly
complicated
the
python
sort
routine
is
coded
in
c
and
uses
a
highly
optimized
algorithm
that
attempts
to
take
advantage
of
partial
ordering
in
the
items
to
be
sorted
it
s
named
timsort
after
tim
peters
its
creator
and
in
its
documentation
it
claims
to
have
supernatural
performance
at
times
pretty
good
for
a
sort
still
sorting
is
an
inherently
exponential
operation
it
must
chop
up
the
sequence
and
put
it
back
together
many
times
and
the
other
versions
simply
perform
one
linear
left
to
right
scan
the
net
effect
is
that
sorting
is
quicker
if
the
arguments
are
partially
ordered
but
is
likely
to
be
slower
otherwise
even
so
python
performance
can
change
over
time
and
the
fact
that
sorting
is
implemented
in
the
c
language
can
help
greatly
for
an
exact
analysis
you
should
time
the
alternatives
with
the
time
or
timeit
modules
we
ll
meet
in
chapter
chapter
arguments
print
min
bb
aa
print
min
all
three
solutions
produce
the
same
result
when
the
file
is
run
try
typing
a
few
calls
interactively
to
experiment
with
these
on
your
own
python
mins
py
aa
notice
that
none
of
these
three
variants
tests
for
the
case
where
no
arguments
are
passed
in
they
could
but
there
s
no
point
in
doing
so
here
in
all
three
solutions
python
will
automatically
raise
an
exception
if
no
arguments
are
passed
in
the
first
variant
raises
an
exception
when
we
try
to
fetch
item
the
second
when
python
detects
an
argument
list
mismatch
and
the
third
when
we
try
to
return
item
at
the
end
this
is
exactly
what
we
want
to
happen
because
these
functions
support
any
data
type
there
is
no
valid
sentinel
value
that
we
could
pass
back
to
designate
an
error
there
are
exceptions
to
this
rule
e
g
if
you
have
to
run
expensive
actions
before
you
reach
the
error
but
in
general
it
s
better
to
assume
that
arguments
will
work
in
your
functions
code
and
let
python
raise
errors
for
you
when
they
do
not
bonus
points
you
can
get
can
get
bonus
points
here
for
changing
these
functions
to
compute
the
maximum
rather
than
minimum
values
this
one
s
easy
the
first
two
versions
only
require
changing
to
and
the
third
simply
requires
that
we
return
tmp
instead
of
tmp
for
an
extra
point
be
sure
to
set
the
function
name
to
max
as
well
though
this
part
is
strictly
optional
it
s
also
possible
to
generalize
a
single
function
to
compute
either
a
minimum
or
a
maximum
value
by
evaluating
comparison
expression
strings
with
a
tool
like
the
eval
built
in
function
see
the
library
manual
or
passing
in
an
arbitrary
comparison
function
the
file
minmax
py
shows
how
to
implement
the
latter
scheme
def
minmax
test
args
res
args
for
arg
in
args
if
test
arg
res
res
arg
return
res
def
lessthan
x
y
return
x
y
def
grtrthan
x
y
return
x
y
see
also
lambda
print
minmax
lessthan
print
minmax
grtrthan
self
test
code
python
minmax
py
the
min
wakeup
call
functions
are
another
kind
of
object
that
can
be
passed
into
a
function
like
this
one
to
make
this
a
max
or
other
function
for
example
we
could
simply
pass
in
the
right
sort
of
test
function
this
may
seem
like
extra
work
but
the
main
point
of
generalizing
functions
this
way
instead
of
cutting
and
pasting
to
change
just
a
single
character
is
that
we
ll
only
have
one
version
to
change
in
the
future
not
two
the
punch
line
of
course
all
this
was
just
a
coding
exercise
there
s
really
no
reason
to
code
min
or
max
functions
because
both
are
built
ins
in
python
we
met
them
briefly
in
chapter
in
conjunction
with
numeric
tools
and
again
in
chapter
when
exploring
iteration
contexts
the
built
in
versions
work
almost
exactly
like
ours
but
they
re
coded
in
c
for
optimal
speed
and
accept
either
a
single
iterable
or
multiple
arguments
still
though
it
s
superfluous
in
this
context
the
general
coding
pattern
we
used
here
might
be
useful
in
other
scenarios
generalized
set
functions
let
s
look
at
a
more
useful
example
of
special
argument
matching
modes
at
work
at
the
end
of
chapter
we
wrote
a
function
that
returned
the
intersection
of
two
sequences
it
picked
out
items
that
appeared
in
both
here
is
a
version
that
intersects
an
arbitrary
number
of
sequences
one
or
more
by
using
the
varargs
matching
form
args
to
collect
all
the
passed
in
arguments
because
the
arguments
come
in
as
a
tuple
we
can
process
them
in
a
simple
for
loop
just
for
fun
we
ll
code
a
union
function
that
also
accepts
an
arbitrary
number
of
arguments
to
collect
items
that
appear
in
any
of
the
operands
def
intersect
args
res
for
x
in
args
for
other
in
args
if
x
not
in
other
break
else
res
append
x
return
res
def
union
args
res
for
seq
in
args
for
x
in
seq
if
not
x
in
res
res
append
x
return
res
chapter
arguments
scan
first
sequence
for
all
other
args
item
in
each
one
no
break
out
of
loop
yes
add
items
to
end
for
all
args
for
all
nodes
add
new
items
to
result
because
these
are
tools
worth
reusing
and
they
re
too
big
to
retype
interactively
we
ll
store
the
functions
in
a
module
file
called
inter
py
if
you
ve
forgotten
how
modules
and
imports
work
see
the
introduction
in
chapter
or
stay
tuned
for
in
depth
coverage
in
part
v
in
both
functions
the
arguments
passed
in
at
the
call
come
in
as
the
args
tuple
as
in
the
original
intersect
both
work
on
any
kind
of
sequence
here
they
are
processing
strings
mixed
types
and
more
than
two
sequences
python
from
inter
import
intersect
union
s
s
s
spam
scam
slam
intersect
s
s
union
s
s
s
a
m
s
p
a
m
c
two
operands
intersect
mixed
types
intersect
s
s
s
s
a
m
three
operands
union
s
s
s
s
p
a
m
c
l
i
should
note
that
because
python
now
has
a
set
object
type
described
in
chapter
none
of
the
set
processing
examples
in
this
book
are
strictly
required
anymore
they
are
included
only
as
demonstrations
of
coding
techniques
because
it
s
constantly
improving
python
has
an
uncanny
way
of
conspiring
to
make
my
book
examples
obsolete
over
time
emulating
the
python
print
function
to
round
out
the
chapter
let
s
look
at
one
last
example
of
argument
matching
at
work
the
code
you
ll
see
here
is
intended
for
use
in
python
or
earlier
it
works
in
too
but
is
pointless
there
it
uses
both
the
args
arbitrary
positional
tuple
and
the
args
arbitrary
keyword
arguments
dictionary
to
simulate
most
of
what
the
python
print
function
does
as
we
learned
in
chapter
this
isn
t
actually
required
because
programmers
can
always
enable
the
print
function
with
an
import
of
this
form
from
future
import
print
function
to
demonstrate
argument
matching
in
general
though
the
following
file
print
py
does
the
same
job
in
a
small
amount
of
reusable
code
emulating
the
python
print
function
emulate
most
of
the
print
function
for
use
in
x
call
signature
print
args
sep
end
n
file
none
import
sys
def
print
args
kargs
sep
kargs
get
sep
keyword
arg
defaults
end
kargs
get
end
n
file
kargs
get
file
sys
stdout
output
first
true
for
arg
in
args
output
if
first
else
sep
str
arg
first
false
file
write
output
end
to
test
it
import
this
into
another
file
or
the
interactive
prompt
and
use
it
like
the
print
function
here
is
a
test
script
testprint
py
notice
that
the
function
must
be
called
print
because
print
is
a
reserved
word
in
from
print
import
print
print
print
sep
print
sep
print
sep
print
sep
end
print
print
suppress
separator
various
object
types
suppress
newline
add
newline
or
blank
line
import
sys
print
sep
end
n
file
sys
stderr
redirect
to
file
when
run
under
we
get
the
same
results
as
s
print
function
c
misc
c
python
python
testprint
py
although
pointless
in
the
results
are
the
same
when
run
there
as
usual
the
generality
of
python
s
design
allows
us
to
prototype
or
develop
concepts
in
the
python
language
itself
in
this
case
argument
matching
tools
are
as
flexible
in
python
code
as
they
are
in
python
s
internal
implementation
chapter
arguments
using
keyword
only
arguments
it
s
interesting
to
notice
that
this
example
could
be
coded
with
python
keyword
only
arguments
described
earlier
in
this
chapter
to
automatically
validate
configuration
arguments
use
keyword
only
args
def
print
args
sep
end
n
file
sys
stdout
output
first
true
for
arg
in
args
output
if
first
else
sep
str
arg
first
false
file
write
output
end
this
version
works
the
same
as
the
original
and
it
s
a
prime
example
of
how
keywordonly
arguments
come
in
handy
the
original
version
assumes
that
all
positional
arguments
are
to
be
printed
and
all
keywords
are
for
options
only
that
s
almost
sufficient
but
any
extra
keyword
arguments
are
silently
ignored
a
call
like
the
following
for
instance
will
generate
an
exception
with
the
keyword
only
form
print
name
bob
typeerror
print
got
an
unexpected
keyword
argument
name
but
will
silently
ignore
the
name
argument
in
the
original
version
to
detect
superfluous
keywords
manually
we
could
use
dict
pop
to
delete
fetched
entries
and
check
if
the
dictionary
is
not
empty
here
is
an
equivalent
to
the
keyword
only
version
use
keyword
args
deletion
with
defaults
def
print
args
kargs
sep
kargs
pop
sep
end
kargs
pop
end
n
file
kargs
pop
file
sys
stdout
if
kargs
raise
typeerror
extra
keywords
s
kargs
output
first
true
for
arg
in
args
output
if
first
else
sep
str
arg
first
false
file
write
output
end
this
works
as
before
but
it
now
catches
extraneous
keyword
arguments
too
print
name
bob
typeerror
extra
keywords
name
bob
emulating
the
python
print
function
this
version
of
the
function
runs
under
python
but
it
requires
four
more
lines
of
code
than
the
keyword
only
version
unfortunately
the
extra
code
is
required
in
this
case
the
keyword
only
version
only
works
on
which
negates
most
of
the
reason
that
i
wrote
this
example
in
the
first
place
a
emulator
that
only
works
on
isn
t
incredibly
useful
in
programs
written
to
run
on
though
keyword
only
arguments
can
simplify
a
specific
category
of
functions
that
accept
both
arguments
and
options
for
another
example
of
keyword
only
arguments
be
sure
to
see
the
upcoming
iteration
timing
case
study
in
chapter
why
you
will
care
keyword
arguments
as
you
can
probably
tell
advanced
argument
matching
modes
can
be
complex
they
are
also
entirely
optional
you
can
get
by
with
just
simple
positional
matching
and
it
s
probably
a
good
idea
to
do
so
when
you
re
starting
out
however
because
some
python
tools
make
use
of
them
some
general
knowledge
of
these
modes
is
important
for
example
keyword
arguments
play
an
important
role
in
tkinter
the
de
facto
standard
gui
api
for
python
this
module
s
name
is
tkinter
in
python
we
touch
on
tkinter
only
briefly
at
various
points
in
this
book
but
in
terms
of
its
call
patterns
keyword
arguments
set
configuration
options
when
gui
components
are
built
for
instance
a
call
of
the
form
from
tkinter
import
widget
button
text
press
me
command
somefunction
creates
a
new
button
and
specifies
its
text
and
callback
function
using
the
text
and
command
keyword
arguments
since
the
number
of
configuration
options
for
a
widget
can
be
large
keyword
arguments
let
you
pick
and
choose
which
to
apply
without
them
you
might
have
to
either
list
all
the
possible
options
by
position
or
hope
for
a
judicious
positional
argument
defaults
protocol
that
would
handle
every
possible
option
arrangement
many
built
in
functions
in
python
expect
us
to
use
keywords
for
usage
mode
options
as
well
which
may
or
may
not
have
defaults
as
we
learned
in
chapter
for
instance
the
sorted
built
in
sorted
iterable
key
none
reverse
false
expects
us
to
pass
an
iterable
object
to
be
sorted
but
also
allows
us
to
pass
in
optional
keyword
arguments
to
specify
a
dictionary
sort
key
and
a
reversal
flag
which
default
to
none
and
false
respectively
since
we
normally
don
t
use
these
options
they
may
be
omitted
to
use
defaults
chapter
summary
in
this
chapter
we
studied
the
second
of
two
key
concepts
related
to
functions
arguments
how
objects
are
passed
into
a
function
as
we
learned
arguments
are
passed
into
a
function
by
assignment
which
means
by
object
reference
which
really
means
chapter
arguments
by
pointer
we
also
studied
some
more
advanced
extensions
including
default
and
keyword
arguments
tools
for
using
arbitrarily
many
arguments
and
keyword
only
arguments
in
finally
we
saw
how
mutable
arguments
can
exhibit
the
same
behavior
as
other
shared
references
to
objects
unless
the
object
is
explicitly
copied
when
it
s
sent
in
changing
a
passed
in
mutable
in
a
function
can
impact
the
caller
the
next
chapter
continues
our
look
at
functions
by
exploring
some
more
advanced
function
related
ideas
function
annotations
lambdas
and
functional
tools
such
as
map
and
filter
many
of
these
concepts
stem
from
the
fact
that
functions
are
normal
objects
in
python
and
so
support
some
advanced
and
very
flexible
processing
modes
before
diving
into
those
topics
however
take
this
chapter
s
quiz
to
review
the
argument
ideas
we
ve
studied
here
test
your
knowledge
quiz
what
is
the
output
of
the
following
code
and
why
def
func
a
b
c
print
a
b
c
func
what
is
the
output
of
this
code
and
why
def
func
a
b
c
print
a
b
c
func
c
b
how
about
this
code
what
is
its
output
and
why
def
func
a
pargs
print
a
pargs
func
what
does
this
code
print
and
why
def
func
a
kargs
print
a
kargs
func
a
c
b
one
last
time
what
is
the
output
of
this
code
and
why
def
func
a
b
c
d
print
a
b
c
d
func
name
three
or
more
ways
that
functions
can
communicate
results
to
a
caller
test
your
knowledge
quiz
test
your
knowledge
answers
the
output
here
is
because
and
are
passed
to
a
and
b
by
position
and
c
is
omitted
in
the
call
and
defaults
to
the
output
this
time
is
is
passed
to
a
by
position
and
b
and
c
are
passed
and
by
name
the
left
to
right
order
doesn
t
matter
when
keyword
arguments
are
used
like
this
this
code
prints
because
is
passed
to
a
and
the
pargs
collects
the
remaining
positional
arguments
into
a
new
tuple
object
we
can
step
through
the
extra
positional
arguments
tuple
with
any
iteration
tool
e
g
for
arg
in
pargs
this
time
the
code
prints
c
b
because
is
passed
to
a
by
name
and
the
kargs
collects
the
remaining
keyword
arguments
into
a
dictionary
we
could
step
through
the
extra
keyword
arguments
dictionary
by
key
with
any
iteration
tool
e
g
for
key
in
kargs
the
output
here
is
matches
a
by
position
and
match
b
and
c
by
name
positionals
overrides
c
s
default
and
d
defaults
to
because
it
was
not
passed
a
value
functions
can
send
back
results
with
return
statements
by
changing
passed
in
mutable
arguments
and
by
setting
global
variables
globals
are
generally
frowned
upon
except
for
very
special
cases
like
multithreaded
programs
because
they
can
make
code
more
difficult
to
understand
and
use
return
statements
are
usually
best
but
changing
mutables
is
fine
if
expected
functions
may
also
communicate
with
system
devices
such
as
files
and
sockets
but
these
are
beyond
our
scope
here
chapter
arguments
chapter
advanced
function
topics
this
chapter
introduces
a
collection
of
more
advanced
function
related
topics
recursive
functions
function
attributes
and
annotations
the
lambda
expression
and
functional
programming
tools
such
as
map
and
filter
these
are
all
somewhat
advanced
tools
that
depending
on
your
job
description
you
may
not
encounter
on
a
regular
basis
because
of
their
roles
in
some
domains
though
a
basic
understanding
can
be
useful
lambdas
for
instance
are
regular
customers
in
guis
part
of
the
art
of
using
functions
lies
in
the
interfaces
between
them
so
we
will
also
explore
some
general
function
design
principles
here
the
next
chapter
continues
this
advanced
theme
with
an
exploration
of
generator
functions
and
expressions
and
a
revival
of
list
comprehensions
in
the
context
of
the
functional
tools
we
will
study
here
function
design
concepts
now
that
we
ve
had
a
chance
to
study
function
basics
in
python
let
s
begin
this
chapter
with
a
few
words
of
context
when
you
start
using
functions
in
earnest
you
re
faced
with
choices
about
how
to
glue
components
together
for
instance
how
to
decompose
a
task
into
purposeful
functions
known
as
cohesion
how
your
functions
should
communicate
called
coupling
and
so
on
you
also
need
to
take
into
account
concepts
such
as
the
size
of
your
functions
because
they
directly
impact
code
usability
some
of
this
falls
into
the
category
of
structured
analysis
and
design
but
it
applies
to
python
code
as
to
any
other
we
introduced
some
ideas
related
to
function
and
module
coupling
in
the
chapter
when
studying
scopes
but
here
is
a
review
of
a
few
general
guidelines
for
function
beginners
coupling
use
arguments
for
inputs
and
return
for
outputs
generally
you
should
strive
to
make
a
function
independent
of
things
outside
of
it
arguments
and
return
statements
are
often
the
best
ways
to
isolate
external
dependencies
to
a
small
number
of
well
known
places
in
your
code
coupling
use
global
variables
only
when
truly
necessary
global
variables
i
e
names
in
the
enclosing
module
are
usually
a
poor
way
for
functions
to
communicate
they
can
create
dependencies
and
timing
issues
that
make
programs
difficult
to
debug
and
change
coupling
don
t
change
mutable
arguments
unless
the
caller
expects
it
functions
can
change
parts
of
passed
in
mutable
objects
but
as
with
global
variables
this
creates
lots
of
coupling
between
the
caller
and
callee
which
can
make
a
function
too
specific
and
brittle
cohesion
each
function
should
have
a
single
unified
purpose
when
designed
well
each
of
your
functions
should
do
one
thing
something
you
can
summarize
in
a
simple
declarative
sentence
if
that
sentence
is
very
broad
e
g
this
function
implements
my
whole
program
or
contains
lots
of
conjunctions
e
g
this
function
gives
employee
raises
and
submits
a
pizza
order
you
might
want
to
think
about
splitting
it
into
separate
and
simpler
functions
otherwise
there
is
no
way
to
reuse
the
code
behind
the
steps
mixed
together
in
the
function
size
each
function
should
be
relatively
small
this
naturally
follows
from
the
preceding
goal
but
if
your
functions
start
spanning
multiple
pages
on
your
display
it
s
probably
time
to
split
them
especially
given
that
python
code
is
so
concise
to
begin
with
a
long
or
deeply
nested
function
is
often
a
symptom
of
design
problems
keep
it
simple
and
keep
it
short
coupling
avoid
changing
variables
in
another
module
file
directly
we
introduced
this
concept
in
chapter
and
we
ll
revisit
it
in
the
next
part
of
the
book
when
we
focus
on
modules
for
reference
though
remember
that
changing
variables
across
file
boundaries
sets
up
a
coupling
between
modules
similar
to
how
global
variables
couple
functions
the
modules
become
difficult
to
understand
and
reuse
use
accessor
functions
whenever
possible
instead
of
direct
assignment
statements
figure
summarizes
the
ways
functions
can
talk
to
the
outside
world
inputs
may
come
from
items
on
the
left
side
and
results
may
be
sent
out
in
any
of
the
forms
on
the
right
good
function
designers
prefer
to
use
only
arguments
for
inputs
and
return
statements
for
outputs
whenever
possible
of
course
there
are
plenty
of
exceptions
to
the
preceding
design
rules
including
some
related
to
python
s
oop
support
as
you
ll
see
in
part
vi
python
classes
depend
on
changing
a
passed
in
mutable
object
class
functions
set
attributes
of
an
automatically
passed
in
argument
called
self
to
change
per
object
state
information
e
g
self
name
bob
moreover
if
classes
are
not
used
global
variables
are
often
the
most
straightforward
way
for
functions
in
modules
to
retain
state
between
calls
side
effects
are
dangerous
only
if
they
re
unexpected
in
general
though
you
should
strive
to
minimize
external
dependencies
in
functions
and
other
program
components
the
more
self
contained
a
function
is
the
easier
it
will
be
to
understand
reuse
and
modify
chapter
advanced
function
topics
figure
function
execution
environment
functions
may
obtain
input
and
produce
output
in
a
variety
of
ways
though
functions
are
usually
easier
to
understand
and
maintain
if
you
use
arguments
for
input
and
return
statements
and
anticipated
mutable
argument
changes
for
output
in
python
outputs
may
also
take
the
form
of
declared
nonlocal
names
that
exist
in
an
enclosing
function
scope
recursive
functions
while
discussing
scope
rules
near
the
start
of
chapter
we
briefly
noted
that
python
supports
recursive
functions
functions
that
call
themselves
either
directly
or
indirectly
in
order
to
loop
recursion
is
a
somewhat
advanced
topic
and
it
s
relatively
rare
to
see
in
python
still
it
s
a
useful
technique
to
know
about
as
it
allows
programs
to
traverse
structures
that
have
arbitrary
and
unpredictable
shapes
recursion
is
even
an
alternative
for
simple
loops
and
iterations
though
not
necessarily
the
simplest
or
most
efficient
one
summation
with
recursion
let
s
look
at
some
examples
to
sum
a
list
or
other
sequence
of
numbers
we
can
either
use
the
built
in
sum
function
or
write
a
more
custom
version
of
our
own
here
s
what
a
custom
summing
function
might
look
like
when
coded
with
recursion
def
mysum
l
if
not
l
return
else
return
l
mysum
l
call
myself
mysum
at
each
level
this
function
calls
itself
recursively
to
compute
the
sum
of
the
rest
of
the
list
which
is
later
added
to
the
item
at
the
front
the
recursive
loop
ends
and
zero
is
returned
when
the
list
becomes
empty
when
using
recursion
like
this
each
open
level
recursive
functions
of
call
to
the
function
has
its
own
copy
of
the
function
s
local
scope
on
the
runtime
call
stack
here
that
means
l
is
different
in
each
level
if
this
is
difficult
to
understand
and
it
often
is
for
new
programmers
try
adding
a
print
of
l
to
the
function
and
run
it
again
to
trace
the
current
list
at
each
call
level
def
mysum
l
print
l
if
not
l
return
else
return
l
mysum
l
trace
recursive
levels
l
shorter
at
each
level
mysum
as
you
can
see
the
list
to
be
summed
grows
smaller
at
each
recursive
level
until
it
becomes
empty
the
termination
of
the
recursive
loop
the
sum
is
computed
as
the
recursive
calls
unwind
coding
alternatives
interestingly
we
can
also
use
python
s
if
else
ternary
expression
described
in
chapter
to
save
some
code
real
estate
here
we
can
also
generalize
for
any
summable
type
which
is
easier
if
we
assume
at
least
one
item
in
the
input
as
we
did
in
chapter
s
minimum
value
example
and
use
python
s
extended
sequence
assignment
to
make
the
first
rest
unpacking
simpler
as
covered
in
chapter
def
mysum
l
return
if
not
l
else
l
mysum
l
use
ternary
expression
def
mysum
l
return
l
if
len
l
else
l
mysum
l
any
type
assume
one
def
mysum
l
first
rest
l
return
first
if
not
rest
else
first
mysum
rest
use
ext
seq
assign
the
latter
two
of
these
fail
for
empty
lists
but
allow
for
sequences
of
any
object
type
that
supports
not
just
numbers
mysum
mysum
mysum
s
p
a
m
spam
chapter
advanced
function
topics
mysum
fails
in
last
but
various
types
now
work
mysum
spam
ham
eggs
spamhameggs
if
you
study
these
three
variants
you
ll
find
that
the
latter
two
also
work
on
a
single
string
argument
e
g
mysum
spam
because
strings
are
sequences
of
one
character
strings
the
third
variant
works
on
arbitary
iterables
including
open
input
files
but
the
others
do
not
because
they
index
and
the
function
header
def
mysum
first
rest
although
similar
to
the
third
variant
wouldn
t
work
at
all
because
it
expects
individual
arguments
not
a
single
iterable
keep
in
mind
that
recursion
can
be
direct
as
in
the
examples
so
far
or
indirect
as
in
the
following
a
function
that
calls
another
function
which
calls
back
to
its
caller
the
net
effect
is
the
same
though
there
are
two
function
calls
at
each
level
instead
of
one
def
mysum
l
if
not
l
return
return
nonempty
l
def
nonempty
l
return
l
mysum
l
mysum
call
a
function
that
calls
me
indirectly
recursive
loop
statements
versus
recursion
though
recursion
works
for
summing
in
the
prior
sections
examples
it
s
probably
overkill
in
this
context
in
fact
recursion
is
not
used
nearly
as
often
in
python
as
in
more
esoteric
languages
like
prolog
or
lisp
because
python
emphasizes
simpler
procedural
statements
like
loops
which
are
usually
more
natural
the
while
for
example
often
makes
things
a
bit
more
concrete
and
it
doesn
t
require
that
a
function
be
defined
to
allow
recursive
calls
l
sum
while
l
sum
l
l
l
sum
better
yet
for
loops
iterate
for
us
automatically
making
recursion
largely
extraneous
in
most
cases
and
in
all
likelihood
less
efficient
in
terms
of
memory
space
and
execution
time
l
sum
for
x
in
l
sum
x
sum
recursive
functions
with
looping
statements
we
don
t
require
a
fresh
copy
of
a
local
scope
on
the
call
stack
for
each
iteration
and
we
avoid
the
speed
costs
associated
with
function
calls
in
general
stay
tuned
for
chapter
s
timer
case
study
for
ways
to
compare
the
execution
times
of
alternatives
like
these
handling
arbitrary
structures
on
the
other
hand
recursion
or
equivalent
explicit
stack
based
algorithms
which
we
ll
finesse
here
can
be
required
to
traverse
arbitrarily
shaped
structures
as
a
simple
example
of
recursion
s
role
in
this
context
consider
the
task
of
computing
the
sum
of
all
the
numbers
in
a
nested
sublists
structure
like
this
arbitrarily
nested
sublists
simple
looping
statements
won
t
work
here
because
this
not
a
linear
iteration
nested
looping
statements
do
not
suffice
either
because
the
sublists
may
be
nested
to
arbitrary
depth
and
in
an
arbitrary
shape
instead
the
following
code
accommodates
such
general
nesting
by
using
recursion
to
visit
sublists
along
the
way
def
sumtree
l
tot
for
x
in
l
if
not
isinstance
x
list
tot
x
else
tot
sumtree
x
return
tot
l
print
sumtree
l
for
each
item
at
this
level
add
numbers
directly
recur
for
sublists
arbitrary
nesting
prints
pathological
cases
print
sumtree
prints
right
heavy
print
sumtree
prints
left
heavy
trace
through
the
test
cases
at
the
bottom
of
this
script
to
see
how
recursion
traverses
their
nested
lists
although
this
example
is
artificial
it
is
representative
of
a
larger
class
of
programs
inheritance
trees
and
module
import
chains
for
example
can
exhibit
similarly
general
structures
in
fact
we
will
use
recursion
again
in
such
roles
in
more
realistic
examples
later
in
this
book
in
chapter
s
reloadall
py
to
traverse
import
chains
in
chapter
s
classtree
py
to
traverse
class
inheritance
trees
in
chapter
s
lister
py
to
traverse
class
inheritance
trees
again
chapter
advanced
function
topics
although
you
should
generally
prefer
looping
statements
to
recursion
for
linear
iterations
on
the
grounds
of
simplicity
and
efficiency
we
ll
find
that
recursion
is
essential
in
scenarios
like
those
in
these
later
examples
moreover
you
sometimes
need
to
be
aware
of
the
potential
of
unintended
recursion
in
your
programs
as
you
ll
also
see
later
in
the
book
some
operator
overloading
methods
in
classes
such
as
setattr
and
getattribute
have
the
potential
to
recursively
loop
if
used
incorrectly
recursion
is
a
powerful
tool
but
it
tends
to
be
best
when
expected
function
objects
attributes
and
annotations
python
functions
are
more
flexible
than
you
might
think
as
we
ve
seen
in
this
part
of
the
book
functions
in
python
are
much
more
than
code
generation
specifications
for
a
compiler
python
functions
are
full
blown
objects
stored
in
pieces
of
memory
all
their
own
as
such
they
can
be
freely
passed
around
a
program
and
called
indirectly
they
also
support
operations
that
have
little
to
do
with
calls
at
all
attribute
storage
and
annotation
indirect
function
calls
because
python
functions
are
objects
you
can
write
programs
that
process
them
generically
function
objects
may
be
assigned
to
other
names
passed
to
other
functions
embedded
in
data
structures
returned
from
one
function
to
another
and
more
as
if
they
were
simple
numbers
or
strings
function
objects
also
happen
to
support
a
special
operation
they
can
be
called
by
listing
arguments
in
parentheses
after
a
function
expression
still
functions
belong
to
the
same
general
category
as
other
objects
we
ve
seen
some
of
these
generic
use
cases
for
functions
in
earlier
examples
but
a
quick
review
helps
to
underscore
the
object
model
for
example
there
s
really
nothing
special
about
the
name
used
in
a
def
statement
it
s
just
a
variable
assigned
in
the
current
scope
as
if
it
had
appeared
on
the
left
of
an
sign
after
a
def
runs
the
function
name
is
simply
a
reference
to
an
object
you
can
reassign
that
object
to
other
names
freely
and
call
it
through
any
reference
def
echo
message
print
message
echo
direct
call
direct
call
name
echo
assigned
to
function
object
x
echo
x
indirect
call
indirect
call
now
x
references
the
function
too
call
object
through
name
by
adding
call
object
through
original
name
function
objects
attributes
and
annotations
because
arguments
are
passed
by
assigning
objects
it
s
just
as
easy
to
pass
functions
to
other
functions
as
arguments
the
callee
may
then
call
the
passed
in
function
just
by
adding
arguments
in
parentheses
def
indirect
func
arg
func
arg
indirect
echo
argument
call
argument
call
call
the
passed
in
object
by
adding
pass
the
function
to
another
function
you
can
even
stuff
function
objects
into
data
structures
as
though
they
were
integers
or
strings
the
following
for
example
embeds
the
function
twice
in
a
list
of
tuples
as
a
sort
of
actions
table
because
python
compound
types
like
these
can
contain
any
sort
of
object
there
s
no
special
case
here
either
schedule
echo
spam
echo
ham
for
func
arg
in
schedule
func
arg
call
functions
embedded
in
containers
spam
ham
this
code
simply
steps
through
the
schedule
list
calling
the
echo
function
with
one
argument
each
time
through
notice
the
tuple
unpacking
assignment
in
the
for
loop
header
introduced
in
chapter
as
we
saw
in
chapter
s
examples
functions
can
also
be
created
and
returned
for
use
elsewhere
def
make
label
make
a
function
but
don
t
call
it
def
echo
message
print
label
message
return
echo
f
make
spam
label
in
enclosing
scope
is
retained
f
ham
call
the
function
that
make
returned
spam
ham
f
eggs
spam
eggs
python
s
universal
object
model
and
lack
of
type
declarations
make
for
an
incredibly
flexible
programming
language
function
introspection
because
they
are
objects
we
can
also
process
functions
with
normal
object
tools
in
fact
functions
are
more
flexible
than
you
might
expect
for
instance
once
we
make
a
function
we
can
call
it
as
usual
def
func
a
b
spam
return
b
a
func
spamspamspamspamspamspamspamspam
chapter
advanced
function
topics
but
the
call
expression
is
just
one
operation
defined
to
work
on
function
objects
we
can
also
inspect
their
attributes
generically
the
following
is
run
in
python
but
results
are
similar
func
name
func
dir
func
annotations
call
class
closure
code
more
omitted
repr
setattr
sizeof
str
subclasshook
introspection
tools
allow
us
to
explore
implementation
details
too
functions
have
attached
code
objects
for
example
which
provide
details
on
aspects
such
as
the
functions
local
variables
and
arguments
func
code
code
object
func
at
x
c
b
file
stdin
line
dir
func
code
class
delattr
doc
eq
format
ge
more
omitted
co
argcount
co
cellvars
co
code
co
consts
co
filename
co
firstlineno
co
flags
co
freevars
co
kwonlyargcount
co
lnotab
co
name
co
names
co
nlocals
co
stacksize
co
varnames
func
code
co
varnames
a
b
func
code
co
argcount
tool
writers
can
make
use
of
such
information
to
manage
functions
in
fact
we
will
too
in
chapter
to
implement
validation
of
function
arguments
in
decorators
function
attributes
function
objects
are
not
limited
to
the
system
defined
attributes
listed
in
the
prior
section
though
as
we
learned
in
chapter
it
s
possible
to
attach
arbitrary
userdefined
attributes
to
them
as
well
func
function
func
at
x
c
func
count
func
count
func
count
func
handles
button
press
func
handles
button
press
dir
func
annotations
call
class
closure
code
more
omitted
str
subclasshook
count
handles
function
objects
attributes
and
annotations
as
we
saw
in
that
chapter
such
attributes
can
be
used
to
attach
state
information
to
function
objects
directly
instead
of
using
other
techniques
such
as
globals
nonlocals
and
classes
unlike
nonlocals
such
attributes
are
accessible
anywhere
the
function
itself
is
in
a
sense
this
is
also
a
way
to
emulate
static
locals
in
other
languages
variables
whose
names
are
local
to
a
function
but
whose
values
are
retained
after
a
function
exits
attributes
are
related
to
objects
instead
of
scopes
but
the
net
effect
is
similar
function
annotations
in
in
python
but
not
it
s
also
possible
to
attach
annotation
information
arbitrary
user
defined
data
about
a
function
s
arguments
and
result
to
a
function
object
python
provides
special
syntax
for
specifying
annotations
but
it
doesn
t
do
anything
with
them
itself
annotations
are
completely
optional
and
when
present
are
simply
attached
to
the
function
object
s
annotations
attribute
for
use
by
other
tools
we
met
python
s
keyword
only
arguments
in
the
prior
chapter
annotations
generalize
function
header
syntax
further
consider
the
following
nonannotated
function
which
is
coded
with
three
arguments
and
returns
a
result
def
func
a
b
c
return
a
b
c
func
syntactically
function
annotations
are
coded
in
def
header
lines
as
arbitrary
expressions
associated
with
arguments
and
return
values
for
arguments
they
appear
after
a
colon
immediately
following
the
argument
s
name
for
return
values
they
are
written
after
a
following
the
arguments
list
this
code
for
example
annotates
all
three
of
the
prior
function
s
arguments
as
well
as
its
return
value
def
func
a
spam
b
c
float
int
return
a
b
c
func
calls
to
an
annotated
function
work
as
usual
but
when
annotations
are
present
python
collects
them
in
a
dictionary
and
attaches
it
to
the
function
object
itself
argument
names
become
keys
the
return
value
annotation
is
stored
under
key
return
if
coded
and
the
values
of
annotation
keys
are
assigned
to
the
results
of
the
annotation
expressions
func
annotations
a
spam
c
class
float
b
return
class
int
because
they
are
just
python
objects
attached
to
a
python
object
annotations
are
straightforward
to
process
the
following
annotates
just
two
of
three
arguments
and
steps
through
the
attached
annotations
generically
chapter
advanced
function
topics
def
func
a
spam
b
c
return
a
b
c
func
func
annotations
a
spam
c
for
arg
in
func
annotations
print
arg
func
annotations
arg
a
spam
c
there
are
two
fine
points
to
note
here
first
you
can
still
use
defaults
for
arguments
if
you
code
annotations
the
annotation
and
its
character
appear
before
the
default
and
its
character
in
the
following
for
example
a
spam
means
that
argument
a
defaults
to
and
is
annotated
with
the
string
spam
def
func
a
spam
b
c
float
int
return
a
b
c
func
func
all
defaults
func
c
keywords
work
normally
func
annotations
a
spam
c
class
float
b
return
class
int
second
note
that
the
blank
spaces
in
the
prior
example
are
all
optional
you
can
use
spaces
between
components
in
function
headers
or
not
but
omitting
them
might
degrade
your
code
s
readability
to
some
observers
def
func
a
spam
b
c
float
int
return
a
b
c
func
func
annotations
a
spam
c
class
float
b
return
class
int
annotations
are
a
new
feature
in
and
some
of
their
potential
uses
remain
to
be
uncovered
it
s
easy
to
imagine
annotations
being
used
to
specify
constraints
for
argument
types
or
values
though
and
larger
apis
might
use
this
feature
as
a
way
to
register
function
interface
information
in
fact
we
ll
see
a
potential
application
in
chapter
where
we
ll
look
at
annotations
as
an
alternative
to
function
decorator
arguments
a
more
general
concept
in
which
information
is
coded
outside
the
function
header
and
so
is
not
limited
to
a
single
role
like
python
itself
annotation
is
a
tool
whose
roles
are
shaped
by
your
imagination
function
objects
attributes
and
annotations
finally
note
that
annotations
work
only
in
def
statements
not
lambda
expressions
because
lambda
s
syntax
already
limits
the
utility
of
the
functions
it
defines
coincidentally
this
brings
us
to
our
next
topic
anonymous
functions
lambda
besides
the
def
statement
python
also
provides
an
expression
form
that
generates
function
objects
because
of
its
similarity
to
a
tool
in
the
lisp
language
it
s
called
lambda
like
def
this
expression
creates
a
function
to
be
called
later
but
it
returns
the
function
instead
of
assigning
it
to
a
name
this
is
why
lambdas
are
sometimes
known
as
anonymous
i
e
unnamed
functions
in
practice
they
are
often
used
as
a
way
to
inline
a
function
definition
or
to
defer
execution
of
a
piece
of
code
lambda
basics
the
lambda
s
general
form
is
the
keyword
lambda
followed
by
one
or
more
arguments
exactly
like
the
arguments
list
you
enclose
in
parentheses
in
a
def
header
followed
by
an
expression
after
a
colon
lambda
argument
argument
argumentn
expression
using
arguments
function
objects
returned
by
running
lambda
expressions
work
exactly
the
same
as
those
created
and
assigned
by
defs
but
there
are
a
few
differences
that
make
lambdas
useful
in
specialized
roles
lambda
is
an
expression
not
a
statement
because
of
this
a
lambda
can
appear
in
places
a
def
is
not
allowed
by
python
s
syntax
inside
a
list
literal
or
a
function
call
s
arguments
for
example
as
an
expression
lambda
returns
a
value
a
new
function
that
can
optionally
be
assigned
a
name
in
contrast
the
def
statement
always
assigns
the
new
function
to
the
name
in
the
header
instead
of
returning
it
as
a
result
lambda
s
body
is
a
single
expression
not
a
block
of
statements
the
lambda
s
body
is
similar
to
what
you
d
put
in
a
def
body
s
return
statement
you
simply
type
the
result
as
a
naked
expression
instead
of
explicitly
returning
it
because
it
is
limited
to
an
expression
a
lambda
is
less
general
than
a
def
you
can
only
squeeze
so
much
logic
into
a
lambda
body
without
using
statements
such
as
if
this
is
by
design
to
limit
program
nesting
lambda
is
designed
for
coding
simple
functions
and
def
handles
larger
tasks
the
lambda
tends
to
intimidate
people
more
than
it
should
this
reaction
seems
to
stem
from
the
name
lambda
itself
a
name
that
comes
from
the
lisp
language
which
got
it
from
lambda
calculus
which
is
a
form
of
symbolic
logic
in
python
though
it
s
really
just
a
keyword
that
introduces
the
expression
syntactically
obscure
mathematical
heritage
aside
lambda
is
simpler
to
use
than
you
may
think
chapter
advanced
function
topics
apart
from
those
distinctions
defs
and
lambdas
do
the
same
sort
of
work
for
instance
we
ve
seen
how
to
make
a
function
with
a
def
statement
def
func
x
y
z
return
x
y
z
func
but
you
can
achieve
the
same
effect
with
a
lambda
expression
by
explicitly
assigning
its
result
to
a
name
through
which
you
can
later
call
the
function
f
lambda
x
y
z
x
y
z
f
here
f
is
assigned
the
function
object
the
lambda
expression
creates
this
is
how
def
works
too
but
its
assignment
is
automatic
defaults
work
on
lambda
arguments
just
like
in
a
def
x
lambda
a
fee
b
fie
c
foe
a
b
c
x
wee
weefiefoe
the
code
in
a
lambda
body
also
follows
the
same
scope
lookup
rules
as
code
inside
a
def
lambda
expressions
introduce
a
local
scope
much
like
a
nested
def
which
automatically
sees
names
in
enclosing
functions
the
module
and
the
built
in
scope
via
the
legb
rule
def
knights
title
sir
action
lambda
x
title
x
return
action
act
knights
act
robin
sir
robin
title
in
enclosing
def
return
a
function
in
this
example
prior
to
release
the
value
for
the
name
title
would
typically
have
been
passed
in
as
a
default
argument
value
instead
flip
back
to
the
scopes
coverage
in
chapter
if
you
ve
forgotten
why
why
use
lambda
generally
speaking
lambdas
come
in
handy
as
a
sort
of
function
shorthand
that
allows
you
to
embed
a
function
s
definition
within
the
code
that
uses
it
they
are
entirely
optional
you
can
always
use
defs
instead
but
they
tend
to
be
simpler
coding
constructs
in
scenarios
where
you
just
need
to
embed
small
bits
of
executable
code
for
instance
we
ll
see
later
that
callback
handlers
are
frequently
coded
as
inline
lambda
expressions
embedded
directly
in
a
registration
call
s
arguments
list
instead
of
being
defined
with
a
def
elsewhere
in
a
file
and
referenced
by
name
see
the
sidebar
why
you
will
care
callbacks
on
page
for
an
example
anonymous
functions
lambda
lambdas
are
also
commonly
used
to
code
jump
tables
which
are
lists
or
dictionaries
of
actions
to
be
performed
on
demand
for
example
inline
function
definition
l
lambda
x
x
lambda
x
x
lambda
x
x
a
list
of
callable
functions
for
f
in
l
print
f
prints
print
l
prints
the
lambda
expression
is
most
useful
as
a
shorthand
for
def
when
you
need
to
stuff
small
pieces
of
executable
code
into
places
where
statements
are
illegal
syntactically
this
code
snippet
for
example
builds
up
a
list
of
three
functions
by
embedding
lambda
expressions
inside
a
list
literal
a
def
won
t
work
inside
a
list
literal
like
this
because
it
is
a
statement
not
an
expression
the
equivalent
def
coding
would
require
temporary
function
names
and
function
definitions
outside
the
context
of
intended
use
def
f
x
return
x
def
f
x
return
x
def
f
x
return
x
define
named
functions
l
f
f
f
reference
by
name
for
f
in
l
print
f
prints
print
l
prints
in
fact
you
can
do
the
same
sort
of
thing
with
dictionaries
and
other
data
structures
in
python
to
build
up
more
general
sorts
of
action
tables
here
s
another
example
to
illustrate
at
the
interactive
prompt
key
got
already
lambda
got
lambda
one
lambda
key
here
when
python
makes
the
temporary
dictionary
each
of
the
nested
lambdas
generates
and
leaves
behind
a
function
to
be
called
later
indexing
by
key
fetches
one
of
those
functions
and
parentheses
force
the
fetched
function
to
be
called
when
coded
this
way
a
dictionary
becomes
a
more
general
multiway
branching
tool
than
what
i
could
show
you
in
chapter
s
coverage
of
if
statements
to
make
this
work
without
lambda
you
d
need
to
instead
code
three
def
statements
somewhere
else
in
your
file
outside
the
dictionary
in
which
the
functions
are
to
be
used
and
reference
the
functions
by
name
def
f
return
def
f
return
chapter
advanced
function
topics
def
f
return
key
one
already
f
got
f
one
f
key
this
works
too
but
your
defs
may
be
arbitrarily
far
away
in
your
file
even
if
they
are
just
little
bits
of
code
the
code
proximity
that
lambdas
provide
is
especially
useful
for
functions
that
will
only
be
used
in
a
single
context
if
the
three
functions
here
are
not
useful
anywhere
else
it
makes
sense
to
embed
their
definitions
within
the
dictionary
as
lambdas
moreover
the
def
form
requires
you
to
make
up
names
for
these
little
functions
that
may
clash
with
other
names
in
this
file
perhaps
unlikely
but
always
possible
lambdas
also
come
in
handy
in
function
call
argument
lists
as
a
way
to
inline
temporary
function
definitions
not
used
anywhere
else
in
your
program
we
ll
see
some
examples
of
such
other
uses
later
in
this
chapter
when
we
study
map
how
not
to
obfuscate
your
python
code
the
fact
that
the
body
of
a
lambda
has
to
be
a
single
expression
not
a
series
of
statements
would
seem
to
place
severe
limits
on
how
much
logic
you
can
pack
into
a
lambda
if
you
know
what
you
re
doing
though
you
can
code
most
statements
in
python
as
expression
based
equivalents
for
example
if
you
want
to
print
from
the
body
of
a
lambda
function
simply
say
sys
stdout
write
str
x
n
instead
of
print
x
recall
from
chapter
that
this
is
what
print
really
does
similarly
to
nest
logic
in
a
lambda
you
can
use
the
if
else
ternary
expression
introduced
in
chapter
or
the
equivalent
but
trickier
and
or
combination
also
described
there
as
you
learned
earlier
the
following
statement
if
a
b
else
c
can
be
emulated
by
either
of
these
roughly
equivalent
expressions
b
if
a
else
c
a
and
b
or
c
because
expressions
like
these
can
be
placed
inside
a
lambda
they
may
be
used
to
implement
selection
logic
within
a
lambda
function
lower
lambda
x
y
x
if
x
y
else
y
lower
bb
aa
aa
lower
aa
bb
aa
anonymous
functions
lambda
furthermore
if
you
need
to
perform
loops
within
a
lambda
you
can
also
embed
things
like
map
calls
and
list
comprehension
expressions
tools
we
met
in
earlier
chapters
and
will
revisit
in
this
and
the
next
chapter
import
sys
showall
lambda
x
list
map
sys
stdout
write
x
use
list
in
t
showall
spam
n
toast
n
eggs
n
spam
toast
eggs
showall
lambda
x
sys
stdout
write
line
for
line
in
x
t
showall
bright
n
side
n
of
n
life
n
bright
side
of
life
now
that
i
ve
shown
you
these
tricks
i
am
required
by
law
to
ask
you
to
please
only
use
them
as
a
last
resort
without
due
care
they
can
lead
to
unreadable
a
k
a
obfuscated
python
code
in
general
simple
is
better
than
complex
explicit
is
better
than
implicit
and
full
statements
are
better
than
arcane
expressions
that
s
why
lambda
is
limited
to
expressions
if
you
have
larger
logic
to
code
use
def
lambda
is
for
small
pieces
of
inline
code
on
the
other
hand
you
may
find
these
techniques
useful
in
moderation
nested
lambdas
and
scopes
lambdas
are
the
main
beneficiaries
of
nested
function
scope
lookup
the
e
in
the
legb
scope
rule
we
studied
in
chapter
in
the
following
for
example
the
lambda
appears
inside
a
def
the
typical
case
and
so
can
access
the
value
that
the
name
x
had
in
the
enclosing
function
s
scope
at
the
time
that
the
enclosing
function
was
called
def
action
x
return
lambda
y
x
y
act
action
act
function
lambda
at
x
a
a
act
make
and
return
function
remember
x
call
what
action
returned
what
wasn
t
illustrated
in
the
prior
discussion
of
nested
function
scopes
is
that
a
lambda
also
has
access
to
the
names
in
any
enclosing
lambda
this
case
is
somewhat
obscure
but
imagine
if
we
recoded
the
prior
def
with
a
lambda
action
lambda
x
lambda
y
x
y
act
action
act
chapter
advanced
function
topics
lambda
x
lambda
y
x
y
here
the
nested
lambda
structure
makes
a
function
that
makes
a
function
when
called
in
both
cases
the
nested
lambda
s
code
has
access
to
the
variable
x
in
the
enclosing
lambda
this
works
but
it
s
fairly
convoluted
code
in
the
interest
of
readability
nested
lambdas
are
generally
best
avoided
why
you
will
care
callbacks
another
very
common
application
of
lambda
is
to
define
inline
callback
functions
for
python
s
tkinter
gui
api
this
module
is
named
tkinter
in
python
for
example
the
following
creates
a
button
that
prints
a
message
on
the
console
when
pressed
assuming
tkinter
is
available
on
your
computer
it
is
by
default
on
windows
and
other
oss
import
sys
from
tkinter
import
button
mainloop
tkinter
in
x
button
text
press
me
command
lambda
sys
stdout
write
spam
n
x
pack
mainloop
here
the
callback
handler
is
registered
by
passing
a
function
generated
with
a
lambda
to
the
command
keyword
argument
the
advantage
of
lambda
over
def
here
is
that
the
code
that
handles
a
button
press
is
right
here
embedded
in
the
button
creation
call
in
effect
the
lambda
defers
execution
of
the
handler
until
the
event
occurs
the
write
call
happens
on
button
presses
not
when
the
button
is
created
because
the
nested
function
scope
rules
apply
to
lambdas
as
well
they
are
also
easier
to
use
as
callback
handlers
as
of
python
they
automatically
see
names
in
the
functions
in
which
they
are
coded
and
no
longer
require
passed
in
defaults
in
most
cases
this
is
especially
handy
for
accessing
the
special
self
instance
argument
that
is
a
local
variable
in
enclosing
class
method
functions
more
on
classes
in
part
vi
class
mygui
def
makewidgets
self
button
command
lambda
self
onpress
spam
def
onpress
self
message
use
message
in
prior
releases
even
self
had
to
be
passed
in
to
a
lambda
with
defaults
mapping
functions
over
sequences
map
one
of
the
more
common
things
programs
do
with
lists
and
other
sequences
is
apply
an
operation
to
each
item
and
collect
the
results
for
instance
updating
all
the
counters
in
a
list
can
be
done
easily
with
a
for
loop
mapping
functions
over
sequences
map
counters
updated
for
x
in
counters
updated
append
x
updated
add
to
each
item
but
because
this
is
such
a
common
operation
python
actually
provides
a
built
in
that
does
most
of
the
work
for
you
the
map
function
applies
a
passed
in
function
to
each
item
in
an
iterable
object
and
returns
a
list
containing
all
the
function
call
results
for
example
def
inc
x
return
x
list
map
inc
counters
function
to
be
run
collect
results
we
met
map
briefly
in
chapters
and
as
a
way
to
apply
a
built
in
function
to
items
in
an
iterable
here
we
make
better
use
of
it
by
passing
in
a
user
defined
function
to
be
applied
to
each
item
in
the
list
map
calls
inc
on
each
list
item
and
collects
all
the
return
values
into
a
new
list
remember
that
map
is
an
iterable
in
python
so
a
list
call
is
used
to
force
it
to
produce
all
its
results
for
display
here
this
isn
t
necessary
in
because
map
expects
a
function
to
be
passed
in
it
also
happens
to
be
one
of
the
places
where
lambda
commonly
appears
list
map
lambda
x
x
counters
function
expression
here
the
function
adds
to
each
item
in
the
counters
list
as
this
little
function
isn
t
needed
elsewhere
it
was
written
inline
as
a
lambda
because
such
uses
of
map
are
equivalent
to
for
loops
with
a
little
extra
code
you
can
always
code
a
general
mapping
utility
yourself
def
mymap
func
seq
res
for
x
in
seq
res
append
func
x
return
res
assuming
the
function
inc
is
still
as
it
was
when
it
was
shown
previously
we
can
map
it
across
a
sequence
with
the
built
in
or
our
equivalent
list
map
inc
mymap
inc
built
in
is
an
iterator
ours
builds
a
list
see
generators
however
as
map
is
a
built
in
it
s
always
available
always
works
the
same
way
and
has
some
performance
benefits
as
we
ll
prove
in
the
next
chapter
it
s
usually
faster
than
a
manually
coded
for
loop
moreover
map
can
be
used
in
more
advanced
ways
than
chapter
advanced
function
topics
shown
here
for
instance
given
multiple
sequence
arguments
it
sends
items
taken
from
sequences
in
parallel
as
distinct
arguments
to
the
function
pow
list
map
pow
with
multiple
sequences
map
expects
an
n
argument
function
for
n
sequences
here
the
pow
function
takes
two
arguments
on
each
call
one
from
each
sequence
passed
to
map
it
s
not
much
extra
work
to
simulate
this
multiple
sequence
generality
in
code
too
but
we
ll
postpone
doing
so
until
later
in
the
next
chapter
after
we
ve
met
some
additional
iteration
tools
the
map
call
is
similar
to
the
list
comprehension
expressions
we
studied
in
chapter
and
will
meet
again
in
the
next
chapter
but
map
applies
a
function
call
to
each
item
instead
of
an
arbitrary
expression
because
of
this
limitation
it
is
a
somewhat
less
general
tool
however
in
some
cases
map
may
be
faster
to
run
than
a
list
comprehension
e
g
when
mapping
a
built
in
function
and
it
may
also
require
less
coding
functional
programming
tools
filter
and
reduce
the
map
function
is
the
simplest
representative
of
a
class
of
python
built
ins
used
for
functional
programming
tools
that
apply
functions
to
sequences
and
other
iterables
its
relatives
filter
out
items
based
on
a
test
function
filter
and
apply
functions
to
pairs
of
items
and
running
results
reduce
because
they
return
iterables
range
and
filter
both
require
list
calls
to
display
all
their
results
in
for
example
the
following
filter
call
picks
out
items
in
a
sequence
that
are
greater
than
zero
list
range
an
iterator
in
list
filter
lambda
x
x
range
an
iterator
in
items
in
the
sequence
or
iterable
for
which
the
function
returns
a
true
result
are
added
to
the
result
list
like
map
this
function
is
roughly
equivalent
to
a
for
loop
but
it
is
built
in
and
fast
res
for
x
in
range
if
x
res
append
x
res
reduce
which
is
a
simple
built
in
function
in
but
lives
in
the
functools
module
in
is
more
complex
it
accepts
an
iterator
to
process
but
it
s
not
an
iterator
itself
it
functional
programming
tools
filter
and
reduce
returns
a
single
result
here
are
two
reduce
calls
that
compute
the
sum
and
product
of
the
items
in
a
list
from
functools
import
reduce
import
in
not
in
reduce
lambda
x
y
x
y
reduce
lambda
x
y
x
y
at
each
step
reduce
passes
the
current
sum
or
product
along
with
the
next
item
from
the
list
to
the
passed
in
lambda
function
by
default
the
first
item
in
the
sequence
initializes
the
starting
value
to
illustrate
here
s
the
for
loop
equivalent
to
the
first
of
these
calls
with
the
addition
hardcoded
inside
the
loop
l
res
l
for
x
in
l
res
res
x
res
coding
your
own
version
of
reduce
is
actually
fairly
straightforward
the
following
function
emulates
most
of
the
built
in
s
behavior
and
helps
demystify
its
operation
in
general
def
myreduce
function
sequence
tally
sequence
for
next
in
sequence
tally
function
tally
next
return
tally
myreduce
lambda
x
y
x
y
myreduce
lambda
x
y
x
y
the
built
in
reduce
also
allows
an
optional
third
argument
placed
before
the
items
in
the
sequence
to
serve
as
a
default
result
when
the
sequence
is
empty
but
we
ll
leave
this
extension
as
a
suggested
exercise
if
this
coding
technique
has
sparked
your
interest
you
might
also
be
interested
in
the
standard
library
operator
module
which
provides
functions
that
correspond
to
builtin
expressions
and
so
comes
in
handy
for
some
uses
of
functional
tools
see
python
s
library
manual
for
more
details
on
this
module
import
operator
functools
functools
reduce
operator
add
function
based
functools
reduce
lambda
x
y
x
y
chapter
advanced
function
topics
together
with
map
filter
and
reduce
support
powerful
functional
programming
techniques
some
observers
might
also
extend
the
functional
programming
toolset
in
python
to
include
lambda
discussed
earlier
as
well
as
list
comprehensions
a
topic
we
will
return
to
in
the
next
chapter
chapter
summary
this
chapter
took
us
on
a
tour
of
advanced
function
related
concepts
recursive
functions
function
annotations
lambda
expression
functions
functional
tools
such
as
map
filter
and
reduce
and
general
function
design
ideas
the
next
chapter
continues
the
advanced
topics
motif
with
a
look
at
generators
and
a
reprisal
of
iterators
and
list
comprehensions
tools
that
are
just
as
related
to
functional
programming
as
to
looping
statements
before
you
move
on
though
make
sure
you
ve
mastered
the
concepts
covered
here
by
working
through
this
chapter
s
quiz
test
your
knowledge
quiz
how
are
lambda
expressions
and
def
statements
related
what
s
the
point
of
using
lamba
compare
and
contrast
map
filter
and
reduce
what
are
function
annotations
and
how
are
they
used
what
are
recursive
functions
and
how
are
they
used
what
are
some
general
design
guidelines
for
coding
functions
test
your
knowledge
answers
both
lambda
and
def
create
function
objects
to
be
called
later
because
lambda
is
an
expression
though
it
returns
a
function
object
instead
of
assigning
it
to
a
name
and
it
can
be
used
to
nest
a
function
definition
in
places
where
a
def
will
not
work
syntactically
a
lambda
only
allows
for
a
single
implicit
return
value
expression
though
because
it
does
not
support
a
block
of
statements
it
is
not
ideal
for
larger
functions
lambdas
allow
us
to
inline
small
units
of
executable
code
defer
its
execution
and
provide
it
with
state
in
the
form
of
default
arguments
and
enclosing
scope
variables
using
a
lambda
is
never
required
you
can
always
code
a
def
instead
and
reference
the
function
by
name
lambdas
come
in
handy
though
to
embed
small
pieces
of
deferred
code
that
are
unlikely
to
be
used
elsewhere
in
a
program
they
commonly
appear
in
callback
based
program
such
as
guis
and
they
have
a
natural
affinity
with
function
tools
like
map
and
filter
that
expect
a
processing
function
test
your
knowledge
answers
these
three
built
in
functions
all
apply
another
function
to
items
in
a
sequence
iterable
object
and
collect
results
map
passes
each
item
to
the
function
and
collects
all
results
filter
collects
items
for
which
the
function
returns
a
true
value
and
reduce
computes
a
single
value
by
applying
the
function
to
an
accumulator
and
successive
items
unlike
the
other
two
reduce
is
available
in
the
functools
module
in
not
the
built
in
scope
function
annotations
available
in
and
later
are
syntactic
embellishments
of
a
function
s
arguments
and
result
which
are
collected
into
a
dictionary
assigned
to
the
function
s
annotations
attribute
python
places
no
semantic
meaning
on
these
annotations
but
simply
packages
them
for
potential
use
by
other
tools
recursive
functions
call
themselves
either
directly
or
indirectly
in
order
to
loop
they
may
be
used
to
traverse
arbitrarily
shaped
structures
but
they
can
also
be
used
for
iteration
in
general
though
the
latter
role
is
often
more
simply
and
efficiently
coded
with
looping
statements
functions
should
generally
be
small
as
self
contained
as
possible
have
a
single
unified
purpose
and
communicate
with
other
components
through
input
arguments
and
return
values
they
may
use
mutable
arguments
to
communicate
results
too
if
changes
are
expected
and
some
types
of
programs
imply
other
communication
mechanisms
chapter
advanced
function
topics
chapter
iterations
and
comprehensions
part
this
chapter
continues
the
advanced
function
topics
theme
with
a
reprisal
of
the
comprehension
and
iteration
concepts
introduced
in
chapter
because
list
comprehensions
are
as
much
related
to
the
prior
chapter
s
functional
tools
e
g
map
and
filter
as
they
are
to
for
loops
we
ll
revisit
them
in
this
context
here
we
ll
also
take
a
second
look
at
iterators
in
order
to
study
generator
functions
and
their
generator
expression
relatives
user
defined
ways
to
produce
results
on
demand
iteration
in
python
also
encompasses
user
defined
classes
but
we
ll
defer
that
final
part
of
this
story
until
part
vi
when
we
study
operator
overloading
as
this
is
the
last
pass
we
ll
make
over
built
in
iteration
tools
though
we
will
summarize
the
various
tools
we
ve
met
thus
far
and
time
the
relative
performance
of
some
of
them
finally
because
this
is
the
last
chapter
in
the
part
of
the
book
we
ll
close
with
the
usual
sets
of
gotchas
and
exercises
to
help
you
start
coding
the
ideas
you
ve
read
about
list
comprehensions
revisited
functional
tools
in
the
prior
chapter
we
studied
functional
programming
tools
like
map
and
filter
which
map
operations
over
sequences
and
collect
results
because
this
is
such
a
common
task
in
python
coding
python
eventually
sprouted
a
new
expression
the
list
comprehension
that
is
even
more
flexible
than
the
tools
we
just
studied
in
short
list
comprehensions
apply
an
arbitrary
expression
to
items
in
an
iterable
rather
than
applying
a
function
as
such
they
can
be
more
general
tools
we
met
list
comprehensions
in
chapter
in
conjunction
with
looping
statements
because
they
re
also
related
to
functional
programming
tools
like
the
map
and
filter
calls
though
we
ll
resurrect
the
topic
here
for
one
last
look
technically
this
feature
is
not
tied
to
functions
as
we
ll
see
list
comprehensions
can
be
a
more
general
tool
than
map
and
filter
but
it
is
sometimes
best
understood
by
analogy
to
function
based
alternatives
list
comprehensions
versus
map
let
s
work
through
an
example
that
demonstrates
the
basics
as
we
saw
in
chapter
python
s
built
in
ord
function
returns
the
ascii
integer
code
of
a
single
character
the
chr
built
in
is
the
converse
it
returns
the
character
for
an
ascii
integer
code
ord
s
now
suppose
we
wish
to
collect
the
ascii
codes
of
all
characters
in
an
entire
string
perhaps
the
most
straightforward
approach
is
to
use
a
simple
for
loop
and
append
the
results
to
a
list
res
for
x
in
spam
res
append
ord
x
res
now
that
we
know
about
map
though
we
can
achieve
similar
results
with
a
single
function
call
without
having
to
manage
list
construction
in
the
code
res
list
map
ord
spam
res
apply
function
to
sequence
however
we
can
get
the
same
results
from
a
list
comprehension
expression
while
map
maps
a
function
over
a
sequence
list
comprehensions
map
an
expression
over
a
sequence
res
ord
x
for
x
in
spam
res
apply
expression
to
sequence
list
comprehensions
collect
the
results
of
applying
an
arbitrary
expression
to
a
sequence
of
values
and
return
them
in
a
new
list
syntactically
list
comprehensions
are
enclosed
in
square
brackets
to
remind
you
that
they
construct
lists
in
their
simple
form
within
the
brackets
you
code
an
expression
that
names
a
variable
followed
by
what
looks
like
a
for
loop
header
that
names
the
same
variable
python
then
collects
the
expression
s
results
for
each
iteration
of
the
implied
loop
the
effect
of
the
preceding
example
is
similar
to
that
of
the
manual
for
loop
and
the
map
call
list
comprehensions
become
more
convenient
though
when
we
wish
to
apply
an
arbitrary
expression
to
a
sequence
x
for
x
in
range
here
we
ve
collected
the
squares
of
the
numbers
through
we
re
just
letting
the
interactive
prompt
print
the
resulting
list
assign
it
to
a
variable
if
you
need
to
retain
it
to
do
similar
work
with
a
map
call
we
would
probably
need
to
invent
a
little
function
to
implement
the
square
operation
because
we
won
t
need
this
function
elsewhere
chapter
iterations
and
comprehensions
part
we
d
typically
but
not
necessarily
code
it
inline
with
a
lambda
instead
of
using
a
def
statement
elsewhere
list
map
lambda
x
x
range
this
does
the
same
job
and
it
s
only
a
few
keystrokes
longer
than
the
equivalent
list
comprehension
it
s
also
only
marginally
more
complex
at
least
once
you
understand
the
lambda
for
more
advanced
kinds
of
expressions
though
list
comprehensions
will
often
require
considerably
less
typing
the
next
section
shows
why
adding
tests
and
nested
loops
filter
list
comprehensions
are
even
more
general
than
shown
so
far
for
instance
as
we
learned
in
chapter
you
can
code
an
if
clause
after
the
for
to
add
selection
logic
list
comprehensions
with
if
clauses
can
be
thought
of
as
analogous
to
the
filter
builtin
discussed
in
the
prior
chapter
they
skip
sequence
items
for
which
the
if
clause
is
not
true
to
demonstrate
here
are
both
schemes
picking
up
even
numbers
from
to
like
the
map
list
comprehension
alternative
of
the
prior
section
the
filter
version
here
must
invent
a
little
lambda
function
for
the
test
expression
for
comparison
the
equivalent
for
loop
is
shown
here
as
well
x
for
x
in
range
if
x
list
filter
lambda
x
x
range
res
for
x
in
range
if
x
res
append
x
res
all
of
these
use
the
modulus
remainder
of
division
operator
to
detect
even
numbers
if
there
is
no
remainder
after
dividing
a
number
by
it
must
be
even
the
filter
call
here
is
not
much
longer
than
the
list
comprehension
either
however
we
can
combine
an
if
clause
and
an
arbitrary
expression
in
our
list
comprehension
to
give
it
the
effect
of
a
filter
and
a
map
in
a
single
expression
x
for
x
in
range
if
x
this
time
we
collect
the
squares
of
the
even
numbers
from
through
the
for
loop
skips
numbers
for
which
the
attached
if
clause
on
the
right
is
false
and
the
expression
on
the
left
computes
the
squares
the
equivalent
map
call
would
require
a
lot
more
work
list
comprehensions
revisited
functional
tools
on
our
part
we
would
have
to
combine
filter
selections
with
map
iteration
making
for
a
noticeably
more
complex
expression
list
map
lambda
x
x
filter
lambda
x
x
range
in
fact
list
comprehensions
are
more
general
still
you
can
code
any
number
of
nested
for
loops
in
a
list
comprehension
and
each
may
have
an
optional
associated
if
test
the
general
structure
of
list
comprehensions
looks
like
this
expression
for
target
in
iterable
if
condition
for
target
in
iterable
if
condition
for
targetn
in
iterablen
if
conditionn
when
for
clauses
are
nested
within
a
list
comprehension
they
work
like
equivalent
nested
for
loop
statements
for
example
the
following
res
x
y
for
x
in
for
y
in
res
has
the
same
effect
as
this
substantially
more
verbose
equivalent
res
for
x
in
for
y
in
res
append
x
y
res
although
list
comprehensions
construct
lists
remember
that
they
can
iterate
over
any
sequence
or
other
iterable
type
here
s
a
similar
bit
of
code
that
traverses
strings
instead
of
lists
of
numbers
and
so
collects
concatenation
results
x
y
for
x
in
spam
for
y
in
spam
ss
sp
sa
sm
ps
pp
pa
pm
as
ap
aa
am
ms
mp
ma
mm
finally
here
is
a
much
more
complex
list
comprehension
that
illustrates
the
effect
of
attached
if
selections
on
nested
for
clauses
x
y
for
x
in
range
if
x
for
y
in
range
if
y
this
expression
permutes
even
numbers
from
through
with
odd
numbers
from
through
the
if
clauses
filter
out
items
in
each
sequence
iteration
here
is
the
equivalent
statement
based
code
res
for
x
in
range
if
x
for
y
in
range
if
y
res
append
x
y
chapter
iterations
and
comprehensions
part
res
recall
that
if
you
re
confused
about
what
a
complex
list
comprehension
does
you
can
always
nest
the
list
comprehension
s
for
and
if
clauses
inside
each
other
indenting
successively
further
to
the
right
to
derive
the
equivalent
statements
the
result
is
longer
but
perhaps
clearer
the
map
and
filter
equivalent
would
be
wildly
complex
and
deeply
nested
so
i
won
t
even
try
showing
it
here
i
ll
leave
its
coding
as
an
exercise
for
zen
masters
ex
lisp
programmers
and
the
criminally
insane
list
comprehensions
and
matrixes
not
all
list
comprehensions
are
so
artificial
of
course
let
s
look
at
one
more
application
to
stretch
a
few
synapses
one
basic
way
to
code
matrixes
a
k
a
multidimensional
arrays
in
python
is
with
nested
list
structures
the
following
for
example
defines
two
matrixes
as
lists
of
nested
lists
m
n
given
this
structure
we
can
always
index
rows
and
columns
within
rows
using
normal
index
operations
m
m
list
comprehensions
are
powerful
tools
for
processing
such
structures
though
because
they
automatically
scan
rows
and
columns
for
us
for
instance
although
this
structure
stores
the
matrix
by
rows
to
collect
the
second
column
we
can
simply
iterate
across
the
rows
and
pull
out
the
desired
column
or
iterate
through
positions
in
the
rows
and
index
as
we
go
row
for
row
in
m
m
row
for
row
in
given
positions
we
can
also
easily
perform
tasks
such
as
pulling
out
a
diagonal
the
following
expression
uses
range
to
generate
the
list
of
offsets
and
then
indexes
with
the
row
and
column
the
same
picking
out
m
then
m
and
so
on
we
assume
the
matrix
has
the
same
number
of
rows
and
columns
list
comprehensions
revisited
functional
tools
m
i
i
for
i
in
range
len
m
finally
with
a
bit
of
creativity
we
can
also
use
list
comprehensions
to
combine
multiple
matrixes
the
following
first
builds
a
flat
list
that
contains
the
result
of
multiplying
the
matrixes
pairwise
and
then
builds
a
nested
list
structure
having
the
same
values
by
nesting
list
comprehensions
m
row
col
n
row
col
for
row
in
range
for
col
in
range
m
row
col
n
row
col
for
col
in
range
for
row
in
range
this
last
expression
works
because
the
row
iteration
is
an
outer
loop
for
each
row
it
runs
the
nested
column
iteration
to
build
up
one
row
of
the
result
matrix
it
s
equivalent
to
this
statement
based
code
res
for
res
row
in
range
tmp
for
col
in
range
tmp
append
m
row
col
n
row
col
res
append
tmp
compared
to
these
statements
the
list
comprehension
version
requires
only
one
line
of
code
will
probably
run
substantially
faster
for
large
matrixes
and
just
might
make
your
head
explode
which
brings
us
to
the
next
section
comprehending
list
comprehensions
with
such
generality
list
comprehensions
can
quickly
become
well
incomprehensible
especially
when
nested
consequently
my
advice
is
typically
to
use
simple
for
loops
when
getting
started
with
python
and
map
or
comprehensions
in
isolated
cases
where
they
are
easy
to
apply
the
keep
it
simple
rule
applies
here
as
always
code
conciseness
is
a
much
less
important
goal
than
code
readability
however
in
this
case
there
is
currently
a
substantial
performance
advantage
to
the
extra
complexity
based
on
tests
run
under
python
today
map
calls
are
roughly
twice
as
fast
as
equivalent
for
loops
and
list
comprehensions
are
usually
slightly
faster
than
map
calls
this
speed
difference
is
generally
due
to
the
fact
that
map
and
list
these
performance
generalizations
can
depend
on
call
patterns
as
well
as
changes
and
optimizations
in
python
itself
recent
python
releases
have
sped
up
the
simple
for
loop
statement
for
example
usually
though
list
comprehensions
are
still
substantially
faster
than
for
loops
and
even
faster
than
map
though
map
can
still
win
for
built
in
functions
to
time
these
alternatives
yourself
see
the
standard
library
s
time
module
s
time
clock
and
time
time
calls
the
newer
timeit
module
added
in
release
or
this
chapter
s
upcoming
section
timing
iteration
alternatives
on
page
chapter
iterations
and
comprehensions
part
comprehensions
run
at
c
language
speed
inside
the
interpreter
which
is
much
faster
than
stepping
through
python
for
loop
code
within
the
pvm
because
for
loops
make
logic
more
explicit
i
recommend
them
in
general
on
the
grounds
of
simplicity
however
map
and
list
comprehensions
are
worth
knowing
and
using
for
simpler
kinds
of
iterations
and
if
your
application
s
speed
is
an
important
consideration
in
addition
because
map
and
list
comprehensions
are
both
expressions
they
can
show
up
syntactically
in
places
that
for
loop
statements
cannot
such
as
in
the
bodies
of
lambda
functions
within
list
and
dictionary
literals
and
more
still
you
should
try
to
keep
your
map
calls
and
list
comprehensions
simple
for
more
complex
tasks
use
full
statements
instead
why
you
will
care
list
comprehensions
and
map
here
s
a
more
realistic
example
of
list
comprehensions
and
map
in
action
we
solved
this
problem
with
list
comprehensions
in
chapter
but
we
ll
revive
it
here
to
add
map
based
alternatives
recall
that
the
file
readlines
method
returns
lines
with
n
endof
line
characters
at
the
ends
open
myfile
readlines
aaa
n
bbb
n
ccc
n
if
you
don
t
want
the
end
of
line
characters
you
can
slice
them
off
all
the
lines
in
a
single
step
with
a
list
comprehension
or
a
map
call
map
results
are
iterables
in
python
so
we
must
run
them
through
list
to
see
all
their
results
at
once
line
rstrip
for
line
in
open
myfile
readlines
aaa
bbb
ccc
line
rstrip
for
line
in
open
myfile
aaa
bbb
ccc
list
map
lambda
line
line
rstrip
open
myfile
aaa
bbb
ccc
the
last
two
of
these
make
use
of
file
iterators
which
essentially
means
that
you
don
t
need
a
method
call
to
grab
all
the
lines
in
iteration
contexts
such
as
these
the
map
call
is
slightly
longer
than
the
list
comprehension
but
neither
has
to
manage
result
list
construction
explicitly
a
list
comprehension
can
also
be
used
as
a
sort
of
column
projection
operation
python
s
standard
sql
database
api
returns
query
results
as
a
list
of
tuples
much
like
the
following
the
list
is
the
table
tuples
are
rows
and
items
in
tuples
are
column
values
listoftuple
bob
mgr
mel
dev
a
for
loop
could
pick
up
all
the
values
from
a
selected
column
manually
but
map
and
list
comprehensions
can
do
it
in
a
single
step
and
faster
age
for
name
age
job
in
listoftuple
list
map
lambda
row
row
listoftuple
list
comprehensions
revisited
functional
tools
the
first
of
these
makes
use
of
tuple
assignment
to
unpack
row
tuples
in
the
list
and
the
second
uses
indexing
in
python
but
not
in
see
the
note
on
argument
unpacking
in
chapter
map
can
use
tuple
unpacking
on
its
argument
too
only
list
map
lambda
name
age
job
age
listoftuple
see
other
books
and
resources
for
more
on
python
s
database
api
beside
the
distinction
between
running
functions
versus
expressions
the
biggest
difference
between
map
and
list
comprehensions
in
python
is
that
map
is
an
iterator
generating
results
on
demand
to
achieve
the
same
memory
economy
list
comprehensions
must
be
coded
as
generator
expressions
one
of
the
topics
of
this
chapter
iterators
revisited
generators
python
today
supports
procrastination
much
more
than
it
did
in
the
past
it
provides
tools
that
produce
results
only
when
needed
instead
of
all
at
once
in
particular
two
language
constructs
delay
result
creation
whenever
possible
generator
functions
are
coded
as
normal
def
statements
but
use
yield
statements
to
return
results
one
at
a
time
suspending
and
resuming
their
state
between
each
generator
expressions
are
similar
to
the
list
comprehensions
of
the
prior
section
but
they
return
an
object
that
produces
results
on
demand
instead
of
building
a
result
list
because
neither
constructs
a
result
list
all
at
once
they
save
memory
space
and
allow
computation
time
to
be
split
across
result
requests
as
we
ll
see
both
of
these
ultimately
perform
their
delayed
results
magic
by
implementing
the
iteration
protocol
we
studied
in
chapter
generator
functions
yield
versus
return
in
this
part
of
the
book
we
ve
learned
about
coding
normal
functions
that
receive
input
parameters
and
send
back
a
single
result
immediately
it
is
also
possible
however
to
write
functions
that
may
send
back
a
value
and
later
be
resumed
picking
up
where
they
left
off
such
functions
are
known
as
generator
functions
because
they
generate
a
sequence
of
values
over
time
generator
functions
are
like
normal
functions
in
most
respects
and
in
fact
are
coded
with
normal
def
statements
however
when
created
they
are
automatically
made
to
implement
the
iteration
protocol
so
that
they
can
appear
in
iteration
contexts
we
studied
iterators
in
chapter
here
we
ll
revisit
them
to
see
how
they
relate
to
generators
chapter
iterations
and
comprehensions
part
state
suspension
unlike
normal
functions
that
return
a
value
and
exit
generator
functions
automatically
suspend
and
resume
their
execution
and
state
around
the
point
of
value
generation
because
of
that
they
are
often
a
useful
alternative
to
both
computing
an
entire
series
of
values
up
front
and
manually
saving
and
restoring
state
in
classes
because
the
state
that
generator
functions
retain
when
they
are
suspended
includes
their
entire
local
scope
their
local
variables
retain
information
and
make
it
available
when
the
functions
are
resumed
the
chief
code
difference
between
generator
and
normal
functions
is
that
a
generator
yields
a
value
rather
than
returning
one
the
yield
statement
suspends
the
function
and
sends
a
value
back
to
the
caller
but
retains
enough
state
to
enable
the
function
to
resume
from
where
it
left
off
when
resumed
the
function
continues
execution
immediately
after
the
last
yield
run
from
the
function
s
perspective
this
allows
its
code
to
produce
a
series
of
values
over
time
rather
than
computing
them
all
at
once
and
sending
them
back
in
something
like
a
list
iteration
protocol
integration
to
truly
understand
generator
functions
you
need
to
know
that
they
are
closely
bound
up
with
the
notion
of
the
iteration
protocol
in
python
as
we
ve
seen
iterable
objects
define
a
next
method
which
either
returns
the
next
item
in
the
iteration
or
raises
the
special
stopiteration
exception
to
end
the
iteration
an
object
s
iterator
is
fetched
with
the
iter
built
in
function
python
for
loops
and
all
other
iteration
contexts
use
this
iteration
protocol
to
step
through
a
sequence
or
value
generator
if
the
protocol
is
supported
if
not
iteration
falls
back
on
repeatedly
indexing
sequences
instead
to
support
this
protocol
functions
containing
a
yield
statement
are
compiled
specially
as
generators
when
called
they
return
a
generator
object
that
supports
the
iteration
interface
with
an
automatically
created
method
named
next
to
resume
execution
generator
functions
may
also
have
a
return
statement
that
along
with
falling
off
the
end
of
the
def
block
simply
terminates
the
generation
of
values
technically
by
raising
a
stopiteration
exception
after
any
normal
function
exit
actions
from
the
caller
s
perspective
the
generator
s
next
method
resumes
the
function
and
runs
until
either
the
next
yield
result
is
returned
or
a
stopiteration
is
raised
the
net
effect
is
that
generator
functions
coded
as
def
statements
containing
yield
statements
are
automatically
made
to
support
the
iteration
protocol
and
thus
may
be
used
in
any
iteration
context
to
produce
results
over
time
and
on
demand
iterators
revisited
generators
as
noted
in
chapter
in
python
and
earlier
iterable
objects
define
a
method
named
next
instead
of
next
this
includes
the
generator
objects
we
are
using
here
in
this
method
is
renamed
to
next
the
next
built
in
function
is
provided
as
a
convenience
and
portability
tool
next
i
is
the
same
as
i
next
in
and
i
next
in
prior
to
programs
simply
call
i
next
instead
to
iterate
manually
generator
functions
in
action
to
illustrate
generator
basics
let
s
turn
to
some
code
the
following
code
defines
a
generator
function
that
can
be
used
to
generate
the
squares
of
a
series
of
numbers
over
time
def
gensquares
n
for
i
in
range
n
yield
i
resume
here
later
this
function
yields
a
value
and
so
returns
to
its
caller
each
time
through
the
loop
when
it
is
resumed
its
prior
state
is
restored
and
control
picks
up
again
immediately
after
the
yield
statement
for
example
when
it
s
used
in
the
body
of
a
for
loop
control
returns
to
the
function
after
its
yield
statement
each
time
through
the
loop
resume
the
function
print
last
yielded
value
for
i
in
gensquares
print
i
end
to
end
the
generation
of
values
functions
either
use
a
return
statement
with
no
value
or
simply
allow
control
to
fall
off
the
end
of
the
function
body
if
you
want
to
see
what
is
going
on
inside
the
for
call
the
generator
function
directly
x
gensquares
x
generator
object
at
x
c
you
get
back
a
generator
object
that
supports
the
iteration
protocol
we
met
in
chapter
the
generator
object
has
a
next
method
that
starts
the
function
or
resumes
it
from
where
it
last
yielded
a
value
and
raises
a
stopiteration
exception
when
the
end
of
the
series
of
values
is
reached
for
convenience
the
next
x
built
in
calls
an
object
s
x
next
method
for
us
next
x
same
as
x
next
in
next
x
use
x
next
or
next
in
next
x
next
x
next
x
chapter
iterations
and
comprehensions
part
traceback
most
recent
call
last
more
text
omitted
stopiteration
as
we
learned
in
chapter
for
loops
and
other
iteration
contexts
work
with
generators
in
the
same
way
by
calling
the
next
method
repeatedly
until
an
exception
is
caught
if
the
object
to
be
iterated
over
does
not
support
this
protocol
for
loops
instead
use
the
indexing
protocol
to
iterate
note
that
in
this
example
we
could
also
simply
build
the
list
of
yielded
values
all
at
once
def
buildsquares
n
res
for
i
in
range
n
res
append
i
return
res
for
x
in
buildsquares
print
x
end
for
that
matter
we
could
use
any
of
the
for
loop
map
or
list
comprehension
techniques
for
x
in
n
for
n
in
range
print
x
end
for
x
in
map
lambda
n
n
range
print
x
end
however
generators
can
be
better
in
terms
of
both
memory
use
and
performance
they
allow
functions
to
avoid
doing
all
the
work
up
front
which
is
especially
useful
when
the
result
lists
are
large
or
when
it
takes
a
lot
of
computation
to
produce
each
value
generators
distribute
the
time
required
to
produce
the
series
of
values
among
loop
iterations
moreover
for
more
advanced
uses
generators
can
provide
a
simpler
alternative
to
manually
saving
the
state
between
iterations
in
class
objects
with
generators
variables
accessible
in
the
function
s
scopes
are
saved
and
restored
automatically
we
ll
discuss
class
based
iterators
in
more
detail
in
part
vi
interestingly
generator
functions
are
also
something
of
a
poor
man
s
multithreading
device
they
interleave
a
function
s
work
with
that
of
its
caller
by
dividing
its
operation
into
steps
run
between
yields
generators
are
not
threads
though
the
program
is
explicitly
directed
to
and
from
the
function
within
a
single
thread
of
control
in
one
sense
threading
is
more
general
producers
can
run
truly
independently
and
post
results
to
a
queue
but
generators
may
be
simpler
to
code
see
the
second
footnote
in
chapter
for
a
brief
introduction
to
python
multithreading
tools
note
that
because
control
is
routed
explicitly
at
yield
and
next
calls
generators
are
also
not
backtracking
but
are
more
strongly
related
to
coroutines
formal
concepts
that
are
both
beyond
this
chapter
s
scope
iterators
revisited
generators
extended
generator
function
protocol
send
versus
next
in
python
a
send
method
was
added
to
the
generator
function
protocol
the
send
method
advances
to
the
next
item
in
the
series
of
results
just
like
next
but
also
provides
a
way
for
the
caller
to
communicate
with
the
generator
to
affect
its
operation
technically
yield
is
now
an
expression
form
that
returns
the
item
passed
to
send
not
a
statement
though
it
can
be
called
either
way
as
yield
x
or
a
yield
x
the
expression
must
be
enclosed
in
parentheses
unless
it
s
the
only
item
on
the
right
side
of
the
assignment
statement
for
example
x
yield
y
is
ok
as
is
x
yield
y
when
this
extra
protocol
is
used
values
are
sent
into
a
generator
g
by
calling
g
send
value
the
generator
s
code
is
then
resumed
and
the
yield
expression
in
the
generator
returns
the
value
passed
to
send
if
the
regular
g
next
method
or
its
next
g
equivalent
is
called
to
advance
the
yield
simply
returns
none
for
example
def
gen
for
i
in
range
x
yield
i
print
x
g
gen
next
g
must
call
next
first
to
start
generator
g
send
advance
and
send
value
to
yield
expression
g
send
next
g
next
and
x
next
send
none
none
the
send
method
can
be
used
for
example
to
code
a
generator
that
its
caller
can
terminate
by
sending
a
termination
code
or
redirect
by
passing
a
new
position
in
addition
generators
in
also
support
a
throw
type
method
to
raise
an
exception
inside
the
generator
at
the
latest
yield
and
a
close
method
that
raises
a
special
generator
exit
exception
inside
the
generator
to
terminate
the
iteration
these
are
advanced
features
that
we
won
t
delve
into
in
more
detail
here
see
reference
texts
and
python
s
standard
manuals
for
more
information
note
that
while
python
provides
a
next
x
convenience
built
in
that
calls
the
x
next
method
of
an
object
other
generator
methods
like
send
must
be
called
as
methods
of
generator
objects
directly
e
g
g
send
x
this
makes
sense
if
you
realize
that
these
extra
methods
are
implemented
on
built
in
generator
objects
only
whereas
the
next
method
applies
to
all
iterable
objects
both
built
in
types
and
user
defined
classes
chapter
iterations
and
comprehensions
part
generator
expressions
iterators
meet
comprehensions
in
all
recent
versions
of
python
the
notions
of
iterators
and
list
comprehensions
are
combined
in
a
new
feature
of
the
language
generator
expressions
syntactically
generator
expressions
are
just
like
normal
list
comprehensions
but
they
are
enclosed
in
parentheses
instead
of
square
brackets
x
for
x
in
range
list
comprehension
build
a
list
x
for
x
in
range
generator
object
at
x
dc
generator
expression
make
an
iterable
in
fact
at
least
on
a
function
basis
coding
a
list
comprehension
is
essentially
the
same
as
wrapping
a
generator
expression
in
a
list
built
in
call
to
force
it
to
produce
all
its
results
in
a
list
at
once
list
x
for
x
in
range
list
comprehension
equivalence
operationally
however
generator
expressions
are
very
different
instead
of
building
the
result
list
in
memory
they
return
a
generator
object
which
in
turn
supports
the
iteration
protocol
to
yield
one
piece
of
the
result
list
at
a
time
in
any
iteration
context
g
x
for
x
in
range
next
g
next
g
next
g
next
g
next
g
traceback
most
recent
call
last
more
text
omitted
stopiteration
we
don
t
typically
see
the
next
iterator
machinery
under
the
hood
of
a
generator
expression
like
this
because
for
loops
trigger
it
for
us
automatically
for
num
in
x
for
x
in
range
print
s
s
num
num
as
we
ve
already
learned
every
iteration
context
does
this
including
the
sum
map
and
sorted
built
in
functions
list
comprehensions
and
other
iteration
contexts
we
learned
about
in
chapter
such
as
the
any
all
and
list
built
in
functions
iterators
revisited
generators
notice
that
the
parentheses
are
not
required
around
a
generator
expression
if
they
are
the
sole
item
enclosed
in
other
parentheses
like
those
of
a
function
call
extra
parentheses
are
required
however
in
the
second
call
to
sorted
sum
x
for
x
in
range
sorted
x
for
x
in
range
sorted
x
for
x
in
range
reverse
true
import
math
list
map
math
sqrt
x
for
x
in
range
generator
expressions
are
primarily
a
memory
space
optimization
they
do
not
require
the
entire
result
list
to
be
constructed
all
at
once
as
the
square
bracketed
list
comprehension
does
they
may
also
run
slightly
slower
in
practice
so
they
are
probably
best
used
only
for
very
large
result
sets
a
more
authoritative
statement
about
performance
though
will
have
to
await
the
timing
script
we
ll
code
later
in
this
chapter
generator
functions
versus
generator
expressions
interestingly
the
same
iteration
can
often
be
coded
with
either
a
generator
function
or
a
generator
expression
the
following
generator
expression
for
example
repeats
each
character
in
a
string
four
times
g
c
for
c
in
spam
list
g
ssss
pppp
aaaa
mmmm
generator
expression
force
generator
to
produce
all
results
the
equivalent
generator
function
requires
slightly
more
code
but
as
a
multistatement
function
it
will
be
able
to
code
more
logic
and
use
more
state
information
if
needed
def
timesfour
s
for
c
in
s
yield
c
g
timesfour
spam
list
g
ssss
pppp
aaaa
mmmm
generator
function
iterate
automatically
both
expressions
and
functions
support
both
automatic
and
manual
iteration
the
prior
list
call
iterates
automatically
and
the
following
iterate
manually
g
c
for
c
in
spam
i
iter
g
next
i
ssss
next
i
pppp
chapter
iterations
and
comprehensions
part
iterate
manually
g
timesfour
spam
i
iter
g
next
i
ssss
next
i
pppp
notice
that
we
make
new
generators
here
to
iterate
again
as
explained
in
the
next
section
generators
are
one
shot
iterators
generators
are
single
iterator
objects
both
generator
functions
and
generator
expressions
are
their
own
iterators
and
thus
support
just
one
active
iteration
unlike
some
built
in
types
you
can
t
have
multiple
iterators
of
either
positioned
at
different
locations
in
the
set
of
results
for
example
using
the
prior
section
s
generator
expression
a
generator
s
iterator
is
the
generator
itself
in
fact
calling
iter
on
a
generator
is
a
no
op
g
c
for
c
in
spam
iter
g
is
g
true
my
iterator
is
myself
g
has
next
if
you
iterate
over
the
results
stream
manually
with
multiple
iterators
they
will
all
point
to
the
same
position
g
c
for
c
in
spam
i
iter
g
next
i
ssss
next
i
pppp
i
iter
g
next
i
aaaa
make
a
new
generator
iterate
manually
second
iterator
at
same
position
moreover
once
any
iteration
runs
to
completion
all
are
exhausted
we
have
to
make
a
new
generator
to
start
again
list
i
mmmm
next
i
stopiteration
collect
the
rest
of
i
s
items
i
iter
g
next
i
stopiteration
ditto
for
new
iterators
i
iter
c
for
c
in
spam
next
i
ssss
new
generator
to
start
over
other
iterators
exhausted
too
iterators
revisited
generators
the
same
holds
true
for
generator
functions
the
following
def
statement
based
equivalent
supports
just
one
active
iterator
and
is
exhausted
after
one
pass
def
timesfour
s
for
c
in
s
yield
c
g
timesfour
spam
iter
g
is
g
true
i
i
iter
g
iter
g
next
i
ssss
next
i
pppp
next
i
aaaa
generator
functions
work
the
same
way
i
at
same
position
as
i
this
is
different
from
the
behavior
of
some
built
in
types
which
support
multiple
iterators
and
passes
and
reflect
their
in
place
changes
in
active
iterators
l
i
i
iter
l
iter
l
next
i
next
i
next
i
del
l
next
i
stopiteration
lists
support
multiple
iterators
changes
reflected
in
iterators
when
we
begin
coding
class
based
iterators
in
part
vi
we
ll
see
that
it
s
up
to
us
to
decide
how
any
iterations
we
wish
to
support
for
our
objects
if
any
emulating
zip
and
map
with
iteration
tools
to
demonstrate
the
power
of
iteration
tools
in
action
let
s
turn
to
some
more
advanced
use
case
examples
once
you
know
about
list
comprehensions
generators
and
other
iteration
tools
it
turns
out
that
emulating
many
of
python
s
functional
built
ins
is
both
straightforward
and
instructive
for
example
we
ve
already
seen
how
the
built
in
zip
and
map
functions
combine
iterables
and
project
functions
across
them
respectively
with
multiple
sequence
arguments
map
projects
the
function
across
items
taken
from
each
sequence
in
much
the
same
way
that
zip
pairs
them
up
s
abc
s
xyz
list
zip
s
s
a
x
b
y
c
z
chapter
iterations
and
comprehensions
part
zip
pairs
items
from
iterables
zip
pairs
items
truncates
at
shortest
list
zip
single
sequence
ary
tuples
list
zip
n
sequences
n
ary
tuples
map
passes
paired
itenms
to
a
function
truncates
list
map
abs
single
sequence
ary
function
list
map
pow
n
sequences
n
ary
function
though
they
re
being
used
for
different
purposes
if
you
study
these
examples
long
enough
you
might
notice
a
relationship
between
zip
results
and
mapped
function
arguments
that
our
next
example
can
exploit
coding
your
own
map
func
although
the
map
and
zip
built
ins
are
fast
and
convenient
it
s
always
possible
to
emulate
them
in
code
of
our
own
in
the
preceding
chapter
for
example
we
saw
a
function
that
emulated
the
map
built
in
for
a
single
sequence
argument
it
doesn
t
take
much
more
work
to
allow
for
multiple
sequences
as
the
built
in
does
map
func
seqs
workalike
with
zip
def
mymap
func
seqs
res
for
args
in
zip
seqs
res
append
func
args
return
res
print
mymap
abs
print
mymap
pow
this
version
relies
heavily
upon
the
special
args
argument
passing
syntax
it
collects
multiple
sequence
really
iterable
arguments
unpacks
them
as
zip
arguments
to
combine
and
then
unpacks
the
paired
zip
results
as
arguments
to
the
passed
in
function
that
is
we
re
using
the
fact
that
the
zipping
is
essentially
a
nested
operation
in
mapping
the
test
code
at
the
bottom
applies
this
to
both
one
and
two
sequences
to
produce
this
output
the
same
we
would
get
with
the
built
in
map
really
though
the
prior
version
exhibits
the
classic
list
comprehension
pattern
building
a
list
of
operation
results
within
a
for
loop
we
can
code
our
map
more
concisely
as
an
equivalent
one
line
list
comprehension
iterators
revisited
generators
using
a
list
comprehension
def
mymap
func
seqs
return
func
args
for
args
in
zip
seqs
print
mymap
abs
print
mymap
pow
when
this
is
run
the
result
is
the
same
as
before
but
the
code
is
more
concise
and
might
run
faster
more
on
performance
in
the
section
timing
iteration
alternatives
on
page
both
of
the
preceding
mymap
versions
build
result
lists
all
at
once
though
and
this
can
waste
memory
for
larger
lists
now
that
we
know
about
generator
functions
and
expressions
it
s
simple
to
recode
both
these
alternatives
to
produce
results
on
demand
instead
using
generators
yield
and
def
mymap
func
seqs
res
for
args
in
zip
seqs
yield
func
args
def
mymap
func
seqs
return
func
args
for
args
in
zip
seqs
these
versions
produce
the
same
results
but
return
generators
designed
to
support
the
iteration
protocol
the
first
yields
one
result
at
a
time
and
the
second
returns
a
generator
expression
s
result
to
do
the
same
they
produce
the
same
results
if
we
wrap
them
in
list
calls
to
force
them
to
produce
their
values
all
at
once
print
list
mymap
abs
print
list
mymap
pow
no
work
is
really
done
here
until
the
list
calls
force
the
generators
to
run
by
activating
the
iteration
protocol
the
generators
returned
by
these
functions
themselves
as
well
as
that
returned
by
the
python
flavor
of
the
zip
built
in
they
use
produce
results
only
on
demand
coding
your
own
zip
and
map
none
of
course
much
of
the
magic
in
the
examples
shown
so
far
lies
in
their
use
of
the
zip
built
in
to
pair
arguments
from
multiple
sequences
you
ll
also
note
that
our
map
workalikes
are
really
emulating
the
behavior
of
the
python
map
they
truncate
at
the
length
of
the
shortest
sequence
and
they
do
not
support
the
notion
of
padding
results
when
lengths
differ
as
map
does
in
python
x
with
a
none
argument
c
misc
c
python
python
map
none
none
map
none
abc
xyz
a
x
b
y
c
z
none
none
none
chapter
iterations
and
comprehensions
part
using
iteration
tools
we
can
code
workalikes
that
emulate
both
truncating
zip
and
s
padding
map
these
turn
out
to
be
nearly
the
same
in
code
zip
seqs
and
map
none
seqs
workalikes
def
myzip
seqs
seqs
list
s
for
s
in
seqs
res
while
all
seqs
res
append
tuple
s
pop
for
s
in
seqs
return
res
def
mymappad
seqs
pad
none
seqs
list
s
for
s
in
seqs
res
while
any
seqs
res
append
tuple
s
pop
if
s
else
pad
for
s
in
seqs
return
res
s
s
abc
xyz
print
myzip
s
s
print
mymappad
s
s
print
mymappad
s
s
pad
both
of
the
functions
coded
here
work
on
any
type
of
iterable
object
because
they
run
their
arguments
through
the
list
built
in
to
force
result
generation
e
g
files
would
work
as
arguments
in
addition
to
sequences
like
strings
notice
the
use
of
the
all
and
any
built
ins
here
these
return
true
if
all
and
any
items
in
an
iterable
are
true
or
equivalently
nonempty
respectively
these
built
ins
are
used
to
stop
looping
when
any
or
all
of
the
listified
arguments
become
empty
after
deletions
also
note
the
use
of
the
python
keyword
only
argument
pad
unlike
the
map
our
version
will
allow
any
pad
object
to
be
specified
if
you
re
using
use
a
kargs
form
to
support
this
option
instead
see
chapter
for
details
when
these
functions
are
run
the
following
results
are
printed
a
zip
and
two
padding
maps
a
x
b
y
c
z
a
x
b
y
c
z
none
none
none
a
x
b
y
c
z
these
functions
aren
t
amenable
to
list
comprehension
translation
because
their
loops
are
too
specific
as
before
though
while
our
zip
and
map
workalikes
currently
build
and
return
result
lists
it
s
just
as
easy
to
turn
them
into
generators
with
yield
so
that
they
each
return
one
piece
of
their
result
set
at
a
time
the
results
are
the
same
as
before
but
we
need
to
use
list
again
to
force
the
generators
to
yield
their
values
for
display
using
generators
yield
def
myzip
seqs
seqs
list
s
for
s
in
seqs
while
all
seqs
yield
tuple
s
pop
for
s
in
seqs
iterators
revisited
generators
def
mymappad
seqs
pad
none
seqs
list
s
for
s
in
seqs
while
any
seqs
yield
tuple
s
pop
if
s
else
pad
for
s
in
seqs
s
s
abc
xyz
print
list
myzip
s
s
print
list
mymappad
s
s
print
list
mymappad
s
s
pad
finally
here
s
an
alternative
implementation
of
our
zip
and
map
emulators
rather
than
deleting
arguments
from
lists
with
the
pop
method
the
following
versions
do
their
job
by
calculating
the
minimum
and
maximum
argument
lengths
armed
with
these
lengths
it
s
easy
to
code
nested
list
comprehensions
to
step
through
argument
index
ranges
alternate
implementation
with
lengths
def
myzip
seqs
minlen
min
len
s
for
s
in
seqs
return
tuple
s
i
for
s
in
seqs
for
i
in
range
minlen
def
mymappad
seqs
pad
none
maxlen
max
len
s
for
s
in
seqs
index
range
maxlen
return
tuple
s
i
if
len
s
i
else
pad
for
s
in
seqs
for
i
in
index
s
s
abc
xyz
print
myzip
s
s
print
mymappad
s
s
print
mymappad
s
s
pad
because
these
use
len
and
indexing
they
assume
that
arguments
are
sequences
or
similar
not
arbitrary
iterables
the
outer
comprehensions
here
step
through
argument
index
ranges
and
the
inner
comprehensions
passed
to
tuple
step
through
the
passedin
sequences
to
pull
out
arguments
in
parallel
when
they
re
run
the
results
are
as
before
most
strikingly
generators
and
iterators
seem
to
run
rampant
in
this
example
the
arguments
passed
to
min
and
max
are
generator
expressions
which
run
to
completion
before
the
nested
comprehensions
begin
iterating
moreover
the
nested
list
comprehensions
employ
two
levels
of
delayed
evaluation
the
python
range
built
in
is
an
iterable
as
is
the
generator
expression
argument
to
tuple
in
fact
no
results
are
produced
here
until
the
square
brackets
of
the
list
comprehensions
request
values
to
place
in
the
result
list
they
force
the
comprehensions
and
generators
to
run
to
turn
these
functions
themselves
into
generators
instead
of
list
builders
use
parentheses
instead
of
square
brackets
again
here
s
the
case
for
our
zip
using
generators
def
myzip
seqs
minlen
min
len
s
for
s
in
seqs
chapter
iterations
and
comprehensions
part
return
tuple
s
i
for
s
in
seqs
for
i
in
range
minlen
print
list
myzip
s
s
in
this
case
it
takes
a
list
call
to
activate
the
generators
and
iterators
to
produce
their
results
experiment
with
these
on
your
own
for
more
details
developing
further
coding
alternatives
is
left
as
a
suggested
exercise
see
also
the
sidebar
why
you
will
care
one
shot
iterations
for
investigation
of
one
such
option
why
you
will
care
one
shot
iterations
in
chapter
we
saw
how
some
built
ins
like
map
support
only
a
single
traversal
and
are
empty
after
it
occurs
and
i
promised
to
show
you
an
example
of
how
that
can
become
subtle
but
important
in
practice
now
that
we
ve
studied
a
few
more
iteration
topics
i
can
make
good
on
this
promise
consider
the
following
clever
alternative
coding
for
this
chapter
s
zip
emulation
examples
adapted
from
one
in
python
s
manuals
def
myzip
args
iters
map
iter
args
while
iters
res
next
i
for
i
in
iters
yield
tuple
res
because
this
code
uses
iter
and
next
it
works
on
any
type
of
iterable
note
that
there
is
no
reason
to
catch
the
stopiteration
raised
by
the
next
it
inside
the
comprehension
here
when
any
one
of
the
arguments
iterators
is
exhausted
allowing
it
to
pass
ends
this
generator
function
and
has
the
same
effect
that
a
return
statement
would
the
while
iters
suffices
to
loop
if
at
least
one
argument
is
passed
and
avoids
an
infinite
loop
otherwise
the
list
comprehension
would
always
return
an
empty
list
this
code
works
fine
in
python
as
is
list
myzip
abc
lmnop
a
l
b
m
c
n
but
it
falls
into
an
infinite
loop
and
fails
in
python
because
the
map
returns
a
one
shot
iterable
object
instead
of
a
list
as
in
in
as
soon
as
we
ve
run
the
list
comprehension
inside
the
loop
once
iters
will
be
empty
and
res
will
be
forever
to
make
this
work
in
we
need
to
use
the
list
built
in
function
to
create
an
object
that
can
support
multiple
iterations
def
myzip
args
iters
list
map
iter
args
rest
as
is
run
this
on
your
own
to
trace
its
operation
the
lesson
here
wrapping
map
calls
in
list
calls
in
is
not
just
for
display
iterators
revisited
generators
value
generation
in
built
in
types
and
classes
finally
although
we
ve
focused
on
coding
value
generators
ourselves
in
this
section
don
t
forget
that
many
built
in
types
behave
in
similar
ways
as
we
saw
in
chapter
for
example
dictionaries
have
iterators
that
produce
keys
on
each
iteration
a
c
d
a
b
c
x
iter
d
next
x
next
x
like
the
values
produced
by
handcoded
generators
dictionary
keys
may
be
iterated
over
both
manually
and
with
automatic
iteration
tools
including
for
loops
map
calls
list
comprehensions
and
the
many
other
contexts
we
met
in
chapter
for
key
in
d
print
key
d
key
a
c
b
as
we
ve
also
seen
for
file
iterators
python
simply
loads
lines
from
the
file
on
demand
for
line
in
open
temp
txt
print
line
end
tis
but
a
flesh
wound
while
built
in
type
iterators
are
bound
to
a
specific
type
of
value
generation
the
concept
is
similar
to
generators
we
code
with
expressions
and
functions
iteration
contexts
like
for
loops
accept
any
iterable
whether
user
defined
or
built
in
although
beyond
the
scope
of
this
chapter
it
is
also
possible
to
implement
arbitrary
user
defined
generator
objects
with
classes
that
conform
to
the
iteration
protocol
such
classes
define
a
special
iter
method
run
by
the
iter
built
in
function
that
returns
an
object
having
a
next
method
run
by
the
next
built
in
function
a
getitem
indexing
method
is
also
available
as
a
fallback
option
for
iteration
the
instance
objects
created
from
such
a
class
are
considered
iterable
and
may
be
used
in
for
loops
and
all
other
iteration
contexts
with
classes
though
we
have
access
to
richer
logic
and
data
structuring
options
than
other
generator
constructs
can
offer
the
iterator
story
won
t
really
be
complete
until
we
ve
seen
how
it
maps
to
classes
too
for
now
we
ll
have
to
settle
for
postponing
its
conclusion
until
we
study
class
based
iterators
in
chapter
chapter
iterations
and
comprehensions
part
comprehension
syntax
summary
we
ve
been
focusing
on
list
comprehensions
and
generators
in
this
chapter
but
keep
in
mind
that
there
are
two
other
comprehension
expression
forms
set
and
dictionary
comprehensions
are
also
available
as
of
python
we
met
these
briefly
in
chapters
and
but
with
our
new
knowledge
of
comprehensions
and
generators
you
should
now
be
able
to
grasp
these
extensions
in
full
for
sets
the
new
literal
form
is
equivalent
to
set
and
the
new
set
comprehension
syntax
f
x
for
x
in
s
if
p
x
is
like
the
generator
expression
set
f
x
for
x
in
s
if
p
x
where
f
x
is
an
arbitrary
expression
for
dictionaries
the
new
dictionary
comprehension
syntax
key
val
for
key
val
in
zip
keys
vals
works
like
the
form
dict
zip
keys
vals
and
x
f
x
for
x
in
items
is
like
the
generator
expression
dict
x
f
x
for
x
in
items
here
s
a
summary
of
all
the
comprehension
alternatives
in
the
last
two
are
new
and
are
not
available
in
x
x
for
x
in
range
list
comprehension
builds
list
like
list
generator
expr
x
x
for
x
in
range
generator
object
at
x
e
generator
expression
produces
items
parens
are
often
optional
x
x
for
x
in
range
set
comprehension
new
in
x
y
is
a
set
in
too
x
x
x
for
x
in
range
dictionary
comprehension
new
in
comprehending
set
and
dictionary
comprehensions
in
a
sense
set
and
dictionary
comprehensions
are
just
syntactic
sugar
for
passing
generator
expressions
to
the
type
names
because
both
accept
any
iterable
a
generator
works
well
here
comprehension
x
x
for
x
in
range
set
x
x
for
x
in
range
x
x
x
for
x
in
range
dict
x
x
x
for
x
in
range
generator
and
type
name
as
for
list
comprehensions
though
we
can
always
build
the
result
objects
with
manual
code
too
here
are
statement
based
equivalents
of
the
last
two
comprehensions
comprehension
syntax
summary
res
set
for
x
in
range
res
add
x
x
res
for
x
in
range
res
x
x
x
set
comprehension
equivalent
res
dict
comprehension
equivalent
res
notice
that
although
both
forms
accept
iterators
they
have
no
notion
of
generating
results
on
demand
both
forms
build
objects
all
at
once
if
you
mean
to
produce
keys
and
values
upon
request
a
generator
expression
is
more
appropriate
g
x
x
x
for
x
in
range
next
g
next
g
extended
comprehension
syntax
for
sets
and
dictionaries
like
list
comprehensions
and
generator
expressions
both
set
and
dictionary
comprehensions
support
nested
associated
if
clauses
to
filter
items
out
of
the
result
the
following
collect
squares
of
even
items
i
e
items
having
no
remainder
for
division
by
in
a
range
x
x
for
x
in
x
x
for
x
in
x
x
x
for
x
range
if
x
lists
are
ordered
range
if
x
but
sets
are
not
in
range
if
x
neither
are
dict
keys
nested
for
loops
work
as
well
though
the
unordered
and
no
duplicates
nature
of
both
types
of
objects
can
make
the
results
a
bit
less
straightforward
to
decipher
x
y
for
x
in
for
y
in
x
y
for
x
in
for
y
in
x
y
for
x
in
for
y
in
lists
keep
duplicates
but
sets
do
not
neither
do
dict
keys
like
list
comprehensions
the
set
and
dictionary
varieties
can
also
iterate
over
any
type
of
iterator
lists
strings
files
ranges
and
anything
else
that
supports
the
iteration
protocol
x
y
for
x
in
ab
for
y
in
cd
bd
ac
ad
bc
chapter
iterations
and
comprehensions
part
x
y
ord
x
ord
y
for
x
in
ab
for
y
in
cd
bd
ac
ad
bc
k
for
k
in
spam
ham
sausage
if
k
s
sausagesausage
spamspam
k
upper
k
for
k
in
spam
ham
sausage
if
k
s
sausage
sausagesausage
spam
spamspam
for
more
details
experiment
with
these
tools
on
your
own
they
may
or
may
not
have
a
performance
advantage
over
the
generator
or
for
loop
alternatives
but
we
would
have
to
time
their
performance
explicitly
to
be
sure
which
seems
a
natural
segue
to
the
next
section
timing
iteration
alternatives
we
ve
met
quite
a
few
iteration
alternatives
in
this
book
to
summarize
let
s
work
through
a
larger
case
study
that
pulls
together
some
of
the
things
we
ve
learned
about
iteration
and
functions
i
ve
mentioned
a
few
times
that
list
comprehensions
have
a
speed
performance
advantage
over
for
loop
statements
and
that
map
performance
can
be
better
or
worse
depending
on
call
patterns
the
generator
expressions
of
the
prior
sections
tend
to
be
slightly
slower
than
list
comprehensions
though
they
minimize
memory
space
requirements
all
that
s
true
today
but
relative
performance
can
vary
over
time
because
python
s
internals
are
constantly
being
changed
and
optimized
if
you
want
to
verify
their
performance
for
yourself
you
need
to
time
these
alternatives
on
your
own
computer
and
your
own
version
of
python
timing
module
luckily
python
makes
it
easy
to
time
code
to
see
how
the
iteration
options
stack
up
let
s
start
with
a
simple
but
general
timer
utility
function
coded
in
a
module
file
so
it
can
be
used
in
a
variety
of
programs
file
mytimer
py
import
time
reps
repslist
range
reps
def
timer
func
pargs
kargs
start
time
clock
for
i
in
repslist
ret
func
pargs
kargs
elapsed
time
clock
start
return
elapsed
ret
timing
iteration
alternatives
operationally
this
module
times
calls
to
any
function
with
any
positional
and
keyword
arguments
by
fetching
the
start
time
calling
the
function
a
fixed
number
of
times
and
subtracting
the
start
time
from
the
stop
time
points
to
notice
python
s
time
module
gives
access
to
the
current
time
with
precision
that
varies
per
platform
on
windows
this
call
is
claimed
to
give
microsecond
granularity
and
so
is
very
accurate
the
range
call
is
hoisted
out
of
the
timing
loop
so
its
construction
cost
is
not
charged
to
the
timed
function
in
python
in
range
is
an
iterator
so
this
step
isn
t
required
but
doesn
t
hurt
the
reps
count
is
a
global
that
importers
can
change
if
needed
mytimer
reps
n
when
complete
the
total
elapsed
time
for
all
calls
is
returned
in
a
tuple
along
with
the
timed
function
s
final
return
value
so
callers
can
verify
its
operation
from
a
larger
perspective
because
this
function
is
coded
in
a
module
file
it
becomes
a
generally
useful
tool
anywhere
we
wish
to
import
it
you
ll
learn
more
about
modules
and
imports
in
the
next
part
of
this
book
but
you
ve
already
seen
enough
of
the
basics
to
make
sense
of
this
code
simply
import
the
module
and
call
the
function
to
use
this
file
s
timer
and
see
chapter
s
coverage
of
module
attributes
if
you
need
a
refresher
timing
script
now
to
time
iteration
tool
speed
run
the
following
script
it
uses
the
timer
module
we
just
wrote
to
time
the
relative
speeds
of
the
various
list
construction
techniques
we
ve
studied
file
timeseqs
py
import
sys
mytimer
reps
repslist
range
reps
import
timer
function
hoist
range
out
in
def
forloop
res
for
x
in
repslist
res
append
abs
x
return
res
def
listcomp
return
abs
x
for
x
in
repslist
def
mapcall
return
list
map
abs
repslist
use
list
in
only
def
genexpr
return
list
abs
x
for
x
in
repslist
list
forces
results
def
genfunc
def
gen
chapter
iterations
and
comprehensions
part
for
x
in
repslist
yield
abs
x
return
list
gen
print
sys
version
for
test
in
forloop
listcomp
mapcall
genexpr
genfunc
elapsed
result
mytimer
timer
test
print
print
s
f
s
s
test
name
elapsed
result
result
this
script
tests
five
alternative
ways
to
build
lists
of
results
and
as
shown
executes
on
the
order
of
million
steps
for
each
that
is
each
of
the
five
tests
builds
a
list
of
items
times
notice
how
we
have
to
run
the
generator
expression
and
function
results
through
the
built
in
list
call
to
force
them
to
yield
all
of
their
values
if
we
did
not
we
would
just
produce
generators
that
never
do
any
real
work
in
python
only
we
must
do
the
same
for
the
map
result
since
it
is
now
an
iterable
object
as
well
also
notice
how
the
code
at
the
bottom
steps
through
a
tuple
of
four
function
objects
and
prints
the
name
of
each
as
we
ve
seen
this
is
a
built
in
attribute
that
gives
a
function
s
name
timing
results
when
the
script
of
the
prior
section
is
run
under
python
i
get
the
following
results
on
my
windows
vista
laptop
map
is
slightly
faster
than
list
comprehensions
both
are
substantially
quicker
than
for
loops
and
generator
expressions
and
functions
place
in
the
middle
c
misc
c
python
python
timeseqs
py
r
feb
msc
v
bit
intel
forloop
listcomp
mapcall
genexpr
genfunc
if
you
study
this
code
and
its
output
long
enough
you
ll
notice
that
generator
expressions
run
slower
than
list
comprehensions
although
wrapping
a
generator
expression
in
a
list
call
makes
it
functionally
equivalent
to
a
square
bracketed
list
comprehension
the
internal
implementations
of
the
two
expressions
appear
to
differ
though
we
re
also
effectively
timing
the
list
call
for
the
generator
test
return
abs
x
for
x
in
range
size
return
list
abs
x
for
x
in
range
size
seconds
seconds
differs
internally
timing
iteration
alternatives
interestingly
when
i
ran
this
on
windows
xp
with
python
for
the
prior
edition
of
this
book
the
results
were
relatively
similar
list
comprehensions
were
nearly
twice
as
fast
as
equivalent
for
loop
statements
and
map
was
slightly
quicker
than
list
comprehensions
when
mapping
a
built
in
function
such
as
abs
absolute
value
i
didn
t
test
generator
functions
then
and
the
output
format
wasn
t
quite
as
grandiose
r
sep
msc
v
bit
intel
forstatement
listcomprehension
mapfunction
generatorexpression
the
fact
that
the
actual
test
times
listed
here
are
over
two
times
as
slow
as
the
output
i
showed
earlier
is
likely
due
to
my
using
a
quicker
laptop
for
the
more
recent
test
not
due
to
improvements
in
python
in
fact
all
the
results
for
this
script
are
slightly
quicker
than
on
this
same
machine
if
the
list
call
is
removed
from
the
map
test
to
avoid
creating
the
results
list
twice
try
this
on
your
own
to
verify
watch
what
happens
though
if
we
change
this
script
to
perform
a
real
operation
on
each
iteration
such
as
addition
instead
of
calling
a
trivial
built
in
function
like
abs
the
omitted
parts
of
the
following
are
the
same
as
before
file
timeseqs
py
def
forloop
res
for
x
in
repslist
res
append
x
return
res
def
listcomp
return
x
for
x
in
repslist
def
mapcall
return
list
map
lambda
x
x
repslist
list
in
only
def
genexpr
return
list
x
for
x
in
repslist
list
in
def
genfunc
def
gen
for
x
in
repslist
yield
x
return
list
gen
now
the
need
to
call
a
user
defined
function
for
the
map
call
makes
it
slower
than
the
for
loop
statements
despite
the
fact
that
the
looping
statements
version
is
larger
in
terms
of
code
on
python
c
misc
c
python
python
timeseqs
py
r
feb
msc
v
bit
intel
chapter
iterations
and
comprehensions
part
forloop
listcomp
mapcall
genexpr
genfunc
the
python
results
on
a
slower
machine
were
again
relatively
similar
in
the
prior
edition
but
twice
as
slow
due
to
test
machine
differences
r
sep
msc
v
bit
intel
forstatement
listcomprehension
mapfunction
generatorexpression
because
the
interpreter
optimizes
so
much
internally
performance
analysis
of
python
code
like
this
is
a
very
tricky
affair
it
s
virtually
impossible
to
guess
which
method
will
perform
the
best
the
best
you
can
do
is
time
your
own
code
on
your
computer
with
your
version
of
python
in
this
case
all
we
should
say
for
certain
is
that
on
this
python
using
a
user
defined
function
in
map
calls
can
slow
performance
by
at
least
a
factor
of
and
that
list
comprehensions
run
quickest
for
this
test
as
i
ve
mentioned
before
however
performance
should
not
be
your
primary
concern
when
writing
python
code
the
first
thing
you
should
do
to
optimize
python
code
is
to
not
optimize
python
code
write
for
readability
and
simplicity
first
then
optimize
later
if
and
only
if
needed
it
could
very
well
be
that
any
of
the
five
alternatives
is
quick
enough
for
the
data
sets
your
program
needs
to
process
if
so
program
clarity
should
be
the
chief
goal
timing
module
alternatives
the
timing
module
of
the
prior
section
works
but
it
s
a
bit
primitive
on
multiple
fronts
it
always
uses
the
time
clock
call
to
time
code
while
that
option
is
best
on
windows
the
time
time
call
may
provide
better
resolution
on
some
unix
platforms
adjusting
the
number
of
repetitions
requires
changing
module
level
globals
a
less
than
ideal
arrangement
if
the
timer
function
is
being
used
and
shared
by
multiple
importers
as
is
the
timer
works
by
running
the
test
function
a
large
number
of
times
to
account
for
random
system
load
fluctuations
it
might
be
better
to
select
the
best
time
among
all
the
tests
instead
of
the
total
time
the
following
alternative
implements
a
more
sophisticated
timer
module
that
addresses
all
three
points
by
selecting
a
timer
call
based
on
platform
allowing
the
repeat
count
timing
iteration
alternatives
to
be
passed
in
as
a
keyword
argument
named
reps
and
providing
a
best
of
n
alternative
timing
function
file
mytimer
py
and
timer
spam
a
b
reps
calls
and
times
spam
a
reps
times
and
returns
total
time
for
all
runs
with
final
result
best
spam
a
b
reps
runs
best
of
n
timer
to
filter
out
any
system
load
variation
and
returns
best
time
among
reps
tests
import
time
sys
if
sys
platform
win
timefunc
time
clock
else
timefunc
time
time
use
time
clock
on
windows
def
trace
args
pass
or
print
args
def
timer
func
pargs
kargs
reps
kargs
pop
reps
trace
func
pargs
kargs
reps
repslist
range
reps
start
timefunc
for
i
in
repslist
ret
func
pargs
kargs
elapsed
timefunc
start
return
elapsed
ret
better
resolution
on
some
unix
platforms
passed
in
or
default
reps
hoist
range
out
for
lists
def
best
func
pargs
kargs
reps
kargs
pop
reps
best
for
i
in
range
reps
time
ret
timer
func
pargs
reps
kargs
if
time
best
best
time
return
best
ret
this
module
s
docstring
at
the
top
of
the
file
describes
its
intended
usage
it
uses
dictionary
pop
operations
to
remove
the
reps
argument
from
arguments
intended
for
the
test
function
and
provide
it
with
a
default
and
it
traces
arguments
during
development
if
you
change
its
trace
function
to
print
to
test
with
this
new
timer
module
on
either
python
or
change
the
timing
script
as
follows
the
omitted
code
in
the
test
functions
of
this
version
use
the
x
operation
for
each
test
as
coded
in
the
prior
section
file
timeseqs
py
import
sys
mytimer
reps
repslist
range
reps
def
forloop
chapter
iterations
and
comprehensions
part
def
listcomp
def
mapcall
def
genexpr
def
genfunc
print
sys
version
for
tester
in
mytimer
timer
mytimer
best
print
s
tester
name
for
test
in
forloop
listcomp
mapcall
genexpr
genfunc
elapsed
result
tester
test
print
print
s
f
s
s
test
name
elapsed
result
result
when
run
under
python
the
timing
results
are
essentially
the
same
as
before
and
relatively
the
same
for
both
to
the
total
of
n
and
best
of
n
timing
techniques
running
tests
many
times
seems
to
do
as
good
a
job
filtering
out
system
load
fluctuations
as
taking
the
best
case
but
the
best
of
n
scheme
may
be
better
when
testing
a
longrunning
function
the
results
on
my
machine
are
as
follows
c
misc
c
python
python
timeseqs
py
r
feb
msc
v
bit
intel
timer
forloop
listcomp
mapcall
genexpr
genfunc
best
forloop
listcomp
mapcall
genexpr
genfunc
the
times
reported
by
the
best
of
n
timer
here
are
small
of
course
but
they
might
become
significant
if
your
program
iterates
many
times
over
large
data
sets
at
least
in
terms
of
relative
performance
list
comprehensions
appear
best
in
most
cases
map
is
only
slightly
better
when
built
ins
are
applied
timing
iteration
alternatives
using
keyword
only
arguments
in
we
can
also
make
use
of
python
keyword
only
arguments
here
to
simplify
the
timer
module
s
code
as
we
learned
in
chapter
keyword
only
arguments
are
ideal
for
configuration
options
such
as
our
functions
reps
argument
they
must
be
coded
after
a
and
before
a
in
the
function
header
and
in
a
function
call
they
must
be
passed
by
keyword
and
appear
before
the
if
used
here
s
a
keyword
only
based
alternative
to
the
prior
module
though
simpler
it
compiles
and
runs
under
python
x
only
not
file
mytimer
py
x
only
use
keyword
only
default
arguments
instead
of
and
dict
pops
no
need
to
hoist
range
out
of
test
in
a
generator
not
a
list
import
time
sys
trace
lambda
args
none
or
print
timefunc
time
clock
if
sys
platform
win
else
time
time
def
timer
func
pargs
reps
kargs
trace
func
pargs
kargs
reps
start
timefunc
for
i
in
range
reps
ret
func
pargs
kargs
elapsed
timefunc
start
return
elapsed
ret
def
best
func
pargs
reps
kargs
best
for
i
in
range
reps
time
ret
timer
func
pargs
reps
kargs
if
time
best
best
time
return
best
ret
this
version
is
used
the
same
way
as
and
produces
results
identical
to
the
prior
version
not
counting
negligible
test
time
differences
from
run
to
run
c
misc
c
python
python
timeseqs
py
same
results
as
before
in
fact
for
variety
we
can
also
test
this
version
of
the
module
from
the
interactive
prompt
completely
independent
of
the
sequence
timer
script
it
s
a
general
purpose
tool
c
misc
c
python
python
from
mytimer
import
timer
best
def
power
x
y
return
x
y
timer
power
timer
power
reps
chapter
iterations
and
comprehensions
part
test
function
total
time
last
result
override
defult
reps
timer
power
best
power
e
best
power
best
power
reps
tot
time
reps
best
time
last
result
best
time
override
default
reps
for
trivial
functions
like
the
one
tested
in
this
interactive
session
the
costs
of
the
timer
s
code
are
probably
as
significant
as
those
of
the
timed
function
so
you
should
not
take
timer
results
too
absolutely
we
are
timing
more
than
just
x
y
here
the
timer
s
results
can
help
you
judge
relative
speeds
of
coding
alternatives
though
and
may
be
more
meaningful
for
longer
running
operations
like
the
following
calculating
to
the
power
one
million
takes
an
order
of
magnitude
power
of
longer
than
the
preceding
timer
power
reps
timer
power
reps
total
time
best
power
reps
best
power
reps
best
power
reps
best
time
is
sometimes
as
good
as
best
resolution
again
although
the
times
measured
here
are
small
the
differences
can
be
significant
in
programs
that
compute
powers
often
see
chapter
for
more
on
keyword
only
arguments
in
they
can
simplify
code
for
configurable
tools
like
this
one
but
are
not
backward
compatible
with
x
pythons
if
you
want
to
compare
x
and
x
speed
for
example
or
support
programmers
using
either
python
line
the
prior
version
is
likely
a
better
choice
if
you
re
using
python
the
above
session
runs
the
same
with
the
prior
version
of
the
timer
module
other
suggestions
for
more
insight
try
modifying
the
repetition
counts
used
by
these
modules
or
explore
the
alternative
timeit
module
in
python
s
standard
library
which
automates
timing
of
code
supports
command
line
usage
modes
and
finesses
some
platform
specific
issues
python
s
manuals
document
its
use
you
might
also
want
to
look
at
the
profile
standard
library
module
for
a
complete
source
code
profiler
tool
we
ll
learn
more
about
it
in
chapter
in
the
context
of
development
tools
for
large
projects
in
general
you
should
profile
code
to
isolate
bottlenecks
before
recoding
and
timing
alternatives
as
we
ve
done
here
timing
iteration
alternatives
it
might
be
useful
as
well
to
experiment
with
using
the
new
str
format
method
in
python
and
instead
of
the
formatting
expression
which
could
potentially
be
deprecated
in
the
future
by
changing
the
timing
script
s
formatted
print
lines
as
follows
print
s
tester
name
print
format
tester
name
from
expression
to
method
call
print
s
f
s
s
test
name
elapsed
result
result
print
f
format
test
name
elapsed
result
result
you
can
judge
the
difference
between
these
techniques
yourself
if
you
feel
ambitious
you
might
also
try
modifying
or
emulating
the
timing
script
to
measure
the
speed
of
the
set
and
dictionary
comprehensions
illustrated
in
this
chapter
and
their
for
loop
equivalents
since
using
them
is
much
less
common
in
python
programs
than
building
lists
of
results
we
ll
leave
this
task
in
the
suggested
exercise
column
and
please
no
wagering
finally
keep
the
timing
module
we
wrote
here
filed
away
for
future
reference
we
ll
repurpose
it
to
measure
performance
of
alternative
numeric
square
root
operations
in
an
exercise
at
the
end
of
this
chapter
if
you
re
interested
in
pursuing
this
topic
further
we
ll
also
experiment
with
techniques
for
timing
dictionary
comprehensions
versus
for
loops
interactively
function
gotchas
now
that
we
ve
reached
the
end
of
the
function
story
let
s
review
some
common
pitfalls
functions
have
some
jagged
edges
that
you
might
not
expect
they
re
all
obscure
and
a
few
have
started
to
fall
away
from
the
language
completely
in
recent
releases
but
most
have
been
known
to
trip
up
new
users
local
names
are
detected
statically
as
you
know
python
classifies
names
assigned
in
a
function
as
locals
by
default
they
live
in
the
function
s
scope
and
exist
only
while
the
function
is
running
what
you
may
not
realize
is
that
python
detects
locals
statically
when
it
compiles
the
def
s
code
rather
than
by
noticing
assignments
as
they
happen
at
runtime
this
leads
to
one
of
the
most
common
oddities
posted
on
the
python
newsgroup
by
beginners
normally
a
name
that
isn
t
assigned
in
a
function
is
looked
up
in
the
enclosing
module
chapter
iterations
and
comprehensions
part
x
def
selector
print
x
selector
x
used
but
not
assigned
x
found
in
global
scope
here
the
x
in
the
function
resolves
to
the
x
in
the
module
but
watch
what
happens
if
you
add
an
assignment
to
x
after
the
reference
def
selector
print
x
does
not
yet
exist
x
x
classified
as
a
local
name
everywhere
can
also
happen
for
import
x
def
x
selector
error
text
omitted
unboundlocalerror
local
variable
x
referenced
before
assignment
you
get
the
name
usage
error
shown
here
but
the
reason
is
subtle
python
reads
and
compiles
this
code
when
it
s
typed
interactively
or
imported
from
a
module
while
compiling
python
sees
the
assignment
to
x
and
decides
that
x
will
be
a
local
name
everywhere
in
the
function
but
when
the
function
is
actually
run
because
the
assignment
hasn
t
yet
happened
when
the
print
executes
python
says
you
re
using
an
undefined
name
according
to
its
name
rules
it
should
say
this
the
local
x
is
used
before
being
assigned
in
fact
any
assignment
in
a
function
body
makes
a
name
local
imports
nested
defs
nested
classes
and
so
on
are
all
susceptible
to
this
behavior
the
problem
occurs
because
assigned
names
are
treated
as
locals
everywhere
in
a
function
not
just
after
the
statements
where
they
are
assigned
really
the
previous
example
is
ambiguous
at
best
was
the
intention
to
print
the
global
x
and
then
create
a
local
x
or
is
this
a
genuine
programming
error
because
python
treats
x
as
a
local
everywhere
it
is
viewed
as
an
error
if
you
really
mean
to
print
the
global
x
you
need
to
declare
it
in
a
global
statement
def
selector
global
x
print
x
x
selector
force
x
to
be
global
everywhere
remember
though
that
this
means
the
assignment
also
changes
the
global
x
not
a
local
x
within
a
function
you
can
t
use
both
local
and
global
versions
of
the
same
simple
name
if
you
really
meant
to
print
the
global
and
then
set
a
local
of
the
same
name
you
d
need
to
import
the
enclosing
module
and
use
module
attribute
notation
to
get
to
the
global
version
x
def
selector
import
main
print
main
x
x
import
enclosing
module
qualify
to
get
to
global
version
of
name
unqualified
x
classified
as
local
function
gotchas
print
x
selector
prints
local
version
of
name
qualification
the
x
part
fetches
a
value
from
a
namespace
object
the
interactive
namespace
is
a
module
called
main
so
main
x
reaches
the
global
version
of
x
if
that
isn
t
clear
check
out
chapter
in
recent
versions
python
has
improved
on
this
story
somewhat
by
issuing
for
this
case
the
more
specific
unbound
local
error
message
shown
in
the
example
listing
it
used
to
simply
raise
a
generic
name
error
this
gotcha
is
still
present
in
general
though
defaults
and
mutable
objects
default
argument
values
are
evaluated
and
saved
when
a
def
statement
is
run
not
when
the
resulting
function
is
called
internally
python
saves
one
object
per
default
argument
attached
to
the
function
itself
that
s
usually
what
you
want
because
defaults
are
evaluated
at
def
time
it
lets
you
save
values
from
the
enclosing
scope
if
needed
but
because
a
default
retains
an
object
between
calls
you
have
to
be
careful
about
changing
mutable
defaults
for
instance
the
following
function
uses
an
empty
list
as
a
default
value
and
then
changes
it
in
place
each
time
the
function
is
called
def
saver
x
x
append
print
x
saves
away
a
list
object
changes
same
object
each
time
saver
saver
default
not
used
saver
saver
grows
on
each
call
default
used
some
see
this
behavior
as
a
feature
because
mutable
default
arguments
retain
their
state
between
function
calls
they
can
serve
some
of
the
same
roles
as
static
local
function
variables
in
the
c
language
in
a
sense
they
work
sort
of
like
global
variables
but
their
names
are
local
to
the
functions
and
so
will
not
clash
with
names
elsewhere
in
a
program
to
most
observers
though
this
seems
like
a
gotcha
especially
the
first
time
they
run
into
it
there
are
better
ways
to
retain
state
between
calls
in
python
e
g
using
classes
which
will
be
discussed
in
part
vi
moreover
mutable
defaults
are
tricky
to
remember
and
to
understand
at
all
they
depend
upon
the
timing
of
default
object
construction
in
the
prior
example
there
is
chapter
iterations
and
comprehensions
part
just
one
list
object
for
the
default
value
the
one
created
when
the
def
is
executed
you
don
t
get
a
new
list
every
time
the
function
is
called
so
the
list
grows
with
each
new
append
it
is
not
reset
to
empty
on
each
call
if
that
s
not
the
behavior
you
want
simply
make
a
copy
of
the
default
at
the
start
of
the
function
body
or
move
the
default
value
expression
into
the
function
body
as
long
as
the
value
resides
in
code
that
s
actually
executed
each
time
the
function
runs
you
ll
get
a
new
object
each
time
through
def
saver
x
none
if
x
is
none
x
x
append
print
x
saver
saver
no
argument
passed
run
code
to
make
a
new
list
changes
new
list
object
doesn
t
grow
here
saver
by
the
way
the
if
statement
in
this
example
could
almost
be
replaced
by
the
assignment
x
x
or
which
takes
advantage
of
the
fact
that
python
s
or
returns
one
of
its
operand
objects
if
no
argument
was
passed
x
would
default
to
none
so
the
or
would
return
the
new
empty
list
on
the
right
however
this
isn
t
exactly
the
same
if
an
empty
list
were
passed
in
the
or
expression
would
cause
the
function
to
extend
and
return
a
newly
created
list
rather
than
extending
and
returning
the
passed
in
list
like
the
if
version
the
expression
becomes
or
which
evaluates
to
the
new
empty
list
on
the
right
see
the
section
truth
tests
on
page
if
you
don
t
recall
why
real
program
requirements
may
call
for
either
behavior
today
another
way
to
achieve
the
effect
of
mutable
defaults
in
a
possibly
less
confusing
way
is
to
use
the
function
attributes
we
discussed
in
chapter
def
saver
saver
x
append
print
saver
x
saver
x
saver
saver
saver
the
function
name
is
global
to
the
function
itself
but
it
need
not
be
declared
because
it
isn
t
changed
directly
within
the
function
this
isn
t
used
in
exactly
the
same
way
function
gotchas
but
when
coded
like
this
the
attachment
of
an
object
to
the
function
is
much
more
explicit
and
arguably
less
magical
functions
without
returns
in
python
functions
return
and
yield
statements
are
optional
when
a
function
doesn
t
return
a
value
explicitly
the
function
exits
when
control
falls
off
the
end
of
the
function
body
technically
all
functions
return
a
value
if
you
don
t
provide
a
return
statement
your
function
returns
the
none
object
automatically
def
proc
x
print
x
x
proc
testing
testing
print
x
none
no
return
is
a
none
return
functions
such
as
this
without
a
return
are
python
s
equivalent
of
what
are
called
procedures
in
some
languages
they
re
usually
invoked
as
statements
and
the
none
results
are
ignored
as
they
do
their
business
without
computing
a
useful
result
this
is
worth
knowing
because
python
won
t
tell
you
if
you
try
to
use
the
result
of
a
function
that
doesn
t
return
one
for
instance
assigning
the
result
of
a
list
append
method
won
t
raise
an
error
but
you
ll
get
back
none
not
the
modified
list
list
list
list
append
print
list
none
append
is
a
procedure
append
changes
list
in
place
as
mentioned
in
common
coding
gotchas
on
page
in
chapter
such
functions
do
their
business
as
a
side
effect
and
are
usually
designed
to
be
run
as
statements
not
expressions
enclosing
scope
loop
variables
we
described
this
gotcha
in
chapter
s
discussion
of
enclosing
function
scopes
but
as
a
reminder
be
careful
about
relying
on
enclosing
function
scope
lookup
for
variables
that
are
changed
by
enclosing
loops
all
such
references
will
remember
the
value
of
the
last
loop
iteration
use
defaults
to
save
loop
variable
values
instead
see
chapter
for
more
details
on
this
topic
chapter
summary
this
chapter
wrapped
up
our
coverage
of
built
in
comprehension
and
iteration
tools
it
explored
list
comprehensions
in
the
context
of
functional
tools
and
presented
generator
functions
and
expressions
as
additional
iteration
protocol
tools
as
a
finale
we
chapter
iterations
and
comprehensions
part
also
measured
the
performance
of
iteration
alternatives
and
we
closed
with
a
review
of
common
function
related
mistakes
to
help
you
avoid
pitfalls
this
concludes
the
functions
part
of
this
book
in
the
next
part
we
will
study
modules
the
topmost
organizational
structure
in
python
and
the
structure
in
which
our
functions
always
live
after
that
we
will
explore
classes
tools
that
are
largely
packages
of
functions
with
special
first
arguments
as
we
ll
see
user
defined
classes
can
implement
objects
that
tap
into
the
iteration
protocol
just
like
the
generators
and
iterables
we
met
here
everything
we
have
learned
in
this
part
of
the
book
will
apply
when
functions
pop
up
later
in
the
context
of
class
methods
before
moving
on
to
modules
though
be
sure
to
work
through
this
chapter
s
quiz
and
the
exercises
for
this
part
of
the
book
to
practice
what
we
ve
learned
about
functions
here
test
your
knowledge
quiz
what
is
the
difference
between
enclosing
a
list
comprehension
in
square
brackets
and
parentheses
how
are
generators
and
iterators
related
how
can
you
tell
if
a
function
is
a
generator
function
what
does
a
yield
statement
do
how
are
map
calls
and
list
comprehensions
related
compare
and
contrast
the
two
test
your
knowledge
answers
list
comprehensions
in
square
brackets
produce
the
result
list
all
at
once
in
memory
when
they
are
enclosed
in
parentheses
instead
they
are
actually
generator
expressions
they
have
a
similar
meaning
but
do
not
produce
the
result
list
all
at
once
instead
generator
expressions
return
a
generator
object
which
yields
one
item
in
the
result
at
a
time
when
used
in
an
iteration
context
generators
are
objects
that
support
the
iteration
protocol
they
have
a
next
method
that
repeatedly
advances
to
the
next
item
in
a
series
of
results
and
raises
an
exception
at
the
end
of
the
series
in
python
we
can
code
generator
functions
with
def
generator
expressions
with
parenthesized
list
comprehensions
and
generator
objects
with
classes
that
define
a
special
method
named
iter
discussed
later
in
the
book
a
generator
function
has
a
yield
statement
somewhere
in
its
code
generator
functions
are
otherwise
identical
to
normal
functions
syntactically
but
they
are
compiled
specially
by
python
so
as
to
return
an
iterable
object
when
called
test
your
knowledge
answers
when
present
this
statement
makes
python
compile
the
function
specially
as
a
generator
when
called
the
function
returns
a
generator
object
that
supports
the
iteration
protocol
when
the
yield
statement
is
run
it
sends
a
result
back
to
the
caller
and
suspends
the
function
s
state
the
function
can
then
be
resumed
after
the
last
yield
statement
in
response
to
a
next
built
in
or
next
method
call
issued
by
the
caller
generator
functions
may
also
have
a
return
statement
which
terminates
the
generator
the
map
call
is
similar
to
a
list
comprehension
both
build
a
new
list
by
collecting
the
results
of
applying
an
operation
to
each
item
in
a
sequence
or
other
iterable
one
item
at
a
time
the
main
difference
is
that
map
applies
a
function
call
to
each
item
and
list
comprehensions
apply
arbitrary
expressions
because
of
this
list
comprehensions
are
more
general
they
can
apply
a
function
call
expression
like
map
but
map
requires
a
function
to
apply
other
kinds
of
expressions
list
comprehensions
also
support
extended
syntax
such
as
nested
for
loops
and
if
clauses
that
subsume
the
filter
built
in
test
your
knowledge
part
iv
exercises
in
these
exercises
you
re
going
to
start
coding
more
sophisticated
programs
be
sure
to
check
the
solutions
in
part
iv
functions
on
page
in
appendix
b
and
be
sure
to
start
writing
your
code
in
module
files
you
won
t
want
to
retype
these
exercises
from
scratch
if
you
make
a
mistake
the
basics
at
the
python
interactive
prompt
write
a
function
that
prints
its
single
argument
to
the
screen
and
call
it
interactively
passing
a
variety
of
object
types
string
integer
list
dictionary
then
try
calling
it
without
passing
any
argument
what
happens
what
happens
when
you
pass
two
arguments
arguments
write
a
function
called
adder
in
a
python
module
file
the
function
should
accept
two
arguments
and
return
the
sum
or
concatenation
of
the
two
then
add
code
at
the
bottom
of
the
file
to
call
the
adder
function
with
a
variety
of
object
types
two
strings
two
lists
two
floating
points
and
run
this
file
as
a
script
from
the
system
command
line
do
you
have
to
print
the
call
statement
results
to
see
results
on
your
screen
varargs
generalize
the
adder
function
you
wrote
in
the
last
exercise
to
compute
the
sum
of
an
arbitrary
number
of
arguments
and
change
the
calls
to
pass
more
or
fewer
than
two
arguments
what
type
is
the
return
value
sum
hints
a
slice
such
as
s
returns
an
empty
sequence
of
the
same
type
as
s
and
the
type
builtin
function
can
test
types
but
see
the
manually
coded
min
examples
in
chapter
for
a
simpler
approach
what
happens
if
you
pass
in
arguments
of
different
types
what
about
passing
in
dictionaries
chapter
iterations
and
comprehensions
part
keywords
change
the
adder
function
from
exercise
to
accept
and
sum
concatenate
three
arguments
def
adder
good
bad
ugly
now
provide
default
values
for
each
argument
and
experiment
with
calling
the
function
interactively
try
passing
one
two
three
and
four
arguments
then
try
passing
keyword
arguments
does
the
call
adder
ugly
good
work
why
finally
generalize
the
new
adder
to
accept
and
sum
concatenate
an
arbitrary
number
of
keyword
arguments
this
is
similar
to
what
you
did
in
exercise
but
you
ll
need
to
iterate
over
a
dictionary
not
a
tuple
hint
the
dict
keys
method
returns
a
list
you
can
step
through
with
a
for
or
while
but
be
sure
to
wrap
it
in
a
list
call
to
index
it
in
write
a
function
called
copydict
dict
that
copies
its
dictionary
argument
it
should
return
a
new
dictionary
containing
all
the
items
in
its
argument
use
the
dictionary
keys
method
to
iterate
or
in
python
step
over
a
dictionary
s
keys
without
calling
keys
copying
sequences
is
easy
x
makes
a
top
level
copy
does
this
work
for
dictionaries
too
write
a
function
called
adddict
dict
dict
that
computes
the
union
of
two
dictionaries
it
should
return
a
new
dictionary
containing
all
the
items
in
both
its
arguments
which
are
assumed
to
be
dictionaries
if
the
same
key
appears
in
both
arguments
feel
free
to
pick
a
value
from
either
test
your
function
by
writing
it
in
a
file
and
running
the
file
as
a
script
what
happens
if
you
pass
lists
instead
of
dictionaries
how
could
you
generalize
your
function
to
handle
this
case
too
hint
see
the
type
built
in
function
used
earlier
does
the
order
of
the
arguments
passed
in
matter
more
argument
matching
examples
first
define
the
following
six
functions
either
interactively
or
in
a
module
file
that
can
be
imported
def
f
a
b
print
a
b
def
f
a
b
print
a
b
normal
args
positional
varargs
def
f
a
b
print
a
b
keyword
varargs
def
f
a
b
c
print
a
b
c
mixed
modes
def
f
a
b
c
print
a
b
c
defaults
def
f
a
b
c
print
a
b
c
defaults
and
positional
varargs
now
test
the
following
calls
interactively
and
try
to
explain
each
result
in
some
cases
you
ll
probably
need
to
fall
back
on
the
matching
algorithm
shown
in
chapter
do
you
think
mixing
matching
modes
is
a
good
idea
in
general
can
you
think
of
cases
where
it
would
be
useful
f
f
b
a
f
f
x
y
f
x
y
test
your
knowledge
part
iv
exercises
f
f
f
f
primes
revisited
recall
the
following
code
snippet
from
chapter
which
simplistically
determines
whether
a
positive
integer
is
prime
x
y
while
x
if
y
x
print
y
has
factor
x
break
x
else
print
y
is
prime
for
some
y
remainder
skip
else
normal
exit
package
this
code
as
a
reusable
function
in
a
module
file
y
should
be
a
passed
in
argument
and
add
some
calls
to
the
function
at
the
bottom
of
your
file
while
you
re
at
it
experiment
with
replacing
the
first
line
s
operator
with
to
see
how
true
division
changes
the
operator
in
python
and
breaks
this
code
refer
back
to
chapter
if
you
need
a
refresher
what
can
you
do
about
negatives
and
the
values
and
how
about
speeding
this
up
your
outputs
should
look
something
like
this
is
prime
is
prime
has
factor
has
factor
list
comprehensions
write
code
to
build
a
new
list
containing
the
square
roots
of
all
the
numbers
in
this
list
code
this
as
a
for
loop
first
then
as
a
map
call
and
finally
as
a
list
comprehension
use
the
sqrt
function
in
the
builtin
math
module
to
do
the
calculation
i
e
import
math
and
say
math
sqrt
x
of
the
three
which
approach
do
you
like
best
timing
tools
in
chapter
we
saw
three
ways
to
compute
square
roots
math
sqrt
x
x
and
pow
x
if
your
programs
run
a
lot
these
their
relative
performance
might
become
important
to
see
which
is
quickest
repurpose
the
timerseqs
py
script
we
wrote
in
this
chapter
to
time
each
of
these
three
tools
use
the
mytimer
py
timer
module
with
the
best
function
you
can
use
either
the
ony
keyword
only
variant
or
the
version
you
might
also
want
to
repackage
the
testing
code
in
this
script
for
better
reusability
by
passing
a
test
functions
tuple
to
a
general
tester
function
for
example
for
this
exercise
a
copy
and
modify
approach
is
fine
which
of
the
three
square
root
tools
seems
to
run
fastest
on
your
machine
and
python
in
general
finally
how
might
you
go
about
interactively
timing
the
speed
of
dictionary
comprehensions
versus
for
loops
chapter
iterations
and
comprehensions
part
part
v
modules
chapter
modules
the
big
picture
this
chapter
begins
our
in
depth
look
at
the
python
module
the
highest
level
program
organization
unit
which
packages
program
code
and
data
for
reuse
in
concrete
terms
modules
usually
correspond
to
python
program
files
or
extensions
coded
in
external
languages
such
as
c
java
or
c
each
file
is
a
module
and
modules
import
other
modules
to
use
the
names
they
define
modules
are
processed
with
two
statements
and
one
important
function
import
lets
a
client
importer
fetch
a
module
as
a
whole
from
allows
clients
to
fetch
particular
names
from
a
module
imp
reload
provides
a
way
to
reload
a
module
s
code
without
stopping
python
chapter
introduced
module
fundamentals
and
we
ve
been
using
them
ever
since
this
part
of
the
book
begins
by
expanding
on
core
module
concepts
then
moves
on
to
explore
more
advanced
module
usage
this
first
chapter
offers
a
general
look
at
the
role
of
modules
in
overall
program
structure
in
the
following
chapters
we
ll
dig
into
the
coding
details
behind
the
theory
along
the
way
we
ll
flesh
out
module
details
omitted
so
far
you
ll
learn
about
reloads
the
name
and
all
attributes
package
imports
relative
import
syntax
and
so
on
because
modules
and
classes
are
really
just
glorified
namespaces
we
ll
formalize
namespace
concepts
here
as
well
why
use
modules
in
short
modules
provide
an
easy
way
to
organize
components
into
a
system
by
serving
as
self
contained
packages
of
variables
known
as
namespaces
all
the
names
defined
at
the
top
level
of
a
module
file
become
attributes
of
the
imported
module
object
as
we
saw
in
the
last
part
of
this
book
imports
give
access
to
names
in
a
module
s
global
scope
that
is
the
module
file
s
global
scope
morphs
into
the
module
object
s
attribute
namespace
when
it
is
imported
ultimately
python
s
modules
allow
us
to
link
individual
files
into
a
larger
program
system
more
specifically
from
an
abstract
perspective
modules
have
at
least
three
roles
code
reuse
as
discussed
in
chapter
modules
let
you
save
code
in
files
permanently
unlike
code
you
type
at
the
python
interactive
prompt
which
goes
away
when
you
exit
python
code
in
module
files
is
persistent
it
can
be
reloaded
and
rerun
as
many
times
as
needed
more
to
the
point
modules
are
a
place
to
define
names
known
as
attributes
which
may
be
referenced
by
multiple
external
clients
system
namespace
partitioning
modules
are
also
the
highest
level
program
organization
unit
in
python
fundamentally
they
are
just
packages
of
names
modules
seal
up
names
into
self
contained
packages
which
helps
avoid
name
clashes
you
can
never
see
a
name
in
another
file
unless
you
explicitly
import
that
file
in
fact
everything
lives
in
a
module
code
you
execute
and
objects
you
create
are
always
implicitly
enclosed
in
modules
because
of
that
modules
are
natural
tools
for
grouping
system
components
implementing
shared
services
or
data
from
an
operational
perspective
modules
also
come
in
handy
for
implementing
components
that
are
shared
across
a
system
and
hence
require
only
a
single
copy
for
instance
if
you
need
to
provide
a
global
object
that
s
used
by
more
than
one
function
or
file
you
can
code
it
in
a
module
that
can
then
be
imported
by
many
clients
for
you
to
truly
understand
the
role
of
modules
in
a
python
system
though
we
need
to
digress
for
a
moment
and
explore
the
general
structure
of
a
python
program
python
program
architecture
so
far
in
this
book
i
ve
sugarcoated
some
of
the
complexity
in
my
descriptions
of
python
programs
in
practice
programs
usually
involve
more
than
just
one
file
for
all
but
the
simplest
scripts
your
programs
will
take
the
form
of
multifile
systems
and
even
if
you
can
get
by
with
coding
a
single
file
yourself
you
will
almost
certainly
wind
up
using
external
files
that
someone
else
has
already
written
this
section
introduces
the
general
architecture
of
python
programs
the
way
you
divide
a
program
into
a
collection
of
source
files
a
k
a
modules
and
link
the
parts
into
a
whole
along
the
way
we
ll
also
explore
the
central
concepts
of
python
modules
imports
and
object
attributes
chapter
modules
the
big
picture
how
to
structure
a
program
generally
a
python
program
consists
of
multiple
text
files
containing
python
statements
the
program
is
structured
as
one
main
top
level
file
along
with
zero
or
more
supplemental
files
known
as
modules
in
python
in
python
the
top
level
a
k
a
script
file
contains
the
main
flow
of
control
of
your
program
this
is
the
file
you
run
to
launch
your
application
the
module
files
are
libraries
of
tools
used
to
collect
components
used
by
the
top
level
file
and
possibly
elsewhere
top
level
files
use
tools
defined
in
module
files
and
modules
use
tools
defined
in
other
modules
module
files
generally
don
t
do
anything
when
run
directly
rather
they
define
tools
intended
for
use
in
other
files
in
python
a
file
imports
a
module
to
gain
access
to
the
tools
it
defines
which
are
known
as
its
attributes
i
e
variable
names
attached
to
objects
such
as
functions
ultimately
we
import
modules
and
access
their
attributes
to
use
their
tools
imports
and
attributes
let
s
make
this
a
bit
more
concrete
figure
sketches
the
structure
of
a
python
program
composed
of
three
files
a
py
b
py
and
c
py
the
file
a
py
is
chosen
to
be
the
top
level
file
it
will
be
a
simple
text
file
of
statements
which
is
executed
from
top
to
bottom
when
launched
the
files
b
py
and
c
py
are
modules
they
are
simple
text
files
of
statements
as
well
but
they
are
not
usually
launched
directly
instead
as
explained
previously
modules
are
normally
imported
by
other
files
that
wish
to
use
the
tools
they
define
figure
program
architecture
in
python
a
program
is
a
system
of
modules
it
has
one
top
level
script
file
launched
to
run
the
program
and
multiple
module
files
imported
libraries
of
tools
scripts
and
modules
are
both
text
files
containing
python
statements
though
the
statements
in
modules
usually
just
create
objects
to
be
used
later
python
s
standard
library
provides
a
collection
of
precoded
modules
python
program
architecture
for
instance
suppose
the
file
b
py
in
figure
defines
a
function
called
spam
for
external
use
as
we
learned
when
studying
functions
in
part
iv
b
py
will
contain
a
python
def
statement
to
generate
the
function
which
can
later
be
run
by
passing
zero
or
more
values
in
parentheses
after
the
function
s
name
def
spam
text
print
text
spam
now
suppose
a
py
wants
to
use
spam
to
this
end
it
might
contain
python
statements
such
as
the
following
import
b
b
spam
gumby
the
first
of
these
a
python
import
statement
gives
the
file
a
py
access
to
everything
defined
by
top
level
code
in
the
file
b
py
it
roughly
means
load
the
file
b
py
unless
it
s
already
loaded
and
give
me
access
to
all
its
attributes
through
the
name
b
import
and
as
you
ll
see
later
from
statements
execute
and
load
other
files
at
runtime
in
python
cross
file
module
linking
is
not
resolved
until
such
import
statements
are
executed
at
runtime
their
net
effect
is
to
assign
module
names
simple
variables
to
loaded
module
objects
in
fact
the
module
name
used
in
an
import
statement
serves
two
purposes
it
identifies
the
external
file
to
be
loaded
but
it
also
becomes
a
variable
assigned
to
the
loaded
module
objects
defined
by
a
module
are
also
created
at
runtime
as
the
import
is
executing
import
literally
runs
statements
in
the
target
file
one
at
a
time
to
create
its
contents
the
second
of
the
statements
in
a
py
calls
the
function
spam
defined
in
the
module
b
using
object
attribute
notation
the
code
b
spam
means
fetch
the
value
of
the
name
spam
that
lives
within
the
object
b
this
happens
to
be
a
callable
function
in
our
example
so
we
pass
a
string
in
parentheses
gumby
if
you
actually
type
these
files
save
them
and
run
a
py
the
words
gumby
spam
will
be
printed
you
ll
see
the
object
attribute
notation
used
throughout
python
scripts
most
objects
have
useful
attributes
that
are
fetched
with
the
operator
some
are
callable
things
like
functions
and
others
are
simple
data
values
that
give
object
properties
e
g
a
person
s
name
the
notion
of
importing
is
also
completely
general
throughout
python
any
file
can
import
tools
from
any
other
file
for
instance
the
file
a
py
may
import
b
py
to
call
its
function
but
b
py
might
also
import
c
py
to
leverage
different
tools
defined
there
import
chains
can
go
as
deep
as
you
like
in
this
example
the
module
a
can
import
b
which
can
import
c
which
can
import
b
again
and
so
on
besides
serving
as
the
highest
organizational
structure
modules
and
module
packages
described
in
chapter
are
also
the
highest
level
of
code
reuse
in
python
coding
components
in
module
files
makes
them
useful
in
your
original
program
and
in
any
other
programs
you
may
write
for
instance
if
after
coding
the
program
in
figure
we
discover
that
the
function
b
spam
is
a
general
purpose
tool
we
can
reuse
chapter
modules
the
big
picture
it
in
a
completely
different
program
all
we
have
to
do
is
import
the
file
b
py
again
from
the
other
program
s
files
standard
library
modules
notice
the
rightmost
portion
of
figure
some
of
the
modules
that
your
programs
will
import
are
provided
by
python
itself
and
are
not
files
you
will
code
python
automatically
comes
with
a
large
collection
of
utility
modules
known
as
the
standard
library
this
collection
roughly
modules
large
at
last
count
contains
platform
independent
support
for
common
programming
tasks
operating
system
interfaces
object
persistence
text
pattern
matching
network
and
internet
scripting
gui
construction
and
much
more
none
of
these
tools
are
part
of
the
python
language
itself
but
you
can
use
them
by
importing
the
appropriate
modules
on
any
standard
python
installation
because
they
are
standard
library
modules
you
can
also
be
reasonably
sure
that
they
will
be
available
and
will
work
portably
on
most
platforms
on
which
you
will
run
python
you
will
see
a
few
of
the
standard
library
modules
in
action
in
this
book
s
examples
but
for
a
complete
look
you
should
browse
the
standard
python
library
reference
manual
available
either
with
your
python
installation
via
idle
or
the
python
start
button
menu
on
windows
or
online
at
http
www
python
org
because
there
are
so
many
modules
this
is
really
the
only
way
to
get
a
feel
for
what
tools
are
available
you
can
also
find
tutorials
on
python
library
tools
in
commercial
books
that
cover
application
level
programming
such
as
o
reilly
s
programming
py
thon
but
the
manuals
are
free
viewable
in
any
web
browser
they
ship
in
html
format
and
updated
each
time
python
is
rereleased
how
imports
work
the
prior
section
talked
about
importing
modules
without
really
explaining
what
happens
when
you
do
so
because
imports
are
at
the
heart
of
program
structure
in
python
this
section
goes
into
more
detail
on
the
import
operation
to
make
this
process
less
abstract
some
c
programmers
like
to
compare
the
python
module
import
operation
to
a
c
include
but
they
really
shouldn
t
in
python
imports
are
not
just
textual
insertions
of
one
file
into
another
they
are
really
runtime
operations
that
perform
three
distinct
steps
the
first
time
a
program
imports
a
given
file
find
the
module
s
file
compile
it
to
byte
code
if
needed
run
the
module
s
code
to
build
the
objects
it
defines
how
imports
work
to
better
understand
module
imports
we
ll
explore
these
steps
in
turn
bear
in
mind
that
all
three
of
these
steps
are
carried
out
only
the
first
time
a
module
is
imported
during
a
program
s
execution
later
imports
of
the
same
module
bypass
all
of
these
steps
and
simply
fetch
the
already
loaded
module
object
in
memory
technically
python
does
this
by
storing
loaded
modules
in
a
table
named
sys
modules
and
checking
there
at
the
start
of
an
import
operation
if
the
module
is
not
present
a
three
step
process
begins
find
it
first
python
must
locate
the
module
file
referenced
by
an
import
statement
notice
that
the
import
statement
in
the
prior
section
s
example
names
the
file
without
a
py
suffix
and
without
its
directory
path
it
just
says
import
b
instead
of
something
like
import
c
dir
b
py
in
fact
you
can
only
list
a
simple
name
path
and
suffix
details
are
omitted
on
purpose
and
python
uses
a
standard
module
search
path
to
locate
the
module
file
corresponding
to
an
import
statement
because
this
is
the
main
part
of
the
import
operation
that
programmers
must
know
about
we
ll
return
to
this
topic
in
a
moment
compile
it
maybe
after
finding
a
source
code
file
that
matches
an
import
statement
by
traversing
the
module
search
path
python
next
compiles
it
to
byte
code
if
necessary
we
discussed
byte
code
in
chapter
python
checks
the
file
timestamps
and
if
the
byte
code
file
is
older
than
the
source
file
i
e
if
you
ve
changed
the
source
automatically
regenerates
the
byte
code
when
the
program
is
run
if
on
the
other
hand
it
finds
a
pyc
byte
code
file
that
is
not
older
than
the
corresponding
py
source
file
it
skips
the
source
to
byte
code
compile
step
in
addition
if
python
finds
only
a
byte
code
file
on
the
search
path
and
no
source
it
simply
loads
the
byte
code
directly
this
means
you
can
ship
a
program
as
just
byte
code
files
and
avoid
sending
source
in
other
words
the
compile
step
is
bypassed
if
possible
to
speed
program
startup
notice
that
compilation
happens
when
a
file
is
being
imported
because
of
this
you
will
not
usually
see
a
pyc
byte
code
file
for
the
top
level
file
of
your
program
unless
it
is
also
imported
elsewhere
only
imported
files
leave
behind
pyc
files
on
your
it
s
actually
syntactically
illegal
to
include
path
and
suffix
details
in
a
standard
import
package
imports
which
we
ll
discuss
in
chapter
allow
import
statements
to
include
part
of
the
directory
path
leading
to
a
file
as
a
set
of
period
separated
names
however
package
imports
still
rely
on
the
normal
module
search
path
to
locate
the
leftmost
directory
in
a
package
path
i
e
they
are
relative
to
a
directory
in
the
search
path
they
also
cannot
make
use
of
any
platform
specific
directory
syntax
in
the
import
statements
such
syntax
only
works
on
the
search
path
also
note
that
module
file
search
path
issues
are
not
as
relevant
when
you
run
frozen
executables
discussed
in
chapter
they
typically
embed
byte
code
in
the
binary
image
chapter
modules
the
big
picture
machine
the
byte
code
of
top
level
files
is
used
internally
and
discarded
byte
code
of
imported
files
is
saved
in
files
to
speed
future
imports
top
level
files
are
often
designed
to
be
executed
directly
and
not
imported
at
all
later
we
ll
see
that
it
is
possible
to
design
a
file
that
serves
both
as
the
top
level
code
of
a
program
and
as
a
module
of
tools
to
be
imported
such
a
file
may
be
both
executed
and
imported
and
thus
does
generate
a
pyc
to
learn
how
this
works
watch
for
the
discussion
of
the
special
name
attribute
and
main
in
chapter
run
it
the
final
step
of
an
import
operation
executes
the
byte
code
of
the
module
all
statements
in
the
file
are
executed
in
turn
from
top
to
bottom
and
any
assignments
made
to
names
during
this
step
generate
attributes
of
the
resulting
module
object
this
execution
step
therefore
generates
all
the
tools
that
the
module
s
code
defines
for
instance
def
statements
in
a
file
are
run
at
import
time
to
create
functions
and
assign
attributes
within
the
module
to
those
functions
the
functions
can
then
be
called
later
in
the
program
by
the
file
s
importers
because
this
last
import
step
actually
runs
the
file
s
code
if
any
top
level
code
in
a
module
file
does
real
work
you
ll
see
its
results
at
import
time
for
example
top
level
print
statements
in
a
module
show
output
when
the
file
is
imported
function
def
statements
simply
define
objects
for
later
use
as
you
can
see
import
operations
involve
quite
a
bit
of
work
they
search
for
files
possibly
run
a
compiler
and
run
python
code
because
of
this
any
given
module
is
imported
only
once
per
process
by
default
future
imports
skip
all
three
import
steps
and
reuse
the
already
loaded
module
in
memory
if
you
need
to
import
a
file
again
after
it
has
already
been
loaded
for
example
to
support
end
user
customization
you
have
to
force
the
issue
with
an
imp
reload
call
a
tool
we
ll
meet
in
the
next
chapter
the
module
search
path
as
mentioned
earlier
the
part
of
the
import
procedure
that
is
most
important
to
programmers
is
usually
the
first
locating
the
file
to
be
imported
the
find
it
part
because
you
may
need
to
tell
python
where
to
look
to
find
files
to
import
you
need
to
know
how
to
tap
into
its
search
path
in
order
to
extend
it
as
described
earlier
python
keeps
already
imported
modules
in
the
built
in
sys
modules
dictionary
so
it
can
keep
track
of
what
s
been
loaded
in
fact
if
you
want
to
see
which
modules
are
loaded
you
can
import
sys
and
print
list
sys
modules
keys
more
on
other
uses
for
this
internal
table
in
chapter
the
module
search
path
in
many
cases
you
can
rely
on
the
automatic
nature
of
the
module
import
search
path
and
won
t
need
to
configure
this
path
at
all
if
you
want
to
be
able
to
import
files
across
directory
boundaries
though
you
will
need
to
know
how
the
search
path
works
in
order
to
customize
it
roughly
python
s
module
search
path
is
composed
of
the
concatenation
of
these
major
components
some
of
which
are
preset
for
you
and
some
of
which
you
can
tailor
to
tell
python
where
to
look
the
home
directory
of
the
program
pythonpath
directories
if
set
standard
library
directories
the
contents
of
any
pth
files
if
present
ultimately
the
concatenation
of
these
four
components
becomes
sys
path
a
list
of
directory
name
strings
that
i
ll
expand
upon
later
in
this
section
the
first
and
third
elements
of
the
search
path
are
defined
automatically
because
python
searches
the
concatenation
of
these
components
from
first
to
last
though
the
second
and
fourth
elements
can
be
used
to
extend
the
path
to
include
your
own
source
code
directories
here
is
how
python
uses
each
of
these
path
components
home
directory
python
first
looks
for
the
imported
file
in
the
home
directory
the
meaning
of
this
entry
depends
on
how
you
are
running
the
code
when
you
re
running
a
program
this
entry
is
the
directory
containing
your
program
s
top
level
script
file
when
you
re
working
interactively
this
entry
is
the
directory
in
which
you
are
working
i
e
the
current
working
directory
because
this
directory
is
always
searched
first
if
a
program
is
located
entirely
in
a
single
directory
all
of
its
imports
will
work
automatically
with
no
path
configuration
required
on
the
other
hand
because
this
directory
is
searched
first
its
files
will
also
override
modules
of
the
same
name
in
directories
elsewhere
on
the
path
be
careful
not
to
accidentally
hide
library
modules
this
way
if
you
need
them
in
your
program
pythonpath
directories
next
python
searches
all
directories
listed
in
your
pythonpath
environment
variable
setting
from
left
to
right
assuming
you
have
set
this
at
all
in
brief
pythonpath
is
simply
set
to
a
list
of
user
defined
and
platform
specific
names
of
directories
that
contain
python
code
files
you
can
add
all
the
directories
from
which
you
wish
to
be
able
to
import
and
python
will
extend
the
module
search
path
to
include
all
the
directories
your
pythonpath
lists
because
python
searches
the
home
directory
first
this
setting
is
only
important
when
importing
files
across
directory
boundaries
that
is
if
you
need
to
import
a
file
that
is
stored
in
a
different
directory
from
the
file
that
imports
it
you
ll
probably
want
to
set
your
pythonpath
variable
once
you
start
writing
substantial
programs
but
when
you
re
first
starting
out
as
long
as
you
save
all
your
module
files
in
the
chapter
modules
the
big
picture
directory
in
which
you
re
working
i
e
the
home
directory
described
earlier
your
imports
will
work
without
you
needing
to
worry
about
this
setting
at
all
standard
library
directories
next
python
automatically
searches
the
directories
where
the
standard
library
modules
are
installed
on
your
machine
because
these
are
always
searched
they
normally
do
not
need
to
be
added
to
your
pythonpath
or
included
in
path
files
discussed
next
pth
path
file
directories
finally
a
lesser
used
feature
of
python
allows
users
to
add
directories
to
the
module
search
path
by
simply
listing
them
one
per
line
in
a
text
file
whose
name
ends
with
a
pth
suffix
for
path
these
path
configuration
files
are
a
somewhat
advanced
installation
related
feature
we
won
t
them
cover
fully
here
but
they
provide
an
alternative
to
pythonpath
settings
in
short
text
files
of
directory
names
dropped
in
an
appropriate
directory
can
serve
roughly
the
same
role
as
the
pythonpath
environment
variable
setting
for
instance
if
you
re
running
windows
and
python
a
file
named
myconfig
pth
may
be
placed
at
the
top
level
of
the
python
install
directory
c
python
or
in
the
sitepackages
subdirectory
of
the
standard
library
there
c
python
lib
sitepackages
to
extend
the
module
search
path
on
unix
like
systems
this
file
might
be
located
in
usr
local
lib
python
site
packages
or
usr
local
lib
site
python
instead
when
present
python
will
add
the
directories
listed
on
each
line
of
the
file
from
first
to
last
near
the
end
of
the
module
search
path
list
in
fact
python
will
collect
the
directory
names
in
all
the
path
files
it
finds
and
will
filter
out
any
duplicates
and
nonexistent
directories
because
they
are
files
rather
than
shell
settings
path
files
can
apply
to
all
users
of
an
installation
instead
of
just
one
user
or
shell
moreover
for
some
users
text
files
may
be
simpler
to
code
than
environment
settings
this
feature
is
more
sophisticated
than
i
ve
described
here
for
more
details
consult
the
python
library
manual
and
especially
its
documentation
for
the
standard
library
module
site
this
module
allows
the
locations
of
python
libraries
and
path
files
to
be
configured
and
its
documentation
describes
the
expected
locations
of
path
files
in
general
i
recommend
that
beginners
use
pythonpath
or
perhaps
a
single
pth
file
and
then
only
if
you
must
import
across
directories
path
files
are
used
more
often
by
third
party
libraries
which
commonly
install
a
path
file
in
python
s
site
packages
directory
so
that
user
settings
are
not
required
python
s
distutils
install
system
described
in
an
upcoming
sidebar
automates
many
install
steps
configuring
the
search
path
the
net
effect
of
all
of
this
is
that
both
the
pythonpath
and
path
file
components
of
the
search
path
allow
you
to
tailor
the
places
where
imports
look
for
files
the
way
you
set
environment
variables
and
where
you
store
path
files
varies
per
platform
for
instance
the
module
search
path
on
windows
you
might
use
your
control
panel
s
system
icon
to
set
pythonpath
to
a
list
of
directories
separated
by
semicolons
like
this
c
pycode
utilities
d
pycode
package
or
you
might
instead
create
a
text
file
called
c
python
pydirs
pth
which
looks
like
this
c
pycode
utilities
d
pycode
package
these
settings
are
analogous
on
other
platforms
but
the
details
can
vary
too
widely
for
us
to
cover
in
this
chapter
see
appendix
a
for
pointers
on
extending
your
module
search
path
with
pythonpath
or
pth
files
on
various
platforms
search
path
variations
this
description
of
the
module
search
path
is
accurate
but
generic
the
exact
configuration
of
the
search
path
is
prone
to
changing
across
platforms
and
python
releases
depending
on
your
platform
additional
directories
may
automatically
be
added
to
the
module
search
path
as
well
for
instance
python
may
add
an
entry
for
the
current
working
directory
the
directory
from
which
you
launched
your
program
in
the
search
path
after
the
pythonpath
directories
and
before
the
standard
library
entries
when
you
re
launching
from
a
command
line
the
current
working
directory
may
not
be
the
same
as
the
home
directory
of
your
top
level
file
i
e
the
directory
where
your
program
file
resides
because
the
current
working
directory
can
vary
each
time
your
program
runs
you
normally
shouldn
t
depend
on
its
value
for
import
purposes
see
chapter
for
more
on
launching
programs
from
command
lines
to
see
how
your
python
configures
the
module
search
path
on
your
platform
you
can
always
inspect
sys
path
the
topic
of
the
next
section
the
sys
path
list
if
you
want
to
see
how
the
module
search
path
is
truly
configured
on
your
machine
you
can
always
inspect
the
path
as
python
knows
it
by
printing
the
built
in
sys
path
list
that
is
the
path
attribute
of
the
standard
library
module
sys
this
list
of
directory
name
strings
is
the
actual
search
path
within
python
on
imports
python
searches
each
directory
in
this
list
from
left
to
right
see
also
chapter
s
discussion
of
the
new
relative
import
syntax
in
python
this
modifies
the
search
path
for
from
statements
in
files
inside
packages
when
characters
are
used
e
g
from
import
string
by
default
a
package
s
own
directory
is
not
automatically
searched
by
imports
in
python
unless
relative
imports
are
used
by
files
in
the
package
itself
chapter
modules
the
big
picture
really
sys
path
is
the
module
search
path
python
configures
it
at
program
startup
automatically
merging
the
home
directory
of
the
top
level
file
or
an
empty
string
to
designate
the
current
working
directory
any
pythonpath
directories
the
contents
of
any
pth
file
paths
you
ve
created
and
the
standard
library
directories
the
result
is
a
list
of
directory
name
strings
that
python
searches
on
each
import
of
a
new
file
python
exposes
this
list
for
two
good
reasons
first
it
provides
a
way
to
verify
the
search
path
settings
you
ve
made
if
you
don
t
see
your
settings
somewhere
in
this
list
you
need
to
recheck
your
work
for
example
here
is
what
my
module
search
path
looks
like
on
windows
under
python
with
my
pythonpath
set
to
c
users
and
a
c
python
mypath
py
path
file
that
lists
c
users
mark
the
empty
string
at
the
front
means
current
directory
and
my
two
settings
are
merged
in
the
rest
are
standard
library
directories
and
files
import
sys
sys
path
c
users
c
windows
system
python
zip
c
python
dlls
c
python
lib
c
python
lib
plat
win
c
python
c
users
mark
c
python
lib
site
packages
second
if
you
know
what
you
re
doing
this
list
provides
a
way
for
scripts
to
tailor
their
search
paths
manually
as
you
ll
see
later
in
this
part
of
the
book
by
modifying
the
sys
path
list
you
can
modify
the
search
path
for
all
future
imports
such
changes
only
last
for
the
duration
of
the
script
however
pythonpath
and
pth
files
offer
more
permanent
ways
to
modify
the
path
module
file
selection
keep
in
mind
that
filename
suffixes
e
g
py
are
intentionally
omitted
from
import
statements
python
chooses
the
first
file
it
can
find
on
the
search
path
that
matches
the
imported
name
for
example
an
import
statement
of
the
form
import
b
might
load
a
source
code
file
named
b
py
a
byte
code
file
named
b
pyc
a
directory
named
b
for
package
imports
described
in
chapter
a
compiled
extension
module
usually
coded
in
c
or
c
and
dynamically
linked
when
imported
e
g
b
so
on
linux
or
b
dll
or
b
pyd
on
cygwin
and
windows
a
compiled
built
in
module
coded
in
c
and
statically
linked
into
python
a
zip
file
component
that
is
automatically
extracted
when
imported
an
in
memory
image
for
frozen
executables
some
programs
really
need
to
change
sys
path
though
scripts
that
run
on
web
servers
for
example
often
run
as
the
user
nobody
to
limit
machine
access
because
such
scripts
cannot
usually
depend
on
nobody
to
have
set
pythonpath
in
any
particular
way
they
often
set
sys
path
manually
to
include
required
source
directories
prior
to
running
any
import
statements
a
sys
path
append
dirname
will
often
suffice
the
module
search
path
a
java
class
in
the
jython
version
of
python
a
net
component
in
the
ironpython
version
of
python
c
extensions
jython
and
package
imports
all
extend
imports
beyond
simple
files
to
importers
though
differences
in
the
loaded
file
type
are
completely
transparent
both
when
importing
and
when
fetching
module
attributes
saying
import
b
gets
whatever
module
b
is
according
to
your
module
search
path
and
b
attr
fetches
an
item
in
the
module
be
it
a
python
variable
or
a
linked
in
c
function
some
standard
modules
we
will
use
in
this
book
are
actually
coded
in
c
not
python
because
of
this
transparency
their
clients
don
t
have
to
care
if
you
have
both
a
b
py
and
a
b
so
in
different
directories
python
will
always
load
the
one
found
in
the
first
leftmost
directory
of
your
module
search
path
during
the
leftto
right
search
of
sys
path
but
what
happens
if
it
finds
both
a
b
py
and
a
b
so
in
the
same
directory
in
this
case
python
follows
a
standard
picking
order
though
this
order
is
not
guaranteed
to
stay
the
same
over
time
in
general
you
should
not
depend
on
which
type
of
file
python
will
choose
within
a
given
directory
make
your
module
names
distinct
or
configure
your
module
search
path
to
make
your
module
selection
preferences
more
obvious
advanced
module
selection
concepts
normally
imports
work
as
described
in
this
section
they
find
and
load
files
on
your
machine
however
it
is
possible
to
redefine
much
of
what
an
import
operation
does
in
python
using
what
are
known
as
import
hooks
these
hooks
can
be
used
to
make
imports
do
various
useful
things
such
as
loading
files
from
archives
performing
decryption
and
so
on
in
fact
python
itself
makes
use
of
these
hooks
to
enable
files
to
be
directly
imported
from
zip
archives
archived
files
are
automatically
extracted
at
import
time
when
a
zip
file
is
selected
from
the
module
import
search
path
one
of
the
standard
library
directories
in
the
earlier
sys
path
display
for
example
is
a
zip
file
today
for
more
details
see
the
python
standard
library
manual
s
description
of
the
built
in
import
function
the
customizable
tool
that
import
statements
actually
run
python
also
supports
the
notion
of
pyo
optimized
byte
code
files
created
and
run
with
the
o
python
command
line
flag
because
these
run
only
slightly
faster
than
normal
pyc
files
typically
percent
faster
however
they
are
infrequently
used
the
psyco
system
see
chapter
provides
more
substantial
speedups
third
party
software
distutils
this
chapter
s
description
of
module
search
path
settings
is
targeted
mainly
at
userdefined
source
code
that
you
write
on
your
own
third
party
extensions
for
python
typically
use
the
distutils
tools
in
the
standard
library
to
automatically
install
themselves
so
no
path
configuration
is
required
to
use
their
code
chapter
modules
the
big
picture
systems
that
use
distutils
generally
come
with
a
setup
py
script
which
is
run
to
install
them
this
script
imports
and
uses
distutils
modules
to
place
such
systems
in
a
directory
that
is
automatically
part
of
the
module
search
path
usually
in
the
lib
sitepackages
subdirectory
of
the
python
install
tree
wherever
that
resides
on
the
target
machine
for
more
details
on
distributing
and
installing
with
distutils
see
the
python
standard
manual
set
its
use
is
beyond
the
scope
of
this
book
for
instance
it
also
provides
ways
to
automatically
compile
c
coded
extensions
on
the
target
machine
also
check
out
the
emerging
third
party
open
source
eggs
system
which
adds
dependency
checking
for
installed
python
software
chapter
summary
in
this
chapter
we
covered
the
basics
of
modules
attributes
and
imports
and
explored
the
operation
of
import
statements
we
learned
that
imports
find
the
designated
file
on
the
module
search
path
compile
it
to
byte
code
and
execute
all
of
its
statements
to
generate
its
contents
we
also
learned
how
to
configure
the
search
path
to
be
able
to
import
from
directories
other
than
the
home
directory
and
the
standard
library
directories
primarily
with
pythonpath
settings
as
this
chapter
demonstrated
the
import
operation
and
modules
are
at
the
heart
of
program
architecture
in
python
larger
programs
are
divided
into
multiple
files
which
are
linked
together
at
runtime
by
imports
imports
in
turn
use
the
module
search
path
to
locate
files
and
modules
define
attributes
for
external
use
of
course
the
whole
point
of
imports
and
modules
is
to
provide
a
structure
to
your
program
which
divides
its
logic
into
self
contained
software
components
code
in
one
module
is
isolated
from
code
in
another
in
fact
no
file
can
ever
see
the
names
defined
in
another
unless
explicit
import
statements
are
run
because
of
this
modules
minimize
name
collisions
between
different
parts
of
your
program
you
ll
see
what
this
all
means
in
terms
of
actual
statements
and
code
in
the
next
chapter
before
we
move
on
though
let
s
run
through
the
chapter
quiz
test
your
knowledge
quiz
how
does
a
module
source
code
file
become
a
module
object
why
might
you
have
to
set
your
pythonpath
environment
variable
name
the
four
major
components
of
the
module
import
search
path
name
four
file
types
that
python
might
load
in
response
to
an
import
operation
what
is
a
namespace
and
what
does
a
module
s
namespace
contain
test
your
knowledge
quiz
test
your
knowledge
answers
a
module
s
source
code
file
automatically
becomes
a
module
object
when
that
module
is
imported
technically
the
module
s
source
code
is
run
during
the
import
one
statement
at
a
time
and
all
the
names
assigned
in
the
process
become
attributes
of
the
module
object
you
only
need
to
set
pythonpath
to
import
from
directories
other
than
the
one
in
which
you
are
working
i
e
the
current
directory
when
working
interactively
or
the
directory
containing
your
top
level
file
the
four
major
components
of
the
module
import
search
path
are
the
top
level
script
s
home
directory
the
directory
containing
it
all
directories
listed
in
the
pythonpath
environment
variable
the
standard
library
directories
and
all
directories
listed
in
pth
path
files
located
in
standard
places
of
these
programmers
can
customize
pythonpath
and
pth
files
python
might
load
a
source
code
py
file
a
byte
code
pyc
file
a
c
extension
module
e
g
a
so
file
on
linux
or
a
dll
or
pyd
file
on
windows
or
a
directory
of
the
same
name
for
package
imports
imports
may
also
load
more
exotic
things
such
as
zip
file
components
java
classes
under
the
jython
version
of
python
net
components
under
ironpython
and
statically
linked
c
extensions
that
have
no
files
present
at
all
with
import
hooks
imports
can
load
anything
a
namespace
is
a
self
contained
package
of
variables
which
are
known
as
the
attributes
of
the
namespace
object
a
module
s
namespace
contains
all
the
names
assigned
by
code
at
the
top
level
of
the
module
file
i
e
not
nested
in
def
or
class
statements
technically
a
module
s
global
scope
morphs
into
the
module
object
s
attributes
namespace
a
module
s
namespace
may
also
be
altered
by
assignments
from
other
files
that
import
it
though
this
is
frowned
upon
see
chapter
for
more
on
this
issue
chapter
modules
the
big
picture
chapter
module
coding
basics
now
that
we
ve
looked
at
the
larger
ideas
behind
modules
let
s
turn
to
a
simple
example
of
modules
in
action
python
modules
are
easy
to
create
they
re
just
files
of
python
program
code
created
with
a
text
editor
you
don
t
need
to
write
special
syntax
to
tell
python
you
re
making
a
module
almost
any
text
file
will
do
because
python
handles
all
the
details
of
finding
and
loading
modules
modules
are
also
easy
to
use
clients
simply
import
a
module
or
specific
names
a
module
defines
and
use
the
objects
they
reference
module
creation
to
define
a
module
simply
use
your
text
editor
to
type
some
python
code
into
a
text
file
and
save
it
with
a
py
extension
any
such
file
is
automatically
considered
a
python
module
all
the
names
assigned
at
the
top
level
of
the
module
become
its
attributes
names
associated
with
the
module
object
and
are
exported
for
clients
to
use
for
instance
if
you
type
the
following
def
into
a
file
called
module
py
and
import
it
you
create
a
module
object
with
one
attribute
the
name
printer
which
happens
to
be
a
reference
to
a
function
object
def
printer
x
print
x
module
attribute
before
we
go
on
i
should
say
a
few
more
words
about
module
filenames
you
can
call
modules
just
about
anything
you
like
but
module
filenames
should
end
in
a
py
suffix
if
you
plan
to
import
them
the
py
is
technically
optional
for
top
level
files
that
will
be
run
but
not
imported
but
adding
it
in
all
cases
makes
your
files
types
more
obvious
and
allows
you
to
import
any
of
your
files
in
the
future
because
module
names
become
variable
names
inside
a
python
program
without
the
py
they
should
also
follow
the
normal
variable
name
rules
outlined
in
chapter
for
instance
you
can
create
a
module
file
named
if
py
but
you
cannot
import
it
because
if
is
a
reserved
word
when
you
try
to
run
import
if
you
ll
get
a
syntax
error
in
fact
both
the
names
of
module
files
and
the
names
of
directories
used
in
package
imports
discussed
in
the
next
chapter
must
conform
to
the
rules
for
variable
names
presented
in
chapter
they
may
for
instance
contain
only
letters
digits
and
underscores
package
directories
also
cannot
contain
platform
specific
syntax
such
as
spaces
in
their
names
when
a
module
is
imported
python
maps
the
internal
module
name
to
an
external
filename
by
adding
a
directory
path
from
the
module
search
path
to
the
front
and
a
py
or
other
extension
at
the
end
for
instance
a
module
named
m
ultimately
maps
to
some
external
file
directory
m
extension
that
contains
the
module
s
code
as
mentioned
in
the
preceding
chapter
it
is
also
possible
to
create
a
python
module
by
writing
code
in
an
external
language
such
as
c
or
c
or
java
in
the
jython
implementation
of
the
language
such
modules
are
called
extension
modules
and
they
are
generally
used
to
wrap
up
external
libraries
for
use
in
python
scripts
when
imported
by
python
code
extension
modules
look
and
feel
the
same
as
modules
coded
as
python
source
code
files
they
are
accessed
with
import
statements
and
they
provide
functions
and
objects
as
module
attributes
extension
modules
are
beyond
the
scope
of
this
book
see
python
s
standard
manuals
or
advanced
texts
such
as
programming
python
for
more
details
module
usage
clients
can
use
the
simple
module
file
we
just
wrote
by
running
an
import
or
from
statement
both
statements
find
compile
and
run
a
module
file
s
code
if
it
hasn
t
yet
been
loaded
the
chief
difference
is
that
import
fetches
the
module
as
a
whole
so
you
must
qualify
to
fetch
its
names
in
contrast
from
fetches
or
copies
specific
names
out
of
the
module
let
s
see
what
this
means
in
terms
of
code
all
of
the
following
examples
wind
up
calling
the
printer
function
defined
in
the
prior
section
s
module
py
module
file
but
in
different
ways
the
import
statement
in
the
first
example
the
name
module
serves
two
different
purposes
it
identifies
an
external
file
to
be
loaded
and
it
becomes
a
variable
in
the
script
which
references
the
module
object
after
the
file
is
loaded
import
module
module
printer
hello
world
hello
world
get
module
as
a
whole
qualify
to
get
names
because
import
gives
a
name
that
refers
to
the
whole
module
object
we
must
go
through
the
module
name
to
fetch
its
attributes
e
g
module
printer
chapter
module
coding
basics
the
from
statement
by
contrast
because
from
also
copies
names
from
one
file
over
to
another
scope
it
allows
us
to
use
the
copied
names
directly
in
the
script
without
going
through
the
module
e
g
printer
from
module
import
printer
printer
hello
world
hello
world
copy
out
one
variable
no
need
to
qualify
name
this
has
the
same
effect
as
the
prior
example
but
because
the
imported
name
is
copied
into
the
scope
where
the
from
statement
appears
using
that
name
in
the
script
requires
less
typing
we
can
use
it
directly
instead
of
naming
the
enclosing
module
as
you
ll
see
in
more
detail
later
the
from
statement
is
really
just
a
minor
extension
to
the
import
statement
it
imports
the
module
file
as
usual
but
adds
an
extra
step
that
copies
one
or
more
names
out
of
the
file
the
from
statement
finally
the
next
example
uses
a
special
form
of
from
when
we
use
a
we
get
copies
of
all
the
names
assigned
at
the
top
level
of
the
referenced
module
here
again
we
can
then
use
the
copied
name
printer
in
our
script
without
going
through
the
module
name
from
module
import
printer
hello
world
hello
world
copy
out
all
variables
technically
both
import
and
from
statements
invoke
the
same
import
operation
the
from
form
simply
adds
an
extra
step
that
copies
all
the
names
in
the
module
into
the
importing
scope
it
essentially
collapses
one
module
s
namespace
into
another
again
the
net
effect
is
less
typing
for
us
and
that
s
it
modules
really
are
simple
to
use
to
give
you
a
better
understanding
of
what
really
happens
when
you
define
and
use
modules
though
let
s
move
on
to
look
at
some
of
their
properties
in
more
detail
in
python
the
from
statement
form
described
here
can
be
used
only
at
the
top
level
of
a
module
file
not
within
a
function
python
allows
it
to
be
used
within
a
function
but
issues
a
warning
it
s
extremely
rare
to
see
this
statement
used
inside
a
function
in
practice
when
present
it
makes
it
impossible
for
python
to
detect
variables
statically
before
the
function
runs
module
usage
imports
happen
only
once
one
of
the
most
common
questions
people
seem
to
ask
when
they
start
using
modules
is
why
won
t
my
imports
keep
working
they
often
report
that
the
first
import
works
fine
but
later
imports
during
an
interactive
session
or
program
run
seem
to
have
no
effect
in
fact
they
re
not
supposed
to
this
section
explains
why
modules
are
loaded
and
run
on
the
first
import
or
from
and
only
the
first
this
is
on
purpose
because
importing
is
an
expensive
operation
by
default
python
does
it
just
once
per
file
per
process
later
import
operations
simply
fetch
the
already
loaded
module
object
as
one
consequence
because
top
level
code
in
a
module
file
is
usually
executed
only
once
you
can
use
it
to
initialize
variables
consider
the
file
simple
py
for
example
print
hello
spam
initialize
variable
in
this
example
the
print
and
statements
run
the
first
time
the
module
is
imported
and
the
variable
spam
is
initialized
at
import
time
python
import
simple
hello
simple
spam
first
import
loads
and
runs
file
s
code
assignment
makes
an
attribute
second
and
later
imports
don
t
rerun
the
module
s
code
they
just
fetch
the
already
created
module
object
from
python
s
internal
modules
table
thus
the
variable
spam
is
not
reinitialized
simple
spam
import
simple
simple
spam
change
attribute
in
module
just
fetches
already
loaded
module
code
wasn
t
rerun
attribute
unchanged
of
course
sometimes
you
really
want
a
module
s
code
to
be
rerun
on
a
subsequent
import
we
ll
see
how
to
do
this
with
python
s
reload
function
later
in
this
chapter
import
and
from
are
assignments
just
like
def
import
and
from
are
executable
statements
not
compile
time
declarations
they
may
be
nested
in
if
tests
appear
in
function
defs
and
so
on
and
they
are
not
resolved
or
run
until
python
reaches
them
while
executing
your
program
in
other
words
imported
modules
and
names
are
not
available
until
their
associated
import
or
from
statements
run
also
like
def
import
and
from
are
implicit
assignments
import
assigns
an
entire
module
object
to
a
single
name
from
assigns
one
or
more
names
to
objects
of
the
same
names
in
another
module
chapter
module
coding
basics
all
the
things
we
ve
already
discussed
about
assignment
apply
to
module
access
too
for
instance
names
copied
with
a
from
become
references
to
shared
objects
as
with
function
arguments
reassigning
a
fetched
name
has
no
effect
on
the
module
from
which
it
was
copied
but
changing
a
fetched
mutable
object
can
change
it
in
the
module
from
which
it
was
imported
to
illustrate
consider
the
following
file
small
py
x
y
python
from
small
import
x
y
x
y
copy
two
names
out
changes
local
x
only
changes
shared
mutable
in
place
here
x
is
not
a
shared
mutable
object
but
y
is
the
name
y
in
the
importer
and
the
importee
reference
the
same
list
object
so
changing
it
from
one
place
changes
it
in
the
other
import
small
small
x
small
y
get
module
name
from
doesn
t
small
s
x
is
not
my
x
but
we
share
a
changed
mutable
for
a
graphical
picture
of
what
from
assignments
do
with
references
flip
back
to
figure
function
argument
passing
and
mentally
replace
caller
and
function
with
imported
and
importer
the
effect
is
the
same
except
that
here
we
re
dealing
with
names
in
modules
not
functions
assignment
works
the
same
everywhere
in
python
cross
file
name
changes
recall
from
the
preceding
example
that
the
assignment
to
x
in
the
interactive
session
changed
the
name
x
in
that
scope
only
not
the
x
in
the
file
there
is
no
link
from
a
name
copied
with
from
back
to
the
file
it
came
from
to
really
change
a
global
name
in
another
file
you
must
use
import
python
from
small
import
x
y
x
copy
two
names
out
changes
my
x
only
import
small
small
x
get
module
name
changes
x
in
other
module
this
phenomenon
was
introduced
in
chapter
because
changing
variables
in
other
modules
like
this
is
a
common
source
of
confusion
and
often
a
bad
design
choice
we
ll
revisit
this
technique
again
later
in
this
part
of
the
book
note
that
the
change
to
y
in
the
prior
session
is
different
it
changes
an
object
not
a
name
module
usage
import
and
from
equivalence
notice
in
the
prior
example
that
we
have
to
execute
an
import
statement
after
the
from
to
access
the
small
module
name
at
all
from
only
copies
names
from
one
module
to
another
it
does
not
assign
the
module
name
itself
at
least
conceptually
a
from
statement
like
this
one
from
module
import
name
name
copy
these
two
names
out
only
is
equivalent
to
this
statement
sequence
import
module
name
module
name
name
module
name
del
module
fetch
the
module
object
copy
names
out
by
assignment
get
rid
of
the
module
name
like
all
assignments
the
from
statement
creates
new
variables
in
the
importer
which
initially
refer
to
objects
of
the
same
names
in
the
imported
file
only
the
names
are
copied
out
though
not
the
module
itself
when
we
use
the
from
form
of
this
statement
from
module
import
the
equivalence
is
the
same
but
all
the
top
level
names
in
the
module
are
copied
over
to
the
importing
scope
this
way
notice
that
the
first
step
of
the
from
runs
a
normal
import
operation
because
of
this
the
from
always
imports
the
entire
module
into
memory
if
it
has
not
yet
been
imported
regardless
of
how
many
names
it
copies
out
of
the
file
there
is
no
way
to
load
just
part
of
a
module
file
e
g
just
one
function
but
because
modules
are
byte
code
in
python
instead
of
machine
code
the
performance
implications
are
generally
negligible
potential
pitfalls
of
the
from
statement
because
the
from
statement
makes
the
location
of
a
variable
more
implicit
and
obscure
name
is
less
meaningful
to
the
reader
than
module
name
some
python
users
recommend
using
import
instead
of
from
most
of
the
time
i
m
not
sure
this
advice
is
warranted
though
from
is
commonly
and
widely
used
without
too
many
dire
consequences
in
practice
in
realistic
programs
it
s
often
convenient
not
to
have
to
type
a
module
s
name
every
time
you
wish
to
use
one
of
its
tools
this
is
especially
true
for
large
modules
that
provide
many
attributes
the
standard
library
s
tkinter
gui
module
for
example
it
is
true
that
the
from
statement
has
the
potential
to
corrupt
namespaces
at
least
in
principle
if
you
use
it
to
import
variables
that
happen
to
have
the
same
names
as
existing
variables
in
your
scope
your
variables
will
be
silently
overwritten
this
problem
doesn
t
occur
with
the
simple
import
statement
because
you
must
always
go
through
a
module
s
name
to
get
to
its
contents
module
attr
will
not
clash
with
a
variable
named
attr
in
your
scope
as
long
as
you
understand
and
expect
that
this
can
happen
when
using
from
though
this
isn
t
a
major
concern
in
practice
especially
if
you
list
the
imported
names
explicitly
e
g
from
module
import
x
y
z
on
the
other
hand
the
from
statement
has
more
serious
issues
when
used
in
conjunction
with
the
reload
call
as
imported
names
might
reference
prior
versions
of
objects
chapter
module
coding
basics
moreover
the
from
module
import
form
really
can
corrupt
namespaces
and
make
names
difficult
to
understand
especially
when
applied
to
more
than
one
file
in
this
case
there
is
no
way
to
tell
which
module
a
name
came
from
short
of
searching
the
external
source
files
in
effect
the
from
form
collapses
one
namespace
into
another
and
so
defeats
the
namespace
partitioning
feature
of
modules
we
will
explore
these
issues
in
more
detail
in
the
section
module
gotchas
on
page
at
the
end
of
this
part
of
the
book
see
chapter
probably
the
best
real
world
advice
here
is
to
generally
prefer
import
to
from
for
simple
modules
to
explicitly
list
the
variables
you
want
in
most
from
statements
and
to
limit
the
from
form
to
just
one
import
per
file
that
way
any
undefined
names
can
be
assumed
to
live
in
the
module
referenced
with
the
from
some
care
is
required
when
using
the
from
statement
but
armed
with
a
little
knowledge
most
programmers
find
it
to
be
a
convenient
way
to
access
modules
when
import
is
required
the
only
time
you
really
must
use
import
instead
of
from
is
when
you
must
use
the
same
name
defined
in
two
different
modules
for
example
if
two
files
define
the
same
name
differently
m
py
def
func
do
something
n
py
def
func
do
something
else
and
you
must
use
both
versions
of
the
name
in
your
program
the
from
statement
will
fail
you
can
only
have
one
assignment
to
the
name
in
your
scope
o
py
from
m
import
func
from
n
import
func
func
this
overwites
the
one
we
got
from
m
calls
n
func
only
an
import
will
work
here
though
because
including
the
name
of
the
enclosing
module
makes
the
two
names
unique
o
py
import
m
n
m
func
n
func
get
the
whole
modules
not
their
names
we
can
call
both
names
now
the
module
names
make
them
unique
this
case
is
unusual
enough
that
you
re
unlikely
to
encounter
it
very
often
in
practice
if
you
do
though
import
allows
you
to
avoid
the
name
collision
module
usage
module
namespaces
modules
are
probably
best
understood
as
simply
packages
of
names
i
e
places
to
define
names
you
want
to
make
visible
to
the
rest
of
a
system
technically
modules
usually
correspond
to
files
and
python
creates
a
module
object
to
contain
all
the
names
assigned
in
a
module
file
but
in
simple
terms
modules
are
just
namespaces
places
where
names
are
created
and
the
names
that
live
in
a
module
are
called
its
attributes
we
ll
explore
how
all
this
works
in
this
section
files
generate
namespaces
so
how
do
files
morph
into
namespaces
the
short
story
is
that
every
name
that
is
assigned
a
value
at
the
top
level
of
a
module
file
i
e
not
nested
in
a
function
or
class
body
becomes
an
attribute
of
that
module
for
instance
given
an
assignment
statement
such
as
x
at
the
top
level
of
a
module
file
m
py
the
name
x
becomes
an
attribute
of
m
which
we
can
refer
to
from
outside
the
module
as
m
x
the
name
x
also
becomes
a
global
variable
to
other
code
inside
m
py
but
we
need
to
explain
the
notion
of
module
loading
and
scopes
a
bit
more
formally
to
understand
why
module
statements
run
on
the
first
import
the
first
time
a
module
is
imported
anywhere
in
a
system
python
creates
an
empty
module
object
and
executes
the
statements
in
the
module
file
one
after
another
from
the
top
of
the
file
to
the
bottom
top
level
assignments
create
module
attributes
during
an
import
statements
at
the
top
level
of
the
file
not
nested
in
a
def
or
class
that
assign
names
e
g
def
create
attributes
of
the
module
object
assigned
names
are
stored
in
the
module
s
namespace
module
namespaces
can
be
accessed
via
the
attribute
dict
or
dir
m
module
namespaces
created
by
imports
are
dictionaries
they
may
be
accessed
through
the
built
in
dict
attribute
associated
with
module
objects
and
may
be
inspected
with
the
dir
function
the
dir
function
is
roughly
equivalent
to
the
sorted
keys
list
of
an
object
s
dict
attribute
but
it
includes
inherited
names
for
classes
may
not
be
complete
and
is
prone
to
changing
from
release
to
release
modules
are
a
single
scope
local
is
global
as
we
saw
in
chapter
names
at
the
top
level
of
a
module
follow
the
same
reference
assignment
rules
as
names
in
a
function
but
the
local
and
global
scopes
are
the
same
more
formally
they
follow
the
legb
scope
rule
we
met
in
chapter
but
without
the
l
and
e
lookup
layers
but
in
modules
the
module
scope
becomes
an
attribute
dictionary
of
a
module
object
after
the
module
has
been
loaded
unlike
with
functions
where
the
local
namespace
exists
only
while
the
function
runs
a
module
file
s
scope
becomes
a
module
object
s
attribute
namespace
and
lives
on
after
the
import
chapter
module
coding
basics
here
s
a
demonstration
of
these
ideas
suppose
we
create
the
following
module
file
in
a
text
editor
and
call
it
module
py
print
starting
to
load
import
sys
name
def
func
pass
class
klass
pass
print
done
loading
the
first
time
this
module
is
imported
or
run
as
a
program
python
executes
its
statements
from
top
to
bottom
some
statements
create
names
in
the
module
s
namespace
as
a
side
effect
but
others
do
actual
work
while
the
import
is
going
on
for
instance
the
two
print
statements
in
this
file
execute
at
import
time
import
module
starting
to
load
done
loading
once
the
module
is
loaded
its
scope
becomes
an
attribute
namespace
in
the
module
object
we
get
back
from
import
we
can
then
access
attributes
in
this
namespace
by
qualifying
them
with
the
name
of
the
enclosing
module
module
sys
module
sys
built
in
module
name
module
func
function
func
at
x
d
bb
module
klass
class
module
klass
here
sys
name
func
and
klass
were
all
assigned
while
the
module
s
statements
were
being
run
so
they
are
attributes
after
the
import
we
ll
talk
about
classes
in
part
vi
but
notice
the
sys
attribute
import
statements
really
assign
module
objects
to
names
and
any
type
of
assignment
to
a
name
at
the
top
level
of
a
file
generates
a
module
attribute
internally
module
namespaces
are
stored
as
dictionary
objects
these
are
just
normal
dictionary
objects
with
the
usual
methods
we
can
access
a
module
s
namespace
dictionary
through
the
module
s
dict
attribute
remember
to
wrap
this
in
a
list
call
in
python
it
s
a
view
object
list
module
dict
keys
name
builtins
file
package
sys
klass
func
name
doc
module
namespaces
the
names
we
assigned
in
the
module
file
become
dictionary
keys
internally
so
most
of
the
names
here
reflect
top
level
assignments
in
our
file
however
python
also
adds
some
names
in
the
module
s
namespace
for
us
for
instance
file
gives
the
name
of
the
file
the
module
was
loaded
from
and
name
gives
its
name
as
known
to
importers
without
the
py
extension
and
directory
path
attribute
name
qualification
now
that
you
re
becoming
more
familiar
with
modules
we
should
look
at
the
notion
of
name
qualification
fetching
attributes
in
more
depth
in
python
you
can
access
the
attributes
of
any
object
that
has
attributes
using
the
qualification
syntax
object
attribute
qualification
is
really
an
expression
that
returns
the
value
assigned
to
an
attribute
name
associated
with
an
object
for
example
the
expression
module
sys
in
the
previous
example
fetches
the
value
assigned
to
sys
in
module
similarly
if
we
have
a
built
in
list
object
l
l
append
returns
the
append
method
object
associated
with
that
list
so
what
does
attribute
qualification
do
to
the
scope
rules
we
studied
in
chapter
nothing
really
it
s
an
independent
concept
when
you
use
qualification
to
access
names
you
give
python
an
explicit
object
from
which
to
fetch
the
specified
names
the
legb
rule
applies
only
to
bare
unqualified
names
here
are
the
rules
simple
variables
x
means
search
for
the
name
x
in
the
current
scopes
following
the
legb
rule
qualification
x
y
means
find
x
in
the
current
scopes
then
search
for
the
attribute
y
in
the
object
x
not
in
scopes
qualification
paths
x
y
z
means
look
up
the
name
y
in
the
object
x
then
look
up
z
in
the
object
x
y
generality
qualification
works
on
all
objects
with
attributes
modules
classes
c
extension
types
etc
in
part
vi
we
ll
see
that
qualification
means
a
bit
more
for
classes
it
s
also
the
place
where
something
called
inheritance
happens
but
in
general
the
rules
outlined
here
apply
to
all
names
in
python
imports
versus
scopes
as
we
ve
learned
it
is
never
possible
to
access
names
defined
in
another
module
file
without
first
importing
that
file
that
is
you
never
automatically
get
to
see
names
in
another
file
regardless
of
the
structure
of
imports
or
function
calls
in
your
program
a
variable
s
meaning
is
always
determined
by
the
locations
of
assignments
in
your
source
code
and
attributes
are
always
requested
of
an
object
explicitly
chapter
module
coding
basics
for
example
consider
the
following
two
simple
modules
the
first
moda
py
defines
a
variable
x
global
to
code
in
its
file
only
along
with
a
function
that
changes
the
global
x
in
this
file
x
def
f
global
x
x
my
x
global
to
this
file
only
change
this
file
s
x
cannot
see
names
in
other
modules
the
second
module
modb
py
defines
its
own
global
variable
x
and
imports
and
calls
the
function
in
the
first
module
x
my
x
global
to
this
file
only
import
moda
moda
f
print
x
moda
x
gain
access
to
names
in
moda
sets
moda
x
not
this
file
s
x
when
run
moda
f
changes
the
x
in
moda
not
the
x
in
modb
the
global
scope
for
moda
f
is
always
the
file
enclosing
it
regardless
of
which
module
it
is
ultimately
called
from
python
modb
py
in
other
words
import
operations
never
give
upward
visibility
to
code
in
imported
files
an
imported
file
cannot
see
names
in
the
importing
file
more
formally
functions
can
never
see
names
in
other
functions
unless
they
are
physically
enclosing
module
code
can
never
see
names
in
other
modules
unless
they
are
explicitly
imported
such
behavior
is
part
of
the
lexical
scoping
notion
in
python
the
scopes
surrounding
a
piece
of
code
are
completely
determined
by
the
code
s
physical
position
in
your
file
scopes
are
never
influenced
by
function
calls
or
module
imports
namespace
nesting
in
some
sense
although
imports
do
not
nest
namespaces
upward
they
do
nest
downward
using
attribute
qualification
paths
it
s
possible
to
descend
into
arbitrarily
nested
modules
and
access
their
attributes
for
example
consider
the
next
three
files
mod
py
defines
a
single
global
name
and
attribute
by
assignment
x
mod
py
in
turn
defines
its
own
x
then
imports
mod
and
uses
qualification
to
access
the
imported
module
s
attribute
some
languages
act
differently
and
provide
for
dynamic
scoping
where
scopes
really
may
depend
on
runtime
calls
this
tends
to
make
code
trickier
though
because
the
meaning
of
a
variable
can
differ
over
time
module
namespaces
x
import
mod
print
x
end
print
mod
x
my
global
x
mod
s
x
mod
py
also
defines
its
own
x
then
imports
mod
and
fetches
attributes
in
both
the
first
and
second
files
x
import
mod
print
x
end
print
mod
x
end
print
mod
mod
x
my
global
x
mod
s
x
nested
mod
s
x
really
when
mod
imports
mod
here
it
sets
up
a
two
level
namespace
nesting
by
using
the
path
of
names
mod
mod
x
it
can
descend
into
mod
which
is
nested
in
the
imported
mod
the
net
effect
is
that
mod
can
see
the
xs
in
all
three
files
and
hence
has
access
to
all
three
global
scopes
python
mod
py
the
reverse
however
is
not
true
mod
cannot
see
names
in
mod
and
mod
cannot
see
names
in
mod
this
example
may
be
easier
to
grasp
if
you
don
t
think
in
terms
of
namespaces
and
scopes
but
instead
focus
on
the
objects
involved
within
mod
mod
is
just
a
name
that
refers
to
an
object
with
attributes
some
of
which
may
refer
to
other
objects
with
attributes
import
is
an
assignment
for
paths
like
mod
mod
x
python
simply
evaluates
from
left
to
right
fetching
attributes
from
objects
along
the
way
note
that
mod
can
say
import
mod
and
then
mod
mod
x
but
it
cannot
say
import
mod
mod
this
syntax
invokes
something
called
package
directory
imports
described
in
the
next
chapter
package
imports
also
create
module
namespace
nesting
but
their
import
statements
are
taken
to
reflect
directory
trees
not
simple
import
chains
reloading
modules
as
we
ve
seen
a
module
s
code
is
run
only
once
per
process
by
default
to
force
a
module
s
code
to
be
reloaded
and
rerun
you
need
to
ask
python
to
do
so
explicitly
by
calling
the
reload
built
in
function
in
this
section
we
ll
explore
how
to
use
reloads
to
make
your
systems
more
dynamic
in
a
nutshell
imports
via
both
import
and
from
statements
load
and
run
a
module
s
code
only
the
first
time
the
module
is
imported
in
a
process
later
imports
use
the
already
loaded
module
object
without
reloading
or
rerunning
the
file
s
code
chapter
module
coding
basics
the
reload
function
forces
an
already
loaded
module
s
code
to
be
reloaded
and
rerun
assignments
in
the
file
s
new
code
change
the
existing
module
object
in
place
why
all
the
fuss
about
reloading
modules
the
reload
function
allows
parts
of
a
program
to
be
changed
without
stopping
the
whole
program
with
reload
therefore
the
effects
of
changes
in
components
can
be
observed
immediately
reloading
doesn
t
help
in
every
situation
but
where
it
does
it
makes
for
a
much
shorter
development
cycle
for
instance
imagine
a
database
program
that
must
connect
to
a
server
on
startup
because
program
changes
or
customizations
can
be
tested
immediately
after
reloads
you
need
to
connect
only
once
while
debugging
long
running
servers
can
update
themselves
this
way
too
because
python
is
interpreted
more
or
less
it
already
gets
rid
of
the
compile
link
steps
you
need
to
go
through
to
get
a
c
program
to
run
modules
are
loaded
dynamically
when
imported
by
a
running
program
reloading
offers
a
further
performance
advantage
by
allowing
you
to
also
change
parts
of
running
programs
without
stopping
note
that
reload
currently
only
works
on
modules
written
in
python
compiled
extension
modules
coded
in
a
language
such
as
c
can
be
dynamically
loaded
at
runtime
too
but
they
can
t
be
reloaded
version
skew
note
in
python
reload
is
available
as
a
built
in
function
in
python
it
has
been
moved
to
the
imp
standard
library
module
it
s
known
as
imp
reload
in
this
simply
means
that
an
extra
import
or
from
statement
is
required
to
load
this
tool
in
only
readers
using
can
ignore
these
imports
in
this
book
s
examples
or
use
them
anyhow
also
has
a
reload
in
its
imp
module
to
ease
migration
to
reloading
works
the
same
regardless
of
its
packaging
reload
basics
unlike
import
and
from
reload
is
a
function
in
python
not
a
statement
reload
is
passed
an
existing
module
object
not
a
name
reload
lives
in
a
module
in
python
and
must
be
imported
itself
because
reload
expects
an
object
a
module
must
have
been
previously
imported
successfully
before
you
can
reload
it
if
the
import
was
unsuccessful
due
to
a
syntax
or
other
error
you
may
need
to
repeat
it
before
you
can
reload
the
module
furthermore
the
syntax
of
import
statements
and
reload
calls
differs
reloads
require
parentheses
but
imports
do
not
reloading
looks
like
this
import
module
use
module
attributes
initial
import
now
go
change
the
module
file
reloading
modules
from
imp
import
reload
reload
module
use
module
attributes
get
reload
itself
in
get
updated
exports
the
typical
usage
pattern
is
that
you
import
a
module
then
change
its
source
code
in
a
text
editor
and
then
reload
it
when
you
call
reload
python
rereads
the
module
file
s
source
code
and
reruns
its
top
level
statements
perhaps
the
most
important
thing
to
know
about
reload
is
that
it
changes
a
module
object
in
place
it
does
not
delete
and
re
create
the
module
object
because
of
that
every
reference
to
a
module
object
anywhere
in
your
program
is
automatically
affected
by
a
reload
here
are
the
details
reload
runs
a
module
file
s
new
code
in
the
module
s
current
namespace
rerunning
a
module
file
s
code
overwrites
its
existing
namespace
rather
than
deleting
and
re
creating
it
top
level
assignments
in
the
file
replace
names
with
new
values
for
instance
rerunning
a
def
statement
replaces
the
prior
version
of
the
function
in
the
module
s
namespace
by
reassigning
the
function
name
reloads
impact
all
clients
that
use
import
to
fetch
modules
because
clients
that
use
import
qualify
to
fetch
attributes
they
ll
find
new
values
in
the
module
object
after
a
reload
reloads
impact
future
from
clients
only
clients
that
used
from
to
fetch
attributes
in
the
past
won
t
be
affected
by
a
reload
they
ll
still
have
references
to
the
old
objects
fetched
before
the
reload
reload
example
to
demonstrate
here
s
a
more
concrete
example
of
reload
in
action
in
the
following
we
ll
change
and
reload
a
module
file
without
stopping
the
interactive
python
session
reloads
are
used
in
many
other
scenarios
too
see
the
sidebar
why
you
will
care
module
reloads
on
page
but
we
ll
keep
things
simple
for
illustration
here
first
in
the
text
editor
of
your
choice
write
a
module
file
named
changer
py
with
the
following
contents
message
first
version
def
printer
print
message
this
module
creates
and
exports
two
names
one
bound
to
a
string
and
another
to
a
function
now
start
the
python
interpreter
import
the
module
and
call
the
function
it
exports
the
function
will
print
the
value
of
the
global
message
variable
python
import
changer
changer
printer
first
version
chapter
module
coding
basics
keeping
the
interpreter
active
now
edit
the
module
file
in
another
window
modify
changer
py
without
stopping
python
vi
changer
py
change
the
global
message
variable
as
well
as
the
printer
function
body
message
after
editing
def
printer
print
reloaded
message
then
return
to
the
python
window
and
reload
the
module
to
fetch
the
new
code
notice
in
the
following
interaction
that
importing
the
module
again
has
no
effect
we
get
the
original
message
even
though
the
file
s
been
changed
we
have
to
call
reload
in
order
to
get
the
new
version
back
to
the
python
interpreter
program
import
changer
changer
printer
first
version
from
imp
import
reload
reload
changer
module
changer
from
changer
py
changer
printer
reloaded
after
editing
no
effect
uses
loaded
module
forces
new
code
to
load
run
runs
the
new
version
now
notice
that
reload
actually
returns
the
module
object
for
us
its
result
is
usually
ignored
but
because
expression
results
are
printed
at
the
interactive
prompt
python
shows
a
default
module
name
representation
why
you
will
care
module
reloads
besides
allowing
you
to
reload
and
hence
rerun
modules
at
the
interactive
prompt
module
reloads
are
also
useful
in
larger
systems
especially
when
the
cost
of
restarting
the
entire
application
is
prohibitive
for
instance
systems
that
must
connect
to
servers
over
a
network
on
startup
are
prime
candidates
for
dynamic
reloads
they
re
also
useful
in
gui
work
a
widget
s
callback
action
can
be
changed
while
the
gui
remains
active
and
when
python
is
used
as
an
embedded
language
in
a
c
or
c
program
the
enclosing
program
can
request
a
reload
of
the
python
code
it
runs
without
having
to
stop
see
programming
python
for
more
on
reloading
gui
callbacks
and
embedded
python
code
more
generally
reloads
allow
programs
to
provide
highly
dynamic
interfaces
for
instance
python
is
often
used
as
a
customization
language
for
larger
systems
users
can
customize
products
by
coding
bits
of
python
code
onsite
without
having
to
recompile
the
entire
product
or
even
having
its
source
code
at
all
in
such
worlds
the
python
code
already
adds
a
dynamic
flavor
by
itself
reloading
modules
to
be
even
more
dynamic
though
such
systems
can
automatically
reload
the
python
customization
code
periodically
at
runtime
that
way
users
changes
are
picked
up
while
the
system
is
running
there
is
no
need
to
stop
and
restart
each
time
the
python
code
is
modified
not
all
systems
require
such
a
dynamic
approach
but
for
those
that
do
module
reloads
provide
an
easy
to
use
dynamic
customization
tool
chapter
summary
this
chapter
delved
into
the
basics
of
module
coding
tools
the
import
and
from
statements
and
the
reload
call
we
learned
how
the
from
statement
simply
adds
an
extra
step
that
copies
names
out
of
a
file
after
it
has
been
imported
and
how
reload
forces
a
file
to
be
imported
again
without
stopping
and
restarting
python
we
also
surveyed
namespace
concepts
saw
what
happens
when
imports
are
nested
explored
the
way
files
become
module
namespaces
and
learned
about
some
potential
pitfalls
of
the
from
statement
although
we
ve
already
seen
enough
to
handle
module
files
in
our
programs
the
next
chapter
extends
our
coverage
of
the
import
model
by
presenting
package
imports
a
way
for
our
import
statements
to
specify
part
of
the
directory
path
leading
to
the
desired
module
as
we
ll
see
package
imports
give
us
a
hierarchy
that
is
useful
in
larger
systems
and
allow
us
to
break
conflicts
between
same
named
modules
before
we
move
on
though
here
s
a
quick
quiz
on
the
concepts
presented
here
test
your
knowledge
quiz
how
do
you
make
a
module
how
is
the
from
statement
related
to
the
import
statement
how
is
the
reload
function
related
to
imports
when
must
you
use
import
instead
of
from
name
three
potential
pitfalls
of
the
from
statement
what
is
the
airspeed
velocity
of
an
unladen
swallow
test
your
knowledge
answers
to
create
a
module
you
just
write
a
text
file
containing
python
statements
every
source
code
file
is
automatically
a
module
and
there
is
no
syntax
for
declaring
one
import
operations
load
module
files
into
module
objects
in
memory
you
can
also
make
a
module
by
writing
code
in
an
external
language
like
c
or
java
but
such
extension
modules
are
beyond
the
scope
of
this
book
chapter
module
coding
basics
the
from
statement
imports
an
entire
module
like
the
import
statement
but
as
an
extra
step
it
also
copies
one
or
more
variables
from
the
imported
module
into
the
scope
where
the
from
appears
this
enables
you
to
use
the
imported
names
directly
name
instead
of
having
to
go
through
the
module
module
name
by
default
a
module
is
imported
only
once
per
process
the
reload
function
forces
a
module
to
be
imported
again
it
is
mostly
used
to
pick
up
new
versions
of
a
module
s
source
code
during
development
and
in
dynamic
customization
scenarios
you
must
use
import
instead
of
from
only
when
you
need
to
access
the
same
name
in
two
different
modules
because
you
ll
have
to
specify
the
names
of
the
enclosing
modules
the
two
names
will
be
unique
the
from
statement
can
obscure
the
meaning
of
a
variable
which
module
it
is
defined
in
can
have
problems
with
the
reload
call
names
may
reference
prior
versions
of
objects
and
can
corrupt
namespaces
it
might
silently
overwrite
names
you
are
using
in
your
scope
the
from
form
is
worse
in
most
regards
it
can
seriously
corrupt
namespaces
and
obscure
the
meaning
of
variables
so
it
is
probably
best
used
sparingly
what
do
you
mean
an
african
or
european
swallow
test
your
knowledge
answers
chapter
module
packages
so
far
when
we
ve
imported
modules
we
ve
been
loading
files
this
represents
typical
module
usage
and
it
s
probably
the
technique
you
ll
use
for
most
imports
you
ll
code
early
on
in
your
python
career
however
the
module
import
story
is
a
bit
richer
than
i
have
thus
far
implied
in
addition
to
a
module
name
an
import
can
name
a
directory
path
a
directory
of
python
code
is
said
to
be
a
package
so
such
imports
are
known
as
package
imports
in
effect
a
package
import
turns
a
directory
on
your
computer
into
another
python
namespace
with
attributes
corresponding
to
the
subdirectories
and
module
files
that
the
directory
contains
this
is
a
somewhat
advanced
feature
but
the
hierarchy
it
provides
turns
out
to
be
handy
for
organizing
the
files
in
a
large
system
and
tends
to
simplify
module
search
path
settings
as
we
ll
see
package
imports
are
also
sometimes
required
to
resolve
import
ambiguities
when
multiple
program
files
of
the
same
name
are
installed
on
a
single
machine
because
it
is
relevant
to
code
in
packages
only
we
ll
also
introduce
python
s
recent
relative
imports
model
and
syntax
here
as
we
ll
see
this
model
modifies
search
paths
and
extends
the
from
statement
for
imports
within
packages
package
import
basics
so
how
do
package
imports
work
in
the
place
where
you
have
been
naming
a
simple
file
in
your
import
statements
you
can
instead
list
a
path
of
names
separated
by
periods
import
dir
dir
mod
the
same
goes
for
from
statements
from
dir
dir
mod
import
x
the
dotted
path
in
these
statements
is
assumed
to
correspond
to
a
path
through
the
directory
hierarchy
on
your
machine
leading
to
the
file
mod
py
or
similar
the
extension
may
vary
that
is
the
preceding
statements
indicate
that
on
your
machine
there
is
a
directory
dir
which
has
a
subdirectory
dir
which
contains
a
module
file
mod
py
or
similar
furthermore
these
imports
imply
that
dir
resides
within
some
container
directory
dir
which
is
a
component
of
the
python
module
search
path
in
other
words
the
two
import
statements
imply
a
directory
structure
that
looks
something
like
this
shown
with
dos
backslash
separators
dir
dir
dir
mod
py
or
mod
pyc
mod
so
etc
the
container
directory
dir
needs
to
be
added
to
your
module
search
path
unless
it
s
the
home
directory
of
the
top
level
file
exactly
as
if
dir
were
a
simple
module
file
more
generally
the
leftmost
component
in
a
package
import
path
is
still
relative
to
a
directory
included
in
the
sys
path
module
search
path
list
we
met
in
chapter
from
there
down
though
the
import
statements
in
your
script
give
the
directory
paths
leading
to
the
modules
explicitly
packages
and
search
path
settings
if
you
use
this
feature
keep
in
mind
that
the
directory
paths
in
your
import
statements
can
only
be
variables
separated
by
periods
you
cannot
use
any
platform
specific
path
syntax
in
your
import
statements
such
as
c
dir
my
documents
dir
or
dir
these
do
not
work
syntactically
instead
use
platform
specific
syntax
in
your
module
search
path
settings
to
name
the
container
directories
for
instance
in
the
prior
example
dir
the
directory
name
you
add
to
your
module
search
path
can
be
an
arbitrarily
long
and
platform
specific
directory
path
leading
up
to
dir
instead
of
using
an
invalid
statement
like
this
import
c
mycode
dir
dir
mod
error
illegal
syntax
add
c
mycode
to
your
pythonpath
variable
or
a
pth
file
assuming
it
is
not
the
program
s
home
directory
in
which
case
this
step
is
not
necessary
and
say
this
in
your
script
import
dir
dir
mod
in
effect
entries
on
the
module
search
path
provide
platform
specific
directory
path
prefixes
which
lead
to
the
leftmost
names
in
import
statements
import
statements
provide
directory
path
tails
in
a
platform
neutral
fashion
the
dot
path
syntax
was
chosen
partly
for
platform
neutrality
but
also
because
paths
in
import
statements
become
real
nested
object
paths
this
syntax
also
means
that
you
get
odd
error
messages
if
you
forget
to
omit
the
py
in
your
import
statements
for
example
import
mod
py
is
assumed
to
be
a
directory
path
import
it
loads
mod
py
then
tries
to
load
a
mod
py
py
and
ultimately
issues
a
potentially
confusing
no
module
named
py
error
message
chapter
module
packages
package
init
py
files
if
you
choose
to
use
package
imports
there
is
one
more
constraint
you
must
follow
each
directory
named
within
the
path
of
a
package
import
statement
must
contain
a
file
named
init
py
or
your
package
imports
will
fail
that
is
in
the
example
we
ve
been
using
both
dir
and
dir
must
contain
a
file
called
init
py
the
container
directory
dir
does
not
require
such
a
file
because
it
s
not
listed
in
the
import
statement
itself
more
formally
for
a
directory
structure
such
as
this
dir
dir
dir
mod
py
and
an
import
statement
of
the
form
import
dir
dir
mod
the
following
rules
apply
dir
and
dir
both
must
contain
an
init
py
file
dir
the
container
does
not
require
an
init
py
file
this
file
will
simply
be
ignored
if
present
dir
not
dir
dir
must
be
listed
on
the
module
search
path
i
e
it
must
be
the
home
directory
or
be
listed
in
your
pythonpath
etc
the
net
effect
is
that
this
example
s
directory
structure
should
be
as
follows
with
indentation
designating
directory
nesting
dir
dir
init
py
dir
init
py
mod
py
container
on
module
search
path
the
init
py
files
can
contain
python
code
just
like
normal
module
files
they
are
partly
present
as
a
declaration
to
python
however
and
can
be
completely
empty
as
declarations
these
files
serve
to
prevent
directories
with
common
names
from
unintentionally
hiding
true
modules
that
appear
later
on
the
module
search
path
without
this
safeguard
python
might
pick
a
directory
that
has
nothing
to
do
with
your
code
just
because
it
appears
in
an
earlier
directory
on
the
search
path
more
generally
the
init
py
file
serves
as
a
hook
for
package
initialization
time
actions
generates
a
module
namespace
for
a
directory
and
implements
the
behavior
of
from
i
e
from
import
statements
when
used
with
directory
imports
package
initialization
the
first
time
python
imports
through
a
directory
it
automatically
runs
all
the
code
in
the
directory
s
init
py
file
because
of
that
these
files
are
a
natural
place
to
put
code
to
initialize
the
state
required
by
files
in
a
package
for
instance
a
package
might
use
its
initialization
file
to
create
required
data
files
open
connections
to
package
import
basics
databases
and
so
on
typically
init
py
files
are
not
meant
to
be
useful
if
executed
directly
they
are
run
automatically
when
a
package
is
first
accessed
module
namespace
initialization
in
the
package
import
model
the
directory
paths
in
your
script
become
real
nested
object
paths
after
an
import
for
instance
in
the
preceding
example
after
the
import
the
expression
dir
dir
works
and
returns
a
module
object
whose
namespace
contains
all
the
names
assigned
by
dir
s
init
py
file
such
files
provide
a
namespace
for
module
objects
created
for
directories
which
have
no
real
associated
module
files
from
statement
behavior
as
an
advanced
feature
you
can
use
all
lists
in
init
py
files
to
define
what
is
exported
when
a
directory
is
imported
with
the
from
statement
form
in
an
init
py
file
the
all
list
is
taken
to
be
the
list
of
submodule
names
that
should
be
imported
when
from
is
used
on
the
package
directory
name
if
all
is
not
set
the
from
statement
does
not
automatically
load
submodules
nested
in
the
directory
instead
it
loads
just
names
defined
by
assignments
in
the
directory
s
init
py
file
including
any
submodules
explicitly
imported
by
code
in
this
file
for
instance
the
statement
from
submodule
import
x
in
a
directory
s
init
py
makes
the
name
x
available
in
that
directory
s
namespace
we
ll
see
additional
roles
for
all
in
chapter
you
can
also
simply
leave
these
files
empty
if
their
roles
are
beyond
your
needs
and
frankly
they
are
often
empty
in
practice
they
must
exist
though
for
your
directory
imports
to
work
at
all
don
t
confuse
package
init
py
files
with
the
class
init
constructor
methods
we
ll
meet
in
the
next
part
of
the
book
the
former
are
files
of
code
run
when
imports
first
step
through
a
package
directory
while
the
latter
are
called
when
an
instance
is
created
both
have
initialization
roles
but
they
are
otherwise
very
different
package
import
example
let
s
actually
code
the
example
we
ve
been
talking
about
to
show
how
initialization
files
and
paths
come
into
play
the
following
three
files
are
coded
in
a
directory
dir
and
its
subdirectory
dir
comments
give
the
path
names
of
these
files
dir
init
py
print
dir
init
x
dir
dir
init
py
print
dir
init
y
chapter
module
packages
dir
dir
mod
py
print
in
mod
py
z
here
dir
will
be
either
a
subdirectory
of
the
one
we
re
working
in
i
e
the
home
directory
or
a
subdirectory
of
a
directory
that
is
listed
on
the
module
search
path
technically
on
sys
path
either
way
dir
s
container
does
not
need
an
init
py
file
import
statements
run
each
directory
s
initialization
file
the
first
time
that
directory
is
traversed
as
python
descends
the
path
print
statements
are
included
here
to
trace
their
execution
as
with
module
files
an
already
imported
directory
may
be
passed
to
reload
to
force
reexecution
of
that
single
item
as
shown
here
reload
accepts
a
dotted
pathname
to
reload
nested
directories
and
files
python
import
dir
dir
mod
first
imports
run
init
files
dir
init
dir
init
in
mod
py
import
dir
dir
mod
later
imports
do
not
from
imp
import
reload
needed
in
reload
dir
dir
init
module
dir
from
dir
init
pyc
reload
dir
dir
dir
init
module
dir
dir
from
dir
dir
init
pyc
once
imported
the
path
in
your
import
statement
becomes
a
nested
object
path
in
your
script
here
mod
is
an
object
nested
in
the
object
dir
which
in
turn
is
nested
in
the
object
dir
dir
module
dir
from
dir
init
pyc
dir
dir
module
dir
dir
from
dir
dir
init
pyc
dir
dir
mod
module
dir
dir
mod
from
dir
dir
mod
pyc
in
fact
each
directory
name
in
the
path
becomes
a
variable
assigned
to
a
module
object
whose
namespace
is
initialized
by
all
the
assignments
in
that
directory
s
init
py
file
dir
x
refers
to
the
variable
x
assigned
in
dir
init
py
much
as
mod
z
refers
to
the
variable
z
assigned
in
mod
py
dir
x
dir
dir
y
dir
dir
mod
z
package
import
example
from
versus
import
with
packages
import
statements
can
be
somewhat
inconvenient
to
use
with
packages
because
you
may
have
to
retype
the
paths
frequently
in
your
program
in
the
prior
section
s
example
for
instance
you
must
retype
and
rerun
the
full
path
from
dir
each
time
you
want
to
reach
z
if
you
try
to
access
dir
or
mod
directly
you
ll
get
an
error
dir
mod
nameerror
name
dir
is
not
defined
mod
z
nameerror
name
mod
is
not
defined
it
s
often
more
convenient
therefore
to
use
the
from
statement
with
packages
to
avoid
retyping
the
paths
at
each
access
perhaps
more
importantly
if
you
ever
restructure
your
directory
tree
the
from
statement
requires
just
one
path
update
in
your
code
whereas
imports
may
require
many
the
import
as
extension
discussed
formally
in
the
next
chapter
can
also
help
here
by
providing
a
shorter
synonym
for
the
full
path
python
from
dir
dir
import
mod
dir
init
dir
init
in
mod
py
mod
z
from
dir
dir
mod
import
z
z
import
dir
dir
mod
as
mod
mod
z
code
path
here
only
don
t
repeat
path
use
shorter
name
see
chapter
why
use
package
imports
if
you
re
new
to
python
make
sure
that
you
ve
mastered
simple
modules
before
stepping
up
to
packages
as
they
are
a
somewhat
advanced
feature
they
do
serve
useful
roles
though
especially
in
larger
programs
they
make
imports
more
informative
serve
as
an
organizational
tool
simplify
your
module
search
path
and
can
resolve
ambiguities
first
of
all
because
package
imports
give
some
directory
information
in
program
files
they
both
make
it
easier
to
locate
your
files
and
serve
as
an
organizational
tool
without
package
paths
you
must
often
resort
to
consulting
the
module
search
path
to
find
files
moreover
if
you
organize
your
files
into
subdirectories
for
functional
areas
package
imports
make
it
more
obvious
what
role
a
module
plays
and
so
make
your
code
more
readable
for
example
a
normal
import
of
a
file
in
a
directory
somewhere
on
the
module
search
path
like
this
import
utilities
chapter
module
packages
offers
much
less
information
than
an
import
that
includes
the
path
import
database
client
utilities
package
imports
can
also
greatly
simplify
your
pythonpath
and
pth
file
search
path
settings
in
fact
if
you
use
explicit
package
imports
for
all
your
cross
directory
imports
and
you
make
those
package
imports
relative
to
a
common
root
directory
where
all
your
python
code
is
stored
you
really
only
need
a
single
entry
on
your
search
path
the
common
root
finally
package
imports
serve
to
resolve
ambiguities
by
making
explicit
exactly
which
files
you
want
to
import
the
next
section
explores
this
role
in
more
detail
a
tale
of
three
systems
the
only
time
package
imports
are
actually
required
is
to
resolve
ambiguities
that
may
arise
when
multiple
programs
with
same
named
files
are
installed
on
a
single
machine
this
is
something
of
an
install
issue
but
it
can
also
become
a
concern
in
general
practice
let
s
turn
to
a
hypothetical
scenario
to
illustrate
suppose
that
a
programmer
develops
a
python
program
that
contains
a
file
called
utilities
py
for
common
utility
code
and
a
top
level
file
named
main
py
that
users
launch
to
start
the
program
all
over
this
program
its
files
say
import
utilities
to
load
and
use
the
common
code
when
the
program
is
shipped
it
arrives
as
a
single
tar
or
zip
file
containing
all
the
program
s
files
and
when
it
is
installed
it
unpacks
all
its
files
into
a
single
directory
named
system
on
the
target
machine
system
utilities
py
main
py
other
py
common
utility
functions
classes
launch
this
to
start
the
program
import
utilities
to
load
my
tools
now
suppose
that
a
second
programmer
develops
a
different
program
with
files
also
called
utilities
py
and
main
py
and
again
uses
import
utilities
throughout
the
program
to
load
the
common
code
file
when
this
second
system
is
fetched
and
installed
on
the
same
computer
as
the
first
system
its
files
will
unpack
into
a
new
directory
called
system
somewhere
on
the
receiving
machine
ensuring
that
they
do
not
overwrite
same
named
files
from
the
first
system
system
utilities
py
main
py
other
py
common
utilities
launch
this
to
run
imports
utilities
so
far
there
s
no
problem
both
systems
can
coexist
and
run
on
the
same
machine
in
fact
you
won
t
even
need
to
configure
the
module
search
path
to
use
these
programs
on
your
computer
because
python
always
searches
the
home
directory
first
that
is
the
directory
containing
the
top
level
file
imports
in
either
system
s
files
will
automatically
see
all
the
files
in
that
system
s
directory
for
instance
if
you
click
on
system
main
py
all
imports
will
search
system
first
similarly
if
you
launch
why
use
package
imports
system
main
py
system
will
be
searched
first
instead
remember
module
search
path
settings
are
only
needed
to
import
across
directory
boundaries
however
suppose
that
after
you
ve
installed
these
two
programs
on
your
machine
you
decide
that
you
d
like
to
use
some
of
the
code
in
each
of
the
utilities
py
files
in
a
system
of
your
own
it
s
common
utility
code
after
all
and
python
code
by
nature
wants
to
be
reused
in
this
case
you
want
to
be
able
to
say
the
following
from
code
that
you
re
writing
in
a
third
directory
to
load
one
of
the
two
files
import
utilities
utilities
func
spam
now
the
problem
starts
to
materialize
to
make
this
work
at
all
you
ll
have
to
set
the
module
search
path
to
include
the
directories
containing
the
utilities
py
files
but
which
directory
do
you
put
first
in
the
path
system
or
system
the
problem
is
the
linear
nature
of
the
search
path
it
is
always
scanned
from
left
to
right
so
no
matter
how
long
you
ponder
this
dilemma
you
will
always
get
utilities
py
from
the
directory
listed
first
leftmost
on
the
search
path
as
is
you
ll
never
be
able
to
import
it
from
the
other
directory
at
all
you
could
try
changing
sys
path
within
your
script
before
each
import
operation
but
that
s
both
extra
work
and
highly
error
prone
by
default
you
re
stuck
this
is
the
issue
that
packages
actually
fix
rather
than
installing
programs
as
flat
lists
of
files
in
standalone
directories
you
can
package
and
install
them
as
subdirectories
under
a
common
root
for
instance
you
might
organize
all
the
code
in
this
example
as
an
install
hierarchy
that
looks
like
this
root
system
init
py
utilities
py
main
py
other
py
system
init
py
utilities
py
main
py
other
py
system
init
py
myfile
py
here
or
elsewhere
your
new
code
here
now
add
just
the
common
root
directory
to
your
search
path
if
your
code
s
imports
are
all
relative
to
this
common
root
you
can
import
either
system
s
utility
file
with
a
package
import
the
enclosing
directory
name
makes
the
path
and
hence
the
module
reference
unique
in
fact
you
can
import
both
utility
files
in
the
same
module
as
long
as
you
use
an
import
statement
and
repeat
the
full
path
each
time
you
reference
the
utility
modules
chapter
module
packages
import
system
utilities
import
system
utilities
system
utilities
function
spam
system
utilities
function
eggs
the
names
of
the
enclosing
directories
here
make
the
module
references
unique
note
that
you
have
to
use
import
instead
of
from
with
packages
only
if
you
need
to
access
the
same
attribute
in
two
or
more
paths
if
the
name
of
the
called
function
here
was
different
in
each
path
from
statements
could
be
used
to
avoid
repeating
the
full
package
path
whenever
you
call
one
of
the
functions
as
described
earlier
also
notice
in
the
install
hierarchy
shown
earlier
that
init
py
files
were
added
to
the
system
and
system
directories
to
make
this
work
but
not
to
the
root
directory
only
directories
listed
within
import
statements
in
your
code
require
these
files
as
you
ll
recall
they
are
run
automatically
the
first
time
the
python
process
imports
through
a
package
directory
technically
in
this
case
the
system
directory
doesn
t
have
to
be
under
root
just
the
packages
of
code
from
which
you
will
import
however
because
you
never
know
when
your
own
modules
might
be
useful
in
other
programs
you
might
as
well
place
them
under
the
common
root
directory
as
well
to
avoid
similar
name
collision
problems
in
the
future
finally
notice
that
both
of
the
two
original
systems
imports
will
keep
working
unchanged
because
their
home
directories
are
searched
first
the
addition
of
the
common
root
on
the
search
path
is
irrelevant
to
code
in
system
and
system
they
can
keep
saying
just
import
utilities
and
expect
to
find
their
own
files
moreover
if
you
re
careful
to
unpack
all
your
python
systems
under
a
common
root
like
this
path
configuration
becomes
simple
you
ll
only
need
to
add
the
common
root
directory
once
package
relative
imports
the
coverage
of
package
imports
so
far
has
focused
mostly
on
importing
package
files
from
outside
the
package
within
the
package
itself
imports
of
package
files
can
use
the
same
path
syntax
as
outside
imports
but
they
can
also
make
use
of
special
intrapackage
search
rules
to
simplify
import
statements
that
is
rather
than
listing
package
import
paths
imports
within
the
package
can
be
relative
to
the
package
the
way
this
works
is
version
dependent
today
python
implicitly
searches
package
directories
first
on
imports
while
requires
explicit
relative
import
syntax
this
change
can
enhance
code
readability
by
making
same
package
imports
more
obvious
if
you
re
starting
out
in
python
with
version
your
focus
in
this
section
will
likely
be
on
its
new
import
syntax
if
you
ve
used
other
python
packages
in
the
past
though
you
ll
probably
also
be
interested
in
how
the
model
differs
package
relative
imports
changes
in
python
the
way
import
operations
in
packages
work
has
changed
slightly
in
python
this
change
applies
only
to
imports
within
files
located
in
the
package
directories
we
ve
been
studying
in
this
chapter
imports
in
other
files
work
as
before
for
imports
in
packages
though
python
introduces
two
changes
it
modifies
the
module
import
search
path
semantics
to
skip
the
package
s
own
directory
by
default
imports
check
only
other
components
of
the
search
path
these
are
known
as
absolute
imports
it
extends
the
syntax
of
from
statements
to
allow
them
to
explicitly
request
that
imports
search
the
package
s
directory
only
this
is
known
as
relative
import
syntax
these
changes
are
fully
present
in
python
the
new
from
statement
relative
syntax
is
also
available
in
python
but
the
default
search
path
change
must
be
enabled
as
an
option
it
s
currently
scheduled
to
be
added
in
the
release
this
change
is
being
phased
in
this
way
because
the
search
path
portion
is
not
backward
compatible
with
earlier
pythons
the
impact
of
this
change
is
that
in
and
optionally
in
you
must
generally
use
special
from
syntax
to
import
modules
located
in
the
same
package
as
the
importer
unless
you
spell
out
a
complete
path
from
a
package
root
without
this
syntax
your
package
is
not
automatically
searched
relative
import
basics
in
python
and
from
statements
can
now
use
leading
dots
to
specify
that
they
require
modules
located
within
the
same
package
known
as
package
relative
imports
instead
of
modules
located
elsewhere
on
the
module
import
search
path
called
absolute
imports
that
is
in
both
python
and
you
can
use
leading
dots
in
from
statements
to
indicate
that
imports
should
be
relative
to
the
containing
package
such
imports
will
search
for
modules
inside
the
package
only
and
will
not
look
for
same
named
modules
located
elsewhere
on
the
import
search
path
sys
path
the
net
effect
is
that
package
modules
override
outside
modules
in
python
normal
imports
in
a
package
s
code
without
leading
dots
currently
default
to
a
relative
then
absolute
search
path
order
that
is
they
search
the
package
s
own
directory
first
however
in
python
imports
within
a
package
are
absolute
by
default
in
the
absence
of
any
special
dot
syntax
imports
skip
the
containing
package
itself
and
look
elsewhere
on
the
sys
path
search
path
yes
there
will
be
a
release
and
possibly
and
later
releases
in
parallel
with
new
releases
in
the
x
line
as
described
in
the
preface
both
the
python
and
python
lines
are
expected
to
be
fully
supported
for
years
to
come
to
accommodate
the
large
existing
python
user
and
code
bases
chapter
module
packages
for
example
in
both
python
and
a
statement
of
the
form
relative
to
this
package
from
import
spam
instructs
python
to
import
a
module
named
spam
located
in
the
same
package
directory
as
the
file
in
which
this
statement
appears
similarly
this
statement
from
spam
import
name
means
from
a
module
named
spam
located
in
the
same
package
as
the
file
that
contains
this
statement
import
the
variable
name
the
behavior
of
a
statement
without
the
leading
dot
depends
on
which
version
of
python
you
use
in
such
an
import
will
still
default
to
the
current
relative
then
absolute
search
path
order
i
e
searching
the
package
s
directory
first
unless
a
statement
of
the
following
form
is
included
in
the
importing
file
from
future
import
absolute
import
required
until
if
present
this
statement
enables
the
python
absolute
by
default
default
search
path
change
described
in
the
next
paragraph
in
an
import
without
a
leading
dot
always
causes
python
to
skip
the
relative
components
of
the
module
import
search
path
and
look
instead
in
the
absolute
directories
that
sys
path
contains
for
instance
in
s
model
a
statement
of
the
following
form
will
always
find
a
string
module
somewhere
on
sys
path
instead
of
a
module
of
the
same
name
in
the
package
import
string
skip
this
package
s
version
without
the
from
future
statement
in
if
there
s
a
string
module
in
the
package
it
will
be
imported
instead
to
get
the
same
behavior
in
and
in
when
the
absolute
import
change
is
enabled
run
a
statement
of
the
following
form
to
force
a
relative
import
from
import
string
searches
this
package
only
this
works
in
both
python
and
today
the
only
difference
in
the
model
is
that
it
is
required
in
order
to
load
a
module
that
is
located
in
the
same
package
directory
as
the
file
in
which
this
appears
when
the
module
is
given
with
a
simple
name
note
that
leading
dots
can
be
used
to
force
relative
imports
only
with
the
from
statement
not
with
the
import
statement
in
python
the
import
modname
statement
is
always
absolute
skipping
the
containing
package
s
directory
in
this
statement
form
still
performs
relative
imports
today
i
e
the
package
s
directory
is
searched
first
but
these
will
become
absolute
in
python
too
from
statements
without
leading
dots
behave
the
same
as
import
statements
absolute
in
skipping
the
package
directory
and
relative
then
absolute
in
searching
the
package
directory
first
other
dot
based
relative
reference
patterns
are
possible
too
within
a
module
file
located
in
a
package
directory
named
mypkg
the
following
alternative
import
forms
work
as
described
package
relative
imports
from
string
import
name
name
from
import
string
from
import
string
imports
names
from
mypkg
string
imports
mypkg
string
imports
string
sibling
of
mypkg
to
understand
these
latter
forms
better
we
need
to
understand
the
rationale
behind
this
change
why
relative
imports
this
feature
is
designed
to
allow
scripts
to
resolve
ambiguities
that
can
arise
when
a
same
named
file
appears
in
multiple
places
on
the
module
search
path
consider
the
following
package
directory
mypkg
init
py
main
py
string
py
this
defines
a
package
named
mypkg
containing
modules
named
mypkg
main
and
mypkg
string
now
suppose
that
the
main
module
tries
to
import
a
module
named
string
in
python
and
earlier
python
will
first
look
in
the
mypkg
directory
to
perform
a
relative
import
it
will
find
and
import
the
string
py
file
located
there
assigning
it
to
the
name
string
in
the
mypkg
main
module
s
namespace
it
could
be
though
that
the
intent
of
this
import
was
to
load
the
python
standard
library
s
string
module
instead
unfortunately
in
these
versions
of
python
there
s
no
straightforward
way
to
ignore
mypkg
string
and
look
for
the
standard
library
s
string
module
located
on
the
module
search
path
moreover
we
cannot
resolve
this
with
package
import
paths
because
we
cannot
depend
on
any
extra
package
directory
structure
above
the
standard
library
being
present
on
every
machine
in
other
words
imports
in
packages
can
be
ambiguous
within
a
package
it
s
not
clear
whether
an
import
spam
statement
refers
to
a
module
within
or
outside
the
package
more
accurately
a
local
module
or
package
can
hide
another
hanging
directly
off
of
sys
path
whether
intentionally
or
not
in
practice
python
users
can
avoid
reusing
the
names
of
standard
library
modules
they
need
for
modules
of
their
own
if
you
need
the
standard
string
don
t
name
a
new
module
string
but
this
doesn
t
help
if
a
package
accidentally
hides
a
standard
module
moreover
python
might
add
a
new
standard
library
module
in
the
future
that
has
the
same
name
as
a
module
of
your
own
code
that
relies
on
relative
imports
is
also
less
easy
to
understand
because
the
reader
may
be
confused
about
which
module
is
intended
to
be
used
it
s
better
if
the
resolution
can
be
made
explicit
in
code
the
relative
imports
solution
in
to
address
this
dilemma
imports
run
within
packages
have
changed
in
python
and
as
an
option
in
to
be
absolute
under
this
model
an
import
statement
of
the
chapter
module
packages
following
form
in
our
example
file
mypkg
main
py
will
always
find
a
string
outside
the
package
via
an
absolute
import
search
of
sys
path
import
string
imports
string
outside
package
a
from
import
without
leading
dot
syntax
is
considered
absolute
as
well
from
string
import
name
imports
name
from
string
outside
package
if
you
really
want
to
import
a
module
from
your
package
without
giving
its
full
path
from
the
package
root
though
relative
imports
are
still
possible
by
using
the
dot
syntax
in
the
from
statement
from
import
string
imports
mypkg
string
relative
this
form
imports
the
string
module
relative
to
the
current
package
only
and
is
the
relative
equivalent
to
the
prior
import
example
s
absolute
form
when
this
special
relative
syntax
is
used
the
package
s
directory
is
the
only
directory
searched
we
can
also
copy
specific
names
from
a
module
with
relative
syntax
from
string
import
name
name
imports
names
from
mypkg
string
this
statement
again
refers
to
the
string
module
relative
to
the
current
package
if
this
code
appears
in
our
mypkg
main
module
for
example
it
will
import
name
and
name
from
mypkg
string
in
effect
the
in
a
relative
import
is
taken
to
stand
for
the
package
directory
containing
the
file
in
which
the
import
appears
an
additional
leading
dot
performs
the
relative
import
starting
from
the
parent
of
the
current
package
for
example
this
statement
from
import
spam
imports
a
sibling
of
mypkg
will
load
a
sibling
of
mypkg
i
e
the
spam
module
located
in
the
package
s
own
container
directory
next
to
mypkg
more
generally
code
located
in
some
module
a
b
c
can
do
any
of
these
from
import
d
from
import
e
imports
a
b
d
means
a
b
imports
a
e
means
a
from
d
import
x
from
e
import
x
imports
a
b
d
x
means
a
b
imports
a
e
x
means
a
relative
imports
versus
absolute
package
paths
alternatively
a
file
can
sometimes
name
its
own
package
explicitly
in
an
absolute
import
statement
for
example
in
the
following
mypkg
will
be
found
in
an
absolute
directory
on
sys
path
from
mypkg
import
string
imports
mypkg
string
absolute
however
this
relies
on
both
the
configuration
and
the
order
of
the
module
search
path
settings
while
relative
import
dot
syntax
does
not
in
fact
this
form
requires
that
the
directory
immediately
containing
mypkg
be
included
in
the
module
search
path
in
package
relative
imports
general
absolute
import
statements
must
list
all
the
directories
below
the
package
s
root
entry
in
sys
path
when
naming
packages
explicitly
like
this
from
system
section
mypkg
import
string
system
container
on
sys
path
only
in
large
or
deep
packages
that
could
be
much
more
work
than
a
dot
from
import
string
relative
import
syntax
with
this
latter
form
the
containing
package
is
searched
automatically
regardless
of
the
search
path
settings
the
scope
of
relative
imports
relative
imports
can
seem
a
bit
perplexing
on
first
encounter
but
it
helps
if
you
remember
a
few
key
points
about
them
relative
imports
apply
to
imports
within
packages
only
keep
in
mind
that
this
feature
s
module
search
path
change
applies
only
to
import
statements
within
module
files
located
in
a
package
normal
imports
coded
outside
package
files
still
work
exactly
as
described
earlier
automatically
searching
the
directory
containing
the
top
level
script
first
relative
imports
apply
to
the
from
statement
only
also
remember
that
this
feature
s
new
syntax
applies
only
to
from
statements
not
import
statements
it
s
detected
by
the
fact
that
the
module
name
in
a
from
begins
with
one
or
more
dots
periods
module
names
that
contain
dots
but
don
t
have
a
leading
dot
are
package
imports
not
relative
imports
the
terminology
is
ambiguous
frankly
the
terminology
used
to
describe
this
feature
is
probably
more
confusing
than
it
needs
to
be
really
all
imports
are
relative
to
something
outside
a
package
imports
are
still
relative
to
directories
listed
on
the
sys
path
module
search
path
as
we
learned
in
chapter
this
path
includes
the
program
s
container
directory
pythonpath
settings
path
file
settings
and
standard
libraries
when
working
interactively
the
program
container
directory
is
simply
the
current
working
directory
for
imports
made
inside
packages
augments
this
behavior
by
searching
the
package
itself
first
in
the
model
all
that
really
changes
is
that
normal
absolute
import
syntax
skips
the
package
directory
but
special
relative
import
syntax
causes
it
to
be
searched
first
and
only
when
we
talk
about
imports
as
being
absolute
what
we
really
mean
is
that
they
are
relative
to
the
directories
on
sys
path
but
not
the
package
itself
conversely
when
we
speak
of
relative
imports
we
mean
they
are
relative
to
the
package
directory
only
some
sys
path
entries
could
of
course
be
absolute
or
relative
paths
too
and
i
could
probably
make
up
something
more
confusing
but
it
would
be
a
stretch
chapter
module
packages
in
other
words
package
relative
imports
in
really
just
boil
down
to
a
removal
of
s
special
search
path
behavior
for
packages
along
with
the
addition
of
special
from
syntax
to
explicitly
request
relative
behavior
if
you
wrote
your
package
imports
in
the
past
to
not
depend
on
s
special
implicit
relative
lookup
e
g
by
always
spelling
out
full
paths
from
a
package
root
this
change
is
largely
a
moot
point
if
you
didn
t
you
ll
need
to
update
your
package
files
to
use
the
new
from
syntax
for
local
package
files
module
lookup
rules
summary
with
packages
and
relative
imports
the
module
search
story
in
python
in
its
entirety
can
be
summarized
as
follows
simple
module
names
e
g
a
are
looked
up
by
searching
each
directory
on
the
sys
path
list
from
left
to
right
this
list
is
constructed
from
both
system
defaults
and
user
configurable
settings
packages
are
simply
directories
of
python
modules
with
a
special
init
py
file
which
enables
a
b
c
directory
path
syntax
in
imports
in
an
import
of
a
b
c
for
example
the
directory
named
a
is
located
relative
to
the
normal
module
import
search
of
sys
path
b
is
another
package
subdirectory
within
a
and
c
is
a
module
or
other
importable
item
within
b
within
a
package
s
files
normal
import
statements
use
the
same
sys
path
search
rule
as
imports
elsewhere
imports
in
packages
using
from
statements
and
leading
dots
however
are
relative
to
the
package
that
is
only
the
package
directory
is
checked
and
the
normal
sys
path
lookup
is
not
used
in
from
import
a
for
example
the
module
search
is
restricted
to
the
directory
containing
the
file
in
which
this
statement
appears
relative
imports
in
action
but
enough
theory
let
s
run
some
quick
tests
to
demonstrate
the
concepts
behind
relative
imports
imports
outside
packages
first
of
all
as
mentioned
previously
this
feature
does
not
impact
imports
outside
a
package
thus
the
following
finds
the
standard
library
string
module
as
expected
c
test
c
python
python
import
string
string
module
string
from
c
python
lib
string
py
package
relative
imports
but
if
we
add
a
module
of
the
same
name
in
the
directory
we
re
working
in
it
is
selected
instead
because
the
first
entry
on
the
module
search
path
is
the
current
working
directory
cwd
test
string
py
print
string
c
test
c
python
python
import
string
stringstringstringstringstringstringstringstring
string
module
string
from
string
py
in
other
words
normal
imports
are
still
relative
to
the
home
directory
the
top
level
script
s
container
or
the
directory
you
re
working
in
in
fact
relative
import
syntax
is
not
even
allowed
in
code
that
is
not
in
a
file
being
used
as
part
of
a
package
from
import
string
traceback
most
recent
call
last
file
stdin
line
in
module
valueerror
attempted
relative
import
in
non
package
in
this
and
all
examples
in
this
section
code
entered
at
the
interactive
prompt
behaves
the
same
as
it
would
if
run
in
a
top
level
script
because
the
first
entry
on
sys
path
is
either
the
interactive
working
directory
or
the
directory
containing
the
top
level
file
the
only
difference
is
that
the
start
of
sys
path
is
an
absolute
directory
not
an
empty
string
test
main
py
import
string
print
string
c
test
c
python
python
main
py
stringstringstringstringstringstringstringstring
module
string
from
c
test
string
py
same
results
in
imports
within
packages
now
let
s
get
rid
of
the
local
string
module
we
coded
in
the
cwd
and
build
a
package
directory
there
with
two
modules
including
the
required
but
empty
test
pkg
init
py
file
which
i
ll
omit
here
c
test
del
string
c
test
mkdir
pkg
test
pkg
spam
py
import
eggs
print
eggs
x
test
pkg
eggs
py
x
import
string
print
string
chapter
module
packages
works
in
but
not
the
first
file
in
this
package
tries
to
import
the
second
with
a
normal
import
statement
because
this
is
taken
to
be
relative
in
but
absolute
in
it
fails
in
the
latter
that
is
searches
the
containing
package
first
but
does
not
this
is
the
noncompatible
behavior
you
have
to
be
aware
of
in
c
test
c
python
python
import
pkg
spam
module
string
from
c
python
lib
string
pyc
c
test
c
python
python
import
pkg
spam
traceback
most
recent
call
last
file
stdin
line
in
module
file
pkg
spam
py
line
in
module
import
eggs
importerror
no
module
named
eggs
to
make
this
work
in
both
and
change
the
first
file
to
use
the
special
relative
import
syntax
so
that
its
import
searches
the
package
directory
in
too
test
pkg
spam
py
from
import
eggs
print
eggs
x
use
package
relative
import
in
or
test
pkg
eggs
py
x
import
string
print
string
c
test
c
python
python
import
pkg
spam
module
string
from
c
python
lib
string
pyc
c
test
c
python
python
import
pkg
spam
module
string
from
c
python
lib
string
py
imports
are
still
relative
to
the
cwd
notice
in
the
preceding
example
that
the
package
modules
still
have
access
to
standard
library
modules
like
string
really
their
imports
are
still
relative
to
the
entries
on
the
module
search
path
even
if
those
entries
are
relative
themselves
if
you
add
a
string
module
to
the
cwd
again
imports
in
a
package
will
find
it
there
instead
of
in
the
standard
library
although
you
can
skip
the
package
directory
with
an
absolute
import
in
you
still
can
t
skip
the
home
directory
of
the
program
that
imports
the
package
test
string
py
print
string
test
pkg
spam
py
from
import
eggs
package
relative
imports
print
eggs
x
test
pkg
eggs
py
x
import
string
print
string
gets
string
in
cwd
not
python
lib
c
test
c
python
python
same
result
in
import
pkg
spam
stringstringstringstringstringstringstringstring
module
string
from
string
py
selecting
modules
with
relative
and
absolute
imports
to
show
how
this
applies
to
imports
of
standard
library
modules
reset
the
package
one
more
time
get
rid
of
the
local
string
module
and
define
a
new
one
inside
the
package
itself
c
test
del
string
test
pkg
spam
py
import
string
print
string
relative
in
absolute
in
test
pkg
string
py
print
ni
now
which
version
of
the
string
module
you
get
depends
on
which
python
you
use
as
before
interprets
the
import
in
the
first
file
as
absolute
and
skips
the
package
but
does
not
c
test
c
python
python
import
pkg
spam
module
string
from
c
python
lib
string
py
c
test
c
python
python
import
pkg
spam
nininininininini
module
pkg
string
from
pkg
string
py
using
relative
import
syntax
in
forces
the
package
to
be
searched
again
as
it
is
in
by
using
absolute
or
relative
import
syntax
in
you
can
either
skip
or
select
the
package
directory
explicitly
in
fact
this
is
the
use
case
that
the
model
addresses
test
pkg
spam
py
from
import
string
print
string
test
pkg
string
py
print
ni
c
test
c
python
python
import
pkg
spam
nininininininini
chapter
module
packages
relative
in
both
and
module
pkg
string
from
pkg
string
py
c
test
c
python
python
import
pkg
spam
nininininininini
module
pkg
string
from
pkg
string
py
it
s
important
to
note
that
relative
import
syntax
is
really
a
binding
declaration
not
just
a
preference
if
we
delete
the
string
py
file
in
this
example
the
relative
import
in
spam
py
fails
in
both
and
instead
of
falling
back
on
the
standard
library
s
version
of
this
module
or
any
other
test
pkg
spam
py
from
import
string
fails
if
no
string
py
here
c
test
c
python
python
import
pkg
spam
text
omitted
importerror
cannot
import
name
string
modules
referenced
by
relative
imports
must
exist
in
the
package
directory
imports
are
still
relative
to
the
cwd
again
although
absolute
imports
let
you
skip
package
modules
they
still
rely
on
other
components
of
sys
path
for
one
last
test
let
s
define
two
string
modules
of
our
own
in
the
following
there
is
one
module
by
that
name
in
the
cwd
one
in
the
package
and
another
in
the
standard
library
test
string
py
print
string
test
pkg
spam
py
from
import
string
print
string
relative
in
both
and
test
pkg
string
py
print
ni
when
we
import
the
string
module
with
relative
import
syntax
we
get
the
version
in
the
package
as
desired
c
test
c
python
python
same
result
in
import
pkg
spam
nininininininini
module
pkg
string
from
pkg
string
py
when
absolute
syntax
is
used
though
the
module
we
get
varies
per
version
again
interprets
this
as
relative
to
the
package
but
makes
it
absolute
which
in
this
case
really
just
means
it
skips
the
package
and
loads
the
version
relative
to
the
cwd
not
the
version
the
standard
library
test
string
py
print
string
package
relative
imports
test
pkg
spam
py
import
string
print
string
relative
in
absolute
in
cwd
test
pkg
string
py
print
ni
c
test
c
python
python
import
pkg
spam
stringstringstringstringstringstringstringstring
module
string
from
string
py
c
test
c
python
python
import
pkg
spam
nininininininini
module
pkg
string
from
pkg
string
pyc
as
you
can
see
although
packages
can
explicitly
request
modules
within
their
own
directories
their
imports
are
otherwise
still
relative
to
the
rest
of
the
normal
module
search
path
in
this
case
a
file
in
the
program
using
the
package
hides
the
standard
library
module
the
package
may
want
all
that
the
change
in
really
accomplishes
is
allowing
package
code
to
select
files
either
inside
or
outside
the
package
i
e
relatively
or
absolutely
because
import
resolution
can
depend
on
an
enclosing
context
that
may
not
be
foreseen
absolute
imports
in
are
not
a
guarantee
of
finding
a
module
in
the
standard
library
experiment
with
these
examples
on
your
own
for
more
insight
in
practice
this
is
not
usually
as
ad
hoc
as
it
might
seem
you
can
generally
structure
your
imports
search
paths
and
module
names
to
work
the
way
you
wish
during
development
you
should
keep
in
mind
though
that
imports
in
larger
systems
may
depend
upon
context
of
use
and
the
module
import
protocol
is
part
of
a
successful
library
s
design
now
that
you
ve
learned
about
package
relative
imports
also
keep
in
mind
that
they
may
not
always
be
your
best
option
absolute
package
imports
relative
to
a
directory
on
sys
path
are
still
sometimes
preferred
over
both
implicit
package
relative
imports
in
python
and
explicit
package
relative
import
syntax
in
both
python
and
package
relative
import
syntax
and
python
s
new
absolute
import
search
rules
at
least
require
relative
imports
from
a
package
to
be
made
explicit
and
thus
easier
to
understand
and
maintain
files
that
use
imports
with
dots
though
are
implicitly
bound
to
a
package
directory
and
cannot
be
used
elsewhere
without
code
changes
naturally
the
extent
to
which
this
may
impact
your
modules
can
vary
per
package
absolute
imports
may
also
require
changes
when
directories
are
reorganized
chapter
module
packages
why
you
will
care
module
packages
now
that
packages
are
a
standard
part
of
python
it
s
common
to
see
larger
third
party
extensions
shipped
as
sets
of
package
directories
rather
than
flat
lists
of
modules
the
win
all
windows
extensions
package
for
python
for
instance
was
one
of
the
first
to
jump
on
the
package
bandwagon
many
of
its
utility
modules
reside
in
packages
imported
with
paths
for
instance
to
load
client
side
com
tools
you
use
a
statement
like
this
from
win
com
client
import
constants
dispatch
this
line
fetches
names
from
the
client
module
of
the
win
com
package
an
install
subdirectory
package
imports
are
also
pervasive
in
code
run
under
the
jython
java
based
implementation
of
python
because
java
libraries
are
organized
into
hierarchies
as
well
in
recent
python
releases
the
email
and
xml
tools
are
likewise
organized
into
package
subdirectories
in
the
standard
library
and
python
groups
even
more
related
modules
into
packages
including
tkinter
gui
tools
http
networking
tools
and
more
the
following
imports
access
various
standard
library
tools
in
from
email
message
import
message
from
tkinter
filedialog
import
askopenfilename
from
http
server
import
cgihttprequesthandler
whether
you
create
package
directories
or
not
you
will
probably
import
from
them
eventually
chapter
summary
this
chapter
introduced
python
s
package
import
model
an
optional
but
useful
way
to
explicitly
list
part
of
the
directory
path
leading
up
to
your
modules
package
imports
are
still
relative
to
a
directory
on
your
module
import
search
path
but
rather
than
relying
on
python
to
traverse
the
search
path
manually
your
script
gives
the
rest
of
the
path
to
the
module
explicitly
as
we
ve
seen
packages
not
only
make
imports
more
meaningful
in
larger
systems
but
also
simplify
import
search
path
settings
if
all
cross
directory
imports
are
relative
to
a
common
root
directory
and
resolve
ambiguities
when
there
is
more
than
one
module
of
the
same
name
including
the
name
of
the
enclosing
directory
in
a
package
import
helps
distinguish
between
them
because
it
s
relevant
only
to
code
in
packages
we
also
explored
the
newer
relative
import
model
here
a
way
for
imports
in
package
files
to
select
modules
in
the
same
package
using
leading
dots
in
a
from
instead
of
relying
on
an
older
implicit
package
search
rule
chapter
summary
in
the
next
chapter
we
will
survey
a
handful
of
more
advanced
module
related
topics
such
as
relative
import
syntax
and
the
name
usage
mode
variable
as
usual
though
we
ll
close
out
this
chapter
with
a
short
quiz
to
test
what
you
ve
learned
here
test
your
knowledge
quiz
what
is
the
purpose
of
an
init
py
file
in
a
module
package
directory
how
can
you
avoid
repeating
the
full
package
path
every
time
you
reference
a
package
s
content
which
directories
require
init
py
files
when
must
you
use
import
instead
of
from
with
packages
what
is
the
difference
between
from
mypkg
import
spam
and
from
import
spam
test
your
knowledge
answers
the
init
py
file
serves
to
declare
and
initialize
a
module
package
python
automatically
runs
its
code
the
first
time
you
import
through
a
directory
in
a
process
its
assigned
variables
become
the
attributes
of
the
module
object
created
in
memory
to
correspond
to
that
directory
it
is
also
not
optional
you
can
t
import
through
a
directory
with
package
syntax
unless
it
contains
this
file
use
the
from
statement
with
a
package
to
copy
names
out
of
the
package
directly
or
use
the
as
extension
with
the
import
statement
to
rename
the
path
to
a
shorter
synonym
in
both
cases
the
path
is
listed
in
only
one
place
in
the
from
or
import
statement
each
directory
listed
in
an
import
or
from
statement
must
contain
an
init
py
file
other
directories
including
the
directory
containing
the
leftmost
component
of
a
package
path
do
not
need
to
include
this
file
you
must
use
import
instead
of
from
with
packages
only
if
you
need
to
access
the
same
name
defined
in
more
than
one
path
with
import
the
path
makes
the
references
unique
but
from
allows
only
one
version
of
any
given
name
from
mypkg
import
spam
is
an
absolute
import
the
search
for
mypkg
skips
the
package
directory
and
the
module
is
located
in
an
absolute
directory
in
sys
path
a
statement
from
import
spam
on
the
other
hand
is
a
relative
import
spam
is
looked
up
relative
to
the
package
in
which
this
statement
is
contained
before
sys
path
is
searched
chapter
module
packages
chapter
advanced
module
topics
this
chapter
concludes
this
part
of
the
book
with
a
collection
of
more
advanced
module
related
topics
data
hiding
the
future
module
the
name
variable
sys
path
changes
listing
tools
running
modules
by
name
string
transitive
reloads
and
so
on
along
with
the
standard
set
of
gotchas
and
exercises
related
to
what
we
ve
covered
in
this
part
of
the
book
along
the
way
we
ll
build
some
larger
and
more
useful
tools
than
we
have
so
far
that
combine
functions
and
modules
like
functions
modules
are
more
effective
when
their
interfaces
are
well
defined
so
this
chapter
also
briefly
reviews
module
design
concepts
some
of
which
we
have
explored
in
prior
chapters
despite
the
word
advanced
in
this
chapter
s
title
this
is
also
something
of
a
grab
bag
of
additional
module
topics
because
some
of
the
topics
discussed
here
are
widely
used
especially
the
name
trick
be
sure
to
take
a
look
before
moving
on
to
classes
in
the
next
part
of
the
book
data
hiding
in
modules
as
we
ve
seen
a
python
module
exports
all
the
names
assigned
at
the
top
level
of
its
file
there
is
no
notion
of
declaring
which
names
should
and
shouldn
t
be
visible
outside
the
module
in
fact
there
s
no
way
to
prevent
a
client
from
changing
names
inside
a
module
if
it
wants
to
in
python
data
hiding
in
modules
is
a
convention
not
a
syntactical
constraint
if
you
want
to
break
a
module
by
trashing
its
names
you
can
but
fortunately
i
ve
yet
to
meet
a
programmer
who
would
some
purists
object
to
this
liberal
attitude
toward
data
hiding
claiming
that
it
means
python
can
t
implement
encapsulation
however
encapsulation
in
python
is
more
about
packaging
than
about
restricting
minimizing
from
damage
x
and
all
as
a
special
case
you
can
prefix
names
with
a
single
underscore
e
g
x
to
prevent
them
from
being
copied
out
when
a
client
imports
a
module
s
names
with
a
from
statement
this
really
is
intended
only
to
minimize
namespace
pollution
because
from
copies
out
all
names
the
importer
may
get
more
than
it
s
bargained
for
including
names
that
overwrite
names
in
the
importer
underscores
aren
t
private
declarations
you
can
still
see
and
change
such
names
with
other
import
forms
such
as
the
import
statement
alternatively
you
can
achieve
a
hiding
effect
similar
to
the
x
naming
convention
by
assigning
a
list
of
variable
name
strings
to
the
variable
all
at
the
top
level
of
the
module
for
example
all
error
encode
decode
export
these
only
when
this
feature
is
used
the
from
statement
will
copy
out
only
those
names
listed
in
the
all
list
in
effect
this
is
the
converse
of
the
x
convention
all
identifies
names
to
be
copied
while
x
identifies
names
not
to
be
copied
python
looks
for
an
all
list
in
the
module
first
if
one
is
not
defined
from
copies
all
names
without
a
single
leading
underscore
like
the
x
convention
the
all
list
has
meaning
only
to
the
from
statement
form
and
does
not
amount
to
a
privacy
declaration
module
writers
can
use
either
trick
to
implement
modules
that
are
well
behaved
when
used
with
from
see
also
the
discussion
of
all
lists
in
package
init
py
files
in
chapter
there
these
lists
declare
submodules
to
be
loaded
for
a
from
enabling
future
language
features
changes
to
the
language
that
may
potentially
break
existing
code
are
introduced
gradually
initially
they
appear
as
optional
extensions
which
are
disabled
by
default
to
turn
on
such
extensions
use
a
special
import
statement
of
this
form
from
future
import
featurename
this
statement
should
generally
appear
at
the
top
of
a
module
file
possibly
after
a
docstring
because
it
enables
special
compilation
of
code
on
a
per
module
basis
it
s
also
possible
to
submit
this
statement
at
the
interactive
prompt
to
experiment
with
upcoming
language
changes
the
feature
will
then
be
available
for
the
rest
of
the
interactive
session
for
example
in
prior
editions
of
this
book
we
had
to
use
this
statement
form
to
demonstrate
generator
functions
which
required
a
keyword
that
was
not
yet
enabled
by
default
they
use
a
featurename
of
generators
we
also
used
this
statement
to
activate
true
division
in
chapter
print
calls
in
chapter
and
absolute
imports
for
packages
in
chapter
chapter
advanced
module
topics
all
of
these
changes
have
the
potential
to
break
existing
code
in
python
so
they
are
being
phased
in
gradually
as
optional
features
enabled
with
this
special
import
mixed
usage
modes
name
and
main
here
s
another
module
related
trick
that
lets
you
both
import
a
file
as
a
module
and
run
it
as
a
standalone
program
each
module
has
a
built
in
attribute
called
name
which
python
sets
automatically
as
follows
if
the
file
is
being
run
as
a
top
level
program
file
name
is
set
to
the
string
main
when
it
starts
if
the
file
is
being
imported
instead
name
is
set
to
the
module
s
name
as
known
by
its
clients
the
upshot
is
that
a
module
can
test
its
own
name
to
determine
whether
it
s
being
run
or
imported
for
example
suppose
we
create
the
following
module
file
named
runme
py
to
export
a
single
function
called
tester
def
tester
print
it
s
christmas
in
heaven
if
name
main
tester
only
when
run
not
when
imported
this
module
defines
a
function
for
clients
to
import
and
use
as
usual
python
import
runme
runme
tester
it
s
christmas
in
heaven
but
the
module
also
includes
code
at
the
bottom
that
is
set
up
to
call
the
function
when
this
file
is
run
as
a
program
python
runme
py
it
s
christmas
in
heaven
in
effect
a
module
s
name
variable
serves
as
a
usage
mode
flag
allowing
its
code
to
be
leveraged
as
both
an
importable
library
and
a
top
level
script
though
simple
you
ll
see
this
hook
used
in
nearly
every
realistic
python
program
file
you
are
likely
to
encounter
perhaps
the
most
common
way
you
ll
see
the
name
test
applied
is
for
self
test
code
in
short
you
can
package
code
that
tests
a
module
s
exports
in
the
module
itself
by
wrapping
it
in
a
name
test
at
the
bottom
of
the
file
this
way
you
can
use
the
file
in
clients
by
importing
it
but
also
test
its
logic
by
running
it
from
the
system
shell
or
via
another
launching
scheme
in
practice
self
test
code
at
the
bottom
of
a
file
under
the
name
test
is
probably
the
most
common
and
simplest
unit
testing
protocol
in
python
chapter
will
discuss
other
commonly
used
options
for
testing
python
mixed
usage
modes
name
and
main
code
as
you
ll
see
the
unittest
and
doctest
standard
library
modules
provide
more
advanced
testing
tools
the
name
trick
is
also
commonly
used
when
writing
files
that
can
be
used
both
as
command
line
utilities
and
as
tool
libraries
for
instance
suppose
you
write
a
file
finder
script
in
python
you
can
get
more
mileage
out
of
your
code
if
you
package
it
in
functions
and
add
a
name
test
in
the
file
to
automatically
call
those
functions
when
the
file
is
run
standalone
that
way
the
script
s
code
becomes
reusable
in
other
programs
unit
tests
with
name
in
fact
we
ve
already
seen
a
prime
example
in
this
book
of
an
instance
where
the
name
check
could
be
useful
in
the
section
on
arguments
in
chapter
we
coded
a
script
that
computed
the
minimum
value
from
the
set
of
arguments
sent
in
def
minmax
test
args
res
args
for
arg
in
args
if
test
arg
res
res
arg
return
res
def
lessthan
x
y
return
x
y
def
grtrthan
x
y
return
x
y
print
minmax
lessthan
print
minmax
grtrthan
self
test
code
this
script
includes
self
test
code
at
the
bottom
so
we
can
test
it
without
having
to
retype
everything
at
the
interactive
command
line
each
time
we
run
it
the
problem
with
the
way
it
is
currently
coded
however
is
that
the
output
of
the
self
test
call
will
appear
every
time
this
file
is
imported
from
another
file
to
be
used
as
a
tool
not
exactly
a
user
friendly
feature
to
improve
it
we
can
wrap
up
the
self
test
call
in
a
name
check
so
that
it
will
be
launched
only
when
the
file
is
run
as
a
top
level
script
not
when
it
is
imported
print
i
am
name
def
minmax
test
args
res
args
for
arg
in
args
if
test
arg
res
res
arg
return
res
def
lessthan
x
y
return
x
y
def
grtrthan
x
y
return
x
y
if
name
main
print
minmax
lessthan
print
minmax
grtrthan
chapter
advanced
module
topics
self
test
code
we
re
also
printing
the
value
of
name
at
the
top
here
to
trace
its
value
python
creates
and
assigns
this
usage
mode
variable
as
soon
as
it
starts
loading
a
file
when
we
run
this
file
as
a
top
level
script
its
name
is
set
to
main
so
its
self
test
code
kicks
in
automatically
python
min
py
i
am
main
but
if
we
import
the
file
its
name
is
not
main
so
we
must
explicitly
call
the
function
to
make
it
run
import
min
i
am
min
min
minmax
min
lessthan
s
p
a
m
a
again
regardless
of
whether
this
is
used
for
testing
the
net
effect
is
that
we
get
to
use
our
code
in
two
different
roles
as
a
library
module
of
tools
or
as
an
executable
program
using
command
line
arguments
with
name
here
s
a
more
substantial
module
example
that
demonstrates
another
way
that
the
name
trick
is
commonly
employed
the
following
module
formats
py
defines
string
formatting
utilities
for
importers
but
also
checks
its
name
to
see
if
it
is
being
run
as
a
top
level
script
if
so
it
tests
and
uses
arguments
listed
on
the
system
command
line
to
run
a
canned
or
passed
in
test
in
python
the
sys
argv
list
contains
command
line
arguments
it
is
a
list
of
strings
reflecting
words
typed
on
the
command
line
where
the
first
item
is
always
the
name
of
the
script
being
run
various
specialized
string
display
formatting
utilities
test
me
with
canned
self
test
or
command
line
arguments
def
commas
n
format
positive
integer
like
n
for
display
with
commas
between
digit
groupings
xxx
yyy
zzz
digits
str
n
assert
digits
isdigit
result
while
digits
digits
last
digits
digits
result
last
result
if
result
else
last
return
result
def
money
n
width
mixed
usage
modes
name
and
main
format
number
n
for
display
with
commas
decimal
digits
leading
and
sign
and
optional
padding
xxx
yyy
zz
sign
if
n
else
n
abs
n
whole
commas
int
n
fract
f
n
format
s
s
s
sign
whole
fract
return
s
width
format
if
name
main
def
selftest
tests
fails
tests
tests
for
test
in
tests
print
commas
test
print
tests
tests
tests
tests
tests
tests
tests
for
test
in
tests
print
s
s
money
test
test
import
sys
if
len
sys
argv
selftest
else
print
money
float
sys
argv
int
sys
argv
this
file
works
the
same
in
python
and
when
run
directly
it
tests
itself
as
before
but
it
uses
options
on
the
command
line
to
control
the
test
behavior
run
this
file
directly
with
no
command
line
arguments
on
your
own
to
see
what
its
self
test
code
prints
to
test
specific
strings
pass
them
in
on
the
command
line
along
with
a
minimum
field
width
c
misc
python
formats
py
c
misc
python
formats
py
c
misc
python
formats
py
c
misc
python
formats
py
c
misc
python
formats
py
chapter
advanced
module
topics
c
misc
python
formats
py
c
misc
python
formats
py
canned
tests
try
this
yourself
as
before
because
this
code
is
instrumented
for
dual
mode
usage
we
can
also
import
its
tools
normally
in
other
contexts
as
library
components
from
formats
import
money
commas
money
money
x
s
s
commas
x
x
because
this
file
uses
the
docstring
feature
introduced
in
chapter
we
can
use
the
help
function
to
explore
its
tools
as
well
it
serves
as
a
general
purpose
tool
import
formats
help
formats
help
on
module
formats
name
formats
file
c
misc
formats
py
description
various
specialized
string
display
formatting
utilities
test
me
with
canned
self
test
or
command
line
arguments
functions
commas
n
format
positive
integer
like
n
for
display
with
commas
between
digit
groupings
xxx
yyy
zzz
money
n
width
format
number
n
for
display
with
commas
decimal
digits
leading
and
sign
and
optional
padding
xxx
yyy
zz
you
can
use
command
line
arguments
in
similar
ways
to
provide
general
inputs
to
scripts
that
may
also
package
their
code
as
functions
and
classes
for
reuse
by
importers
for
more
advanced
command
line
processing
be
sure
to
see
the
getopt
and
optparse
modules
in
python
s
standard
library
and
manuals
in
some
scenarios
you
might
also
use
the
built
in
input
function
introduced
in
chapter
and
used
in
chapter
to
prompt
the
shell
user
for
test
inputs
instead
of
pulling
them
from
the
command
line
mixed
usage
modes
name
and
main
also
see
chapter
s
discussion
of
the
new
d
string
format
method
syntax
that
will
be
available
in
python
and
later
this
formatting
extension
separates
thousands
groups
with
commas
much
like
the
code
here
the
module
listed
here
though
adds
money
formatting
and
serves
as
a
manual
alternative
for
comma
insertion
for
python
versions
before
changing
the
module
search
path
in
chapter
we
learned
that
the
module
search
path
is
a
list
of
directories
that
can
be
customized
via
the
environment
variable
pythonpath
and
possibly
via
pth
files
what
i
haven
t
shown
you
until
now
is
how
a
python
program
itself
can
actually
change
the
search
path
by
changing
a
built
in
list
called
sys
path
the
path
attribute
in
the
builtin
sys
module
sys
path
is
initialized
on
startup
but
thereafter
you
can
delete
append
and
reset
its
components
however
you
like
import
sys
sys
path
c
users
c
windows
system
python
zip
more
deleted
sys
path
append
c
sourcedir
import
string
extend
module
search
path
all
imports
search
the
new
dir
last
once
you
ve
made
such
a
change
it
will
impact
future
imports
anywhere
in
the
python
program
as
all
imports
and
all
files
share
the
single
sys
path
list
in
fact
this
list
may
be
changed
arbitrarily
sys
path
r
d
temp
sys
path
append
c
lp
e
examples
sys
path
d
temp
c
lp
e
examples
change
module
search
path
for
this
process
only
import
string
traceback
most
recent
call
last
file
stdin
line
in
module
importerror
no
module
named
string
thus
you
can
use
this
technique
to
dynamically
configure
a
search
path
inside
a
python
program
be
careful
though
if
you
delete
a
critical
directory
from
the
path
you
may
lose
access
to
critical
utilities
in
the
prior
example
for
instance
we
no
longer
have
access
to
the
string
module
because
we
deleted
the
python
source
library
s
directory
from
the
path
also
remember
that
such
sys
path
settings
endure
for
only
as
long
as
the
python
session
or
program
technically
process
that
made
them
runs
they
are
not
retained
after
python
exits
pythonpath
and
pth
file
path
configurations
live
in
the
operating
system
instead
of
a
running
python
program
and
so
are
more
global
they
are
picked
up
by
every
program
on
your
machine
and
live
on
after
a
program
completes
chapter
advanced
module
topics
the
as
extension
for
import
and
from
both
the
import
and
from
statements
have
been
extended
to
allow
an
imported
name
to
be
given
a
different
name
in
your
script
the
following
import
statement
import
modulename
as
name
is
equivalent
to
import
modulename
name
modulename
del
modulename
don
t
keep
original
name
after
such
an
import
you
can
and
in
fact
must
use
the
name
listed
after
the
as
to
refer
to
the
module
this
works
in
a
from
statement
too
to
assign
a
name
imported
from
a
file
to
a
different
name
in
your
script
from
modulename
import
attrname
as
name
this
extension
is
commonly
used
to
provide
short
synonyms
for
longer
names
and
to
avoid
name
clashes
when
you
are
already
using
a
name
in
your
script
that
would
otherwise
be
overwritten
by
a
normal
import
statement
import
reallylongmodulename
as
name
name
func
use
shorter
nickname
from
module
import
utility
as
util
from
module
import
utility
as
util
util
util
can
have
only
utility
it
also
comes
in
handy
for
providing
a
short
simple
name
for
an
entire
directory
path
when
using
the
package
import
feature
described
in
chapter
import
dir
dir
mod
as
mod
mod
func
only
list
full
path
once
modules
are
objects
metaprograms
because
modules
expose
most
of
their
interesting
properties
as
built
in
attributes
it
s
easy
to
write
programs
that
manage
other
programs
we
usually
call
such
manager
programs
metaprograms
because
they
work
on
top
of
other
systems
this
is
also
referred
to
as
introspection
because
programs
can
see
and
process
object
internals
introspection
is
an
advanced
feature
but
it
can
be
useful
for
building
programming
tools
for
instance
to
get
to
an
attribute
called
name
in
a
module
called
m
we
can
use
qualification
or
index
the
module
s
attribute
dictionary
exposed
in
the
built
in
dict
attribute
we
met
briefly
in
chapter
python
also
exports
the
list
of
all
loaded
modules
as
the
sys
modules
dictionary
that
is
the
modules
attribute
of
the
sys
module
and
provides
a
built
in
called
getattr
that
lets
us
fetch
attributes
from
their
string
names
it
s
like
saying
object
attr
but
attr
is
an
expression
that
yields
a
string
at
runtime
because
of
that
all
the
following
expressions
reach
the
same
attribute
and
object
modules
are
objects
metaprograms
m
name
m
dict
name
sys
modules
m
name
getattr
m
name
qualify
object
index
namespace
dictionary
manually
index
loaded
modules
table
manually
call
built
in
fetch
function
by
exposing
module
internals
like
this
python
helps
you
build
programs
about
programs
for
example
here
is
a
module
named
mydir
py
that
puts
these
ideas
to
work
to
implement
a
customized
version
of
the
built
in
dir
function
it
defines
and
exports
a
function
called
listing
which
takes
a
module
object
as
an
argument
and
prints
a
formatted
listing
of
the
module
s
namespace
mydir
py
a
module
that
lists
the
namespaces
of
other
modules
seplen
sepchr
def
listing
module
verbose
true
sepline
sepchr
seplen
if
verbose
print
sepline
print
name
module
name
file
module
file
print
sepline
count
for
attr
in
module
dict
scan
namespace
keys
print
d
s
count
attr
end
if
attr
startswith
print
built
in
name
skip
file
etc
else
print
getattr
module
attr
same
as
dict
attr
count
if
verbose
print
sepline
print
module
name
has
d
names
count
print
sepline
if
name
main
import
mydir
listing
mydir
self
test
code
list
myself
notice
the
docstring
at
the
top
as
in
the
prior
formats
py
example
because
we
may
want
to
use
this
as
a
general
tool
a
docstring
is
coded
to
provide
functional
information
accessible
via
doc
attributes
or
the
help
function
see
chapter
for
details
as
we
saw
in
chapter
because
a
function
can
access
its
enclosing
module
by
going
through
the
sys
modules
table
like
this
it
s
possible
to
emulate
the
effect
of
the
global
statement
for
instance
the
effect
of
global
x
x
can
be
simulated
albeit
with
much
more
typing
by
saying
this
inside
a
function
import
sys
glob
sys
modules
name
glob
x
remember
each
module
gets
a
name
attribute
for
free
it
s
visible
as
a
global
name
inside
the
functions
within
the
module
this
trick
provides
another
way
to
change
both
local
and
global
variables
of
the
same
name
inside
a
function
chapter
advanced
module
topics
import
mydir
help
mydir
help
on
module
mydir
name
mydir
mydir
py
a
module
that
lists
the
namespaces
of
other
modules
file
c
users
veramark
mark
mydir
py
functions
listing
module
verbose
true
data
sepchr
seplen
i
ve
also
provided
self
test
logic
at
the
bottom
of
this
module
which
narcissistically
imports
and
lists
itself
here
s
the
sort
of
output
produced
in
python
to
use
this
in
enable
print
calls
with
the
future
import
described
in
chapter
the
end
keyword
is
only
c
users
veramark
mark
c
python
python
mydir
py
name
mydir
file
c
users
veramark
mark
mydir
py
seplen
builtins
built
in
name
file
built
in
name
package
built
in
name
listing
function
listing
at
x
d
b
name
built
in
name
sepchr
doc
built
in
name
mydir
has
names
to
use
this
as
a
tool
for
listing
other
modules
simply
pass
the
modules
in
as
objects
to
this
file
s
function
here
it
is
listing
attributes
in
the
tkinter
gui
module
in
the
standard
library
a
k
a
tkinter
in
python
import
mydir
import
tkinter
mydir
listing
tkinter
name
tkinter
file
c
python
lib
tkinter
init
py
getdouble
class
float
multiple
multiple
mainloop
function
mainloop
at
x
b
canvas
class
tkinter
canvas
atsellast
function
atsellast
at
x
fa
c
many
more
name
omitted
stringvar
class
tkinter
stringvar
modules
are
objects
metaprograms
arc
arc
at
function
at
at
x
fa
nsew
nsew
scroll
scroll
tkinter
has
names
we
ll
meet
getattr
and
its
relatives
again
later
the
point
to
notice
here
is
that
mydir
is
a
program
that
lets
you
browse
other
programs
because
python
exposes
its
internals
you
can
process
objects
generically
importing
modules
by
name
string
the
module
name
in
an
import
or
from
statement
is
a
hardcoded
variable
name
sometimes
though
your
program
will
get
the
name
of
a
module
to
be
imported
as
a
string
at
runtime
e
g
if
a
user
selects
a
module
name
from
within
a
gui
unfortunately
you
can
t
use
import
statements
directly
to
load
a
module
given
its
name
as
a
string
python
expects
a
variable
name
not
a
string
for
instance
import
string
file
stdin
line
import
string
syntaxerror
invalid
syntax
it
also
won
t
work
to
simply
assign
the
string
to
a
variable
name
x
string
import
x
here
python
will
try
to
import
a
file
x
py
not
the
string
module
the
name
in
an
import
statement
both
becomes
a
variable
assigned
to
the
loaded
module
and
identifies
the
external
file
literally
to
get
around
this
you
need
to
use
special
tools
to
load
a
module
dynamically
from
a
string
that
is
generated
at
runtime
the
most
general
approach
is
to
construct
an
import
statement
as
a
string
of
python
code
and
pass
it
to
the
exec
built
in
function
to
run
exec
is
a
statement
in
python
but
it
can
be
used
exactly
as
shown
here
the
parentheses
are
simply
ignored
modname
string
exec
import
modname
run
a
string
of
code
string
imported
in
this
namespace
module
string
from
c
python
lib
string
py
tools
such
as
mydir
listing
can
be
preloaded
into
the
interactive
namespace
by
importing
them
in
the
file
referenced
by
the
pythonstartup
environment
variable
because
code
in
the
startup
file
runs
in
the
interactive
namespace
module
main
importing
common
tools
in
the
startup
file
can
save
you
some
typing
see
appendix
a
for
more
details
chapter
advanced
module
topics
the
exec
function
and
its
cousin
for
expressions
eval
compiles
a
string
of
code
and
passes
it
to
the
python
interpreter
to
be
executed
in
python
the
byte
code
compiler
is
available
at
runtime
so
you
can
write
programs
that
construct
and
run
other
programs
like
this
by
default
exec
runs
the
code
in
the
current
scope
but
you
can
get
more
specific
by
passing
in
optional
namespace
dictionaries
the
only
real
drawback
to
exec
is
that
it
must
compile
the
import
statement
each
time
it
runs
if
it
runs
many
times
your
code
may
run
quicker
if
it
uses
the
built
in
import
function
to
load
from
a
name
string
instead
the
effect
is
similar
but
import
returns
the
module
object
so
assign
it
to
a
name
here
to
keep
it
modname
string
string
import
modname
string
module
string
from
c
python
lib
string
py
transitive
module
reloads
we
studied
module
reloads
in
chapter
as
a
way
to
pick
up
changes
in
code
without
stopping
and
restarting
a
program
when
you
reload
a
module
though
python
only
reloads
that
particular
module
s
file
it
doesn
t
automatically
reload
modules
that
the
file
being
reloaded
happens
to
import
for
example
if
you
reload
some
module
a
and
a
imports
modules
b
and
c
the
reload
applies
only
to
a
not
to
b
and
c
the
statements
inside
a
that
import
b
and
c
are
rerun
during
the
reload
but
they
just
fetch
the
already
loaded
b
and
c
module
objects
assuming
they
ve
been
imported
before
in
actual
code
here
s
the
file
a
py
import
b
import
c
not
reloaded
when
a
is
just
an
import
of
an
already
loaded
module
python
from
imp
import
reload
reload
a
by
default
this
means
that
you
cannot
depend
on
reloads
picking
up
changes
in
all
the
modules
in
your
program
transitively
instead
you
must
use
multiple
reload
calls
to
update
the
subcomponents
independently
this
can
require
substantial
work
for
large
systems
you
re
testing
interactively
you
can
design
your
systems
to
reload
their
subcomponents
automatically
by
adding
reload
calls
in
parent
modules
like
a
but
this
complicates
the
modules
code
a
better
approach
is
to
write
a
general
tool
to
do
transitive
reloads
automatically
by
scanning
modules
dict
attributes
and
checking
each
item
s
type
to
find
nested
modules
to
reload
such
a
utility
function
could
call
itself
recursively
to
navigate
arbitrarily
shaped
import
dependency
chains
module
dict
attributes
were
introduced
earlier
in
the
section
modules
are
objects
metaprograms
on
page
and
the
type
call
was
presented
in
chapter
we
just
need
to
combine
the
two
tools
transitive
module
reloads
for
example
the
module
reloadall
py
listed
next
has
a
reload
all
function
that
automatically
reloads
a
module
every
module
that
the
module
imports
and
so
on
all
the
way
to
the
bottom
of
each
import
chain
it
uses
a
dictionary
to
keep
track
of
already
reloaded
modules
recursion
to
walk
the
import
chains
and
the
standard
library
s
types
module
which
simply
predefines
type
results
for
built
in
types
the
visited
dictionary
technique
works
to
avoid
cycles
here
when
imports
are
recursive
or
redundant
because
module
objects
can
be
dictionary
keys
as
we
learned
in
chapter
a
set
would
offer
similar
functionality
if
we
use
visited
add
module
to
insert
reloadall
py
transitively
reload
nested
modules
import
types
from
imp
import
reload
from
required
in
def
status
module
print
reloading
module
name
def
transitive
reload
module
visited
if
not
module
in
visited
status
module
reload
module
visited
module
none
for
attrobj
in
module
dict
values
if
type
attrobj
types
moduletype
transitive
reload
attrobj
visited
trap
cycles
duplicates
reload
this
module
and
visit
children
for
all
attrs
recur
if
module
def
reload
all
args
visited
for
arg
in
args
if
type
arg
types
moduletype
transitive
reload
arg
visited
if
name
main
import
reloadall
reload
all
reloadall
test
code
reload
myself
should
reload
this
types
to
use
this
utility
import
its
reload
all
function
and
pass
it
the
name
of
an
already
loaded
module
like
you
would
the
built
in
reload
function
when
the
file
runs
standalone
its
self
test
code
will
test
itself
it
has
to
import
itself
because
its
own
name
is
not
defined
in
the
file
without
an
import
this
code
works
in
both
and
and
prints
identical
output
because
we
ve
used
instead
of
a
comma
in
the
print
c
misc
c
python
python
reloadall
py
reloading
reloadall
reloading
types
here
is
this
module
at
work
in
on
some
standard
library
modules
notice
how
os
is
imported
by
tkinter
but
tkinter
reaches
sys
before
os
can
if
you
want
to
test
this
on
python
substitute
tkinter
for
tkinter
chapter
advanced
module
topics
from
reloadall
import
reload
all
import
os
tkinter
reload
all
os
reloading
os
reloading
copyreg
reloading
ntpath
reloading
genericpath
reloading
stat
reloading
sys
reloading
errno
reload
all
tkinter
reloading
tkinter
reloading
tkinter
reloading
tkinter
fix
reloading
sys
reloading
ctypes
reloading
os
reloading
copyreg
reloading
ntpath
reloading
genericpath
reloading
stat
reloading
errno
reloading
ctypes
endian
reloading
tkinter
constants
and
here
is
a
session
that
shows
the
effect
of
normal
versus
transitive
reloads
changes
made
to
the
two
nested
files
are
not
picked
up
by
reloads
unless
the
transitive
utility
is
used
import
b
x
a
py
import
c
y
b
py
z
c
py
c
misc
c
python
python
import
a
a
x
a
b
y
a
b
c
z
change
all
three
files
assignment
values
and
save
from
imp
import
reload
reload
a
module
a
from
a
py
a
x
a
b
y
a
b
c
z
normal
reload
is
top
level
only
from
reloadall
import
reload
all
reload
all
a
reloading
a
transitive
module
reloads
reloading
b
reloading
c
a
x
a
b
y
a
b
c
z
reloads
all
nested
modules
too
for
more
insight
study
and
experiment
with
this
example
on
your
own
it
s
another
importable
tool
you
might
want
to
add
to
your
own
source
code
library
module
design
concepts
like
functions
modules
present
design
tradeoffs
you
have
to
think
about
which
functions
go
in
which
modules
module
communication
mechanisms
and
so
on
all
of
this
will
become
clearer
when
you
start
writing
bigger
python
systems
but
here
are
a
few
general
ideas
to
keep
in
mind
you
re
always
in
a
module
in
python
there
s
no
way
to
write
code
that
doesn
t
live
in
some
module
in
fact
code
typed
at
the
interactive
prompt
really
goes
in
a
built
in
module
called
main
the
only
unique
things
about
the
interactive
prompt
are
that
code
runs
and
is
discarded
immediately
and
expression
results
are
printed
automatically
minimize
module
coupling
global
variables
like
functions
modules
work
best
if
they
re
written
to
be
closed
boxes
as
a
rule
of
thumb
they
should
be
as
independent
of
global
variables
used
within
other
modules
as
possible
except
for
functions
and
classes
imported
from
them
maximize
module
cohesion
unified
purpose
you
can
minimize
a
module
s
couplings
by
maximizing
its
cohesion
if
all
the
components
of
a
module
share
a
general
purpose
you
re
less
likely
to
depend
on
external
names
modules
should
rarely
change
other
modules
variables
we
illustrated
this
with
code
in
chapter
but
it
s
worth
repeating
here
it
s
perfectly
ok
to
use
globals
defined
in
another
module
that
s
how
clients
import
services
after
all
but
changing
globals
in
another
module
is
often
a
symptom
of
a
design
problem
there
are
exceptions
of
course
but
you
should
try
to
communicate
results
through
devices
such
as
function
arguments
and
return
values
not
cross
module
changes
otherwise
your
globals
values
become
dependent
on
the
order
of
arbitrarily
remote
assignments
in
other
files
and
your
modules
become
harder
to
understand
and
reuse
as
a
summary
figure
sketches
the
environment
in
which
modules
operate
modules
contain
variables
functions
classes
and
other
modules
if
imported
functions
have
local
variables
of
their
own
as
do
classes
i
e
objects
that
live
within
modules
which
we
ll
meet
next
in
chapter
chapter
advanced
module
topics
figure
module
execution
environment
modules
are
imported
but
modules
also
import
and
use
other
modules
which
may
be
coded
in
python
or
another
language
such
as
c
modules
in
turn
contain
variables
functions
and
classes
to
do
their
work
and
their
functions
and
classes
may
contain
variables
and
other
items
of
their
own
at
the
top
though
programs
are
just
sets
of
modules
module
gotchas
in
this
section
we
ll
take
a
look
at
the
usual
collection
of
boundary
cases
that
make
life
interesting
for
python
beginners
some
are
so
obscure
that
it
was
hard
to
come
up
with
examples
but
most
illustrate
something
important
about
the
language
statement
order
matters
in
top
level
code
when
a
module
is
first
imported
or
reloaded
python
executes
its
statements
one
by
one
from
the
top
of
the
file
to
the
bottom
this
has
a
few
subtle
implications
regarding
forward
references
that
are
worth
underscoring
here
code
at
the
top
level
of
a
module
file
not
nested
in
a
function
runs
as
soon
as
python
reaches
it
during
an
import
because
of
that
it
can
t
reference
names
assigned
lower
in
the
file
code
inside
a
function
body
doesn
t
run
until
the
function
is
called
because
names
in
a
function
aren
t
resolved
until
the
function
actually
runs
they
can
usually
reference
names
anywhere
in
the
file
generally
forward
references
are
only
a
concern
in
top
level
module
code
that
executes
immediately
functions
can
reference
names
arbitrarily
here
s
an
example
that
illustrates
forward
reference
module
gotchas
func
error
func
not
yet
assigned
def
func
print
func
okay
func
looked
up
later
func
error
func
not
yet
assigned
def
func
return
hello
func
okay
func
and
func
assigned
when
this
file
is
imported
or
run
as
a
standalone
program
python
executes
its
statements
from
top
to
bottom
the
first
call
to
func
fails
because
the
func
def
hasn
t
run
yet
the
call
to
func
inside
func
works
as
long
as
func
s
def
has
been
reached
by
the
time
func
is
called
it
hasn
t
when
the
second
top
level
func
call
is
run
the
last
call
to
func
at
the
bottom
of
the
file
works
because
func
and
func
have
both
been
assigned
mixing
defs
with
top
level
code
is
not
only
hard
to
read
it
s
dependent
on
statement
ordering
as
a
rule
of
thumb
if
you
need
to
mix
immediate
code
with
defs
put
your
defs
at
the
top
of
the
file
and
your
top
level
code
at
the
bottom
that
way
your
functions
are
guaranteed
to
be
defined
and
assigned
by
the
time
code
that
uses
them
runs
from
copies
names
but
doesn
t
link
although
it
s
commonly
used
the
from
statement
is
the
source
of
a
variety
of
potential
gotchas
in
python
the
from
statement
is
really
an
assignment
to
names
in
the
importer
s
scope
a
name
copy
operation
not
a
name
aliasing
the
implications
of
this
are
the
same
as
for
all
assignments
in
python
but
they
re
subtle
especially
given
that
the
code
that
shares
the
objects
lives
in
different
files
for
instance
suppose
we
define
the
following
module
nested
py
nested
py
x
def
printer
print
x
if
we
import
its
two
names
using
from
in
another
module
nested
py
we
get
copies
of
those
names
not
links
to
them
changing
a
name
in
the
importer
resets
only
the
binding
of
the
local
version
of
that
name
not
the
name
in
nested
py
nested
py
from
nested
import
x
printer
x
printer
python
nested
py
chapter
advanced
module
topics
copy
names
out
changes
my
x
only
nested
s
x
is
still
if
we
use
import
to
get
the
whole
module
and
then
assign
to
a
qualified
name
however
we
change
the
name
in
nested
py
qualification
directs
python
to
a
name
in
the
module
object
rather
than
a
name
in
the
importer
nested
py
nested
py
import
nested
nested
x
nested
printer
get
module
as
a
whole
ok
change
nested
s
x
python
nested
py
from
can
obscure
the
meaning
of
variables
i
mentioned
this
earlier
but
saved
the
details
for
here
because
you
don
t
list
the
variables
you
want
when
using
the
from
module
import
statement
form
it
can
accidentally
overwrite
names
you
re
already
using
in
your
scope
worse
it
can
make
it
difficult
to
determine
where
a
variable
comes
from
this
is
especially
true
if
the
from
form
is
used
on
more
than
one
imported
file
for
example
if
you
use
from
on
three
modules
you
ll
have
no
way
of
knowing
what
a
raw
function
call
really
means
short
of
searching
all
three
external
module
files
all
of
which
may
be
in
other
directories
from
module
import
from
module
import
from
module
import
func
bad
may
overwrite
my
names
silently
worse
no
way
to
tell
what
we
get
huh
the
solution
again
is
not
to
do
this
try
to
explicitly
list
the
attributes
you
want
in
your
from
statements
and
restrict
the
from
form
to
at
most
one
imported
module
per
file
that
way
any
undefined
names
must
by
deduction
be
in
the
module
named
in
the
single
from
you
can
avoid
the
issue
altogether
if
you
always
use
import
instead
of
from
but
that
advice
is
too
harsh
like
much
else
in
programming
from
is
a
convenient
tool
if
used
wisely
even
this
example
isn
t
an
absolute
evil
it
s
ok
for
a
program
to
use
this
technique
to
collect
names
in
a
single
space
for
convenience
as
long
as
it
s
well
known
reload
may
not
impact
from
imports
here
s
another
from
related
gotcha
as
discussed
previously
because
from
copies
assigns
names
when
run
there
s
no
link
back
to
the
modules
where
the
names
came
from
names
imported
with
from
simply
become
references
to
objects
which
happen
to
have
been
referenced
by
the
same
names
in
the
importee
when
the
from
ran
module
gotchas
because
of
this
behavior
reloading
the
importee
has
no
effect
on
clients
that
import
its
names
using
from
that
is
the
client
s
names
will
still
reference
the
original
objects
fetched
with
from
even
if
the
names
in
the
original
module
are
later
reset
from
module
import
x
from
imp
import
reload
reload
module
x
x
may
not
reflect
any
module
reloads
changes
module
but
not
my
names
still
references
old
object
to
make
reloads
more
effective
use
import
and
name
qualification
instead
of
from
because
qualifications
always
go
back
to
the
module
they
will
find
the
new
bindings
of
module
names
after
reloading
import
module
from
imp
import
reload
reload
module
module
x
get
module
not
names
changes
module
in
place
get
current
x
reflects
module
reloads
reload
from
and
interactive
testing
in
fact
the
prior
gotcha
is
even
more
subtle
than
it
appears
chapter
warned
that
it
s
usually
better
not
to
launch
programs
with
imports
and
reloads
because
of
the
complexities
involved
things
get
even
worse
when
from
is
brought
into
the
mix
python
beginners
often
stumble
onto
its
issues
in
scenarios
like
the
one
outlined
next
say
that
after
opening
a
module
file
in
a
text
edit
window
you
launch
an
interactive
session
to
load
and
test
your
module
with
from
from
module
import
function
function
finding
a
bug
you
jump
back
to
the
edit
window
make
a
change
and
try
to
reload
the
module
this
way
from
imp
import
reload
reload
module
this
doesn
t
work
because
the
from
statement
assigned
the
name
function
not
module
to
refer
to
the
module
in
a
reload
you
have
to
first
load
it
with
an
import
statement
at
least
once
from
imp
import
reload
import
module
reload
module
function
however
this
doesn
t
quite
work
either
reload
updates
the
module
object
but
as
discussed
in
the
preceding
section
names
like
function
that
were
copied
out
of
the
module
in
the
past
still
refer
to
the
old
objects
in
this
instance
the
original
version
of
the
function
to
really
get
the
new
function
you
must
refer
to
it
as
module
function
after
the
reload
or
rerun
the
from
chapter
advanced
module
topics
from
imp
import
reload
import
module
reload
module
from
module
import
function
function
or
give
up
and
use
module
function
now
the
new
version
of
the
function
will
finally
run
as
you
can
see
there
are
problems
inherent
in
using
reload
with
from
not
only
do
you
have
to
remember
to
reload
after
imports
but
you
also
have
to
remember
to
rerun
your
from
statements
after
reloads
this
is
complex
enough
to
trip
up
even
an
expert
once
in
a
while
in
fact
the
situation
has
gotten
even
worse
in
python
because
you
must
also
remember
to
import
reload
itself
the
short
story
is
that
you
should
not
expect
reload
and
from
to
play
together
nicely
the
best
policy
is
not
to
combine
them
at
all
use
reload
with
import
or
launch
your
programs
other
ways
as
suggested
in
chapter
using
the
run
run
module
menu
option
in
idle
file
icon
clicks
system
command
lines
or
the
exec
built
in
function
recursive
from
imports
may
not
work
i
saved
the
most
bizarre
and
thankfully
obscure
gotcha
for
last
because
imports
execute
a
file
s
statements
from
top
to
bottom
you
need
to
be
careful
when
using
modules
that
import
each
other
known
as
recursive
imports
because
the
statements
in
a
module
may
not
all
have
been
run
when
it
imports
another
module
some
of
its
names
may
not
yet
exist
if
you
use
import
to
fetch
the
module
as
a
whole
this
may
or
may
not
matter
the
module
s
names
won
t
be
accessed
until
you
later
use
qualification
to
fetch
their
values
but
if
you
use
from
to
fetch
specific
names
you
must
bear
in
mind
that
you
will
only
have
access
to
names
in
that
module
that
have
already
been
assigned
for
instance
take
the
following
modules
recur
and
recur
recur
assigns
a
name
x
and
then
imports
recur
before
assigning
the
name
y
at
this
point
recur
can
fetch
recur
as
a
whole
with
an
import
it
already
exists
in
python
s
internal
modules
table
but
if
it
uses
from
it
will
be
able
to
see
only
the
name
x
the
name
y
which
is
assigned
below
the
import
in
recur
doesn
t
yet
exist
so
you
get
an
error
recur
py
x
import
recur
y
recur
py
from
recur
import
x
from
recur
import
y
run
recur
now
if
it
doesn
t
exist
ok
x
already
assigned
error
y
not
yet
assigned
c
misc
c
python
python
import
recur
traceback
most
recent
call
last
file
stdin
line
in
module
module
gotchas
file
recur
py
line
in
module
import
recur
file
recur
py
line
in
module
from
recur
import
y
importerror
cannot
import
name
y
python
avoids
rerunning
recur
s
statements
when
they
are
imported
recursively
from
recur
otherwise
the
imports
would
send
the
script
into
an
infinite
loop
but
recur
s
namespace
is
incomplete
when
it
s
imported
by
recur
the
solution
don
t
use
from
in
recursive
imports
no
really
python
won
t
get
stuck
in
a
cycle
if
you
do
but
your
programs
will
once
again
be
dependent
on
the
order
of
the
statements
in
the
modules
there
are
two
ways
out
of
this
gotcha
you
can
usually
eliminate
import
cycles
like
this
by
careful
design
maximizing
cohesion
and
minimizing
coupling
are
good
first
steps
if
you
can
t
break
the
cycles
completely
postpone
module
name
accesses
by
using
import
and
qualification
instead
of
from
or
by
running
your
froms
either
inside
functions
instead
of
at
the
top
level
of
the
module
or
near
the
bottom
of
your
file
to
defer
their
execution
chapter
summary
this
chapter
surveyed
some
more
advanced
module
related
concepts
we
studied
data
hiding
techniques
enabling
new
language
features
with
the
future
module
the
name
usage
mode
variable
transitive
reloads
importing
by
name
strings
and
more
we
also
explored
and
summarized
module
design
issues
and
looked
at
common
mistakes
related
to
modules
to
help
you
avoid
them
in
your
code
the
next
chapter
begins
our
look
at
python
s
object
oriented
programming
tool
the
class
much
of
what
we
ve
covered
in
the
last
few
chapters
will
apply
there
too
classes
live
in
modules
and
are
namespaces
as
well
but
they
add
an
extra
component
to
attribute
lookup
called
inheritance
search
as
this
is
the
last
chapter
in
this
part
of
the
book
however
before
we
dive
into
that
topic
be
sure
to
work
through
this
part
s
set
of
lab
exercises
and
before
that
here
is
this
chapter
s
quiz
to
review
the
topics
covered
here
test
your
knowledge
quiz
what
is
significant
about
variables
at
the
top
level
of
a
module
whose
names
begin
with
a
single
underscore
what
does
it
mean
when
a
module
s
name
variable
is
the
string
main
chapter
advanced
module
topics
if
the
user
interactively
types
the
name
of
a
module
to
test
how
can
you
import
it
how
is
changing
sys
path
different
from
setting
pythonpath
to
modify
the
module
search
path
if
the
module
future
allows
us
to
import
from
the
future
can
we
also
import
from
the
past
test
your
knowledge
answers
variables
at
the
top
level
of
a
module
whose
names
begin
with
a
single
underscore
are
not
copied
out
to
the
importing
scope
when
the
from
statement
form
is
used
they
can
still
be
accessed
by
an
import
or
the
normal
from
statement
form
though
if
a
module
s
name
variable
is
the
string
main
it
means
that
the
file
is
being
executed
as
a
top
level
script
instead
of
being
imported
from
another
file
in
the
program
that
is
the
file
is
being
used
as
a
program
not
a
library
user
input
usually
comes
into
a
script
as
a
string
to
import
the
referenced
module
given
its
string
name
you
can
build
and
run
an
import
statement
with
exec
or
pass
the
string
name
in
a
call
to
the
import
function
changing
sys
path
only
affects
one
running
program
and
is
temporary
the
change
goes
away
when
the
program
ends
pythonpath
settings
live
in
the
operating
system
they
are
picked
up
globally
by
all
programs
on
a
machine
and
changes
to
these
settings
endure
after
programs
exit
no
we
can
t
import
from
the
past
in
python
we
can
install
or
stubbornly
use
an
older
version
of
the
language
but
the
latest
python
is
generally
the
best
python
test
your
knowledge
part
v
exercises
see
part
v
modules
on
page
in
appendix
b
for
the
solutions
import
basics
write
a
program
that
counts
the
lines
and
characters
in
a
file
similar
in
spirit
to
wc
on
unix
with
your
text
editor
code
a
python
module
called
mymod
py
that
exports
three
top
level
names
a
countlines
name
function
that
reads
an
input
file
and
counts
the
number
of
lines
in
it
hint
file
readlines
does
most
of
the
work
for
you
and
len
does
the
rest
a
countchars
name
function
that
reads
an
input
file
and
counts
the
number
of
characters
in
it
hint
file
read
returns
a
single
string
a
test
name
function
that
calls
both
counting
functions
with
a
given
input
filename
such
a
filename
generally
might
be
passed
in
hardcoded
input
with
the
input
built
in
function
or
pulled
from
a
command
line
via
the
sys
argv
list
shown
in
this
chapter
s
formats
py
example
for
now
you
can
assume
it
s
a
passed
in
function
argument
test
your
knowledge
part
v
exercises
all
three
mymod
functions
should
expect
a
filename
string
to
be
passed
in
if
you
type
more
than
two
or
three
lines
per
function
you
re
working
much
too
hard
use
the
hints
i
just
gave
next
test
your
module
interactively
using
import
and
attribute
references
to
fetch
your
exports
does
your
pythonpath
need
to
include
the
directory
where
you
created
mymod
py
try
running
your
module
on
itself
e
g
test
mymod
py
note
that
test
opens
the
file
twice
if
you
re
feeling
ambitious
you
may
be
able
to
improve
this
by
passing
an
open
file
object
into
the
two
count
functions
hint
file
seek
is
a
file
rewind
from
from
test
your
mymod
module
from
exercise
interactively
by
using
from
to
load
the
exports
directly
first
by
name
then
using
the
from
variant
to
fetch
everything
main
add
a
line
in
your
mymod
module
that
calls
the
test
function
automatically
only
when
the
module
is
run
as
a
script
not
when
it
is
imported
the
line
you
add
will
probably
test
the
value
of
name
for
the
string
main
as
shown
in
this
chapter
try
running
your
module
from
the
system
command
line
then
import
the
module
and
test
its
functions
interactively
does
it
still
work
in
both
modes
nested
imports
write
a
second
module
myclient
py
that
imports
mymod
and
tests
its
functions
then
run
myclient
from
the
system
command
line
if
myclient
uses
from
to
fetch
from
mymod
will
mymod
s
functions
be
accessible
from
the
top
level
of
myclient
what
if
it
imports
with
import
instead
try
coding
both
variations
in
myclient
and
test
interactively
by
importing
myclient
and
inspecting
its
dict
attribute
package
imports
import
your
file
from
a
package
create
a
subdirectory
called
mypkg
nested
in
a
directory
on
your
module
import
search
path
move
the
mymod
py
module
file
you
created
in
exercise
or
into
the
new
directory
and
try
to
import
it
with
a
package
import
of
the
form
import
mypkg
mymod
you
ll
need
to
add
an
init
py
file
in
the
directory
your
module
was
moved
to
make
this
go
but
it
should
work
on
all
major
python
platforms
that
s
part
of
the
reason
python
uses
as
a
path
separator
the
package
directory
you
create
can
be
simply
a
subdirectory
of
the
one
you
re
working
in
if
it
is
it
will
be
found
via
the
home
directory
component
of
the
search
path
and
you
won
t
have
to
configure
your
path
add
some
code
to
your
init
py
and
see
if
it
runs
on
each
import
reloads
experiment
with
module
reloads
perform
the
tests
in
chapter
s
changer
py
example
changing
the
called
function
s
message
and
or
behavior
repeatedly
without
stopping
the
python
interpreter
depending
on
your
system
you
might
be
able
to
edit
changer
in
another
window
or
suspend
the
python
interpreter
and
edit
in
the
same
window
on
unix
a
ctrl
z
key
combination
usually
suspends
the
current
process
and
an
fg
command
later
resumes
it
chapter
advanced
module
topics
circular
imports
in
the
section
on
recursive
import
gotchas
importing
recur
raised
an
error
but
if
you
restart
python
and
import
recur
interactively
the
error
doesn
t
occur
test
this
and
see
for
yourself
why
do
you
think
it
works
to
import
recur
but
not
recur
hint
python
stores
new
modules
in
the
built
in
sys
modules
table
a
dictionary
before
running
their
code
later
imports
fetch
the
module
from
this
table
first
whether
the
module
is
complete
yet
or
not
now
try
running
recur
as
a
top
level
script
file
python
recur
py
do
you
get
the
same
error
that
occurs
when
recur
is
imported
interactively
why
hint
when
modules
are
run
as
programs
they
aren
t
imported
so
this
case
has
the
same
effect
as
importing
recur
interactively
recur
is
the
first
module
imported
what
happens
when
you
run
recur
as
a
script
note
that
circular
imports
are
extremely
rare
in
practice
on
the
other
hand
if
you
can
understand
why
they
are
a
potential
problem
you
know
a
lot
about
python
s
import
semantics
test
your
knowledge
part
v
exercises
part
vi
classes
and
oop
chapter
oop
the
big
picture
so
far
in
this
book
we
ve
been
using
the
term
object
generically
really
the
code
written
up
to
this
point
has
been
object
based
we
ve
passed
objects
around
our
scripts
used
them
in
expressions
called
their
methods
and
so
on
for
our
code
to
qualify
as
being
truly
object
oriented
oo
though
our
objects
will
generally
need
to
also
participate
in
something
called
an
inheritance
hierarchy
this
chapter
begins
our
exploration
of
the
python
class
a
device
used
to
implement
new
kinds
of
objects
in
python
that
support
inheritance
classes
are
python
s
main
object
oriented
programming
oop
tool
so
we
ll
also
look
at
oop
basics
along
the
way
in
this
part
of
the
book
oop
offers
a
different
and
often
more
effective
way
of
looking
at
programming
in
which
we
factor
code
to
minimize
redundancy
and
write
new
programs
by
customizing
existing
code
instead
of
changing
it
in
place
in
python
classes
are
created
with
a
new
statement
the
class
statement
as
you
ll
see
the
objects
defined
with
classes
can
look
a
lot
like
the
built
in
types
we
studied
earlier
in
the
book
in
fact
classes
really
just
apply
and
extend
the
ideas
we
ve
already
covered
roughly
they
are
packages
of
functions
that
use
and
process
built
in
object
types
classes
though
are
designed
to
create
and
manage
new
objects
and
they
also
support
inheritance
a
mechanism
of
code
customization
and
reuse
above
and
beyond
anything
we
ve
seen
so
far
one
note
up
front
in
python
oop
is
entirely
optional
and
you
don
t
need
to
use
classes
just
to
get
started
in
fact
you
can
get
plenty
of
work
done
with
simpler
constructs
such
as
functions
or
even
simple
top
level
script
code
because
using
classes
well
requires
some
up
front
planning
they
tend
to
be
of
more
interest
to
people
who
work
in
strategic
mode
doing
long
term
product
development
than
to
people
who
work
in
tactical
mode
where
time
is
in
very
short
supply
still
as
you
ll
see
in
this
part
of
the
book
classes
turn
out
to
be
one
of
the
most
useful
tools
python
provides
when
used
well
classes
can
actually
cut
development
time
radically
they
re
also
employed
in
popular
python
tools
like
the
tkinter
gui
api
so
most
python
programmers
will
usually
find
at
least
a
working
knowledge
of
class
basics
helpful
why
use
classes
remember
when
i
told
you
that
programs
do
things
with
stuff
in
simple
terms
classes
are
just
a
way
to
define
new
sorts
of
stuff
reflecting
real
objects
in
a
program
s
domain
for
instance
suppose
we
decide
to
implement
that
hypothetical
pizza
making
robot
we
used
as
an
example
in
chapter
if
we
implement
it
using
classes
we
can
model
more
of
its
real
world
structure
and
relationships
two
aspects
of
oop
prove
useful
here
inheritance
pizza
making
robots
are
kinds
of
robots
so
they
possess
the
usual
robot
y
properties
in
oop
terms
we
say
they
inherit
properties
from
the
general
category
of
all
robots
these
common
properties
need
to
be
implemented
only
once
for
the
general
case
and
can
be
reused
by
all
types
of
robots
we
may
build
in
the
future
composition
pizza
making
robots
are
really
collections
of
components
that
work
together
as
a
team
for
instance
for
our
robot
to
be
successful
it
might
need
arms
to
roll
dough
motors
to
maneuver
to
the
oven
and
so
on
in
oop
parlance
our
robot
is
an
example
of
composition
it
contains
other
objects
that
it
activates
to
do
its
bidding
each
component
might
be
coded
as
a
class
which
defines
its
own
behavior
and
relationships
general
oop
ideas
like
inheritance
and
composition
apply
to
any
application
that
can
be
decomposed
into
a
set
of
objects
for
example
in
typical
gui
systems
interfaces
are
written
as
collections
of
widgets
buttons
labels
and
so
on
which
are
all
drawn
when
their
container
is
drawn
composition
moreover
we
may
be
able
to
write
our
own
custom
widgets
buttons
with
unique
fonts
labels
with
new
color
schemes
and
the
like
which
are
specialized
versions
of
more
general
interface
devices
inheritance
from
a
more
concrete
programming
perspective
classes
are
python
program
units
just
like
functions
and
modules
they
are
another
compartment
for
packaging
logic
and
data
in
fact
classes
also
define
new
namespaces
much
like
modules
but
compared
to
other
program
units
we
ve
already
seen
classes
have
three
critical
distinctions
that
make
them
more
useful
when
it
comes
to
building
new
objects
multiple
instances
classes
are
essentially
factories
for
generating
one
or
more
objects
every
time
we
call
a
class
we
generate
a
new
object
with
a
distinct
namespace
each
object
generated
from
a
class
has
access
to
the
class
s
attributes
and
gets
a
namespace
of
its
own
for
data
that
varies
per
object
customization
via
inheritance
classes
also
support
the
oop
notion
of
inheritance
we
can
extend
a
class
by
redefining
its
attributes
outside
the
class
itself
more
generally
classes
can
build
up
namespace
hierarchies
which
define
names
to
be
used
by
objects
created
from
classes
in
the
hierarchy
chapter
oop
the
big
picture
operator
overloading
by
providing
special
protocol
methods
classes
can
define
objects
that
respond
to
the
sorts
of
operations
we
saw
at
work
on
built
in
types
for
instance
objects
made
with
classes
can
be
sliced
concatenated
indexed
and
so
on
python
provides
hooks
that
classes
can
use
to
intercept
and
implement
any
built
in
type
operation
oop
from
feet
before
we
see
what
this
all
means
in
terms
of
code
i
d
like
to
say
a
few
words
about
the
general
ideas
behind
oop
if
you
ve
never
done
anything
object
oriented
in
your
life
before
now
some
of
the
terminology
in
this
chapter
may
seem
a
bit
perplexing
on
the
first
pass
moreover
the
motivation
for
these
terms
may
be
elusive
until
you
ve
had
a
chance
to
study
the
ways
that
programmers
apply
them
in
larger
systems
oop
is
as
much
an
experience
as
a
technology
attribute
inheritance
search
the
good
news
is
that
oop
is
much
simpler
to
understand
and
use
in
python
than
in
other
languages
such
as
c
or
java
as
a
dynamically
typed
scripting
language
python
removes
much
of
the
syntactic
clutter
and
complexity
that
clouds
oop
in
other
tools
in
fact
most
of
the
oop
story
in
python
boils
down
to
this
expression
object
attribute
we
ve
been
using
this
expression
throughout
the
book
to
access
module
attributes
call
methods
of
objects
and
so
on
when
we
say
this
to
an
object
that
is
derived
from
a
class
statement
however
the
expression
kicks
off
a
search
in
python
it
searches
a
tree
of
linked
objects
looking
for
the
first
appearance
of
attribute
that
it
can
find
when
classes
are
involved
the
preceding
python
expression
effectively
translates
to
the
following
in
natural
language
find
the
first
occurrence
of
attribute
by
looking
in
object
then
in
all
classes
above
it
from
bottom
to
top
and
left
to
right
in
other
words
attribute
fetches
are
simply
tree
searches
the
term
inheritance
is
applied
because
objects
lower
in
a
tree
inherit
attributes
attached
to
objects
higher
in
that
tree
as
the
search
proceeds
from
the
bottom
up
in
a
sense
the
objects
linked
into
a
tree
are
the
union
of
all
the
attributes
defined
in
all
their
tree
parents
all
the
way
up
the
tree
in
python
this
is
all
very
literal
we
really
do
build
up
trees
of
linked
objects
with
code
and
python
really
does
climb
this
tree
at
runtime
searching
for
attributes
every
time
we
use
the
object
attribute
expression
to
make
this
more
concrete
figure
sketches
an
example
of
one
of
these
trees
in
this
figure
there
is
a
tree
of
five
objects
labeled
with
variables
all
of
which
have
attached
attributes
ready
to
be
searched
more
specifically
this
tree
links
together
three
oop
from
feet
figure
a
class
tree
with
two
instances
at
the
bottom
i
and
i
a
class
above
them
c
and
two
superclasses
at
the
top
c
and
c
all
of
these
objects
are
namespaces
packages
of
variables
and
the
inheritance
search
is
simply
a
search
of
the
tree
from
bottom
to
top
looking
for
the
lowest
occurrence
of
an
attribute
name
code
implies
the
shape
of
such
trees
class
objects
the
ovals
c
c
and
c
and
two
instance
objects
the
rectangles
i
and
i
into
an
inheritance
search
tree
notice
that
in
the
python
object
model
classes
and
the
instances
you
generate
from
them
are
two
distinct
object
types
classes
serve
as
instance
factories
their
attributes
provide
behavior
data
and
functions
that
is
inherited
by
all
the
instances
generated
from
them
e
g
a
function
to
compute
an
employee
s
salary
from
pay
and
hours
instances
represent
the
concrete
items
in
a
program
s
domain
their
attributes
record
data
that
varies
per
specific
object
e
g
an
employee
s
social
security
number
in
terms
of
search
trees
an
instance
inherits
attributes
from
its
class
and
a
class
inherits
attributes
from
all
classes
above
it
in
the
tree
in
figure
we
can
further
categorize
the
ovals
by
their
relative
positions
in
the
tree
we
usually
call
classes
higher
in
the
tree
like
c
and
c
superclasses
classes
lower
in
the
tree
like
c
are
known
as
subclasses
these
terms
refer
to
relative
tree
positions
and
roles
superclasses
provide
behavior
shared
by
all
their
subclasses
but
because
the
search
proceeds
from
the
bottom
up
subclasses
may
override
behavior
defined
in
their
superclasses
by
redefining
superclass
names
lower
in
the
tree
as
these
last
few
words
are
really
the
crux
of
the
matter
of
software
customization
in
oop
let
s
expand
on
this
concept
suppose
we
build
up
the
tree
in
figure
and
then
say
this
i
w
in
other
literature
you
may
also
occasionally
see
the
terms
base
classes
and
derived
classes
used
to
describe
superclasses
and
subclasses
respectively
chapter
oop
the
big
picture
right
away
this
code
invokes
inheritance
because
this
is
an
object
attribute
expression
it
triggers
a
search
of
the
tree
in
figure
python
will
search
for
the
attribute
w
by
looking
in
i
and
above
specifically
it
will
search
the
linked
objects
in
this
order
i
c
c
c
and
stop
at
the
first
attached
w
it
finds
or
raise
an
error
if
w
isn
t
found
at
all
in
this
case
w
won
t
be
found
until
c
is
searched
because
it
appears
only
in
that
object
in
other
words
i
w
resolves
to
c
w
by
virtue
of
the
automatic
search
in
oop
terminology
i
inherits
the
attribute
w
from
c
ultimately
the
two
instances
inherit
four
attributes
from
their
classes
w
x
y
and
z
other
attribute
references
will
wind
up
following
different
paths
in
the
tree
for
example
i
x
and
i
x
both
find
x
in
c
and
stop
because
c
is
lower
than
c
i
y
and
i
y
both
find
y
in
c
because
that
s
the
only
place
y
appears
i
z
and
i
z
both
find
z
in
c
because
c
is
further
to
the
left
than
c
i
name
finds
name
in
i
without
climbing
the
tree
at
all
trace
these
searches
through
the
tree
in
figure
to
get
a
feel
for
how
inheritance
searches
work
in
python
the
first
item
in
the
preceding
list
is
perhaps
the
most
important
to
notice
because
c
redefines
the
attribute
x
lower
in
the
tree
it
effectively
replaces
the
version
above
it
in
c
as
you
ll
see
in
a
moment
such
redefinitions
are
at
the
heart
of
software
customization
in
oop
by
redefining
and
replacing
the
attribute
c
effectively
customizes
what
it
inherits
from
its
superclasses
classes
and
instances
although
they
are
technically
two
separate
object
types
in
the
python
model
the
classes
and
instances
we
put
in
these
trees
are
almost
identical
each
type
s
main
purpose
is
to
serve
as
another
kind
of
namespace
a
package
of
variables
and
a
place
where
we
can
attach
attributes
if
classes
and
instances
therefore
sound
like
modules
they
should
however
the
objects
in
class
trees
also
have
automatically
searched
links
to
other
namespace
objects
and
classes
correspond
to
statements
not
entire
files
the
primary
difference
between
classes
and
instances
is
that
classes
are
a
kind
of
factory
for
generating
instances
for
example
in
a
realistic
application
we
might
have
an
employee
class
that
defines
what
it
means
to
be
an
employee
from
that
class
we
generate
actual
employee
instances
this
is
another
difference
between
classes
and
modules
we
only
ever
have
one
instance
of
a
given
module
in
memory
that
s
why
we
have
to
reload
a
module
to
get
its
new
code
but
with
classes
we
can
make
as
many
instances
as
we
need
oop
from
feet
operationally
classes
will
usually
have
functions
attached
to
them
e
g
computesalary
and
the
instances
will
have
more
basic
data
items
used
by
the
class
functions
e
g
hoursworked
in
fact
the
object
oriented
model
is
not
that
different
from
the
classic
data
processing
model
of
programs
plus
records
in
oop
instances
are
like
records
with
data
and
classes
are
the
programs
for
processing
those
records
in
oop
though
we
also
have
the
notion
of
an
inheritance
hierarchy
which
supports
software
customization
better
than
earlier
models
class
method
calls
in
the
prior
section
we
saw
how
the
attribute
reference
i
w
in
our
example
class
tree
was
translated
to
c
w
by
the
inheritance
search
procedure
in
python
perhaps
just
as
important
to
understand
as
the
inheritance
of
attributes
though
is
what
happens
when
we
try
to
call
methods
i
e
functions
attached
to
classes
as
attributes
if
this
i
w
reference
is
a
function
call
what
it
really
means
is
call
the
c
w
function
to
process
i
that
is
python
will
automatically
map
the
call
i
w
into
the
call
c
w
i
passing
in
the
instance
as
the
first
argument
to
the
inherited
function
in
fact
whenever
we
call
a
function
attached
to
a
class
in
this
fashion
an
instance
of
the
class
is
always
implied
this
implied
subject
or
context
is
part
of
the
reason
we
refer
to
this
as
an
object
oriented
model
there
is
always
a
subject
object
when
an
operation
is
run
in
a
more
realistic
example
we
might
invoke
a
method
called
giveraise
attached
as
an
attribute
to
an
employee
class
such
a
call
has
no
meaning
unless
qualified
with
the
employee
to
whom
the
raise
should
be
given
as
we
ll
see
later
python
passes
in
the
implied
instance
to
a
special
first
argument
in
the
method
called
self
by
convention
as
we
ll
also
learn
methods
can
be
called
through
either
an
instance
e
g
bob
giveraise
or
a
class
e
g
employee
giveraise
bob
and
both
forms
serve
purposes
in
our
scripts
to
see
how
methods
receive
their
subjects
though
we
need
to
move
on
to
some
code
coding
class
trees
although
we
are
speaking
in
the
abstract
here
there
is
tangible
code
behind
all
these
ideas
we
construct
trees
and
their
objects
with
class
statements
and
class
calls
which
we
ll
meet
in
more
detail
later
in
short
each
class
statement
generates
a
new
class
object
each
time
a
class
is
called
it
generates
a
new
instance
object
instances
are
automatically
linked
to
the
classes
from
which
they
are
created
classes
are
linked
to
their
superclasses
by
listing
them
in
parentheses
in
a
class
header
line
the
left
to
right
order
there
gives
the
order
in
the
tree
chapter
oop
the
big
picture
to
build
the
tree
in
figure
for
example
we
would
run
python
code
of
this
form
i
ve
omitted
the
guts
of
the
class
statements
here
class
c
class
c
class
c
c
c
make
class
objects
ovals
i
c
i
c
make
instance
objects
rectangles
linked
to
their
classes
linked
to
superclasses
here
we
build
the
three
class
objects
by
running
three
class
statements
and
make
the
two
instance
objects
by
calling
the
class
c
twice
as
though
it
were
a
function
the
instances
remember
the
class
they
were
made
from
and
the
class
c
remembers
its
listed
superclasses
technically
this
example
is
using
something
called
multiple
inheritance
which
simply
means
that
a
class
has
more
than
one
superclass
above
it
in
the
class
tree
in
python
if
there
is
more
than
one
superclass
listed
in
parentheses
in
a
class
statement
like
c
s
here
their
left
to
right
order
gives
the
order
in
which
those
superclasses
will
be
searched
for
attributes
because
of
the
way
inheritance
searches
proceed
the
object
to
which
you
attach
an
attribute
turns
out
to
be
crucial
it
determines
the
name
s
scope
attributes
attached
to
instances
pertain
only
to
those
single
instances
but
attributes
attached
to
classes
are
shared
by
all
their
subclasses
and
instances
later
we
ll
study
the
code
that
hangs
attributes
on
these
objects
in
depth
as
we
ll
find
attributes
are
usually
attached
to
classes
by
assignments
made
within
class
statements
and
not
nested
inside
function
def
statements
attributes
are
usually
attached
to
instances
by
assignments
to
a
special
argument
passed
to
functions
inside
classes
called
self
for
example
classes
provide
behavior
for
their
instances
with
functions
created
by
coding
def
statements
inside
class
statements
because
such
nested
defs
assign
names
within
the
class
they
wind
up
attaching
attributes
to
the
class
object
that
will
be
inherited
by
all
instances
and
subclasses
class
c
c
c
def
setname
self
who
self
name
who
make
and
link
class
c
assign
name
c
setname
self
is
either
i
or
i
i
c
i
c
i
setname
bob
i
setname
mel
print
i
name
make
two
instances
sets
i
name
to
bob
sets
i
name
to
mel
prints
bob
oop
from
feet
there
s
nothing
syntactically
unique
about
def
in
this
context
operationally
when
a
def
appears
inside
a
class
like
this
it
is
usually
known
as
a
method
and
it
automatically
receives
a
special
first
argument
called
self
by
convention
that
provides
a
handle
back
to
the
instance
to
be
processed
because
classes
are
factories
for
multiple
instances
their
methods
usually
go
through
this
automatically
passed
in
self
argument
whenever
they
need
to
fetch
or
set
attributes
of
the
particular
instance
being
processed
by
a
method
call
in
the
preceding
code
self
is
used
to
store
a
name
in
one
of
two
instances
like
simple
variables
attributes
of
classes
and
instances
are
not
declared
ahead
of
time
but
spring
into
existence
the
first
time
they
are
assigned
values
when
a
method
assigns
to
a
self
attribute
it
creates
or
changes
an
attribute
in
an
instance
at
the
bottom
of
the
class
tree
i
e
one
of
the
rectangles
because
self
automatically
refers
to
the
instance
being
processed
in
fact
because
all
the
objects
in
class
trees
are
just
namespace
objects
we
can
fetch
or
set
any
of
their
attributes
by
going
through
the
appropriate
names
saying
c
setname
is
as
valid
as
saying
i
setname
as
long
as
the
names
c
and
i
are
in
your
code
s
scopes
as
currently
coded
our
c
class
doesn
t
attach
a
name
attribute
to
an
instance
until
the
setname
method
is
called
in
fact
referencing
i
name
before
calling
i
setname
would
produce
an
undefined
name
error
if
a
class
wants
to
guarantee
that
an
attribute
like
name
is
always
set
in
its
instances
it
more
typically
will
fill
out
the
attribute
at
construction
time
like
this
class
c
c
c
def
init
self
who
self
name
who
set
name
when
constructed
self
is
either
i
or
i
i
c
bob
i
c
mel
print
i
name
sets
i
name
to
bob
sets
i
name
to
mel
prints
bob
if
it
s
coded
and
inherited
python
automatically
calls
a
method
named
init
each
time
an
instance
is
generated
from
a
class
the
new
instance
is
passed
in
to
the
self
argument
of
init
as
usual
and
any
values
listed
in
parentheses
in
the
class
call
go
to
arguments
two
and
beyond
the
effect
here
is
to
initialize
instances
when
they
are
made
without
requiring
extra
method
calls
the
init
method
is
known
as
the
constructor
because
of
when
it
is
run
it
s
the
most
commonly
used
representative
of
a
larger
class
of
methods
called
operator
overloading
methods
which
we
ll
discuss
in
more
detail
in
the
chapters
that
follow
such
methods
are
inherited
in
class
trees
as
usual
and
have
double
underscores
at
the
start
and
end
of
their
names
to
make
them
distinct
python
runs
them
automatically
when
instances
that
support
them
appear
in
the
corresponding
operations
and
they
are
if
you
ve
ever
used
c
or
java
you
ll
recognize
that
python
s
self
is
the
same
as
the
this
pointer
but
self
is
always
explicit
in
python
to
make
attribute
accesses
more
obvious
chapter
oop
the
big
picture
mostly
an
alternative
to
using
simple
method
calls
they
re
also
optional
if
omitted
the
operations
are
not
supported
for
example
to
implement
set
intersection
a
class
might
either
provide
a
method
named
intersect
or
overload
the
expression
operator
to
dispatch
to
the
required
logic
by
coding
a
method
named
and
because
the
operator
scheme
makes
instances
look
and
feel
more
like
built
in
types
it
allows
some
classes
to
provide
a
consistent
and
natural
interface
and
be
compatible
with
code
that
expects
a
built
in
type
oop
is
about
code
reuse
and
that
along
with
a
few
syntax
details
is
most
of
the
oop
story
in
python
of
course
there
s
a
bit
more
to
it
than
just
inheritance
for
example
operator
overloading
is
much
more
general
than
i
ve
described
so
far
classes
may
also
provide
their
own
implementations
of
operations
such
as
indexing
fetching
attributes
printing
and
more
by
and
large
though
oop
is
about
looking
up
attributes
in
trees
so
why
would
we
be
interested
in
building
and
searching
trees
of
objects
although
it
takes
some
experience
to
see
how
when
used
well
classes
support
code
reuse
in
ways
that
other
python
program
components
cannot
with
classes
we
code
by
customizing
existing
software
instead
of
either
changing
existing
code
in
place
or
starting
from
scratch
for
each
new
project
at
a
fundamental
level
classes
are
really
just
packages
of
functions
and
other
names
much
like
modules
however
the
automatic
attribute
inheritance
search
that
we
get
with
classes
supports
customization
of
software
above
and
beyond
what
we
can
do
with
modules
and
functions
moreover
classes
provide
a
natural
structure
for
code
that
localizes
logic
and
names
and
so
aids
in
debugging
for
instance
because
methods
are
simply
functions
with
a
special
first
argument
we
can
mimic
some
of
their
behavior
by
manually
passing
objects
to
be
processed
to
simple
functions
the
participation
of
methods
in
class
inheritance
though
allows
us
to
naturally
customize
existing
software
by
coding
subclasses
with
new
method
definitions
rather
than
changing
existing
code
in
place
there
is
really
no
such
concept
with
modules
and
functions
as
an
example
suppose
you
re
assigned
the
task
of
implementing
an
employee
database
application
as
a
python
oop
programmer
you
might
begin
by
coding
a
general
superclass
that
defines
default
behavior
common
to
all
the
kinds
of
employees
in
your
organization
class
employee
def
computesalary
self
def
giveraise
self
def
promote
self
def
retire
self
general
superclass
common
or
default
behavior
oop
from
feet
once
you
ve
coded
this
general
behavior
you
can
specialize
it
for
each
specific
kind
of
employee
to
reflect
how
the
various
types
differ
from
the
norm
that
is
you
can
code
subclasses
that
customize
just
the
bits
of
behavior
that
differ
per
employee
type
the
rest
of
the
employee
types
behavior
will
be
inherited
from
the
more
general
class
for
example
if
engineers
have
a
unique
salary
computation
rule
i
e
not
hours
times
rate
you
can
replace
just
that
one
method
in
a
subclass
class
engineer
employee
def
computesalary
self
specialized
subclass
something
custom
here
because
the
computesalary
version
here
appears
lower
in
the
class
tree
it
will
replace
override
the
general
version
in
employee
you
then
create
instances
of
the
kinds
of
employee
classes
that
the
real
employees
belong
to
to
get
the
correct
behavior
bob
employee
mel
engineer
default
behavior
custom
salary
calculator
notice
that
you
can
make
instances
of
any
class
in
a
tree
not
just
the
ones
at
the
bottom
the
class
you
make
an
instance
from
determines
the
level
at
which
the
attribute
search
will
begin
ultimately
these
two
instance
objects
might
wind
up
embedded
in
a
larger
container
object
e
g
a
list
or
an
instance
of
another
class
that
represents
a
department
or
company
using
the
composition
idea
mentioned
at
the
start
of
this
chapter
when
you
later
ask
for
these
employees
salaries
they
will
be
computed
according
to
the
classes
from
which
the
objects
were
made
due
to
the
principles
of
the
inheritance
search
company
bob
mel
for
emp
in
company
print
emp
computesalary
a
composite
object
run
this
object
s
version
this
is
yet
another
instance
of
the
idea
of
polymorphism
introduced
in
chapter
and
revisited
in
chapter
recall
that
polymorphism
means
that
the
meaning
of
an
operation
depends
on
the
object
being
operated
on
here
the
method
computesalary
is
located
by
inheritance
search
in
each
object
before
it
is
called
in
other
applications
polymorphism
might
also
be
used
to
hide
i
e
encapsulate
interface
differences
for
example
a
program
that
processes
data
streams
might
be
coded
to
expect
objects
with
input
and
output
methods
without
caring
what
those
methods
actually
do
def
processor
reader
converter
writer
while
data
reader
read
if
not
data
break
note
that
the
company
list
in
this
example
could
be
stored
in
a
file
with
python
object
pickling
introduced
in
chapter
when
we
met
files
to
yield
a
persistent
employee
database
python
also
comes
with
a
module
named
shelve
which
would
allow
you
to
store
the
pickled
representation
of
the
class
instances
in
an
accessby
key
filesystem
the
third
party
open
source
zodb
system
does
the
same
but
has
better
support
for
production
quality
object
oriented
databases
chapter
oop
the
big
picture
data
converter
data
writer
write
data
by
passing
in
instances
of
subclasses
that
specialize
the
required
read
and
write
method
interfaces
for
various
data
sources
we
can
reuse
the
processor
function
for
any
data
source
we
need
to
use
both
now
and
in
the
future
class
reader
def
read
self
default
behavior
and
tools
def
other
self
class
filereader
reader
def
read
self
read
from
a
local
file
class
socketreader
reader
def
read
self
read
from
a
network
socket
processor
filereader
converter
filewriter
processor
socketreader
converter
tapewriter
processor
ftpreader
converter
xmlwriter
moreover
because
the
internal
implementations
of
those
read
and
write
methods
have
been
factored
into
single
locations
they
can
be
changed
without
impacting
code
such
as
this
that
uses
them
in
fact
the
processor
function
might
itself
be
a
class
to
allow
the
conversion
logic
of
converter
to
be
filled
in
by
inheritance
and
to
allow
readers
and
writers
to
be
embedded
by
composition
we
ll
see
how
this
works
later
in
this
part
of
the
book
once
you
get
used
to
programming
this
way
by
software
customization
you
ll
find
that
when
it
s
time
to
write
a
new
program
much
of
your
work
may
already
be
done
your
task
largely
becomes
one
of
mixing
together
existing
superclasses
that
already
implement
the
behavior
required
by
your
program
for
example
someone
else
might
have
written
the
employee
reader
and
writer
classes
in
this
example
for
use
in
a
completely
different
program
if
so
you
get
all
of
that
person
s
code
for
free
in
fact
in
many
application
domains
you
can
fetch
or
purchase
collections
of
superclasses
known
as
frameworks
that
implement
common
programming
tasks
as
classes
ready
to
be
mixed
into
your
applications
these
frameworks
might
provide
database
interfaces
testing
protocols
gui
toolkits
and
so
on
with
frameworks
you
often
simply
code
a
subclass
that
fills
in
an
expected
method
or
two
the
framework
classes
higher
in
the
tree
do
most
of
the
work
for
you
programming
in
such
an
oop
world
is
just
a
matter
of
combining
and
specializing
already
debugged
code
by
writing
subclasses
of
your
own
of
course
it
takes
a
while
to
learn
how
to
leverage
classes
to
achieve
such
oop
utopia
in
practice
object
oriented
work
also
entails
substantial
design
work
to
fully
realize
the
code
reuse
benefits
of
classes
to
this
end
programmers
have
begun
cataloging
common
oop
structures
known
as
design
patterns
to
help
with
design
issues
the
actual
code
you
write
to
do
oop
in
python
though
is
so
simple
that
it
will
not
in
itself
pose
an
additional
obstacle
to
your
oop
quest
to
see
why
you
ll
have
to
move
on
to
chapter
oop
from
feet
chapter
summary
we
took
an
abstract
look
at
classes
and
oop
in
this
chapter
taking
in
the
big
picture
before
we
dive
into
syntax
details
as
we
ve
seen
oop
is
mostly
about
looking
up
attributes
in
trees
of
linked
objects
we
call
this
lookup
an
inheritance
search
objects
at
the
bottom
of
the
tree
inherit
attributes
from
objects
higher
up
in
the
tree
a
feature
that
enables
us
to
program
by
customizing
code
rather
than
changing
it
or
starting
from
scratch
when
used
well
this
model
of
programming
can
cut
development
time
radically
the
next
chapter
will
begin
to
fill
in
the
coding
details
behind
the
picture
painted
here
as
we
get
deeper
into
python
classes
though
keep
in
mind
that
the
oop
model
in
python
is
very
simple
as
i
ve
already
stated
it
s
really
just
about
looking
up
attributes
in
object
trees
before
we
move
on
here
s
a
quick
quiz
to
review
what
we
ve
covered
here
test
your
knowledge
quiz
what
is
the
main
point
of
oop
in
python
where
does
an
inheritance
search
look
for
an
attribute
what
is
the
difference
between
a
class
object
and
an
instance
object
why
is
the
first
argument
in
a
class
method
function
special
what
is
the
init
method
used
for
how
do
you
create
a
class
instance
how
do
you
create
a
class
how
do
you
specify
a
class
s
superclasses
test
your
knowledge
answers
oop
is
about
code
reuse
you
factor
code
to
minimize
redundancy
and
program
by
customizing
what
already
exists
instead
of
changing
code
in
place
or
starting
from
scratch
an
inheritance
search
looks
for
an
attribute
first
in
the
instance
object
then
in
the
class
the
instance
was
created
from
then
in
all
higher
superclasses
progressing
from
the
bottom
to
the
top
of
the
object
tree
and
from
left
to
right
by
default
the
search
stops
at
the
first
place
the
attribute
is
found
because
the
lowest
version
of
a
name
found
along
the
way
wins
class
hierarchies
naturally
support
customization
by
extension
chapter
oop
the
big
picture
both
class
and
instance
objects
are
namespaces
packages
of
variables
that
appear
as
attributes
the
main
difference
between
them
is
that
classes
are
a
kind
of
factory
for
creating
multiple
instances
classes
also
support
operator
overloading
methods
which
instances
inherit
and
treat
any
functions
nested
within
them
as
special
methods
for
processing
instances
the
first
argument
in
a
class
method
function
is
special
because
it
always
receives
the
instance
object
that
is
the
implied
subject
of
the
method
call
it
s
usually
called
self
by
convention
because
method
functions
always
have
this
implied
subject
object
context
by
default
we
say
they
are
object
oriented
i
e
designed
to
process
or
change
objects
if
the
init
method
is
coded
or
inherited
in
a
class
python
calls
it
automatically
each
time
an
instance
of
that
class
is
created
it
s
known
as
the
constructor
method
it
is
passed
the
new
instance
implicitly
as
well
as
any
arguments
passed
explicitly
to
the
class
name
it
s
also
the
most
commonly
used
operator
overloading
method
if
no
init
method
is
present
instances
simply
begin
life
as
empty
namespaces
you
create
a
class
instance
by
calling
the
class
name
as
though
it
were
a
function
any
arguments
passed
into
the
class
name
show
up
as
arguments
two
and
beyond
in
the
init
constructor
method
the
new
instance
remembers
the
class
it
was
created
from
for
inheritance
purposes
you
create
a
class
by
running
a
class
statement
like
function
definitions
these
statements
normally
run
when
the
enclosing
module
file
is
imported
more
on
this
in
the
next
chapter
you
specify
a
class
s
superclasses
by
listing
them
in
parentheses
in
the
class
statement
after
the
new
class
s
name
the
left
to
right
order
in
which
the
classes
are
listed
in
the
parentheses
gives
the
left
to
right
inheritance
search
order
in
the
class
tree
test
your
knowledge
answers
chapter
class
coding
basics
now
that
we
ve
talked
about
oop
in
the
abstract
it
s
time
to
see
how
this
translates
to
actual
code
this
chapter
begins
to
fill
in
the
syntax
details
behind
the
class
model
in
python
if
you
ve
never
been
exposed
to
oop
in
the
past
classes
can
seem
somewhat
complicated
if
taken
in
a
single
dose
to
make
class
coding
easier
to
absorb
we
ll
begin
our
detailed
exploration
of
oop
by
taking
a
first
look
at
some
basic
classes
in
action
in
this
chapter
we
ll
expand
on
the
details
introduced
here
in
later
chapters
of
this
part
of
the
book
but
in
their
basic
form
python
classes
are
easy
to
understand
in
fact
classes
have
just
three
primary
distinctions
at
a
base
level
they
are
mostly
just
namespaces
much
like
the
modules
we
studied
in
part
v
unlike
modules
though
classes
also
have
support
for
generating
multiple
objects
for
namespace
inheritance
and
for
operator
overloading
let
s
begin
our
class
statement
tour
by
exploring
each
of
these
three
distinctions
in
turn
classes
generate
multiple
instance
objects
to
understand
how
the
multiple
objects
idea
works
you
have
to
first
understand
that
there
are
two
kinds
of
objects
in
python
s
oop
model
class
objects
and
instance
objects
class
objects
provide
default
behavior
and
serve
as
factories
for
instance
objects
instance
objects
are
the
real
objects
your
programs
process
each
is
a
namespace
in
its
own
right
but
inherits
i
e
has
automatic
access
to
names
in
the
class
from
which
it
was
created
class
objects
come
from
statements
and
instances
come
from
calls
each
time
you
call
a
class
you
get
a
new
instance
of
that
class
this
object
generation
concept
is
very
different
from
any
of
the
other
program
constructs
we
ve
seen
so
far
in
this
book
in
effect
classes
are
essentially
factories
for
generating
multiple
instances
by
contrast
only
one
copy
of
each
module
is
ever
imported
into
a
single
program
in
fact
one
reason
that
we
have
to
call
imp
reload
is
to
update
the
single
module
object
so
that
changes
are
reflected
once
they
ve
been
made
the
following
is
a
quick
summary
of
the
bare
essentials
of
python
oop
as
you
ll
see
python
classes
are
in
some
ways
similar
to
both
defs
and
modules
but
they
may
be
quite
different
from
what
you
re
used
to
in
other
languages
class
objects
provide
default
behavior
when
we
run
a
class
statement
we
get
a
class
object
here
s
a
rundown
of
the
main
properties
of
python
classes
the
class
statement
creates
a
class
object
and
assigns
it
a
name
just
like
the
function
def
statement
the
python
class
statement
is
an
executable
statement
when
reached
and
run
it
generates
a
new
class
object
and
assigns
it
to
the
name
in
the
class
header
also
like
defs
class
statements
typically
run
when
the
files
they
are
coded
in
are
first
imported
assignments
inside
class
statements
make
class
attributes
just
like
in
module
files
top
level
assignments
within
a
class
statement
not
nested
in
a
def
generate
attributes
in
a
class
object
technically
the
class
statement
scope
morphs
into
the
attribute
namespace
of
the
class
object
just
like
a
module
s
global
scope
after
running
a
class
statement
class
attributes
are
accessed
by
name
qualification
object
name
class
attributes
provide
object
state
and
behavior
attributes
of
a
class
object
record
state
information
and
behavior
to
be
shared
by
all
instances
created
from
the
class
function
def
statements
nested
inside
a
class
generate
methods
which
process
instances
instance
objects
are
concrete
items
when
we
call
a
class
object
we
get
an
instance
object
here
s
an
overview
of
the
key
points
behind
class
instances
calling
a
class
object
like
a
function
makes
a
new
instance
object
each
time
a
class
is
called
it
creates
and
returns
a
new
instance
object
instances
represent
concrete
items
in
your
program
s
domain
each
instance
object
inherits
class
attributes
and
gets
its
own
namespace
instance
objects
created
from
classes
are
new
namespaces
they
start
out
empty
but
inherit
attributes
that
live
in
the
class
objects
from
which
they
were
generated
chapter
class
coding
basics
assignments
to
attributes
of
self
in
methods
make
per
instance
attributes
inside
class
method
functions
the
first
argument
called
self
by
convention
references
the
instance
object
being
processed
assignments
to
attributes
of
self
create
or
change
data
in
the
instance
not
the
class
a
first
example
let
s
turn
to
a
real
example
to
show
how
these
ideas
work
in
practice
to
begin
let
s
define
a
class
named
firstclass
by
running
a
python
class
statement
interactively
class
firstclass
def
setdata
self
value
self
data
value
def
display
self
print
self
data
define
a
class
object
define
class
methods
self
is
the
instance
self
data
per
instance
we
re
working
interactively
here
but
typically
such
a
statement
would
be
run
when
the
module
file
it
is
coded
in
is
imported
like
functions
created
with
defs
this
class
won
t
even
exist
until
python
reaches
and
runs
this
statement
like
all
compound
statements
the
class
starts
with
a
header
line
that
lists
the
class
name
followed
by
a
body
of
one
or
more
nested
and
usually
indented
statements
here
the
nested
statements
are
defs
they
define
functions
that
implement
the
behavior
the
class
means
to
export
as
we
learned
in
part
iv
def
is
really
an
assignment
here
it
assigns
function
objects
to
the
names
setdata
and
display
in
the
class
statement
s
scope
and
so
generates
attributes
attached
to
the
class
firstclass
setdata
and
firstclass
display
in
fact
any
name
assigned
at
the
top
level
of
the
class
s
nested
block
becomes
an
attribute
of
the
class
functions
inside
a
class
are
usually
called
methods
they
re
coded
with
normal
defs
and
they
support
everything
we
ve
learned
about
functions
already
they
can
have
defaults
return
values
and
so
on
but
in
a
method
function
the
first
argument
automatically
receives
an
implied
instance
object
when
called
the
subject
of
the
call
we
need
to
create
a
couple
of
instances
to
see
how
this
works
x
firstclass
y
firstclass
make
two
instances
each
is
a
new
namespace
by
calling
the
class
this
way
notice
the
parentheses
we
generate
instance
objects
which
are
just
namespaces
that
have
access
to
their
classes
attributes
properly
speaking
at
this
point
we
have
three
objects
two
instances
and
a
class
really
we
have
three
linked
namespaces
as
sketched
in
figure
in
oop
terms
we
say
that
x
is
a
firstclass
as
is
y
classes
generate
multiple
instance
objects
figure
classes
and
instances
are
linked
namespace
objects
in
a
class
tree
that
is
searched
by
inheritance
here
the
data
attribute
is
found
in
instances
but
setdata
and
display
are
in
the
class
above
them
the
two
instances
start
out
empty
but
have
links
back
to
the
class
from
which
they
were
generated
if
we
qualify
an
instance
with
the
name
of
an
attribute
that
lives
in
the
class
object
python
fetches
the
name
from
the
class
by
inheritance
search
unless
it
also
lives
in
the
instance
x
setdata
king
arthur
y
setdata
call
methods
self
is
x
runs
firstclass
setdata
y
neither
x
nor
y
has
a
setdata
attribute
of
its
own
so
to
find
it
python
follows
the
link
from
instance
to
class
and
that
s
about
all
there
is
to
inheritance
in
python
it
happens
at
attribute
qualification
time
and
it
just
involves
looking
up
names
in
linked
objects
e
g
by
following
the
is
a
links
in
figure
in
the
setdata
function
inside
firstclass
the
value
passed
in
is
assigned
to
self
data
within
a
method
self
the
name
given
to
the
leftmost
argument
by
convention
automatically
refers
to
the
instance
being
processed
x
or
y
so
the
assignments
store
values
in
the
instances
namespaces
not
the
class
s
that
s
how
the
data
names
in
figure
are
created
because
classes
can
generate
multiple
instances
methods
must
go
through
the
self
argument
to
get
to
the
instance
to
be
processed
when
we
call
the
class
s
display
method
to
print
self
data
we
see
that
it
s
different
in
each
instance
on
the
other
hand
the
name
display
itself
is
the
same
in
x
and
y
as
it
comes
is
inherited
from
the
class
x
display
king
arthur
y
display
self
data
differs
in
each
instance
notice
that
we
stored
different
object
types
in
the
data
member
in
each
instance
a
string
and
a
floating
point
as
with
everything
else
in
python
there
are
no
declarations
for
instance
attributes
sometimes
called
members
they
spring
into
existence
the
first
time
they
are
assigned
values
just
like
simple
variables
in
fact
if
we
were
to
call
display
on
one
of
our
instances
before
calling
setdata
we
would
trigger
an
undefined
name
error
the
attribute
named
data
doesn
t
even
exist
in
memory
until
it
is
assigned
within
the
setdata
method
chapter
class
coding
basics
as
another
way
to
appreciate
how
dynamic
this
model
is
consider
that
we
can
change
instance
attributes
in
the
class
itself
by
assigning
to
self
in
methods
or
outside
the
class
by
assigning
to
an
explicit
instance
object
x
data
new
value
x
display
new
value
can
get
set
attributes
outside
the
class
too
although
less
common
we
could
even
generate
a
brand
new
attribute
in
the
instance
s
namespace
by
assigning
to
its
name
outside
the
class
s
method
functions
x
anothername
spam
can
set
new
attributes
here
too
this
would
attach
a
new
attribute
called
anothername
which
may
or
may
not
be
used
by
any
of
the
class
s
methods
to
the
instance
object
x
classes
usually
create
all
of
the
instance
s
attributes
by
assignment
to
the
self
argument
but
they
don
t
have
to
programs
can
fetch
change
or
create
attributes
on
any
objects
to
which
they
have
references
classes
are
customized
by
inheritance
besides
serving
as
factories
for
generating
multiple
instance
objects
classes
also
allow
us
to
make
changes
by
introducing
new
components
called
subclasses
instead
of
changing
existing
components
in
place
instance
objects
generated
from
a
class
inherit
the
class
s
attributes
python
also
allows
classes
to
inherit
from
other
classes
opening
the
door
to
coding
hierarchies
of
classes
that
specialize
behavior
by
redefining
attributes
in
subclasses
that
appear
lower
in
the
hierarchy
we
override
the
more
general
definitions
of
those
attributes
higher
in
the
tree
in
effect
the
further
down
the
hierarchy
we
go
the
more
specific
the
software
becomes
here
too
there
is
no
parallel
with
modules
their
attributes
live
in
a
single
flat
namespace
that
is
not
as
amenable
to
customization
in
python
instances
inherit
from
classes
and
classes
inherit
from
superclasses
here
are
the
key
ideas
behind
the
machinery
of
attribute
inheritance
superclasses
are
listed
in
parentheses
in
a
class
header
to
inherit
attributes
from
another
class
just
list
the
class
in
parentheses
in
a
class
statement
s
header
the
class
that
inherits
is
usually
called
a
subclass
and
the
class
that
is
inherited
from
is
its
superclass
classes
inherit
attributes
from
their
superclasses
just
as
instances
inherit
the
attribute
names
defined
in
their
classes
classes
inherit
all
the
attribute
names
defined
in
their
superclasses
python
finds
them
automatically
when
they
re
accessed
if
they
don
t
exist
in
the
subclasses
instances
inherit
attributes
from
all
accessible
classes
each
instance
gets
names
from
the
class
it
s
generated
from
as
well
as
all
of
that
class
s
superclasses
when
looking
for
a
name
python
checks
the
instance
then
its
class
then
all
superclasses
classes
are
customized
by
inheritance
each
object
attribute
reference
invokes
a
new
independent
search
python
performs
an
independent
search
of
the
class
tree
for
each
attribute
fetch
expression
this
includes
references
to
instances
and
classes
made
outside
class
statements
e
g
x
attr
as
well
as
references
to
attributes
of
the
self
instance
argument
in
class
method
functions
each
self
attr
expression
in
a
method
invokes
a
new
search
for
attr
in
self
and
above
logic
changes
are
made
by
subclassing
not
by
changing
superclasses
by
redefining
superclass
names
in
subclasses
lower
in
the
hierarchy
class
tree
subclasses
replace
and
thus
customize
inherited
behavior
the
net
effect
and
the
main
purpose
of
all
this
searching
is
that
classes
support
factoring
and
customization
of
code
better
than
any
other
language
tool
we
ve
seen
so
far
on
the
one
hand
they
allow
us
to
minimize
code
redundancy
and
so
reduce
maintenance
costs
by
factoring
operations
into
a
single
shared
implementation
on
the
other
they
allow
us
to
program
by
customizing
what
already
exists
rather
than
changing
it
in
place
or
starting
from
scratch
a
second
example
to
illustrate
the
role
of
inheritance
this
next
example
builds
on
the
previous
one
first
we
ll
define
a
new
class
secondclass
that
inherits
all
of
firstclass
s
names
and
provides
one
of
its
own
class
secondclass
firstclass
inherits
setdata
def
display
self
changes
display
print
current
value
s
self
data
secondclass
defines
the
display
method
to
print
with
a
different
format
by
defining
an
attribute
with
the
same
name
as
an
attribute
in
firstclass
secondclass
effectively
replaces
the
display
attribute
in
its
superclass
recall
that
inheritance
searches
proceed
upward
from
instances
to
subclasses
to
superclasses
stopping
at
the
first
appearance
of
the
attribute
name
that
it
finds
in
this
case
since
the
display
name
in
secondclass
will
be
found
before
the
one
in
first
class
we
say
that
secondclass
overrides
firstclass
s
display
sometimes
we
call
this
act
of
replacing
attributes
by
redefining
them
lower
in
the
tree
overloading
the
net
effect
here
is
that
secondclass
specializes
firstclass
by
changing
the
behavior
of
the
display
method
on
the
other
hand
secondclass
and
any
instances
created
from
it
still
inherits
the
setdata
method
in
firstclass
verbatim
let
s
make
an
instance
to
demonstrate
z
secondclass
z
setdata
z
display
current
value
chapter
class
coding
basics
finds
setdata
in
firstclass
finds
overridden
method
in
secondclass
as
before
we
make
a
secondclass
instance
object
by
calling
it
the
setdata
call
still
runs
the
version
in
firstclass
but
this
time
the
display
attribute
comes
from
second
class
and
prints
a
custom
message
figure
sketches
the
namespaces
involved
figure
specialization
by
overriding
inherited
names
by
redefining
them
in
extensions
lower
in
the
class
tree
here
secondclass
redefines
and
so
customizes
the
display
method
for
its
instances
now
here
s
a
very
important
thing
to
notice
about
oop
the
specialization
introduced
in
secondclass
is
completely
external
to
firstclass
that
is
it
doesn
t
affect
existing
or
future
firstclass
objects
like
the
x
from
the
prior
example
x
display
new
value
x
is
still
a
firstclass
instance
old
message
rather
than
changing
firstclass
we
customized
it
naturally
this
is
an
artificial
example
but
as
a
rule
because
inheritance
allows
us
to
make
changes
like
this
in
external
components
i
e
in
subclasses
classes
often
support
extension
and
reuse
better
than
functions
or
modules
can
classes
are
attributes
in
modules
before
we
move
on
remember
that
there
s
nothing
magic
about
a
class
name
it
s
just
a
variable
assigned
to
an
object
when
the
class
statement
runs
and
the
object
can
be
referenced
with
any
normal
expression
for
instance
if
our
firstclass
was
coded
in
a
module
file
instead
of
being
typed
interactively
we
could
import
it
and
use
its
name
normally
in
a
class
header
line
from
modulename
import
firstclass
class
secondclass
firstclass
def
display
self
copy
name
into
my
scope
use
class
name
directly
or
equivalently
import
modulename
class
secondclass
modulename
firstclass
def
display
self
access
the
whole
module
qualify
to
reference
classes
are
customized
by
inheritance
like
everything
else
class
names
always
live
within
a
module
so
they
must
follow
all
the
rules
we
studied
in
part
v
for
example
more
than
one
class
can
be
coded
in
a
single
module
file
like
other
statements
in
a
module
class
statements
are
run
during
imports
to
define
names
and
these
names
become
distinct
module
attributes
more
generally
each
module
may
arbitrarily
mix
any
number
of
variables
functions
and
classes
and
all
names
in
a
module
behave
the
same
way
the
file
food
py
demonstrates
food
py
var
def
func
class
spam
class
ham
class
eggs
food
var
food
func
food
spam
food
ham
food
eggs
this
holds
true
even
if
the
module
and
class
happen
to
have
the
same
name
for
example
given
the
following
file
person
py
class
person
we
need
to
go
through
the
module
to
fetch
the
class
as
usual
import
person
x
person
person
import
module
class
within
module
although
this
path
may
look
redundant
it
s
required
person
person
refers
to
the
person
class
inside
the
person
module
saying
just
person
gets
the
module
not
the
class
unless
the
from
statement
is
used
from
person
import
person
x
person
get
class
from
module
use
class
name
as
with
any
other
variable
we
can
never
see
a
class
in
a
file
without
first
importing
and
somehow
fetching
it
from
its
enclosing
file
if
this
seems
confusing
don
t
use
the
same
name
for
a
module
and
a
class
within
it
in
fact
common
convention
in
python
dictates
that
class
names
should
begin
with
an
uppercase
letter
to
help
make
them
more
distinct
import
person
x
person
person
lowercase
for
modules
uppercase
for
classes
also
keep
in
mind
that
although
classes
and
modules
are
both
namespaces
for
attaching
attributes
they
correspond
to
very
different
source
code
structures
a
module
reflects
an
entire
file
but
a
class
is
a
statement
within
a
file
we
ll
say
more
about
such
distinctions
later
in
this
part
of
the
book
chapter
class
coding
basics
classes
can
intercept
python
operators
let
s
move
on
to
the
third
major
difference
between
classes
and
modules
operator
overloading
in
simple
terms
operator
overloading
lets
objects
coded
with
classes
intercept
and
respond
to
operations
that
work
on
built
in
types
addition
slicing
printing
qualification
and
so
on
it
s
mostly
just
an
automatic
dispatch
mechanism
expressions
and
other
built
in
operations
route
control
to
implementations
in
classes
here
too
there
is
nothing
similar
in
modules
modules
can
implement
function
calls
but
not
the
behavior
of
expressions
although
we
could
implement
all
class
behavior
as
method
functions
operator
overloading
lets
objects
be
more
tightly
integrated
with
python
s
object
model
moreover
because
operator
overloading
makes
our
own
objects
act
like
built
ins
it
tends
to
foster
object
interfaces
that
are
more
consistent
and
easier
to
learn
and
it
allows
class
based
objects
to
be
processed
by
code
written
to
expect
a
built
in
type
s
interface
here
is
a
quick
rundown
of
the
main
ideas
behind
overloading
operators
methods
named
with
double
underscores
x
are
special
hooks
python
operator
overloading
is
implemented
by
providing
specially
named
methods
to
intercept
operations
the
python
language
defines
a
fixed
and
unchangeable
mapping
from
each
of
these
operations
to
a
specially
named
method
such
methods
are
called
automatically
when
instances
appear
in
built
in
operations
for
instance
if
an
instance
object
inherits
an
add
method
that
method
is
called
whenever
the
object
appears
in
a
expression
the
method
s
return
value
becomes
the
result
of
the
corresponding
expression
classes
may
override
most
built
in
type
operations
there
are
dozens
of
special
operator
overloading
method
names
for
intercepting
and
implementing
nearly
every
operation
available
for
built
in
types
this
includes
expressions
but
also
basic
operations
like
printing
and
object
creation
there
are
no
defaults
for
operator
overloading
methods
and
none
are
required
if
a
class
does
not
define
or
inherit
an
operator
overloading
method
it
just
means
that
the
corresponding
operation
is
not
supported
for
the
class
s
instances
if
there
is
no
add
for
example
expressions
raise
exceptions
operators
allow
classes
to
integrate
with
python
s
object
model
by
overloading
type
operations
user
defined
objects
implemented
with
classes
can
act
just
like
built
ins
and
so
provide
consistency
as
well
as
compatibility
with
expected
interfaces
operator
overloading
is
an
optional
feature
it
s
used
primarily
by
people
developing
tools
for
other
python
programmers
not
by
application
developers
and
candidly
you
probably
shouldn
t
try
to
use
it
just
because
it
seems
cool
unless
a
class
needs
to
mimic
built
in
type
interfaces
it
should
usually
stick
to
simpler
named
methods
why
would
an
employee
database
application
support
expressions
like
and
for
example
named
methods
like
giveraise
and
promote
would
usually
make
more
sense
classes
can
intercept
python
operators
because
of
this
we
won
t
go
into
details
on
every
operator
overloading
method
available
in
python
in
this
book
still
there
is
one
operator
overloading
method
you
are
likely
to
see
in
almost
every
realistic
python
class
the
init
method
which
is
known
as
the
constructor
method
and
is
used
to
initialize
objects
state
you
should
pay
special
attention
to
this
method
because
init
along
with
the
self
argument
turns
out
to
be
a
key
requirement
to
understanding
most
oop
code
in
python
a
third
example
on
to
another
example
this
time
we
ll
define
a
subclass
of
secondclass
that
implements
three
specially
named
attributes
that
python
will
call
automatically
init
is
run
when
a
new
instance
object
is
created
self
is
the
new
thirdclass
object
add
is
run
when
a
thirdclass
instance
appears
in
a
expression
str
is
run
when
an
object
is
printed
technically
when
it
s
converted
to
its
print
string
by
the
str
built
in
function
or
its
python
internals
equivalent
our
new
subclass
also
defines
a
normally
named
method
named
mul
which
changes
the
instance
object
in
place
here
s
the
new
subclass
class
thirdclass
secondclass
inherit
from
secondclass
def
init
self
value
on
thirdclass
value
self
data
value
def
add
self
other
on
self
other
return
thirdclass
self
data
other
def
str
self
on
print
self
str
return
thirdclass
s
self
data
def
mul
self
other
in
place
change
named
self
data
other
a
thirdclass
abc
init
called
a
display
inherited
method
called
current
value
abc
print
a
str
returns
display
string
thirdclass
abc
b
a
xyz
b
display
current
value
abcxyz
print
b
thirdclass
abcxyz
add
makes
a
new
instance
b
has
all
thirdclass
methods
a
mul
print
a
thirdclass
abcabcabc
mul
changes
instance
in
place
str
returns
display
string
not
to
be
confused
with
the
init
py
files
in
module
packages
see
chapter
for
more
details
chapter
class
coding
basics
thirdclass
is
a
secondclass
so
its
instances
inherit
the
customized
display
method
from
secondclass
this
time
though
thirdclass
creation
calls
pass
an
argument
e
g
abc
this
argument
is
passed
to
the
value
argument
in
the
init
constructor
and
assigned
to
self
data
there
the
net
effect
is
that
thirdclass
arranges
to
set
the
data
attribute
automatically
at
construction
time
instead
of
requiring
setdata
calls
after
the
fact
further
thirdclass
objects
can
now
show
up
in
expressions
and
print
calls
for
python
passes
the
instance
object
on
the
left
to
the
self
argument
in
add
and
the
value
on
the
right
to
other
as
illustrated
in
figure
whatever
add
returns
becomes
the
result
of
the
expression
for
print
python
passes
the
object
being
printed
to
self
in
str
whatever
string
this
method
returns
is
taken
to
be
the
print
string
for
the
object
with
str
we
can
use
a
normal
print
to
display
objects
of
this
class
instead
of
calling
the
special
display
method
figure
in
operator
overloading
expression
operators
and
other
built
in
operations
performed
on
class
instances
are
mapped
back
to
specially
named
methods
in
the
class
these
special
methods
are
optional
and
may
be
inherited
as
usual
here
a
expression
triggers
the
add
method
specially
named
methods
such
as
init
add
and
str
are
inherited
by
subclasses
and
instances
just
like
any
other
names
assigned
in
a
class
if
they
re
not
coded
in
a
class
python
looks
for
such
names
in
all
its
superclasses
as
usual
operator
overloading
method
names
are
also
not
built
in
or
reserved
words
they
are
just
attributes
that
python
looks
for
when
objects
appear
in
various
contexts
python
usually
calls
them
automatically
but
they
may
occasionally
be
called
by
your
code
as
well
the
init
method
for
example
is
often
called
manually
to
trigger
superclass
constructors
more
on
this
later
notice
that
the
add
method
makes
and
returns
a
new
instance
object
of
its
class
by
calling
thirdclass
with
the
result
value
by
contrast
mul
changes
the
current
instance
object
in
place
by
reassigning
the
self
attribute
we
could
overload
the
expression
to
do
the
latter
but
this
would
be
too
different
from
the
behavior
of
for
built
in
types
such
as
numbers
and
strings
for
which
it
always
makes
new
objects
common
practice
dictates
that
overloaded
operators
should
work
the
same
way
that
built
in
operator
implementations
do
because
operator
overloading
is
really
just
an
expression
tomethod
dispatch
mechanism
though
you
can
interpret
operators
any
way
you
like
in
your
own
class
objects
classes
can
intercept
python
operators
why
use
operator
overloading
as
a
class
designer
you
can
choose
to
use
operator
overloading
or
not
your
choice
simply
depends
on
how
much
you
want
your
object
to
look
and
feel
like
built
in
types
as
mentioned
earlier
if
you
omit
an
operator
overloading
method
and
do
not
inherit
it
from
a
superclass
the
corresponding
operation
will
not
be
supported
for
your
instances
if
it
s
attempted
an
exception
will
be
thrown
or
a
standard
default
will
be
used
frankly
many
operator
overloading
methods
tend
to
be
used
only
when
implementing
objects
that
are
mathematical
in
nature
a
vector
or
matrix
class
may
overload
the
addition
operator
for
example
but
an
employee
class
likely
would
not
for
simpler
classes
you
might
not
use
overloading
at
all
and
would
rely
instead
on
explicit
method
calls
to
implement
your
objects
behavior
on
the
other
hand
you
might
decide
to
use
operator
overloading
if
you
need
to
pass
a
user
defined
object
to
a
function
that
was
coded
to
expect
the
operators
available
on
a
built
in
type
like
a
list
or
a
dictionary
implementing
the
same
operator
set
in
your
class
will
ensure
that
your
objects
support
the
same
expected
object
interface
and
so
are
compatible
with
the
function
although
we
won
t
cover
every
operator
overloading
method
in
this
book
we
ll
see
some
additional
operator
overloading
techniques
in
action
in
chapter
one
overloading
method
we
will
explore
here
is
the
init
constructor
method
which
seems
to
show
up
in
almost
every
realistic
class
because
it
allows
classes
to
fill
out
the
attributes
in
their
newly
created
instances
immediately
the
constructor
is
useful
for
almost
every
kind
of
class
you
might
code
in
fact
even
though
instance
attributes
are
not
declared
in
python
you
can
usually
find
out
which
attributes
an
instance
will
have
by
inspecting
its
class
s
init
method
the
world
s
simplest
python
class
we
ve
begun
studying
class
statement
syntax
in
detail
in
this
chapter
but
i
d
again
like
to
remind
you
that
the
basic
inheritance
model
that
classes
produce
is
very
simple
all
it
really
involves
is
searching
for
attributes
in
trees
of
linked
objects
in
fact
we
can
create
a
class
with
nothing
in
it
at
all
the
following
statement
makes
a
class
with
no
attributes
attached
an
empty
namespace
object
class
rec
pass
empty
namespace
object
we
need
the
no
operation
pass
statement
discussed
in
chapter
here
because
we
don
t
have
any
methods
to
code
after
we
make
the
class
by
running
this
statement
interactively
we
can
start
attaching
attributes
to
the
class
by
assigning
names
to
it
completely
outside
of
the
original
class
statement
rec
name
bob
rec
age
chapter
class
coding
basics
just
objects
with
attributes
and
after
we
ve
created
these
attributes
by
assignment
we
can
fetch
them
with
the
usual
syntax
when
used
this
way
a
class
is
roughly
similar
to
a
struct
in
c
or
a
record
in
pascal
it
s
basically
an
object
with
field
names
attached
to
it
we
can
do
similar
work
with
dictionary
keys
but
it
requires
extra
characters
print
rec
name
bob
like
a
c
struct
or
a
record
notice
that
this
works
even
though
there
are
no
instances
of
the
class
yet
classes
are
objects
in
their
own
right
even
without
instances
in
fact
they
are
just
self
contained
namespaces
so
as
long
as
we
have
a
reference
to
a
class
we
can
set
or
change
its
attributes
anytime
we
wish
watch
what
happens
when
we
do
create
two
instances
though
x
rec
y
rec
instances
inherit
class
names
these
instances
begin
their
lives
as
completely
empty
namespace
objects
because
they
remember
the
class
from
which
they
were
made
though
they
will
obtain
the
attributes
we
attached
to
the
class
by
inheritance
x
name
y
name
bob
bob
name
is
stored
on
the
class
only
really
these
instances
have
no
attributes
of
their
own
they
simply
fetch
the
name
attribute
from
the
class
object
where
it
is
stored
if
we
do
assign
an
attribute
to
an
instance
though
it
creates
or
changes
the
attribute
in
that
object
and
no
other
attribute
references
kick
off
inheritance
searches
but
attribute
assignments
affect
only
the
objects
in
which
the
assignments
are
made
here
x
gets
its
own
name
but
y
still
inherits
the
name
attached
to
the
class
above
it
x
name
sue
rec
name
x
name
y
name
bob
sue
bob
but
assignment
changes
x
only
in
fact
as
we
ll
explore
in
more
detail
in
chapter
the
attributes
of
a
namespace
object
are
usually
implemented
as
dictionaries
and
class
inheritance
trees
are
generally
speaking
just
dictionaries
with
links
to
other
dictionaries
if
you
know
where
to
look
you
can
see
this
explicitly
for
example
the
dict
attribute
is
the
namespace
dictionary
for
most
class
based
objects
some
classes
may
also
define
attributes
in
slots
an
advanced
and
seldomused
feature
that
we
ll
study
in
chapters
and
the
following
was
run
in
python
the
order
of
names
and
set
of
x
internal
names
present
can
vary
from
release
to
release
but
the
names
we
assigned
are
present
in
all
rec
dict
keys
module
name
age
dict
weakref
doc
list
x
dict
keys
name
the
world
s
simplest
python
class
list
y
dict
keys
list
not
required
in
python
here
the
class
s
namespace
dictionary
shows
the
name
and
age
attributes
we
assigned
to
it
x
has
its
own
name
and
y
is
still
empty
each
instance
has
a
link
to
its
class
for
inheritance
though
it
s
called
class
if
you
want
to
inspect
it
x
class
class
main
rec
classes
also
have
a
bases
attribute
which
is
a
tuple
of
their
superclasses
rec
bases
class
object
empty
tuple
in
python
these
two
attributes
are
how
class
trees
are
literally
represented
in
memory
by
python
the
main
point
to
take
away
from
this
look
under
the
hood
is
that
python
s
class
model
is
extremely
dynamic
classes
and
instances
are
just
namespace
objects
with
attributes
created
on
the
fly
by
assignment
those
assignments
usually
happen
within
the
class
statements
you
code
but
they
can
occur
anywhere
you
have
a
reference
to
one
of
the
objects
in
the
tree
even
methods
normally
created
by
a
def
nested
in
a
class
can
be
created
completely
independently
of
any
class
object
the
following
for
example
defines
a
simple
function
outside
of
any
class
that
takes
one
argument
def
uppername
self
return
self
name
upper
still
needs
a
self
there
is
nothing
about
a
class
here
yet
it
s
a
simple
function
and
it
can
be
called
as
such
at
this
point
provided
we
pass
in
an
object
with
a
name
attribute
the
name
self
does
not
make
this
special
in
any
way
uppername
x
sue
call
as
a
simple
function
if
we
assign
this
simple
function
to
an
attribute
of
our
class
though
it
becomes
a
method
callable
through
any
instance
as
well
as
through
the
class
name
itself
as
long
as
we
pass
in
an
instance
manually
rec
method
uppername
x
method
sue
run
method
to
process
x
y
method
bob
same
but
pass
y
to
self
in
fact
this
is
one
of
the
reasons
the
self
argument
must
always
be
explicit
in
python
methods
because
methods
can
be
created
as
simple
functions
independent
of
a
class
they
need
to
make
the
implied
instance
argument
explicit
they
can
be
called
as
either
functions
or
methods
and
python
can
neither
guess
nor
assume
that
a
simple
function
might
eventually
become
a
class
method
the
main
reason
for
the
explicit
self
argument
though
is
to
make
the
meanings
of
names
more
obvious
names
not
referenced
through
self
are
simple
variables
while
names
referenced
through
self
are
obviously
instance
attributes
chapter
class
coding
basics
rec
method
x
sue
can
call
through
instance
or
class
normally
classes
are
filled
out
by
class
statements
and
instance
attributes
are
created
by
assignments
to
self
attributes
in
method
functions
the
point
again
though
is
that
they
don
t
have
to
be
oop
in
python
really
is
mostly
about
looking
up
attributes
in
linked
namespace
objects
classes
versus
dictionaries
although
the
simple
classes
of
the
prior
section
are
meant
to
illustrate
class
model
basics
the
techniques
they
employ
can
also
be
used
for
real
work
for
example
chapter
showed
how
to
use
dictionaries
to
record
properties
of
entities
in
our
programs
it
turns
out
that
classes
can
serve
this
role
too
they
package
information
like
dictionaries
but
can
also
bundle
processing
logic
in
the
form
of
methods
for
reference
here
is
the
example
for
dictionary
based
records
we
used
earlier
in
the
book
mel
rec
rec
name
mel
rec
age
rec
job
trainer
writer
dictionary
based
record
print
rec
name
this
code
emulates
tools
like
records
in
other
languages
as
we
just
saw
though
there
are
also
multiple
ways
to
do
the
same
with
classes
perhaps
the
simplest
is
this
trading
keys
for
attributes
class
rec
pass
rec
name
mel
rec
age
rec
job
trainer
writer
class
based
record
print
rec
age
this
code
has
substantially
less
syntax
than
the
dictionary
equivalent
it
uses
an
empty
class
statement
to
generate
an
empty
namespace
object
once
we
make
the
empty
class
we
fill
it
out
by
assigning
class
attributes
over
time
as
before
this
works
but
a
new
class
statement
will
be
required
for
each
distinct
record
we
will
need
perhaps
more
typically
we
can
instead
generate
instances
of
an
empty
class
to
represent
each
distinct
entity
class
rec
pass
pers
rec
pers
name
mel
pers
job
trainer
instance
based
records
the
world
s
simplest
python
class
pers
age
pers
rec
pers
name
vls
pers
job
developer
pers
name
pers
name
mel
vls
here
we
make
two
records
from
the
same
class
instances
start
out
life
empty
just
like
classes
we
then
fill
in
the
records
by
assigning
to
attributes
this
time
though
there
are
two
separate
objects
and
hence
two
separate
name
attributes
in
fact
instances
of
the
same
class
don
t
even
have
to
have
the
same
set
of
attribute
names
in
this
example
one
has
a
unique
age
name
instances
really
are
distinct
namespaces
so
each
has
a
distinct
attribute
dictionary
although
they
are
normally
filled
out
consistently
by
class
methods
they
are
more
flexible
than
you
might
expect
finally
we
might
instead
code
a
more
full
blown
class
to
implement
the
record
and
its
processing
class
person
def
init
self
name
job
self
name
name
self
job
job
def
info
self
return
self
name
self
job
rec
person
mel
trainer
rec
person
vls
developer
rec
job
rec
info
trainer
vls
developer
class
data
logic
this
scheme
also
makes
multiple
instances
but
the
class
is
not
empty
this
time
we
ve
added
logic
methods
to
initialize
instances
at
construction
time
and
collect
attributes
into
a
tuple
the
constructor
imposes
some
consistency
on
instances
here
by
always
setting
the
name
and
job
attributes
together
the
class
s
methods
and
instance
attributes
create
a
package
which
combines
both
data
and
logic
we
could
further
extend
this
code
by
adding
logic
to
compute
salaries
parse
names
and
so
on
ultimately
we
might
link
the
class
into
a
larger
hierarchy
to
inherit
an
existing
set
of
methods
via
the
automatic
attribute
search
of
classes
or
perhaps
even
store
instances
of
the
class
in
a
file
with
python
object
pickling
to
make
them
persistent
in
fact
we
will
in
the
next
chapter
we
ll
expand
on
this
analogy
between
classes
and
records
with
a
more
realistic
running
example
that
demonstrates
class
basics
in
action
in
the
end
although
types
like
dictionaries
are
flexible
classes
allow
us
to
add
behavior
to
objects
in
ways
that
built
in
types
and
simple
functions
do
not
directly
support
although
we
can
store
functions
in
dictionaries
too
using
them
to
process
implied
instances
is
nowhere
near
as
natural
as
it
is
in
classes
chapter
class
coding
basics
chapter
summary
this
chapter
introduced
the
basics
of
coding
classes
in
python
we
studied
the
syntax
of
the
class
statement
and
we
saw
how
to
use
it
to
build
up
a
class
inheritance
tree
we
also
studied
how
python
automatically
fills
in
the
first
argument
in
method
functions
how
attributes
are
attached
to
objects
in
a
class
tree
by
simple
assignment
and
how
specially
named
operator
overloading
methods
intercept
and
implement
built
in
operations
for
our
instances
e
g
expressions
and
printing
now
that
we
ve
learned
all
about
the
mechanics
of
coding
classes
in
python
the
next
chapter
turns
to
a
larger
and
more
realistic
example
that
ties
together
much
of
what
we
ve
learned
about
oop
so
far
after
that
we
ll
continue
our
look
at
class
coding
taking
a
second
pass
over
the
model
to
fill
in
some
of
the
details
that
were
omitted
here
to
keep
things
simple
first
though
let
s
work
through
a
quiz
to
review
the
basics
we
ve
covered
so
far
test
your
knowledge
quiz
how
are
classes
related
to
modules
how
are
instances
and
classes
created
where
and
how
are
class
attributes
created
where
and
how
are
instance
attributes
created
what
does
self
mean
in
a
python
class
how
is
operator
overloading
coded
in
a
python
class
when
might
you
want
to
support
operator
overloading
in
your
classes
which
operator
overloading
method
is
most
commonly
used
what
are
the
two
key
concepts
required
to
understand
python
oop
code
test
your
knowledge
answers
classes
are
always
nested
inside
a
module
they
are
attributes
of
a
module
object
classes
and
modules
are
both
namespaces
but
classes
correspond
to
statements
not
entire
files
and
support
the
oop
notions
of
multiple
instances
inheritance
and
operator
overloading
in
a
sense
a
module
is
like
a
single
instance
class
without
inheritance
which
corresponds
to
an
entire
file
of
code
classes
are
made
by
running
class
statements
instances
are
created
by
calling
a
class
as
though
it
were
a
function
test
your
knowledge
answers
class
attributes
are
created
by
assigning
attributes
to
a
class
object
they
are
normally
generated
by
top
level
assignments
nested
in
a
class
statement
each
name
assigned
in
the
class
statement
block
becomes
an
attribute
of
the
class
object
technically
the
class
statement
scope
morphs
into
the
class
object
s
attribute
namespace
class
attributes
can
also
be
created
though
by
assigning
attributes
to
the
class
anywhere
a
reference
to
the
class
object
exists
i
e
even
outside
the
class
statement
instance
attributes
are
created
by
assigning
attributes
to
an
instance
object
they
are
normally
created
within
class
method
functions
inside
the
class
statement
by
assigning
attributes
to
the
self
argument
which
is
always
the
implied
instance
again
though
they
may
be
created
by
assignment
anywhere
a
reference
to
the
instance
appears
even
outside
the
class
statement
normally
all
instance
attributes
are
initialized
in
the
init
constructor
method
that
way
later
method
calls
can
assume
the
attributes
already
exist
self
is
the
name
commonly
given
to
the
first
leftmost
argument
in
a
class
method
function
python
automatically
fills
it
in
with
the
instance
object
that
is
the
implied
subject
of
the
method
call
this
argument
need
not
be
called
self
though
this
is
a
very
strong
convention
its
position
is
what
is
significant
ex
c
or
java
programmers
might
prefer
to
call
it
this
because
in
those
languages
that
name
reflects
the
same
idea
in
python
though
this
argument
must
always
be
explicit
operator
overloading
is
coded
in
a
python
class
with
specially
named
methods
they
all
begin
and
end
with
double
underscores
to
make
them
unique
these
are
not
built
in
or
reserved
names
python
just
runs
them
automatically
when
an
instance
appears
in
the
corresponding
operation
python
itself
defines
the
mappings
from
operations
to
special
method
names
operator
overloading
is
useful
to
implement
objects
that
resemble
built
in
types
e
g
sequences
or
numeric
objects
such
as
matrixes
and
to
mimic
the
built
in
type
interface
expected
by
a
piece
of
code
mimicking
built
in
type
interfaces
enables
you
to
pass
in
class
instances
that
also
have
state
information
i
e
attributes
that
remember
data
between
operation
calls
you
shouldn
t
use
operator
overloading
when
a
simple
named
method
will
suffice
though
the
init
constructor
method
is
the
most
commonly
used
almost
every
class
uses
this
method
to
set
initial
values
for
instance
attributes
and
perform
other
startup
tasks
the
special
self
argument
in
method
functions
and
the
init
constructor
method
are
the
two
cornerstones
of
oop
code
in
python
chapter
class
coding
basics
chapter
a
more
realistic
example
we
ll
dig
into
more
class
syntax
details
in
the
next
chapter
before
we
do
though
i
d
like
to
show
you
a
more
realistic
example
of
classes
in
action
that
s
more
practical
than
what
we
ve
seen
so
far
in
this
chapter
we
re
going
to
build
a
set
of
classes
that
do
something
more
concrete
recording
and
processing
information
about
people
as
you
ll
see
what
we
call
instances
and
classes
in
python
programming
can
often
serve
the
same
roles
as
records
and
programs
in
more
traditional
terms
specifically
in
this
chapter
we
re
going
to
code
two
classes
person
a
class
that
creates
and
processes
information
about
people
manager
a
customization
of
person
that
modifies
inherited
behavior
along
the
way
we
ll
make
instances
of
both
classes
and
test
out
their
functionality
when
we
re
done
i
ll
show
you
a
nice
example
use
case
for
classes
we
ll
store
our
instances
in
a
shelve
object
oriented
database
to
make
them
permanent
that
way
you
can
use
this
code
as
a
template
for
fleshing
out
a
full
blown
personal
database
written
entirely
in
python
besides
actual
utility
though
our
aim
here
is
also
educational
this
chapter
provides
a
tutorial
on
object
oriented
programming
in
python
often
people
grasp
the
last
chapter
s
class
syntax
on
paper
but
have
trouble
seeing
how
to
get
started
when
confronted
with
having
to
code
a
new
class
from
scratch
toward
this
end
we
ll
take
it
one
step
at
a
time
here
to
help
you
learn
the
basics
we
ll
build
up
the
classes
gradually
so
you
can
see
how
their
features
come
together
in
complete
programs
in
the
end
our
classes
will
still
be
relatively
small
in
terms
of
code
but
they
will
demonstrate
all
of
the
main
ideas
in
python
s
oop
model
despite
its
syntax
details
python
s
class
system
really
is
largely
just
a
matter
of
searching
for
an
attribute
in
a
tree
of
objects
along
with
a
special
first
argument
for
functions
step
making
instances
ok
so
much
for
the
design
phase
let
s
move
on
to
implementation
our
first
task
is
to
start
coding
the
main
class
person
in
your
favorite
text
editor
open
a
new
file
for
the
code
we
ll
be
writing
it
s
a
fairly
strong
convention
in
python
to
begin
module
names
with
a
lowercase
letter
and
class
names
with
an
uppercase
letter
like
the
name
of
self
arguments
in
methods
this
is
not
required
by
the
language
but
it
s
so
common
that
deviating
might
be
confusing
to
people
who
later
read
your
code
to
conform
we
ll
call
our
new
module
file
person
py
and
our
class
within
it
person
like
this
file
person
py
start
class
person
all
our
work
will
be
done
in
this
file
until
later
in
this
chapter
we
can
code
any
number
of
functions
and
classes
in
a
single
module
file
in
python
and
this
one
s
person
py
name
might
not
make
much
sense
if
we
add
unrelated
components
to
it
later
for
now
we
ll
assume
everything
in
it
will
be
person
related
it
probably
should
be
anyhow
as
we
ve
learned
modules
tend
to
work
best
when
they
have
a
single
cohesive
purpose
coding
constructors
now
the
first
thing
we
want
to
do
with
our
person
class
is
record
basic
information
about
people
to
fill
out
record
fields
if
you
will
of
course
these
are
known
as
instance
object
attributes
in
python
speak
and
they
generally
are
created
by
assignment
to
self
attributes
in
class
method
functions
the
normal
way
to
give
instance
attributes
their
first
values
is
to
assign
them
to
self
in
the
init
constructor
method
which
contains
code
run
automatically
by
python
each
time
an
instance
is
created
let
s
add
one
to
our
class
add
record
field
initialization
class
person
def
init
self
name
job
pay
self
name
name
self
job
job
self
pay
pay
constructor
takes
arguments
fill
out
fields
when
created
self
is
the
new
instance
object
this
is
a
very
common
coding
pattern
we
pass
in
the
data
to
be
attached
to
an
instance
as
arguments
to
the
constructor
method
and
assign
them
to
self
to
retain
them
permanently
in
oo
terms
self
is
the
newly
created
instance
object
and
name
job
and
pay
become
state
information
descriptive
data
saved
on
an
object
for
later
use
although
other
techniques
such
as
enclosing
scope
references
can
save
details
too
instance
attributes
make
this
very
explicit
and
easy
to
understand
notice
that
the
argument
names
appear
twice
here
this
code
might
seem
a
bit
redundant
at
first
but
it
s
not
the
job
argument
for
example
is
a
local
variable
in
the
scope
of
the
init
function
but
self
job
is
an
attribute
of
the
instance
that
s
the
implied
chapter
a
more
realistic
example
subject
of
the
method
call
they
are
two
different
variables
which
happen
to
have
the
same
name
by
assigning
the
job
local
to
the
self
job
attribute
with
self
job
job
we
save
the
passed
in
job
on
the
instance
for
later
use
as
usual
in
python
where
a
name
is
assigned
or
what
object
it
is
assigned
to
determines
what
it
means
speaking
of
arguments
there
s
really
nothing
magical
about
init
apart
from
the
fact
that
it
s
called
automatically
when
an
instance
is
made
and
has
a
special
first
argument
despite
its
weird
name
it
s
a
normal
function
and
supports
all
the
features
of
functions
we
ve
already
covered
we
can
for
example
provide
defaults
for
some
of
its
arguments
so
they
need
not
be
provided
in
cases
where
their
values
aren
t
available
or
useful
to
demonstrate
let
s
make
the
job
argument
optional
it
will
default
to
none
meaning
the
person
being
created
is
not
currently
employed
if
job
defaults
to
none
we
ll
probably
want
to
default
pay
to
too
for
consistency
unless
some
of
the
people
you
know
manage
to
get
paid
without
having
jobs
in
fact
we
have
to
specify
a
default
for
pay
because
according
to
python
s
syntax
rules
any
arguments
in
a
function
s
header
after
the
first
default
must
all
have
defaults
too
add
defaults
for
constructor
arguments
class
person
def
init
self
name
job
none
pay
self
name
name
self
job
job
self
pay
pay
normal
function
args
what
this
code
means
is
that
we
ll
need
to
pass
in
a
name
when
making
persons
but
job
and
pay
are
now
optional
they
ll
default
to
none
and
if
omitted
the
self
argument
as
usual
is
filled
in
by
python
automatically
to
refer
to
the
instance
object
assigning
values
to
attributes
of
self
attaches
them
to
the
new
instance
testing
as
you
go
this
class
doesn
t
do
much
yet
it
essentially
just
fills
out
the
fields
of
a
new
record
but
it
s
a
real
working
class
at
this
point
we
could
add
more
code
to
it
for
more
features
but
we
won
t
do
that
yet
as
you
ve
probably
begun
to
appreciate
already
programming
in
python
is
really
a
matter
of
incremental
prototyping
you
write
some
code
test
it
write
more
code
test
again
and
so
on
because
python
provides
both
an
interactive
session
and
nearly
immediate
turnaround
after
code
changes
it
s
more
natural
to
test
as
you
go
than
to
write
a
huge
amount
of
code
to
test
all
at
once
before
adding
more
features
then
let
s
test
what
we
ve
got
so
far
by
making
a
few
instances
of
our
class
and
displaying
their
attributes
as
created
by
the
constructor
we
could
do
this
interactively
but
as
you
ve
also
probably
surmised
by
now
interactive
testing
has
its
limits
it
gets
tedious
to
have
to
reimport
modules
and
retype
test
cases
each
time
you
start
a
new
testing
session
more
commonly
python
programmers
use
step
making
instances
the
interactive
prompt
for
simple
one
off
tests
but
do
more
substantial
testing
by
writing
code
at
the
bottom
of
the
file
that
contains
the
objects
to
be
tested
like
this
add
incremental
self
test
code
class
person
def
init
self
name
job
none
pay
self
name
name
self
job
job
self
pay
pay
bob
person
bob
smith
test
the
class
sue
person
sue
jones
job
dev
pay
runs
init
automatically
print
bob
name
bob
pay
fetch
attached
attributes
print
sue
name
sue
pay
sue
s
and
bob
s
attrs
differ
notice
here
that
the
bob
object
accepts
the
defaults
for
job
and
pay
but
sue
provides
values
explicitly
also
note
how
we
use
keyword
arguments
when
making
sue
we
could
pass
by
position
instead
but
the
keywords
may
help
remind
us
later
what
the
data
is
and
they
allow
us
to
pass
the
arguments
in
any
left
to
right
order
we
like
again
despite
its
unusual
name
init
is
a
normal
function
supporting
everything
you
already
know
about
functions
including
both
defaults
and
pass
by
name
keyword
arguments
when
this
file
runs
as
a
script
the
test
code
at
the
bottom
makes
two
instances
of
our
class
and
prints
two
attributes
of
each
name
and
pay
c
misc
person
py
bob
smith
sue
jones
you
can
also
type
this
file
s
test
code
at
python
s
interactive
prompt
assuming
you
import
the
person
class
there
first
but
coding
canned
tests
inside
the
module
file
like
this
makes
it
much
easier
to
rerun
them
in
the
future
although
this
is
fairly
simple
code
it
s
already
demonstrating
something
important
notice
that
bob
s
name
is
not
sue
s
and
sue
s
pay
is
not
bob
s
each
is
an
independent
record
of
information
technically
bob
and
sue
are
both
namespace
objects
like
all
class
instances
they
each
have
their
own
independent
copy
of
the
state
information
created
by
the
class
because
each
instance
of
a
class
has
its
own
set
of
self
attributes
classes
are
a
natural
for
recording
information
for
multiple
objects
this
way
just
like
built
in
types
classes
serve
as
a
sort
of
object
factory
other
python
program
structures
such
as
functions
and
modules
have
no
such
concept
using
code
two
ways
as
is
the
test
code
at
the
bottom
of
the
file
works
but
there
s
a
big
catch
its
top
level
print
statements
run
both
when
the
file
is
run
as
a
script
and
when
it
is
imported
as
a
module
this
means
if
we
ever
decide
to
import
the
class
in
this
file
in
order
to
use
it
somewhere
else
and
we
will
later
in
this
chapter
we
ll
see
the
output
of
its
test
code
chapter
a
more
realistic
example
every
time
the
file
is
imported
that
s
not
very
good
software
citizenship
though
client
programs
probably
don
t
care
about
our
internal
tests
and
won
t
want
to
see
our
output
mixed
in
with
their
own
although
we
could
split
the
test
code
off
into
a
separate
file
it
s
often
more
convenient
to
code
tests
in
the
same
file
as
the
items
to
be
tested
it
would
be
better
to
arrange
to
run
the
test
statements
at
the
bottom
only
when
the
file
is
run
for
testing
not
when
the
file
is
imported
that
s
exactly
what
the
module
name
check
is
designed
for
as
you
learned
in
the
preceding
part
of
this
book
here
s
what
this
addition
looks
like
allow
this
file
to
be
imported
as
well
as
run
tested
class
person
def
init
self
name
job
none
pay
self
name
name
self
job
job
self
pay
pay
if
name
main
when
run
for
testing
only
self
test
code
bob
person
bob
smith
sue
person
sue
jones
job
dev
pay
print
bob
name
bob
pay
print
sue
name
sue
pay
now
we
get
exactly
the
behavior
we
re
after
running
the
file
as
a
top
level
script
tests
it
because
its
name
is
main
but
importing
it
as
a
library
of
classes
later
does
not
c
misc
person
py
bob
smith
sue
jones
c
misc
python
python
r
feb
import
person
when
imported
the
file
now
defines
the
class
but
does
not
use
it
when
run
directly
this
file
creates
two
instances
of
our
class
as
before
and
prints
two
attributes
of
each
again
because
each
instance
is
an
independent
namespace
object
the
values
of
their
attributes
differ
version
portability
note
i
m
running
all
the
code
in
this
chapter
under
python
and
using
the
print
function
call
syntax
if
you
run
under
the
code
will
work
as
is
but
you
ll
notice
parentheses
around
some
output
lines
because
the
extra
parentheses
in
prints
turn
multiple
items
into
a
tuple
c
misc
c
python
python
person
py
bob
smith
sue
jones
step
making
instances
if
this
difference
is
the
sort
of
detail
that
might
keep
you
awake
at
nights
simply
remove
the
parentheses
to
use
print
statements
you
can
also
avoid
the
extra
parentheses
portably
by
using
formatting
to
yield
a
single
object
to
print
either
of
the
following
works
in
both
and
though
the
method
form
is
newer
print
format
bob
name
bob
pay
print
s
s
bob
name
bob
pay
new
format
method
format
expression
step
adding
behavior
methods
everything
looks
good
so
far
at
this
point
our
class
is
essentially
a
record
factory
it
creates
and
fills
out
fields
of
records
attributes
of
instances
in
more
pythonic
terms
even
as
limited
as
it
is
though
we
can
still
run
some
operations
on
its
objects
although
classes
add
an
extra
layer
of
structure
they
ultimately
do
most
of
their
work
by
embedding
and
processing
basic
core
data
types
like
lists
and
strings
in
other
words
if
you
already
know
how
to
use
python
s
simple
core
types
you
already
know
much
of
the
python
class
story
classes
are
really
just
a
minor
structural
extension
for
example
the
name
field
of
our
objects
is
a
simple
string
so
we
can
extract
last
names
from
our
objects
by
splitting
on
spaces
and
indexing
these
are
all
core
data
type
operations
which
work
whether
their
subjects
are
embedded
in
class
instances
or
not
name
bob
smith
name
split
bob
smith
name
split
smith
simple
string
outside
class
extract
last
name
or
if
always
just
two
parts
similarly
we
can
give
an
object
a
pay
raise
by
updating
its
pay
field
that
is
by
changing
its
state
information
in
place
with
an
assignment
this
task
also
involves
basic
operations
that
work
on
python
s
core
objects
regardless
of
whether
they
are
standalone
or
embedded
in
a
class
structure
pay
pay
print
pay
simple
variable
outside
class
give
a
raise
or
pay
pay
if
you
like
to
type
or
pay
pay
pay
if
you
really
do
to
apply
these
operations
to
the
person
objects
created
by
our
script
simply
do
to
bob
name
and
sue
pay
what
we
just
did
to
name
and
pay
the
operations
are
the
same
but
the
subject
objects
are
attached
to
attributes
in
our
class
structure
process
embedded
built
in
types
strings
mutability
class
person
def
init
self
name
job
none
pay
self
name
name
self
job
job
self
pay
pay
if
name
main
chapter
a
more
realistic
example
bob
person
bob
smith
sue
person
sue
jones
job
dev
pay
print
bob
name
bob
pay
print
sue
name
sue
pay
print
bob
name
split
extract
object
s
last
name
sue
pay
give
this
object
a
raise
print
sue
pay
we
ve
added
the
last
two
lines
here
when
they
re
run
we
extract
bob
s
last
name
by
using
basic
string
and
list
operations
and
give
sue
a
pay
raise
by
modifying
her
pay
attribute
in
place
with
basic
number
operations
in
a
sense
sue
is
also
a
mutable
object
her
state
changes
in
place
just
like
a
list
after
an
append
call
bob
smith
sue
jones
smith
the
preceding
code
works
as
planned
but
if
you
show
it
to
a
veteran
software
developer
he
ll
probably
tell
you
that
its
general
approach
is
not
a
great
idea
in
practice
hardcoding
operations
like
these
outside
of
the
class
can
lead
to
maintenance
problems
in
the
future
for
example
what
if
you
ve
hardcoded
the
last
name
extraction
formula
at
many
different
places
in
your
program
if
you
ever
need
to
change
the
way
it
works
to
support
a
new
name
structure
for
instance
you
ll
need
to
hunt
down
and
update
every
occurrence
similarly
if
the
pay
raise
code
ever
changes
e
g
to
require
approval
or
database
updates
you
may
have
multiple
copies
to
modify
just
finding
all
the
appearances
of
such
code
may
be
problematic
in
larger
programs
they
may
be
scattered
across
many
files
split
into
individual
steps
and
so
on
coding
methods
what
we
really
want
to
do
here
is
employ
a
software
design
concept
known
as
encapsulation
the
idea
with
encapsulation
is
to
wrap
up
operation
logic
behind
interfaces
such
that
each
operation
is
coded
only
once
in
our
program
that
way
if
our
needs
change
in
the
future
there
is
just
one
copy
to
update
moreover
we
re
free
to
change
the
single
copy
s
internals
almost
arbitrarily
without
breaking
the
code
that
uses
it
in
python
terms
we
want
to
code
operations
on
objects
in
class
methods
instead
of
littering
them
throughout
our
program
in
fact
this
is
one
of
the
things
that
classes
are
very
good
at
factoring
code
to
remove
redundancy
and
thus
optimize
maintainability
as
an
added
bonus
turning
operations
into
methods
enables
them
to
be
applied
to
any
instance
of
the
class
not
just
those
that
they
ve
been
hardcoded
to
process
this
is
all
simpler
in
code
than
it
may
sound
in
theory
the
following
achieves
encapsulation
by
moving
the
two
operations
from
code
outside
the
class
into
class
methods
while
we
re
at
it
let
s
change
our
self
test
code
at
the
bottom
to
use
the
new
methods
we
re
creating
instead
of
hardcoding
operations
step
adding
behavior
methods
add
methods
to
encapsulate
operations
for
maintainability
class
person
def
init
self
name
job
none
pay
self
name
name
self
job
job
self
pay
pay
def
lastname
self
return
self
name
split
def
giveraise
self
percent
self
pay
int
self
pay
percent
behavior
methods
self
is
implied
subject
must
change
here
only
if
name
main
bob
person
bob
smith
sue
person
sue
jones
job
dev
pay
print
bob
name
bob
pay
print
sue
name
sue
pay
print
bob
lastname
sue
lastname
use
the
new
methods
sue
giveraise
instead
of
hardcoding
print
sue
pay
as
we
ve
learned
methods
are
simply
normal
functions
that
are
attached
to
classes
and
designed
to
process
instances
of
those
classes
the
instance
is
the
subject
of
the
method
call
and
is
passed
to
the
method
s
self
argument
automatically
the
transformation
to
the
methods
in
this
version
is
straightforward
the
new
lastname
method
for
example
simply
does
to
self
what
the
previous
version
hardcoded
for
bob
because
self
is
the
implied
subject
when
the
method
is
called
lastname
also
returns
the
result
because
this
operation
is
a
called
function
now
it
computes
a
value
for
its
caller
to
use
even
if
it
is
just
to
be
printed
similarly
the
new
giveraise
method
just
does
to
self
what
we
did
to
sue
before
when
run
now
our
file
s
output
is
similar
to
before
we
ve
mostly
just
refactored
the
code
to
allow
for
easier
changes
in
the
future
not
altered
its
behavior
bob
smith
sue
jones
smith
jones
a
few
coding
details
are
worth
pointing
out
here
first
notice
that
sue
s
pay
is
now
still
an
integer
after
a
pay
raise
we
convert
the
math
result
back
to
an
integer
by
calling
the
int
built
in
within
the
method
changing
the
value
to
either
int
or
float
is
probably
not
a
significant
concern
for
most
purposes
integer
and
floating
point
objects
have
the
same
interfaces
and
can
be
mixed
within
expressions
but
we
may
need
to
address
rounding
issues
in
a
real
system
money
probably
matters
to
persons
as
we
learned
in
chapter
we
might
handle
this
by
using
the
round
n
built
in
to
round
and
retain
cents
using
the
decimal
type
to
fix
precision
or
storing
monetary
values
as
full
floating
point
numbers
and
displaying
them
with
a
f
or
f
formatting
string
to
show
cents
for
this
example
we
ll
simply
truncate
any
cents
with
chapter
a
more
realistic
example
int
for
another
idea
also
see
the
money
function
in
the
formats
py
module
of
chap
ter
you
can
import
this
tool
to
show
pay
with
commas
cents
and
dollar
signs
second
notice
that
we
re
also
printing
sue
s
last
name
this
time
because
the
last
name
logic
has
been
encapsulated
in
a
method
we
get
to
use
it
on
any
instance
of
the
class
as
we
ve
seen
python
tells
a
method
which
instance
to
process
by
automatically
passing
it
in
to
the
first
argument
usually
called
self
specifically
in
the
first
call
bob
lastname
bob
is
the
implied
subject
passed
to
self
in
the
second
call
sue
lastname
sue
goes
to
self
instead
trace
through
these
calls
to
see
how
the
instance
winds
up
in
self
the
net
effect
is
that
the
method
fetches
the
name
of
the
implied
subject
each
time
the
same
happens
for
giveraise
we
could
for
example
give
bob
a
raise
by
calling
giveraise
for
both
instances
this
way
too
but
unfortunately
bob
s
zero
pay
will
prevent
him
from
getting
a
raise
as
the
program
is
currently
coded
something
we
may
want
to
address
in
a
future
release
of
our
software
finally
notice
that
the
giveraise
method
assumes
that
percent
is
passed
in
as
a
floatingpoint
number
between
zero
and
one
that
may
be
too
radical
an
assumption
in
the
real
world
a
raise
would
probably
be
a
bug
for
most
of
us
we
ll
let
it
pass
for
this
prototype
but
we
might
want
to
test
or
at
least
document
this
in
a
future
iteration
of
this
code
stay
tuned
for
a
rehash
of
this
idea
in
a
later
chapter
in
this
book
where
we
ll
code
something
called
function
decorators
and
explore
python
s
assert
statement
alternatives
that
can
do
the
validity
test
for
us
automatically
during
development
step
operator
overloading
at
this
point
we
have
a
fairly
full
featured
class
that
generates
and
initializes
instances
along
with
two
new
bits
of
behavior
for
processing
instances
in
the
form
of
methods
so
far
so
good
as
it
stands
though
testing
is
still
a
bit
less
convenient
than
it
needs
to
be
to
trace
our
objects
we
have
to
manually
fetch
and
print
individual
attributes
e
g
bob
name
sue
pay
it
would
be
nice
if
displaying
an
instance
all
at
once
actually
gave
us
some
useful
information
unfortunately
the
default
display
format
for
an
instance
object
isn
t
very
good
it
displays
the
object
s
class
name
and
its
address
in
memory
which
is
essentially
useless
in
python
except
as
a
unique
identifier
to
see
this
change
the
last
line
in
the
script
to
print
sue
so
it
displays
the
object
as
a
whole
here
s
what
you
ll
get
the
output
says
that
sue
is
an
object
in
and
an
instance
in
bob
smith
sue
jones
smith
jones
main
person
object
at
x
step
operator
overloading
providing
print
displays
fortunately
it
s
easy
to
do
better
by
employing
operator
overloading
coding
methods
in
a
class
that
intercept
and
process
built
in
operations
when
run
on
the
class
s
instances
specifically
we
can
make
use
of
what
is
probably
the
second
most
commonly
used
operator
overloading
method
in
python
after
init
the
str
method
introduced
in
the
preceding
chapter
str
is
run
automatically
every
time
an
instance
is
converted
to
its
print
string
because
that
s
what
printing
an
object
does
the
net
transitive
effect
is
that
printing
an
object
displays
whatever
is
returned
by
the
object
s
str
method
if
it
either
defines
one
itself
or
inherits
one
from
a
superclass
doubleunderscored
names
are
inherited
just
like
any
other
technically
speaking
the
init
constructor
method
we
ve
already
coded
is
operator
overloading
too
it
is
run
automatically
at
construction
time
to
initialize
a
newly
created
instance
constructors
are
so
common
though
that
they
almost
seem
like
a
special
case
more
focused
methods
like
str
allow
us
to
tap
into
specific
operations
and
provide
specialized
behavior
when
our
objects
are
used
in
those
contexts
let
s
put
this
into
code
the
following
extends
our
class
to
give
a
custom
display
that
lists
attributes
when
our
class
s
instances
are
displayed
as
a
whole
instead
of
relying
on
the
less
useful
default
display
add
str
overload
method
for
printing
objects
class
person
def
init
self
name
job
none
pay
self
name
name
self
job
job
self
pay
pay
def
lastname
self
return
self
name
split
def
giveraise
self
percent
self
pay
int
self
pay
percent
def
str
self
return
person
s
s
self
name
self
pay
added
method
string
to
print
if
name
main
bob
person
bob
smith
sue
person
sue
jones
job
dev
pay
print
bob
print
sue
print
bob
lastname
sue
lastname
sue
giveraise
print
sue
notice
that
we
re
doing
string
formatting
to
build
the
display
string
in
str
here
at
the
bottom
classes
use
built
in
type
objects
and
operations
like
these
to
get
their
work
done
again
everything
you
ve
already
learned
about
both
built
in
types
and
functions
applies
to
class
based
code
classes
largely
just
add
an
additional
layer
of
structure
that
packages
functions
and
data
together
and
supports
extensions
chapter
a
more
realistic
example
we
ve
also
changed
our
self
test
code
to
print
objects
directly
instead
of
printing
individual
attributes
when
run
the
output
is
more
coherent
and
meaningful
now
the
lines
are
returned
by
our
new
str
run
automatically
by
print
operations
person
bob
smith
person
sue
jones
smith
jones
person
sue
jones
here
s
a
subtle
point
as
we
ll
learn
in
the
next
chapter
a
related
overloading
method
repr
provides
an
as
code
low
level
display
of
an
object
when
present
sometimes
classes
provide
both
a
str
for
user
friendly
displays
and
a
repr
with
extra
details
for
developers
to
view
because
printing
runs
str
and
the
interactive
prompt
echoes
results
with
repr
this
can
provide
both
target
audiences
with
an
appropriate
display
since
we
re
not
interested
in
displaying
an
as
code
format
str
is
sufficient
for
our
class
step
customizing
behavior
by
subclassing
at
this
point
our
class
captures
much
of
the
oop
machinery
in
python
it
makes
instances
provides
behavior
in
methods
and
even
does
a
bit
of
operator
overloading
now
to
intercept
print
operations
in
str
it
effectively
packages
our
data
and
logic
together
into
a
single
self
contained
software
component
making
it
easy
to
locate
code
and
straightforward
to
change
it
in
the
future
by
allowing
us
to
encapsulate
behavior
it
also
allows
us
to
factor
that
code
to
avoid
redundancy
and
its
associated
maintenance
headaches
the
only
major
oop
concept
it
does
not
yet
capture
is
customization
by
inheritance
in
some
sense
we
re
already
doing
inheritance
because
instances
inherit
methods
from
their
classes
to
demonstrate
the
real
power
of
oop
though
we
need
to
define
a
superclass
subclass
relationship
that
allows
us
to
extend
our
software
and
replace
bits
of
inherited
behavior
that
s
the
main
idea
behind
oop
after
all
by
fostering
a
coding
model
based
upon
customization
of
work
already
done
it
can
dramatically
cut
development
time
coding
subclasses
as
a
next
step
then
let
s
put
oop
s
methodology
to
use
and
customize
our
person
class
by
extending
our
software
hierarchy
for
the
purpose
of
this
tutorial
we
ll
define
a
subclass
of
person
called
manager
that
replaces
the
inherited
giveraise
method
with
a
more
specialized
version
our
new
class
begins
as
follows
class
manager
person
define
a
subclass
of
person
this
code
means
that
we
re
defining
a
new
class
named
manager
which
inherits
from
and
may
add
customizations
to
the
superclass
person
in
plain
terms
a
manager
is
almost
step
customizing
behavior
by
subclassing
like
a
person
admittedly
a
very
long
journey
for
a
very
small
joke
but
manager
has
a
custom
way
to
give
raises
for
the
sake
of
argument
let
s
assume
that
when
a
manager
gets
a
raise
it
receives
the
passed
in
percentage
as
usual
but
also
gets
an
extra
bonus
that
defaults
to
for
instance
if
a
manager
s
raise
is
specified
as
it
will
really
get
any
relation
to
persons
living
or
dead
is
of
course
strictly
coincidental
our
new
method
begins
as
follows
because
this
redefinition
of
giveraise
will
be
closer
in
the
class
tree
to
manager
instances
than
the
original
version
in
person
it
effectively
replaces
and
thereby
customizes
the
operation
recall
that
according
to
the
inheritance
search
rules
the
lowest
version
of
the
name
wins
class
manager
person
def
giveraise
self
percent
bonus
inherit
person
attrs
redefine
to
customize
augmenting
methods
the
bad
way
now
there
are
two
ways
we
might
code
this
manager
customization
a
good
way
and
a
bad
way
let
s
start
with
the
bad
way
since
it
might
be
a
bit
easier
to
understand
the
bad
way
is
to
cut
and
paste
the
code
of
giveraise
in
person
and
modify
it
for
manager
like
this
class
manager
person
def
giveraise
self
percent
bonus
self
pay
int
self
pay
percent
bonus
bad
cut
and
paste
this
works
as
advertised
when
we
later
call
the
giveraise
method
of
a
manager
instance
it
will
run
this
custom
version
which
tacks
on
the
extra
bonus
so
what
s
wrong
with
something
that
runs
correctly
the
problem
here
is
a
very
general
one
any
time
you
copy
code
with
cut
and
paste
you
essentially
double
your
maintenance
effort
in
the
future
think
about
it
because
we
copied
the
original
version
if
we
ever
have
to
change
the
way
raises
are
given
and
we
probably
will
we
ll
have
to
change
the
code
in
two
places
not
one
although
this
is
a
small
and
artificial
example
it
s
also
representative
of
a
universal
issue
any
time
you
re
tempted
to
program
by
copying
code
this
way
you
probably
want
to
look
for
a
better
approach
augmenting
methods
the
good
way
what
we
really
want
to
do
here
is
somehow
augment
the
original
giveraise
instead
of
replacing
it
altogether
the
good
way
to
do
that
in
python
is
by
calling
to
the
original
version
directly
with
augmented
arguments
like
this
class
manager
person
def
giveraise
self
percent
bonus
person
giveraise
self
percent
bonus
chapter
a
more
realistic
example
good
augment
original
this
code
leverages
the
fact
that
a
class
method
can
always
be
called
either
through
an
instance
the
usual
way
where
python
sends
the
instance
to
the
self
argument
automatically
or
through
the
class
the
less
common
scheme
where
you
must
pass
the
instance
manually
in
more
symbolic
terms
recall
that
a
normal
method
call
of
this
form
instance
method
args
is
automatically
translated
by
python
into
this
equivalent
form
class
method
instance
args
where
the
class
containing
the
method
to
be
run
is
determined
by
the
inheritance
search
rule
applied
to
the
method
s
name
you
can
code
either
form
in
your
script
but
there
is
a
slight
asymmetry
between
the
two
you
must
remember
to
pass
along
the
instance
manually
if
you
call
through
the
class
directly
the
method
always
needs
a
subject
instance
one
way
or
another
and
python
provides
it
automatically
only
for
calls
made
through
an
instance
for
calls
through
the
class
name
you
need
to
send
an
instance
to
self
yourself
for
code
inside
a
method
like
giveraise
self
already
is
the
subject
of
the
call
and
hence
the
instance
to
pass
along
calling
through
the
class
directly
effectively
subverts
inheritance
and
kicks
the
call
higher
up
the
class
tree
to
run
a
specific
version
in
our
case
we
can
use
this
technique
to
invoke
the
default
giveraise
in
person
even
though
it
s
been
redefined
at
the
manager
level
in
some
sense
we
must
call
through
person
this
way
because
a
self
giveraise
inside
manager
s
giveraise
code
would
loop
since
self
already
is
a
manager
self
giveraise
would
resolve
again
to
manager
giveraise
and
so
on
and
so
forth
until
available
memory
is
exhausted
this
good
version
may
seem
like
a
small
difference
in
code
but
it
can
make
a
huge
difference
for
future
code
maintenance
because
the
giveraise
logic
lives
in
just
one
place
now
person
s
method
we
have
only
one
version
to
change
in
the
future
as
needs
evolve
and
really
this
form
captures
our
intent
more
directly
anyhow
we
want
to
perform
the
standard
giveraise
operation
but
simply
tack
on
an
extra
bonus
here
s
our
entire
module
file
with
this
step
applied
add
customization
of
one
behavior
in
a
subclass
class
person
def
init
self
name
job
none
pay
self
name
name
self
job
job
self
pay
pay
def
lastname
self
return
self
name
split
def
giveraise
self
percent
self
pay
int
self
pay
percent
def
str
self
return
person
s
s
self
name
self
pay
class
manager
person
step
customizing
behavior
by
subclassing
def
giveraise
self
percent
bonus
person
giveraise
self
percent
bonus
if
name
main
bob
person
bob
smith
sue
person
sue
jones
job
dev
pay
print
bob
print
sue
print
bob
lastname
sue
lastname
sue
giveraise
print
sue
tom
manager
tom
jones
mgr
tom
giveraise
print
tom
lastname
print
tom
redefine
at
this
level
call
person
s
version
make
a
manager
init
runs
custom
version
runs
inherited
method
runs
inherited
str
to
test
our
manager
subclass
customization
we
ve
also
added
self
test
code
that
makes
a
manager
calls
its
methods
and
prints
it
here
s
the
new
version
s
output
person
bob
person
sue
smith
jones
person
sue
jones
person
tom
smith
jones
jones
jones
everything
looks
good
here
bob
and
sue
are
as
before
and
when
tom
the
manager
is
given
a
raise
he
really
gets
his
pay
goes
from
k
to
k
because
the
customized
giveraise
in
manager
is
run
for
him
only
also
notice
how
printing
tom
as
a
whole
at
the
end
of
the
test
code
displays
the
nice
format
defined
in
person
s
str
manager
objects
get
this
lastname
and
the
init
constructor
method
s
code
for
free
from
person
by
inheritance
polymorphism
in
action
to
make
this
acquisition
of
inherited
behavior
even
more
striking
we
can
add
the
following
code
at
the
end
of
our
file
if
name
main
print
all
three
for
object
in
bob
sue
tom
object
giveraise
print
object
here
s
the
resulting
output
person
bob
smith
person
sue
jones
smith
jones
person
sue
jones
jones
person
tom
jones
all
three
chapter
a
more
realistic
example
process
objects
generically
run
this
object
s
giveraise
run
the
common
str
person
bob
smith
person
sue
jones
person
tom
jones
in
the
added
code
object
is
either
a
person
or
a
manager
and
python
runs
the
appropriate
giveraise
automatically
our
original
version
in
person
for
bob
and
sue
and
our
customized
version
in
manager
for
tom
trace
the
method
calls
yourself
to
see
how
python
selects
the
right
giveraise
method
for
each
object
this
is
just
python
s
notion
of
polymorphism
which
we
met
earlier
in
the
book
at
work
again
what
giveraise
does
depends
on
what
you
do
it
to
here
it
s
made
all
the
more
obvious
when
it
selects
from
code
we
ve
written
ourselves
in
classes
the
practical
effect
in
this
code
is
that
sue
gets
another
but
tom
gets
another
because
giveraise
is
dispatched
based
upon
the
object
s
type
as
we
ve
learned
polymorphism
is
at
the
heart
of
python
s
flexibility
passing
any
of
our
three
objects
to
a
function
that
calls
a
giveraise
method
for
example
would
have
the
same
effect
the
appropriate
version
would
be
run
automatically
depending
on
which
type
of
object
was
passed
on
the
other
hand
printing
runs
the
same
str
for
all
three
objects
because
it
s
coded
just
once
in
person
manager
both
specializes
and
applies
the
code
we
originally
wrote
in
person
although
this
example
is
small
it
s
already
leveraging
oop
s
talent
for
code
customization
and
reuse
with
classes
this
almost
seems
automatic
at
times
inherit
customize
and
extend
in
fact
classes
can
be
even
more
flexible
than
our
example
implies
in
general
classes
can
inherit
customize
or
extend
existing
code
in
superclasses
for
example
although
we
re
focused
on
customization
here
we
can
also
add
unique
methods
to
manager
that
are
not
present
in
person
if
managers
require
something
completely
different
python
namesake
reference
intended
the
following
snippet
illustrates
here
giveraise
redefines
a
superclass
method
to
customize
it
but
somethingelse
defines
something
new
to
extend
class
person
def
lastname
self
def
giveraise
self
def
str
self
class
manager
person
def
giveraise
self
def
somethingelse
self
inherit
customize
extend
tom
manager
tom
lastname
tom
giveraise
tom
somethingelse
print
tom
inherited
verbatim
customized
version
extension
here
inherited
overload
method
extra
methods
like
this
code
s
somethingelse
extend
the
existing
software
and
are
available
on
manager
objects
only
not
on
persons
for
the
purposes
of
this
tutorial
however
step
customizing
behavior
by
subclassing
we
ll
limit
our
scope
to
customizing
some
of
person
s
behavior
by
redefining
it
not
adding
to
it
oop
the
big
idea
as
is
our
code
may
be
small
but
it
s
fairly
functional
and
really
it
already
illustrates
the
main
point
behind
oop
in
general
in
oop
we
program
by
customizing
what
has
already
been
done
rather
than
copying
or
changing
existing
code
this
isn
t
always
an
obvious
win
to
newcomers
at
first
glance
especially
given
the
extra
coding
requirements
of
classes
but
overall
the
programming
style
implied
by
classes
can
cut
development
time
radically
compared
to
other
approaches
for
instance
in
our
example
we
could
theoretically
have
implemented
a
custom
giveraise
operation
without
subclassing
but
none
of
the
other
options
yield
code
as
optimal
as
ours
although
we
could
have
simply
coded
manager
from
scratch
as
new
independent
code
we
would
have
had
to
reimplement
all
the
behaviors
in
person
that
are
the
same
for
managers
although
we
could
have
simply
changed
the
existing
person
class
in
place
for
the
requirements
of
manager
s
giveraise
doing
so
would
probably
break
the
places
where
we
still
need
the
original
person
behavior
although
we
could
have
simply
copied
the
person
class
in
its
entirety
renamed
the
copy
to
manager
and
changed
its
giveraise
doing
so
would
introduce
code
redundancy
that
would
double
our
work
in
the
future
changes
made
to
person
in
the
future
would
not
be
picked
up
automatically
but
would
have
to
be
manually
propagated
to
manager
s
code
as
usual
the
cut
and
paste
approach
may
seem
quick
now
but
it
doubles
your
work
in
the
future
the
customizable
hierarchies
we
can
build
with
classes
provide
a
much
better
solution
for
software
that
will
evolve
over
time
no
other
tools
in
python
support
this
development
mode
because
we
can
tailor
and
extend
our
prior
work
by
coding
new
subclasses
we
can
leverage
what
we
ve
already
done
rather
than
starting
from
scratch
each
time
breaking
what
already
works
or
introducing
multiple
copies
of
code
that
may
all
have
to
be
updated
in
the
future
when
done
right
oop
is
a
powerful
programmer
s
ally
step
customizing
constructors
too
our
code
works
as
it
is
but
if
you
study
the
current
version
closely
you
may
be
struck
by
something
a
bit
odd
it
seems
pointless
to
have
to
provide
a
mgr
job
name
for
manager
objects
when
we
create
them
this
is
already
implied
by
the
class
itself
it
would
be
better
if
we
could
somehow
fill
in
this
value
automatically
when
a
manager
is
made
the
trick
we
need
to
improve
on
this
turns
out
to
be
the
same
as
the
one
we
employed
in
the
prior
section
we
want
to
customize
the
constructor
logic
for
managers
in
such
a
chapter
a
more
realistic
example
way
as
to
provide
a
job
name
automatically
in
terms
of
code
we
want
to
redefine
an
init
method
in
manager
that
provides
the
mgr
string
for
us
and
like
with
the
giveraise
customization
we
also
want
to
run
the
original
init
in
person
by
calling
through
the
class
name
so
it
still
initializes
our
objects
state
information
attributes
the
following
extension
will
do
the
job
we
ve
coded
the
new
manager
constructor
and
changed
the
call
that
creates
tom
to
not
pass
in
the
mgr
job
name
add
customization
of
constructor
in
a
subclass
class
person
def
init
self
name
job
none
pay
self
name
name
self
job
job
self
pay
pay
def
lastname
self
return
self
name
split
def
giveraise
self
percent
self
pay
int
self
pay
percent
def
str
self
return
person
s
s
self
name
self
pay
class
manager
person
def
init
self
name
pay
person
init
self
name
mgr
pay
def
giveraise
self
percent
bonus
person
giveraise
self
percent
bonus
redefine
constructor
run
original
with
mgr
if
name
main
bob
person
bob
smith
sue
person
sue
jones
job
dev
pay
print
bob
print
sue
print
bob
lastname
sue
lastname
sue
giveraise
print
sue
tom
manager
tom
jones
tom
giveraise
print
tom
lastname
print
tom
job
name
not
needed
implied
set
by
class
again
we
re
using
the
same
technique
to
augment
the
init
constructor
here
that
we
used
for
giveraise
earlier
running
the
superclass
version
by
calling
through
the
class
name
directly
and
passing
the
self
instance
along
explicitly
although
the
constructor
has
a
strange
name
the
effect
is
identical
because
we
need
person
s
construction
logic
to
run
too
to
initialize
instance
attributes
we
really
have
to
call
it
this
way
otherwise
instances
would
not
have
any
attributes
attached
calling
superclass
constructors
from
redefinitions
this
way
turns
out
to
be
a
very
common
coding
pattern
in
python
by
itself
python
uses
inheritance
to
look
for
and
call
only
one
init
method
at
construction
time
the
lowest
one
in
the
class
tree
if
you
need
higher
init
methods
to
be
run
at
construction
time
and
you
usually
do
step
customizing
constructors
too
you
must
call
them
manually
through
the
superclass
s
name
the
upside
to
this
is
that
you
can
be
explicit
about
which
argument
to
pass
up
to
the
superclass
s
constructor
and
can
choose
to
not
call
it
at
all
not
calling
the
superclass
constructor
allows
you
to
replace
its
logic
altogether
rather
than
augmenting
it
the
output
of
this
file
s
self
test
code
is
the
same
as
before
we
haven
t
changed
what
it
does
we
ve
simply
restructured
to
get
rid
of
some
logical
redundancy
person
bob
person
sue
smith
jones
person
sue
jones
person
tom
smith
jones
jones
jones
oop
is
simpler
than
you
may
think
in
this
complete
form
despite
their
sizes
our
classes
capture
nearly
all
the
important
concepts
in
python
s
oop
machinery
instance
creation
filling
out
instance
attributes
behavior
methods
encapsulating
logic
in
class
methods
operator
overloading
providing
behavior
for
built
in
operations
like
printing
customizing
behavior
redefining
methods
in
subclasses
to
specialize
them
customizing
constructors
adding
initialization
logic
to
superclass
steps
most
of
these
concepts
are
based
upon
just
three
simple
ideas
the
inheritance
search
for
attributes
in
object
trees
the
special
self
argument
in
methods
and
operator
overloading
s
automatic
dispatch
to
methods
along
the
way
we
ve
also
made
our
code
easy
to
change
in
the
future
by
harnessing
the
class
s
propensity
for
factoring
code
to
reduce
redundancy
for
example
we
wrapped
up
logic
in
methods
and
called
back
to
superclass
methods
from
extensions
to
avoid
having
multiple
copies
of
the
same
code
most
of
these
steps
were
a
natural
outgrowth
of
the
structuring
power
of
classes
by
and
large
that
s
all
there
is
to
oop
in
python
classes
certainly
can
become
larger
than
this
and
there
are
some
more
advanced
class
concepts
such
as
decorators
and
metaclasses
which
we
will
meet
in
later
chapters
in
terms
of
the
basics
though
our
classes
already
do
it
all
in
fact
if
you
ve
grasped
the
workings
of
the
classes
we
ve
written
most
oop
python
code
should
now
be
within
your
reach
other
ways
to
combine
classes
having
said
that
i
should
also
tell
you
that
although
the
basic
mechanics
of
oop
are
simple
in
python
some
of
the
art
in
larger
programs
lies
in
the
way
that
classes
are
put
together
we
re
focusing
on
inheritance
in
this
tutorial
because
that
s
the
mechanism
chapter
a
more
realistic
example
the
python
language
provides
but
programmers
sometimes
combine
classes
in
other
ways
too
for
example
a
common
coding
pattern
involves
nesting
objects
inside
each
other
to
build
up
composites
we
ll
explore
this
pattern
in
more
detail
in
chapter
which
is
really
more
about
design
than
about
python
as
a
quick
example
though
we
could
use
this
composition
idea
to
code
our
manager
extension
by
embedding
a
person
instead
of
inheriting
from
it
the
following
alternative
does
so
by
using
the
getattr
operator
overloading
method
we
will
meet
in
chapter
to
intercept
undefined
attribute
fetches
and
delegate
them
to
the
embedded
object
with
the
getattr
built
in
the
giveraise
method
here
still
achieves
customization
by
changing
the
argument
passed
along
to
the
embedded
object
in
effect
manager
becomes
a
controller
layer
that
passes
calls
down
to
the
embedded
object
rather
than
up
to
superclass
methods
embedding
based
manager
alternative
class
person
same
class
manager
def
init
self
name
pay
self
person
person
name
mgr
pay
def
giveraise
self
percent
bonus
self
person
giveraise
percent
bonus
def
getattr
self
attr
return
getattr
self
person
attr
def
str
self
return
str
self
person
embed
a
person
object
intercept
and
delegate
delegate
all
other
attrs
must
overload
again
in
if
name
main
same
in
fact
this
manager
alternative
is
representative
of
a
general
coding
pattern
usually
known
as
delegation
a
composite
based
structure
that
manages
a
wrapped
object
and
propagates
method
calls
to
it
this
pattern
works
in
our
example
but
it
requires
about
twice
as
much
code
and
is
less
well
suited
than
inheritance
to
the
kinds
of
direct
customizations
we
meant
to
express
in
fact
no
reasonable
python
programmer
would
code
this
example
this
way
in
practice
except
perhaps
those
writing
general
tutorials
manager
isn
t
really
a
person
here
so
we
need
extra
code
to
manually
dispatch
method
calls
to
the
embedded
object
operator
overloading
methods
like
str
must
be
redefined
in
at
least
as
noted
in
the
upcoming
sidebar
catching
built
in
attributes
in
on
page
and
adding
new
manager
behavior
is
less
straightforward
since
state
information
is
one
level
removed
still
object
embedding
and
design
patterns
based
upon
it
can
be
a
very
good
fit
when
embedded
objects
require
more
limited
interaction
with
the
container
than
direct
customization
implies
a
controller
layer
like
this
alternative
manager
for
example
might
come
in
handy
if
we
want
to
trace
or
validate
calls
to
another
object
s
methods
indeed
we
will
use
a
nearly
identical
coding
pattern
when
we
study
class
decorators
later
in
the
step
customizing
constructors
too
book
moreover
a
hypothetical
department
class
like
the
following
could
aggregate
other
objects
in
order
to
treat
them
as
a
set
add
this
to
the
bottom
of
the
person
py
file
to
try
this
on
your
own
aggregate
embedded
objects
into
a
composite
bob
person
sue
person
tom
manager
class
department
def
init
self
args
self
members
list
args
def
addmember
self
person
self
members
append
person
def
giveraises
self
percent
for
person
in
self
members
person
giveraise
percent
def
showall
self
for
person
in
self
members
print
person
development
department
bob
sue
development
addmember
tom
development
giveraises
development
showall
embed
objects
in
a
composite
runs
embedded
objects
giveraise
runs
embedded
objects
str
s
interestingly
this
code
uses
both
inheritance
and
composition
department
is
a
composite
that
embeds
and
controls
other
objects
to
aggregate
but
the
embedded
person
and
manager
objects
themselves
use
inheritance
to
customize
as
another
example
a
gui
might
similarly
use
inheritance
to
customize
the
behavior
or
appearance
of
labels
and
buttons
but
also
composition
to
build
up
larger
packages
of
embedded
widgets
such
as
input
forms
calculators
and
text
editors
the
class
structure
to
use
depends
on
the
objects
you
are
trying
to
model
design
issues
like
composition
are
explored
in
chapter
so
we
ll
postpone
further
investigations
for
now
but
again
in
terms
of
the
basic
mechanics
of
oop
in
python
our
person
and
manager
classes
already
tell
the
entire
story
having
mastered
the
basics
of
oop
though
developing
general
tools
for
applying
it
more
easily
in
your
scripts
is
often
a
natural
next
step
and
the
topic
of
the
next
section
catching
built
in
attributes
in
in
python
and
if
new
style
classes
are
used
the
alternative
delegation
based
manager
class
we
just
coded
will
not
be
able
to
intercept
and
delegate
operator
overloading
method
attributes
like
str
without
redefining
them
although
we
know
that
str
is
the
only
such
name
used
in
our
specific
example
this
a
general
issue
for
delegation
based
classes
recall
that
built
in
operations
like
printing
and
indexing
implicitly
invoke
operator
overloading
methods
such
as
str
and
getitem
in
built
in
operations
like
chapter
a
more
realistic
example
these
do
not
route
their
implicit
attribute
fetches
through
generic
attribute
managers
neither
getattr
run
for
undefined
attributes
nor
its
cousin
getattribute
run
for
all
attributes
is
invoked
this
is
why
we
have
to
redefine
str
redundantly
in
the
alternative
manager
in
order
to
ensure
that
printing
is
routed
to
the
embedded
person
object
when
run
in
python
technically
this
happens
because
classic
classes
normally
look
up
operator
overloading
names
in
instances
at
runtime
but
new
style
classes
do
not
they
skip
the
instance
entirely
and
look
up
such
methods
in
classes
in
classic
classes
built
ins
do
route
attributes
generically
printing
for
example
routes
str
through
getattr
new
style
classes
also
inherit
a
default
for
str
that
would
foil
getattr
but
getattribute
doesn
t
intercept
the
name
in
either
this
is
a
change
but
isn
t
a
show
stopper
delegation
based
classes
can
generally
redefine
operator
overloading
methods
to
delegate
them
to
wrapped
objects
in
either
manually
or
via
tools
or
superclasses
this
topic
is
too
advanced
to
explore
further
in
this
tutorial
though
so
don
t
sweat
the
details
too
much
here
watch
for
it
to
be
revisited
in
the
attribute
management
coverage
of
chapter
and
again
in
the
context
of
private
class
decorators
in
chapter
step
using
introspection
tools
let
s
make
one
final
tweak
before
we
throw
our
objects
onto
a
database
as
they
are
our
classes
are
complete
and
demonstrate
most
of
the
basics
of
oop
in
python
they
still
have
two
remaining
issues
we
probably
should
iron
out
though
before
we
go
live
with
them
first
if
you
look
at
the
display
of
the
objects
as
they
are
right
now
you
ll
notice
that
when
you
print
tom
the
manager
labels
him
as
a
person
that
s
not
technically
incorrect
since
manager
is
a
kind
of
customized
and
specialized
person
still
it
would
be
more
accurate
to
display
objects
with
the
most
specific
that
is
lowest
classes
possible
second
and
perhaps
more
importantly
the
current
display
format
shows
only
the
attributes
we
include
in
our
str
and
that
might
not
account
for
future
goals
for
example
we
can
t
yet
verify
that
tom
s
job
name
has
been
set
to
mgr
correctly
by
manager
s
constructor
because
the
str
we
coded
for
person
does
not
print
this
field
worse
if
we
ever
expand
or
otherwise
change
the
set
of
attributes
assigned
to
our
objects
in
init
we
ll
have
to
remember
to
also
update
str
for
new
names
to
be
displayed
or
it
will
become
out
of
sync
over
time
the
last
point
means
that
yet
again
we
ve
made
potential
extra
work
for
ourselves
in
the
future
by
introducing
redundancy
in
our
code
because
any
disparity
in
str
will
be
reflected
in
the
program
s
output
this
redundancy
may
be
more
obvious
than
the
other
forms
we
addressed
earlier
still
avoiding
extra
work
in
the
future
is
generally
a
good
thing
step
using
introspection
tools
special
class
attributes
we
can
address
both
issues
with
python
s
introspection
tools
special
attributes
and
functions
that
give
us
access
to
some
of
the
internals
of
objects
implementations
these
tools
are
somewhat
advanced
and
generally
used
more
by
people
writing
tools
for
other
programmers
to
use
than
by
programmers
developing
applications
even
so
a
basic
knowledge
of
some
of
these
tools
is
useful
because
they
allow
us
to
write
code
that
processes
classes
in
generic
ways
in
our
code
for
example
there
are
two
hooks
that
can
help
us
out
both
of
which
were
introduced
near
the
end
of
the
preceding
chapter
the
built
in
instance
class
attribute
provides
a
link
from
an
instance
to
the
class
from
which
it
was
created
classes
in
turn
have
a
name
just
like
modules
and
a
bases
sequence
that
provides
access
to
superclasses
we
can
use
these
here
to
print
the
name
of
the
class
from
which
an
instance
is
made
rather
than
one
we
ve
hardcoded
the
built
in
object
dict
attribute
provides
a
dictionary
with
one
key
value
pair
for
every
attribute
attached
to
a
namespace
object
including
modules
classes
and
instances
because
it
is
a
dictionary
we
can
fetch
its
keys
list
index
by
key
iterate
over
its
keys
and
so
on
to
process
all
attributes
generically
we
can
use
this
here
to
print
every
attribute
in
any
instance
not
just
those
we
hardcode
in
custom
displays
here
s
what
these
tools
look
like
in
action
at
python
s
interactive
prompt
notice
how
we
load
person
at
the
interactive
prompt
with
a
from
statement
here
class
names
live
in
and
are
imported
from
modules
exactly
like
function
names
and
other
variables
from
person
import
person
bob
person
bob
smith
print
bob
person
bob
smith
show
bob
s
str
bob
class
class
person
person
bob
class
name
person
show
bob
s
class
and
its
name
list
bob
dict
keys
pay
job
name
attributes
are
really
dict
keys
use
list
to
force
list
in
for
key
in
bob
dict
print
key
bob
dict
key
index
manually
pay
job
none
name
bob
smith
for
key
in
bob
dict
print
key
getattr
bob
key
pay
chapter
a
more
realistic
example
obj
attr
but
attr
is
a
var
job
none
name
bob
smith
as
noted
briefly
in
the
prior
chapter
some
attributes
accessible
from
an
instance
might
not
be
stored
in
the
dict
dictionary
if
the
instance
s
class
defines
slots
an
optional
and
relatively
obscure
feature
of
new
style
classes
and
all
classes
in
python
that
stores
attributes
in
an
array
and
that
we
ll
discuss
in
chapters
and
since
slots
really
belong
to
classes
instead
of
instances
and
since
they
are
very
rarely
used
in
any
event
we
can
safely
ignore
them
here
and
focus
on
the
normal
dict
a
generic
display
tool
we
can
put
these
interfaces
to
work
in
a
superclass
that
displays
accurate
class
names
and
formats
all
attributes
of
an
instance
of
any
class
open
a
new
file
in
your
text
editor
to
code
the
following
it
s
a
new
independent
module
named
classtools
py
that
implements
just
such
a
class
because
its
str
print
overload
uses
generic
introspection
tools
it
will
work
on
any
instance
regardless
of
its
attributes
set
and
because
this
is
a
class
it
automatically
becomes
a
general
formatting
tool
thanks
to
inheritance
it
can
be
mixed
into
any
class
that
wishes
to
use
its
display
format
as
an
added
bonus
if
we
ever
want
to
change
how
instances
are
displayed
we
need
only
change
this
class
as
every
class
that
inherits
its
str
will
automatically
pick
up
the
new
format
when
it
s
next
run
file
classtools
py
new
assorted
class
utilities
and
tools
class
attrdisplay
provides
an
inheritable
print
overload
method
that
displays
instances
with
their
class
names
and
a
name
value
pair
for
each
attribute
stored
on
the
instance
itself
but
not
attrs
inherited
from
its
classes
can
be
mixed
into
any
class
and
will
work
on
any
instance
def
gatherattrs
self
attrs
for
key
in
sorted
self
dict
attrs
append
s
s
key
getattr
self
key
return
join
attrs
def
str
self
return
s
s
self
class
name
self
gatherattrs
if
name
main
class
toptest
attrdisplay
count
def
init
self
self
attr
toptest
count
self
attr
toptest
count
toptest
count
step
using
introspection
tools
class
subtest
toptest
pass
x
y
toptest
subtest
print
x
print
y
show
all
instance
attrs
show
lowest
class
name
notice
the
docstrings
here
as
a
general
purpose
tool
we
want
to
add
some
functional
documentation
for
potential
users
to
read
as
we
saw
in
chapter
docstrings
can
be
placed
at
the
top
of
simple
functions
and
modules
and
also
at
the
start
of
classes
and
their
methods
the
help
function
and
the
pydoc
tool
extracts
and
displays
these
automatically
we
ll
look
at
docstrings
again
in
chapter
when
run
directly
this
module
s
self
test
makes
two
instances
and
prints
them
the
str
defined
here
shows
the
instance
s
class
and
all
its
attributes
names
and
values
in
sorted
attribute
name
order
c
misc
classtools
py
toptest
attr
attr
subtest
attr
attr
instance
versus
class
attributes
if
you
study
the
classtools
module
s
self
test
code
long
enough
you
ll
notice
that
its
class
displays
only
instance
attributes
attached
to
the
self
object
at
the
bottom
of
the
inheritance
tree
that
s
what
self
s
dict
contains
as
an
intended
consequence
we
don
t
see
attributes
inherited
by
the
instance
from
classes
above
it
in
the
tree
e
g
count
in
this
file
s
self
test
code
inherited
class
attributes
are
attached
to
the
class
only
not
copied
down
to
instances
if
you
ever
do
wish
to
include
inherited
attributes
too
you
can
climb
the
class
link
to
the
instance
s
class
use
the
dict
there
to
fetch
class
attributes
and
then
iterate
through
the
class
s
bases
attribute
to
climb
to
even
higher
superclasses
repeating
as
necessary
if
you
re
a
fan
of
simple
code
running
a
built
in
dir
call
on
the
instance
instead
of
using
dict
and
climbing
would
have
much
the
same
effect
since
dir
results
include
inherited
names
in
the
sorted
results
list
from
person
import
person
bob
person
bob
smith
in
python
bob
dict
keys
pay
job
name
instance
attrs
only
dir
bob
inherited
attrs
in
classes
doc
init
module
str
giveraise
job
lastname
name
pay
in
python
chapter
a
more
realistic
example
keys
is
a
view
not
a
list
list
bob
dict
keys
pay
job
name
dir
bob
includes
class
type
methods
class
delattr
dict
doc
eq
format
ge
getattribute
gt
hash
init
le
more
lines
omitted
setattr
sizeof
str
subclasshook
weakref
giveraise
job
lastname
name
pay
the
output
here
varies
between
python
and
because
s
dict
keys
is
not
a
list
and
s
dir
returns
extra
class
type
implementation
attributes
technically
dir
returns
more
in
because
classes
are
all
new
style
and
inherit
a
large
set
of
operator
overloading
names
from
the
class
type
in
fact
you
ll
probably
want
to
filter
out
most
of
the
x
names
in
the
dir
result
since
they
are
internal
implementation
details
and
not
something
you
d
normally
want
to
display
in
the
interest
of
space
we
ll
leave
optional
display
of
inherited
class
attributes
with
either
tree
climbs
or
dir
as
suggested
experiments
for
now
for
more
hints
on
this
front
though
watch
for
the
classtree
py
inheritance
tree
climber
we
will
write
in
chapter
and
the
lister
py
attribute
listers
and
climbers
we
ll
code
in
chapter
name
considerations
in
tool
classes
one
last
subtlety
here
because
our
attrdisplay
class
in
the
classtools
module
is
a
general
tool
designed
to
be
mixed
into
other
arbitrary
classes
we
have
to
be
aware
of
the
potential
for
unintended
name
collisions
with
client
classes
as
is
i
ve
assumed
that
client
subclasses
may
want
to
use
both
its
str
and
gatherattrs
but
the
latter
of
these
may
be
more
than
a
subclass
expects
if
a
subclass
innocently
defines
a
gather
attrs
name
of
its
own
it
will
likely
break
our
class
because
the
lower
version
in
the
subclass
will
be
used
instead
of
ours
to
see
this
for
yourself
add
a
gatherattrs
to
toptest
in
the
file
s
self
test
code
unless
the
new
method
is
identical
or
intentionally
customizes
the
original
our
tool
class
will
no
longer
work
as
planned
class
toptest
attrdisplay
def
gatherattrs
self
return
spam
replaces
method
in
attrdisplay
this
isn
t
necessarily
bad
sometimes
we
want
other
methods
to
be
available
to
subclasses
either
for
direct
calls
or
for
customization
if
we
really
meant
to
provide
a
str
only
though
this
is
less
than
ideal
to
minimize
the
chances
of
name
collisions
like
this
python
programmers
often
prefix
methods
not
meant
for
external
use
with
a
single
underscore
gatherattrs
in
our
case
this
isn
t
foolproof
what
if
another
class
defines
gatherattrs
too
but
it
s
usually
sufficient
and
it
s
a
common
python
naming
convention
for
methods
internal
to
a
class
step
using
introspection
tools
a
better
and
less
commonly
used
solution
would
be
to
use
two
underscores
at
the
front
of
the
method
name
only
gatherattrs
for
us
python
automatically
expands
such
names
to
include
the
enclosing
class
s
name
which
makes
them
truly
unique
this
is
a
feature
usually
called
pseudoprivate
class
attributes
which
we
ll
expand
on
in
chapter
for
now
we
ll
make
both
our
methods
available
our
classes
final
form
now
to
use
this
generic
tool
in
our
classes
all
we
need
to
do
is
import
it
from
its
module
mix
it
in
by
inheritance
in
our
top
level
class
and
get
rid
of
the
more
specific
str
we
coded
before
the
new
print
overload
method
will
be
inherited
by
instances
of
person
as
well
as
manager
manager
gets
str
from
person
which
now
obtains
it
from
the
attrdisplay
coded
in
another
module
here
is
the
final
version
of
our
person
py
file
with
these
changes
applied
file
person
py
final
use
generic
display
tool
from
classtools
import
attrdisplay
class
person
attrdisplay
create
and
process
person
records
def
init
self
name
job
none
pay
self
name
name
self
job
job
self
pay
pay
def
lastname
self
return
self
name
split
def
giveraise
self
percent
self
pay
int
self
pay
percent
assumes
last
is
last
class
manager
person
a
customized
person
with
special
requirements
def
init
self
name
pay
person
init
self
name
mgr
pay
def
giveraise
self
percent
bonus
person
giveraise
self
percent
bonus
percent
must
be
if
name
main
bob
person
bob
smith
sue
person
sue
jones
job
dev
pay
print
bob
print
sue
print
bob
lastname
sue
lastname
sue
giveraise
print
sue
tom
manager
tom
jones
tom
giveraise
chapter
a
more
realistic
example
print
tom
lastname
print
tom
as
this
is
the
final
revision
we
ve
added
a
few
comments
here
to
document
our
work
docstrings
for
functional
descriptions
and
for
smaller
notes
per
best
practice
conventions
when
we
run
this
code
now
we
see
all
the
attributes
of
our
objects
not
just
the
ones
we
hardcoded
in
the
original
str
and
our
final
issue
is
resolved
because
attrdisplay
takes
class
names
off
the
self
instance
directly
each
object
is
shown
with
the
name
of
its
closest
lowest
class
tom
displays
as
a
manager
now
not
a
person
and
we
can
finally
verify
that
his
job
name
has
been
correctly
filled
in
by
the
manager
constructor
c
misc
person
py
person
job
none
name
bob
smith
pay
person
job
dev
name
sue
jones
pay
smith
jones
person
job
dev
name
sue
jones
pay
jones
manager
job
mgr
name
tom
jones
pay
this
is
the
more
useful
display
we
were
after
from
a
larger
perspective
though
our
attribute
display
class
has
become
a
general
tool
which
we
can
mix
into
any
class
by
inheritance
to
leverage
the
display
format
it
defines
further
all
its
clients
will
automatically
pick
up
future
changes
in
our
tool
later
in
the
book
we
ll
meet
even
more
powerful
class
tool
concepts
such
as
decorators
and
metaclasses
along
with
python
s
introspection
tools
they
allow
us
to
write
code
that
augments
and
manages
classes
in
structured
and
maintainable
ways
step
final
storing
objects
in
a
database
at
this
point
our
work
is
almost
complete
we
now
have
a
two
module
system
that
not
only
implements
our
original
design
goals
for
representing
people
but
also
provides
a
general
attribute
display
tool
we
can
use
in
other
programs
in
the
future
by
coding
functions
and
classes
in
module
files
we
ve
ensured
that
they
naturally
support
reuse
and
by
coding
our
software
as
classes
we
ve
ensured
that
it
naturally
supports
extension
although
our
classes
work
as
planned
though
the
objects
they
create
are
not
real
database
records
that
is
if
we
kill
python
our
instances
will
disappear
they
re
transient
objects
in
memory
and
are
not
stored
in
a
more
permanent
medium
like
a
file
so
they
won
t
be
available
in
future
program
runs
it
turns
out
that
it
s
easy
to
make
instance
objects
more
permanent
with
a
python
feature
called
object
persistence
making
objects
live
on
after
the
program
that
creates
them
exits
as
a
final
step
in
this
tutorial
let
s
make
our
objects
permanent
step
final
storing
objects
in
a
database
pickles
and
shelves
object
persistence
is
implemented
by
three
standard
library
modules
available
in
every
python
pickle
serializes
arbitrary
python
objects
to
and
from
a
string
of
bytes
dbm
named
anydbm
in
python
implements
an
access
by
key
filesystem
for
storing
strings
shelve
uses
the
other
two
modules
to
store
python
objects
on
a
file
by
key
we
met
these
modules
very
briefly
in
chapter
when
we
studied
file
basics
they
provide
powerful
data
storage
options
although
we
can
t
do
them
complete
justice
in
this
tutorial
or
book
they
are
simple
enough
that
a
brief
introduction
is
enough
to
get
you
started
the
pickle
module
is
a
sort
of
super
general
object
formatting
and
deformatting
tool
given
a
nearly
arbitrary
python
object
in
memory
it
s
clever
enough
to
convert
the
object
to
a
string
of
bytes
which
it
can
use
later
to
reconstruct
the
original
object
in
memory
the
pickle
module
can
handle
almost
any
object
you
can
create
lists
dictionaries
nested
combinations
thereof
and
class
instances
the
latter
are
especially
useful
things
to
pickle
because
they
provide
both
data
attributes
and
behavior
methods
in
fact
the
combination
is
roughly
equivalent
to
records
and
programs
because
pickle
is
so
general
it
can
replace
extra
code
you
might
otherwise
write
to
create
and
parse
custom
text
file
representations
for
your
objects
by
storing
an
object
s
pickle
string
on
a
file
you
effectively
make
it
permanent
and
persistent
simply
load
and
unpickle
it
later
to
re
create
the
original
object
although
it
s
easy
to
use
pickle
by
itself
to
store
objects
in
simple
flat
files
and
load
them
from
there
later
the
shelve
module
provides
an
extra
layer
of
structure
that
allows
you
to
store
pickled
objects
by
key
shelve
translates
an
object
to
its
pickled
string
with
pickle
and
stores
that
string
under
a
key
in
a
dbm
file
when
later
loading
shelve
fetches
the
pickled
string
by
key
and
re
creates
the
original
object
in
memory
with
pickle
this
is
all
quite
a
trick
but
to
your
script
a
shelve
of
pickled
objects
looks
just
like
a
dictionary
you
index
by
key
to
fetch
assign
to
keys
to
store
and
use
dictionary
tools
such
as
len
in
and
dict
keys
to
get
information
shelves
automatically
map
dictionary
operations
to
objects
stored
in
a
file
in
fact
to
your
script
the
only
coding
difference
between
a
shelve
and
a
normal
dictionary
is
that
you
must
open
shelves
initially
and
must
close
them
after
making
changes
the
net
effect
is
that
a
shelve
provides
a
simple
database
for
storing
and
fetching
native
python
objects
by
keys
and
thus
makes
them
persistent
across
program
runs
it
does
yes
we
use
shelve
as
a
noun
in
python
much
to
the
chagrin
of
a
variety
of
editors
i
ve
worked
with
over
the
years
both
electronic
and
human
chapter
a
more
realistic
example
not
support
query
tools
such
as
sql
and
it
lacks
some
advanced
features
found
in
enterprise
level
databases
such
as
true
transaction
processing
but
native
python
objects
stored
on
a
shelve
may
be
processed
with
the
full
power
of
the
python
language
once
they
are
fetched
back
by
key
storing
objects
on
a
shelve
database
pickling
and
shelves
are
somewhat
advanced
topics
and
we
won
t
go
into
all
their
details
here
you
can
read
more
about
them
in
the
standard
library
manuals
as
well
as
application
focused
books
such
as
programming
python
this
is
all
simpler
in
python
than
in
english
though
so
let
s
jump
into
some
code
let
s
write
a
new
script
that
throws
objects
of
our
classes
onto
a
shelve
in
your
text
editor
open
a
new
file
we
ll
call
makedb
py
since
this
is
a
new
file
we
ll
need
to
import
our
classes
in
order
to
create
a
few
instances
to
store
we
used
from
to
load
a
class
at
the
interactive
prompt
earlier
but
really
as
with
functions
and
other
variables
there
are
two
ways
to
load
a
class
from
a
file
class
names
are
variables
like
any
other
and
not
at
all
magic
in
this
context
import
person
bob
person
person
load
class
with
import
go
through
module
name
from
person
import
person
bob
person
load
class
with
from
use
name
directly
we
ll
use
from
to
load
in
our
script
just
because
it
s
a
bit
less
to
type
copy
or
retype
this
code
to
make
instances
of
our
classes
in
the
new
script
so
we
have
something
to
store
this
is
a
simple
demo
so
we
won
t
worry
about
the
test
code
redundancy
here
once
we
have
some
instances
it
s
almost
trivial
to
store
them
on
a
shelve
we
simply
import
the
shelve
module
open
a
new
shelve
with
an
external
filename
assign
the
objects
to
keys
in
the
shelve
and
close
the
shelve
when
we
re
done
because
we
ve
made
changes
file
makedb
py
store
person
objects
on
a
shelve
database
from
person
import
person
manager
load
our
classes
bob
person
bob
smith
re
create
objects
to
be
stored
sue
person
sue
jones
job
dev
pay
tom
manager
tom
jones
import
shelve
db
shelve
open
persondb
for
object
in
bob
sue
tom
db
object
name
object
db
close
filename
where
objects
are
stored
use
object
s
name
attr
as
key
store
object
on
shelve
by
key
close
after
making
changes
notice
how
we
assign
objects
to
the
shelve
using
their
own
names
as
keys
this
is
just
for
convenience
in
a
shelve
the
key
can
be
any
string
including
one
we
might
create
to
be
unique
using
tools
such
as
process
ids
and
timestamps
available
in
the
os
and
time
standard
library
modules
the
only
rule
is
that
the
keys
must
be
strings
and
should
step
final
storing
objects
in
a
database
be
unique
since
we
can
store
just
one
object
per
key
though
that
object
can
be
a
list
or
dictionary
containing
many
objects
the
values
we
store
under
keys
though
can
be
python
objects
of
almost
any
sort
built
in
types
like
strings
lists
and
dictionaries
as
well
as
user
defined
class
instances
and
nested
combinations
of
all
of
these
that
s
all
there
is
to
it
if
this
script
has
no
output
when
run
it
means
it
probably
worked
we
re
not
printing
anything
just
creating
and
storing
objects
c
misc
makedb
py
exploring
shelves
interactively
at
this
point
there
are
one
or
more
real
files
in
the
current
directory
whose
names
all
start
with
persondb
the
actual
files
created
can
vary
per
platform
and
just
like
in
the
built
in
open
function
the
filename
in
shelve
open
is
relative
to
the
current
working
directory
unless
it
includes
a
directory
path
wherever
they
are
stored
these
files
implement
a
keyed
access
file
that
contains
the
pickled
representation
of
our
three
python
objects
don
t
delete
these
files
they
are
your
database
and
are
what
you
ll
need
to
copy
or
transfer
when
you
back
up
or
move
your
storage
you
can
look
at
the
shelve
s
files
if
you
want
to
either
from
windows
explorer
or
the
python
shell
but
they
are
binary
hash
files
and
most
of
their
content
makes
little
sense
outside
the
context
of
the
shelve
module
with
python
and
no
extra
software
installed
our
database
is
stored
in
three
files
in
it
s
just
one
file
persondb
because
the
bsddb
extension
module
is
preinstalled
with
python
for
shelves
in
bsddb
is
a
third
party
open
source
add
on
directory
listing
module
verify
files
are
present
import
glob
glob
glob
person
person
py
person
pyc
persondb
bak
persondb
dat
persondb
dir
type
the
file
text
mode
for
string
binary
mode
for
bytes
print
open
persondb
dir
read
tom
jones
more
omitted
print
open
persondb
dat
rb
read
b
x
x
cperson
nperson
nq
x
x
q
x
q
x
x
x
x
x
x
payq
x
k
more
omitted
this
content
isn
t
impossible
to
decipher
but
it
can
vary
on
different
platforms
and
doesn
t
exactly
qualify
as
a
user
friendly
database
interface
to
verify
our
work
better
we
can
write
another
script
or
poke
around
our
shelve
at
the
interactive
prompt
because
shelves
are
python
objects
containing
python
objects
we
can
process
them
with
normal
python
syntax
and
development
modes
here
the
interactive
prompt
effectively
becomes
a
database
client
chapter
a
more
realistic
example
import
shelve
db
shelve
open
persondb
reopen
the
shelve
len
db
list
db
keys
tom
jones
sue
jones
bob
smith
three
records
stored
bob
db
bob
smith
print
bob
person
job
none
name
bob
smith
pay
fetch
bob
by
key
runs
str
from
attrdisplay
bob
lastname
smith
runs
lastname
from
person
for
key
in
db
print
key
db
key
iterate
fetch
print
keys
is
the
index
list
to
make
a
list
in
tom
jones
manager
job
mgr
name
tom
jones
pay
sue
jones
person
job
dev
name
sue
jones
pay
bob
smith
person
job
none
name
bob
smith
pay
for
key
in
sorted
db
print
key
db
key
iterate
by
sorted
keys
bob
smith
person
job
none
name
bob
smith
pay
sue
jones
person
job
dev
name
sue
jones
pay
tom
jones
manager
job
mgr
name
tom
jones
pay
notice
that
we
don
t
have
to
import
our
person
or
manager
classes
here
in
order
to
load
or
use
our
stored
objects
for
example
we
can
call
bob
s
lastname
method
freely
and
get
his
custom
print
display
format
automatically
even
though
we
don
t
have
his
person
class
in
our
scope
here
this
works
because
when
python
pickles
a
class
instance
it
records
its
self
instance
attributes
along
with
the
name
of
the
class
it
was
created
from
and
the
module
where
the
class
lives
when
bob
is
later
fetched
from
the
shelve
and
unpickled
python
will
automatically
reimport
the
class
and
link
bob
to
it
the
upshot
of
this
scheme
is
that
class
instances
automatically
acquire
all
their
class
behavior
when
they
are
loaded
in
the
future
we
have
to
import
our
classes
only
to
make
new
instances
not
to
process
existing
ones
although
a
deliberate
feature
this
scheme
has
somewhat
mixed
consequences
the
downside
is
that
classes
and
their
module
s
files
must
be
importable
when
an
instance
is
later
loaded
more
formally
pickleable
classes
must
be
coded
at
the
top
level
of
a
module
file
accessible
from
a
directory
listed
on
the
sys
path
module
search
path
and
shouldn
t
live
in
the
most
script
files
module
main
unless
they
re
always
in
that
module
when
used
because
of
this
external
module
file
requirement
some
applications
choose
to
pickle
simpler
objects
such
as
dictionaries
or
lists
especially
if
they
are
to
be
transferred
across
the
internet
step
final
storing
objects
in
a
database
the
upside
is
that
changes
in
a
class
s
source
code
file
are
automatically
picked
up
when
instances
of
the
class
are
loaded
again
there
is
often
no
need
to
update
stored
objects
themselves
since
updating
their
class
s
code
changes
their
behavior
shelves
also
have
well
known
limitations
the
database
suggestions
at
the
end
of
this
chapter
mention
a
few
of
these
for
simple
object
storage
though
shelves
and
pickles
are
remarkably
easy
to
use
tools
updating
objects
on
a
shelve
now
for
one
last
script
let
s
write
a
program
that
updates
an
instance
record
each
time
it
runs
to
prove
the
point
that
our
objects
really
are
persistent
i
e
that
their
current
values
are
available
every
time
a
python
program
runs
the
following
file
updatedb
py
prints
the
database
and
gives
a
raise
to
one
of
our
stored
objects
each
time
if
you
trace
through
what
s
going
on
here
you
ll
notice
that
we
re
getting
a
lot
of
utility
for
free
printing
our
objects
automatically
employs
the
general
str
overloading
method
and
we
give
raises
by
calling
the
giveraise
method
we
wrote
earlier
this
all
just
works
for
objects
based
on
oop
s
inheritance
model
even
when
they
live
in
a
file
file
updatedb
py
update
person
object
on
database
import
shelve
db
shelve
open
persondb
reopen
shelve
with
same
filename
for
key
in
sorted
db
print
key
t
db
key
iterate
to
display
database
objects
prints
with
custom
format
sue
db
sue
jones
sue
giveraise
db
sue
jones
sue
db
close
index
by
key
to
fetch
update
in
memory
using
class
method
assign
to
key
to
update
in
shelve
close
after
making
changes
because
this
script
prints
the
database
when
it
starts
up
we
have
to
run
it
a
few
times
to
see
our
objects
change
here
it
is
in
action
displaying
all
records
and
increasing
sue
s
pay
each
time
it
s
run
it
s
a
pretty
good
script
for
sue
c
misc
updatedb
py
bob
smith
person
job
none
name
bob
smith
pay
sue
jones
person
job
dev
name
sue
jones
pay
tom
jones
manager
job
mgr
name
tom
jones
pay
c
misc
updatedb
py
bob
smith
person
job
none
name
bob
smith
pay
sue
jones
person
job
dev
name
sue
jones
pay
tom
jones
manager
job
mgr
name
tom
jones
pay
c
misc
updatedb
py
bob
smith
person
job
none
name
bob
smith
pay
sue
jones
person
job
dev
name
sue
jones
pay
tom
jones
manager
job
mgr
name
tom
jones
pay
c
misc
updatedb
py
chapter
a
more
realistic
example
bob
smith
sue
jones
tom
jones
person
job
none
name
bob
smith
pay
person
job
dev
name
sue
jones
pay
manager
job
mgr
name
tom
jones
pay
again
what
we
see
here
is
a
product
of
the
shelve
and
pickle
tools
we
get
from
python
and
of
the
behavior
we
coded
in
our
classes
ourselves
and
once
again
we
can
verify
our
script
s
work
at
the
interactive
prompt
the
shelve
s
equivalent
of
a
database
client
c
misc
python
import
shelve
db
shelve
open
persondb
reopen
database
rec
db
sue
jones
fetch
object
by
key
print
rec
person
job
dev
name
sue
jones
pay
rec
lastname
jones
rec
pay
for
another
example
of
object
persistence
in
this
book
see
the
sidebar
in
chapter
titled
why
you
will
care
classes
and
persistence
on
page
it
stores
a
somewhat
larger
composite
object
in
a
flat
file
with
pickle
instead
of
shelve
but
the
effect
is
similar
for
more
details
on
both
pickles
and
shelves
see
other
books
or
python
s
manuals
future
directions
and
that
s
a
wrap
for
this
tutorial
at
this
point
you
ve
seen
all
the
basics
of
python
s
oop
machinery
in
action
and
you
ve
learned
ways
to
avoid
redundancy
and
its
associated
maintenance
issues
in
your
code
you
ve
built
full
featured
classes
that
do
real
work
as
an
added
bonus
you
ve
made
them
real
database
records
by
storing
them
in
a
python
shelve
so
their
information
lives
on
persistently
there
is
much
more
we
could
explore
here
of
course
for
example
we
could
extend
our
classes
to
make
them
more
realistic
add
new
kinds
of
behavior
to
them
and
so
on
giving
a
raise
for
instance
should
in
practice
verify
that
pay
increase
rates
are
between
zero
and
one
an
extension
we
ll
add
when
we
meet
decorators
later
in
this
book
you
might
also
mutate
this
example
into
a
personal
contacts
database
by
changing
the
state
information
stored
on
objects
as
well
as
the
class
methods
used
to
process
it
we
ll
leave
this
a
suggested
exercise
open
to
your
imagination
we
could
also
expand
our
scope
to
use
tools
that
either
come
with
python
or
are
freely
available
in
the
open
source
world
guis
as
is
we
can
only
process
our
database
with
the
interactive
prompt
s
commandbased
interface
and
scripts
we
could
also
work
on
expanding
our
object
database
s
usability
by
adding
a
graphical
user
interface
for
browsing
and
updating
its
records
guis
can
be
built
portably
with
either
python
s
tkinter
tkinter
in
future
directions
standard
library
support
or
third
party
toolkits
such
as
wxpython
and
pyqt
tkinter
ships
with
python
lets
you
build
simple
guis
quickly
and
is
ideal
for
learning
gui
programming
techniques
wxpython
and
pyqt
tend
to
be
more
complex
to
use
but
often
produce
higher
grade
guis
in
the
end
websites
although
guis
are
convenient
and
fast
the
web
is
hard
to
beat
in
terms
of
accessibility
we
might
also
implement
a
website
for
browsing
and
updating
records
instead
of
or
in
addition
to
guis
and
the
interactive
prompt
websites
can
be
constructed
with
either
basic
cgi
scripting
tools
that
come
with
python
or
fullfeatured
third
party
web
frameworks
such
as
django
turbogears
pylons
web
py
zope
or
google
s
app
engine
on
the
web
your
data
can
still
be
stored
in
a
shelve
pickle
file
or
other
python
based
medium
the
scripts
that
process
it
are
simply
run
automatically
on
a
server
in
response
to
requests
from
web
browsers
and
other
clients
and
they
produce
html
to
interact
with
a
user
either
directly
or
by
interfacing
with
framework
apis
web
services
although
web
clients
can
often
parse
information
in
the
replies
from
websites
a
technique
colorfully
known
as
screen
scraping
we
might
go
further
and
provide
a
more
direct
way
to
fetch
records
on
the
web
via
a
web
services
interface
such
as
soap
or
xml
rpc
calls
apis
supported
by
either
python
itself
or
the
third
party
open
source
domain
such
apis
return
data
in
a
more
direct
form
rather
than
embedded
in
the
html
of
a
reply
page
databases
if
our
database
becomes
higher
volume
or
critical
we
might
eventually
move
it
from
shelves
to
a
more
full
featured
storage
mechanism
such
as
the
open
source
zodb
object
oriented
database
system
oodb
or
a
more
traditional
sql
based
relational
database
system
such
as
mysql
oracle
postgresql
or
sqlite
python
itself
comes
with
the
in
process
sqlite
database
system
built
in
but
other
open
source
options
are
freely
available
on
the
web
zodb
for
example
is
similar
to
python
s
shelve
but
addresses
many
of
its
limitations
supporting
larger
databases
concurrent
updates
transaction
processing
and
automatic
write
through
on
inmemory
changes
sql
based
systems
like
mysql
offer
enterprise
level
tools
for
database
storage
and
may
be
directly
used
from
a
within
a
python
script
orms
if
we
do
migrate
to
a
relational
database
system
for
storage
we
don
t
have
to
sacrifice
python
s
oop
tools
object
relational
mappers
orms
like
sqlobject
and
sqlalchemy
can
automatically
map
relational
tables
and
rows
to
and
from
python
classes
and
instances
such
that
we
can
process
the
stored
data
using
normal
python
class
syntax
this
approach
provides
an
alternative
to
oodbs
like
shelve
and
zodb
and
leverages
the
power
of
both
relational
databases
and
python
s
class
model
chapter
a
more
realistic
example
while
i
hope
this
introduction
whets
your
appetite
for
future
exploration
all
of
these
topics
are
of
course
far
beyond
the
scope
of
this
tutorial
and
this
book
at
large
if
you
want
to
explore
any
of
them
on
your
own
see
the
web
python
s
standard
library
manuals
and
application
focused
books
such
as
programming
python
in
the
latter
i
pick
up
this
example
where
we
ve
stopped
here
showing
how
to
add
both
a
gui
and
a
website
on
top
of
the
database
to
allow
for
browsing
and
updating
instance
records
i
hope
to
see
you
there
eventually
but
first
let
s
return
to
class
fundamentals
and
finish
up
the
rest
of
the
core
python
language
story
chapter
summary
in
this
chapter
we
explored
all
the
fundamentals
of
python
classes
and
oop
in
action
by
building
upon
a
simple
but
real
example
step
by
step
we
added
constructors
methods
operator
overloading
customization
with
subclasses
and
introspection
tools
and
we
met
other
concepts
such
as
composition
delegation
and
polymorphism
along
the
way
in
the
end
we
took
objects
created
by
our
classes
and
made
them
persistent
by
storing
them
on
a
shelve
object
database
an
easy
to
use
system
for
saving
and
retrieving
native
python
objects
by
key
while
exploring
class
basics
we
also
encountered
multiple
ways
to
factor
our
code
to
reduce
redundancy
and
minimize
future
maintenance
costs
finally
we
briefly
previewed
ways
to
extend
our
code
with
application
programming
tools
such
as
guis
and
databases
covered
in
follow
up
books
in
the
next
chapters
of
this
part
of
the
book
we
ll
return
to
our
study
of
the
details
behind
python
s
class
model
and
investigate
its
application
to
some
of
the
design
concepts
used
to
combine
classes
in
larger
programs
before
we
move
ahead
though
let
s
work
through
this
chapter
s
quiz
to
review
what
we
covered
here
since
we
ve
already
done
a
lot
of
hands
on
work
in
this
chapter
we
ll
close
with
a
set
of
mostly
theoryoriented
questions
designed
to
make
you
trace
through
some
of
the
code
and
ponder
some
of
the
bigger
ideas
behind
it
test
your
knowledge
quiz
when
we
fetch
a
manager
object
from
the
shelve
and
print
it
where
does
the
display
format
logic
come
from
when
we
fetch
a
person
object
from
a
shelve
without
importing
its
module
how
does
the
object
know
that
it
has
a
giveraise
method
that
we
can
call
why
is
it
so
important
to
move
processing
into
methods
instead
of
hardcoding
it
outside
the
class
test
your
knowledge
quiz
why
is
it
better
to
customize
by
subclassing
rather
than
copying
the
original
and
modifying
why
is
it
better
to
call
back
to
a
superclass
method
to
run
default
actions
instead
of
copying
and
modifying
its
code
in
a
subclass
why
is
it
better
to
use
tools
like
dict
that
allow
objects
to
be
processed
generically
than
to
write
more
custom
code
for
each
type
of
class
in
general
terms
when
might
you
choose
to
use
object
embedding
and
composition
instead
of
inheritance
how
might
you
modify
the
classes
in
this
chapter
to
implement
a
personal
contacts
database
in
python
test
your
knowledge
answers
in
the
final
version
of
our
classes
manager
ultimately
inherits
its
str
printing
method
from
attrdisplay
in
the
separate
classtools
module
manager
doesn
t
have
one
itself
so
the
inheritance
search
climbs
to
its
person
superclass
because
there
is
no
str
there
either
the
search
climbs
higher
and
finds
it
in
attrdisplay
the
class
names
listed
in
parentheses
in
a
class
statement
s
header
line
provide
the
links
to
higher
superclasses
shelves
really
the
pickle
module
they
use
automatically
relink
an
instance
to
the
class
it
was
created
from
when
that
instance
is
later
loaded
back
into
memory
python
reimports
the
class
from
its
module
internally
creates
an
instance
with
its
stored
attributes
and
sets
the
instance
s
class
link
to
point
to
its
original
class
this
way
loaded
instances
automatically
obtain
all
their
original
methods
like
lastname
giveraise
and
str
even
if
we
have
not
imported
the
instance
s
class
into
our
scope
it
s
important
to
move
processing
into
methods
so
that
there
is
only
one
copy
to
change
in
the
future
and
so
that
the
methods
can
be
run
on
any
instance
this
is
python
s
notion
of
encapsulation
wrapping
up
logic
behind
interfaces
to
better
support
future
code
maintenance
if
you
don
t
do
so
you
create
code
redundancy
that
can
multiply
your
work
effort
as
the
code
evolves
in
the
future
customizing
with
subclasses
reduces
development
effort
in
oop
we
code
by
customizing
what
has
already
been
done
rather
than
copying
or
changing
existing
code
this
is
the
real
big
idea
in
oop
because
we
can
easily
extend
our
prior
work
by
coding
new
subclasses
we
can
leverage
what
we
ve
already
done
this
is
much
better
than
either
starting
from
scratch
each
time
or
introducing
multiple
redundant
copies
of
code
that
may
all
have
to
be
updated
in
the
future
chapter
a
more
realistic
example
copying
and
modifying
code
doubles
your
potential
work
effort
in
the
future
regardless
of
the
context
if
a
subclass
needs
to
perform
default
actions
coded
in
a
superclass
method
it
s
much
better
to
call
back
to
the
original
through
the
superclass
s
name
than
to
copy
its
code
this
also
holds
true
for
superclass
constructors
again
copying
code
creates
redundancy
which
is
a
major
issue
as
code
evolves
generic
tools
can
avoid
hardcoded
solutions
that
must
be
kept
in
sync
with
the
rest
of
the
class
as
it
evolves
over
time
a
generic
str
print
method
for
example
need
not
be
updated
each
time
a
new
attribute
is
added
to
instances
in
an
init
constructor
in
addition
a
generic
print
method
inherited
by
all
classes
only
appears
and
need
only
be
modified
in
one
place
changes
in
the
generic
version
are
picked
up
by
all
classes
that
inherit
from
the
generic
class
again
eliminating
code
redundancy
cuts
future
development
effort
that
s
one
of
the
primary
assets
classes
bring
to
the
table
inheritance
is
best
at
coding
extensions
based
on
direct
customization
like
our
manager
specialization
of
person
composition
is
well
suited
to
scenarios
where
multiple
objects
are
aggregated
into
a
whole
and
directed
by
a
controller
layer
class
inheritance
passes
calls
up
to
reuse
and
composition
passes
down
to
delegate
inheritance
and
composition
are
not
mutually
exclusive
often
the
objects
embedded
in
a
controller
are
themselves
customizations
based
upon
inheritance
the
classes
in
this
chapter
could
be
used
as
boilerplate
template
code
to
implement
a
variety
of
types
of
databases
essentially
you
can
repurpose
them
by
modifying
the
constructors
to
record
different
attributes
and
providing
whatever
methods
are
appropriate
for
the
target
application
for
instance
you
might
use
attributes
such
as
name
address
birthday
phone
email
and
so
on
for
a
contacts
database
and
methods
appropriate
for
this
purpose
a
method
named
sendmail
for
example
might
use
python
s
standard
library
smptlib
module
to
send
an
email
to
one
of
the
contacts
automatically
when
called
see
python
s
manuals
or
application
level
books
for
more
details
on
such
tools
the
attrdisplay
tool
we
wrote
here
could
be
used
verbatim
to
print
your
objects
because
it
is
intentionally
generic
most
of
the
shelve
database
code
here
can
be
used
to
store
your
objects
too
with
minor
changes
test
your
knowledge
answers
chapter
class
coding
details
if
you
haven
t
quite
gotten
all
of
python
oop
yet
don
t
worry
now
that
we
ve
had
a
quick
tour
we
re
going
to
dig
a
bit
deeper
and
study
the
concepts
introduced
earlier
in
further
detail
in
this
and
the
following
chapter
we
ll
take
another
look
at
class
mechanics
here
we
re
going
to
study
classes
methods
and
inheritance
formalizing
and
expanding
on
some
of
the
coding
ideas
introduced
in
chapter
because
the
class
is
our
last
namespace
tool
we
ll
summarize
python
s
namespace
concepts
here
as
well
the
next
chapter
continues
this
in
depth
second
pass
over
class
mechanics
by
covering
one
specific
aspect
operator
overloading
besides
presenting
the
details
this
chapter
and
the
next
also
give
us
an
opportunity
to
explore
some
larger
classes
than
those
we
have
studied
so
far
the
class
statement
although
the
python
class
statement
may
seem
similar
to
tools
in
other
oop
languages
on
the
surface
on
closer
inspection
it
is
quite
different
from
what
some
programmers
are
used
to
for
example
as
in
c
the
class
statement
is
python
s
main
oop
tool
but
unlike
in
c
python
s
class
is
not
a
declaration
like
a
def
a
class
statement
is
an
object
builder
and
an
implicit
assignment
when
run
it
generates
a
class
object
and
stores
a
reference
to
it
in
the
name
used
in
the
header
also
like
a
def
a
class
statement
is
true
executable
code
your
class
doesn
t
exist
until
python
reaches
and
runs
the
class
statement
that
defines
it
typically
while
importing
the
module
it
is
coded
in
but
not
before
general
form
class
is
a
compound
statement
with
a
body
of
indented
statements
typically
appearing
under
the
header
in
the
header
superclasses
are
listed
in
parentheses
after
the
class
name
separated
by
commas
listing
more
than
one
superclass
leads
to
multiple
inheritance
which
we
ll
discuss
more
formally
in
chapter
here
is
the
statement
s
general
form
class
name
superclass
data
value
def
method
self
self
member
value
assign
to
name
shared
class
data
methods
per
instance
data
within
the
class
statement
any
assignments
generate
class
attributes
and
specially
named
methods
overload
operators
for
instance
a
function
called
init
is
called
at
instance
object
construction
time
if
defined
example
as
we
ve
seen
classes
are
mostly
just
namespaces
that
is
tools
for
defining
names
i
e
attributes
that
export
data
and
logic
to
clients
so
how
do
you
get
from
the
class
statement
to
a
namespace
here
s
how
just
like
in
a
module
file
the
statements
nested
in
a
class
statement
body
create
its
attributes
when
python
executes
a
class
statement
not
a
call
to
a
class
it
runs
all
the
statements
in
its
body
from
top
to
bottom
assignments
that
happen
during
this
process
create
names
in
the
class
s
local
scope
which
become
attributes
in
the
associated
class
object
because
of
this
classes
resemble
both
modules
and
functions
like
functions
class
statements
are
local
scopes
where
names
created
by
nested
assignments
live
like
names
in
a
module
names
assigned
in
a
class
statement
become
attributes
in
a
class
object
the
main
distinction
for
classes
is
that
their
namespaces
are
also
the
basis
of
inheritance
in
python
reference
attributes
that
are
not
found
in
a
class
or
instance
object
are
fetched
from
other
classes
because
class
is
a
compound
statement
any
sort
of
statement
can
be
nested
inside
its
body
print
if
def
and
so
on
all
the
statements
inside
the
class
statement
run
when
the
class
statement
itself
runs
not
when
the
class
is
later
called
to
make
an
instance
assigning
names
inside
the
class
statement
makes
class
attributes
and
nested
defs
make
class
methods
but
other
assignments
make
attributes
too
for
example
assignments
of
simple
nonfunction
objects
to
class
attributes
produce
data
attributes
shared
by
all
instances
class
shareddata
spam
x
shareddata
y
shareddata
x
spam
y
spam
chapter
class
coding
details
generates
a
class
data
attribute
make
two
instances
they
inherit
and
share
spam
here
because
the
name
spam
is
assigned
at
the
top
level
of
a
class
statement
it
is
attached
to
the
class
and
so
will
be
shared
by
all
instances
we
can
change
it
by
going
through
the
class
name
and
we
can
refer
to
it
through
either
instances
or
the
class
shareddata
spam
x
spam
y
spam
shareddata
spam
such
class
attributes
can
be
used
to
manage
information
that
spans
all
the
instances
a
counter
of
the
number
of
instances
generated
for
example
we
ll
expand
on
this
idea
by
example
in
chapter
now
watch
what
happens
if
we
assign
the
name
spam
through
an
instance
instead
of
the
class
x
spam
x
spam
y
spam
shareddata
spam
assignments
to
instance
attributes
create
or
change
the
names
in
the
instance
rather
than
in
the
shared
class
more
generally
inheritance
searches
occur
only
on
attribute
references
not
on
assignment
assigning
to
an
object
s
attribute
always
changes
that
object
and
no
other
for
example
y
spam
is
looked
up
in
the
class
by
inheritance
but
the
assignment
to
x
spam
attaches
a
name
to
x
itself
here
s
a
more
comprehensive
example
of
this
behavior
that
stores
the
same
name
in
two
places
suppose
we
run
the
following
class
class
mixednames
data
spam
def
init
self
value
self
data
value
def
display
self
print
self
data
mixednames
data
define
class
assign
class
attr
assign
method
name
assign
instance
attr
instance
attr
class
attr
this
class
contains
two
defs
which
bind
class
attributes
to
method
functions
it
also
contains
an
assignment
statement
because
this
assignment
assigns
the
name
data
inside
the
class
it
lives
in
the
class
s
local
scope
and
becomes
an
attribute
of
the
class
object
like
all
class
attributes
this
data
is
inherited
and
shared
by
all
instances
of
the
class
that
don
t
have
data
attributes
of
their
own
when
we
make
instances
of
this
class
the
name
data
is
attached
to
those
instances
by
the
assignment
to
self
data
in
the
constructor
method
x
mixednames
y
mixednames
make
two
instance
objects
each
has
its
own
data
if
you
ve
used
c
you
may
recognize
this
as
similar
to
the
notion
of
c
s
static
data
members
members
that
are
stored
in
the
class
independent
of
instances
in
python
it
s
nothing
special
all
class
attributes
are
just
names
assigned
in
the
class
statement
whether
they
happen
to
reference
functions
c
s
methods
or
something
else
c
s
members
in
chapter
we
ll
also
meet
python
static
methods
akin
to
those
in
c
which
are
just
self
less
functions
that
usually
process
class
attributes
unless
the
class
has
redefined
the
attribute
assignment
operation
to
do
something
unique
with
the
setattr
operator
overloading
method
discussed
in
chapter
the
class
statement
x
display
y
display
spam
spam
self
data
differs
mixednames
data
is
the
same
the
net
result
is
that
data
lives
in
two
places
in
the
instance
objects
created
by
the
self
data
assignment
in
init
and
in
the
class
from
which
they
inherit
names
created
by
the
data
assignment
in
the
class
the
class
s
display
method
prints
both
versions
by
first
qualifying
the
self
instance
and
then
the
class
by
using
these
techniques
to
store
attributes
in
different
objects
we
determine
their
scope
of
visibility
when
attached
to
classes
names
are
shared
in
instances
names
record
per
instance
data
not
shared
behavior
or
data
although
inheritance
searches
look
up
names
for
us
we
can
always
get
to
an
attribute
anywhere
in
a
tree
by
accessing
the
desired
object
directly
in
the
preceding
example
for
instance
specifying
x
data
or
self
data
will
return
an
instance
name
which
normally
hides
the
same
name
in
the
class
however
mixed
names
data
grabs
the
class
name
explicitly
we
ll
see
various
roles
for
such
coding
patterns
later
the
next
section
describes
one
of
the
most
common
methods
because
you
already
know
about
functions
you
also
know
about
methods
in
classes
methods
are
just
function
objects
created
by
def
statements
nested
in
a
class
statement
s
body
from
an
abstract
perspective
methods
provide
behavior
for
instance
objects
to
inherit
from
a
programming
perspective
methods
work
in
exactly
the
same
way
as
simple
functions
with
one
crucial
exception
a
method
s
first
argument
always
receives
the
instance
object
that
is
the
implied
subject
of
the
method
call
in
other
words
python
automatically
maps
instance
method
calls
to
class
method
functions
as
follows
method
calls
made
through
an
instance
like
this
instance
method
args
are
automatically
translated
to
class
method
function
calls
of
this
form
class
method
instance
args
where
the
class
is
determined
by
locating
the
method
name
using
python
s
inheritance
search
procedure
in
fact
both
call
forms
are
valid
in
python
besides
the
normal
inheritance
of
method
attribute
names
the
special
first
argument
is
the
only
real
magic
behind
method
calls
in
a
class
method
the
first
argument
is
usually
called
self
by
convention
technically
only
its
position
is
significant
not
its
name
this
argument
provides
methods
with
a
hook
back
to
the
instance
that
is
the
subject
of
the
call
because
classes
generate
many
instance
objects
they
need
to
use
this
argument
to
manage
data
that
varies
per
instance
chapter
class
coding
details
c
programmers
may
recognize
python
s
self
argument
as
being
similar
to
c
s
this
pointer
in
python
though
self
is
always
explicit
in
your
code
methods
must
always
go
through
self
to
fetch
or
change
attributes
of
the
instance
being
processed
by
the
current
method
call
this
explicit
nature
of
self
is
by
design
the
presence
of
this
name
makes
it
obvious
that
you
are
using
instance
attribute
names
in
your
script
not
names
in
the
local
or
global
scope
method
example
to
clarify
these
concepts
let
s
turn
to
an
example
suppose
we
define
the
following
class
class
nextclass
def
printer
self
text
self
message
text
print
self
message
define
class
define
method
change
instance
access
instance
the
name
printer
references
a
function
object
because
it
s
assigned
in
the
class
statement
s
scope
it
becomes
a
class
object
attribute
and
is
inherited
by
every
instance
made
from
the
class
normally
because
methods
like
printer
are
designed
to
process
instances
we
call
them
through
instances
x
nextclass
make
instance
x
printer
instance
call
instance
call
call
its
method
x
message
instance
call
instance
changed
when
we
call
the
method
by
qualifying
an
instance
like
this
printer
is
first
located
by
inheritance
and
then
its
self
argument
is
automatically
assigned
the
instance
object
x
the
text
argument
gets
the
string
passed
at
the
call
instance
call
notice
that
because
python
automatically
passes
the
first
argument
to
self
for
us
we
only
actually
have
to
pass
in
one
argument
inside
printer
the
name
self
is
used
to
access
or
set
per
instance
data
because
it
refers
back
to
the
instance
currently
being
processed
methods
may
be
called
in
one
of
two
ways
through
an
instance
or
through
the
class
itself
for
example
we
can
also
call
printer
by
going
through
the
class
name
provided
we
pass
an
instance
to
the
self
argument
explicitly
nextclass
printer
x
class
call
class
call
direct
class
call
x
message
class
call
instance
changed
again
methods
calls
routed
through
the
instance
and
the
class
have
the
exact
same
effect
as
long
as
we
pass
the
same
instance
object
ourselves
in
the
class
form
by
default
in
fact
you
get
an
error
message
if
you
try
to
call
a
method
without
any
instance
nextclass
printer
bad
call
typeerror
unbound
method
printer
must
be
called
with
nextclass
instance
calling
superclass
constructors
methods
are
normally
called
through
instances
calls
to
methods
through
a
class
though
do
show
up
in
a
variety
of
special
roles
one
common
scenario
involves
the
constructor
method
the
init
method
like
all
attributes
is
looked
up
by
inheritance
this
means
that
at
construction
time
python
locates
and
calls
just
one
init
if
subclass
constructors
need
to
guarantee
that
superclass
construction
time
logic
runs
too
they
generally
must
call
the
superclass
s
init
method
explicitly
through
the
class
class
super
def
init
self
x
default
code
class
sub
super
def
init
self
x
y
super
init
self
x
custom
code
run
superclass
init
do
my
init
actions
i
sub
this
is
one
of
the
few
contexts
in
which
your
code
is
likely
to
call
an
operator
overloading
method
directly
naturally
you
should
only
call
the
superclass
constructor
this
way
if
you
really
want
it
to
run
without
the
call
the
subclass
replaces
it
completely
for
a
more
realistic
illustration
of
this
technique
in
action
see
the
manager
class
example
in
the
prior
chapter
s
tutorial
other
method
call
possibilities
this
pattern
of
calling
methods
through
a
class
is
the
general
basis
of
extending
instead
of
completely
replacing
inherited
method
behavior
in
chapter
we
ll
also
meet
a
new
option
added
in
python
static
methods
that
allow
you
to
code
methods
that
do
not
expect
instance
objects
in
their
first
arguments
such
methods
can
act
like
simple
instanceless
functions
with
names
that
are
local
to
the
classes
in
which
they
are
coded
and
may
be
used
to
manage
class
data
a
related
concept
the
class
method
receives
a
class
when
called
instead
of
an
instance
and
can
be
used
to
manage
per
class
data
these
are
advanced
and
optional
extensions
though
normally
you
must
always
pass
an
instance
to
a
method
whether
it
is
called
through
an
instance
or
a
class
on
a
somewhat
related
note
you
can
also
code
multiple
init
methods
within
the
same
class
but
only
the
last
definition
will
be
used
see
chapter
for
more
details
on
multiple
method
definitions
chapter
class
coding
details
inheritance
the
whole
point
of
a
namespace
tool
like
the
class
statement
is
to
support
name
inheritance
this
section
expands
on
some
of
the
mechanisms
and
roles
of
attribute
inheritance
in
python
in
python
inheritance
happens
when
an
object
is
qualified
and
it
involves
searching
an
attribute
definition
tree
one
or
more
namespaces
every
time
you
use
an
expression
of
the
form
object
attr
where
object
is
an
instance
or
class
object
python
searches
the
namespace
tree
from
bottom
to
top
beginning
with
object
looking
for
the
first
attr
it
can
find
this
includes
references
to
self
attributes
in
your
methods
because
lower
definitions
in
the
tree
override
higher
ones
inheritance
forms
the
basis
of
specialization
attribute
tree
construction
figure
summarizes
the
way
namespace
trees
are
constructed
and
populated
with
names
generally
instance
attributes
are
generated
by
assignments
to
self
attributes
in
methods
class
attributes
are
created
by
statements
assignments
in
class
statements
superclass
links
are
made
by
listing
classes
in
parentheses
in
a
class
statement
header
the
net
result
is
a
tree
of
attribute
namespaces
that
leads
from
an
instance
to
the
class
it
was
generated
from
to
all
the
superclasses
listed
in
the
class
header
python
searches
upward
in
this
tree
from
instances
to
superclasses
each
time
you
use
qualification
to
fetch
an
attribute
name
from
an
instance
object
specializing
inherited
methods
the
tree
searching
model
of
inheritance
just
described
turns
out
to
be
a
great
way
to
specialize
systems
because
inheritance
finds
names
in
subclasses
before
it
checks
superclasses
subclasses
can
replace
default
behavior
by
redefining
their
superclasses
attributes
in
fact
you
can
build
entire
systems
as
hierarchies
of
classes
which
are
extended
by
adding
new
external
subclasses
rather
than
changing
existing
logic
in
place
this
description
isn
t
complete
because
we
can
also
create
instance
and
class
attributes
by
assigning
to
objects
outside
class
statements
but
that
s
a
much
less
common
and
sometimes
more
error
prone
approach
changes
aren
t
isolated
to
class
statements
in
python
all
attributes
are
always
accessible
by
default
we
ll
talk
more
about
attribute
name
privacy
in
chapter
when
we
study
setattr
in
chapter
when
we
meet
x
names
and
again
in
chapter
where
we
ll
implement
it
with
a
class
decorator
inheritance
the
idea
of
redefining
inherited
names
leads
to
a
variety
of
specialization
techniques
for
instance
subclasses
may
replace
inherited
attributes
completely
provide
attributes
that
a
superclass
expects
to
find
and
extend
superclass
methods
by
calling
back
to
the
superclass
from
an
overridden
method
we
ve
already
seen
replacement
in
action
here
s
an
example
that
shows
how
extension
works
class
super
def
method
self
print
in
super
method
class
sub
super
def
method
self
print
starting
sub
method
super
method
self
print
ending
sub
method
override
method
add
actions
here
run
default
action
figure
program
code
creates
a
tree
of
objects
in
memory
to
be
searched
by
attribute
inheritance
calling
a
class
creates
a
new
instance
that
remembers
its
class
running
a
class
statement
creates
a
new
class
and
superclasses
are
listed
in
parentheses
in
the
class
statement
header
each
attribute
reference
triggers
a
new
bottom
up
tree
search
even
references
to
self
attributes
within
a
class
s
methods
direct
superclass
method
calls
are
the
crux
of
the
matter
here
the
sub
class
replaces
super
s
method
function
with
its
own
specialized
version
but
within
the
replacement
sub
calls
back
to
the
version
exported
by
super
to
carry
out
the
default
behavior
in
other
words
sub
method
just
extends
super
method
s
behavior
rather
than
replacing
it
completely
chapter
class
coding
details
x
super
x
method
in
super
method
make
a
super
instance
runs
super
method
x
sub
x
method
starting
sub
method
in
super
method
ending
sub
method
make
a
sub
instance
runs
sub
method
calls
super
method
this
extension
coding
pattern
is
also
commonly
used
with
constructors
see
the
section
methods
on
page
for
an
example
class
interface
techniques
extension
is
only
one
way
to
interface
with
a
superclass
the
file
shown
in
this
section
specialize
py
defines
multiple
classes
that
illustrate
a
variety
of
common
techniques
super
defines
a
method
function
and
a
delegate
that
expects
an
action
in
a
subclass
inheritor
doesn
t
provide
any
new
names
so
it
gets
everything
defined
in
super
replacer
overrides
super
s
method
with
a
version
of
its
own
extender
customizes
super
s
method
by
overriding
and
calling
back
to
run
the
default
provider
implements
the
action
method
expected
by
super
s
delegate
method
study
each
of
these
subclasses
to
get
a
feel
for
the
various
ways
they
customize
their
common
superclass
here
s
the
file
class
super
def
method
self
print
in
super
method
def
delegate
self
self
action
default
behavior
expected
to
be
defined
class
inheritor
super
pass
inherit
method
verbatim
class
replacer
super
def
method
self
print
in
replacer
method
replace
method
completely
class
extender
super
def
method
self
print
starting
extender
method
super
method
self
print
ending
extender
method
extend
method
behavior
inheritance
class
provider
super
def
action
self
print
in
provider
action
fill
in
a
required
method
if
name
main
for
klass
in
inheritor
replacer
extender
print
n
klass
name
klass
method
print
nprovider
x
provider
x
delegate
a
few
things
are
worth
pointing
out
here
first
the
self
test
code
at
the
end
of
this
example
creates
instances
of
three
different
classes
in
a
for
loop
because
classes
are
objects
you
can
put
them
in
a
tuple
and
create
instances
generically
more
on
this
idea
later
classes
also
have
the
special
name
attribute
like
modules
it
s
preset
to
a
string
containing
the
name
in
the
class
header
here
s
what
happens
when
we
run
the
file
python
specialize
py
inheritor
in
super
method
replacer
in
replacer
method
extender
starting
extender
method
in
super
method
ending
extender
method
provider
in
provider
action
abstract
superclasses
notice
how
the
provider
class
in
the
prior
example
works
when
we
call
the
delegate
method
through
a
provider
instance
two
independent
inheritance
searches
occur
on
the
initial
x
delegate
call
python
finds
the
delegate
method
in
super
by
searching
the
provider
instance
and
above
the
instance
x
is
passed
into
the
method
s
self
argument
as
usual
inside
the
super
delegate
method
self
action
invokes
a
new
independent
inheritance
search
of
self
and
above
because
self
references
a
provider
instance
the
action
method
is
located
in
the
provider
subclass
this
filling
in
the
blanks
sort
of
coding
structure
is
typical
of
oop
frameworks
at
least
in
terms
of
the
delegate
method
the
superclass
in
this
example
is
what
is
sometimes
called
an
abstract
superclass
a
class
that
expects
parts
of
its
behavior
to
be
chapter
class
coding
details
provided
by
its
subclasses
if
an
expected
method
is
not
defined
in
a
subclass
python
raises
an
undefined
name
exception
when
the
inheritance
search
fails
class
coders
sometimes
make
such
subclass
requirements
more
obvious
with
assert
statements
or
by
raising
the
built
in
notimplementederror
exception
with
raise
statements
we
ll
study
statements
that
may
trigger
exceptions
in
depth
in
the
next
part
of
this
book
as
a
quick
preview
here
s
the
assert
scheme
in
action
class
super
def
delegate
self
self
action
def
action
self
assert
false
action
must
be
defined
if
this
version
is
called
x
super
x
delegate
assertionerror
action
must
be
defined
we
ll
meet
assert
in
chapters
and
in
short
if
its
first
expression
evaluates
to
false
it
raises
an
exception
with
the
provided
error
message
here
the
expression
is
always
false
so
as
to
trigger
an
error
message
if
a
method
is
not
redefined
and
inheritance
locates
the
version
here
alternatively
some
classes
simply
raise
a
notimplementederror
exception
directly
in
such
method
stubs
to
signal
the
mistake
class
super
def
delegate
self
self
action
def
action
self
raise
notimplementederror
action
must
be
defined
x
super
x
delegate
notimplementederror
action
must
be
defined
for
instances
of
subclasses
we
still
get
the
exception
unless
the
subclass
provides
the
expected
method
to
replace
the
default
in
the
superclass
class
sub
super
pass
x
sub
x
delegate
notimplementederror
action
must
be
defined
class
sub
super
def
action
self
print
spam
x
sub
x
delegate
spam
for
a
somewhat
more
realistic
example
of
this
section
s
concepts
in
action
see
the
zoo
animal
hierarchy
exercise
exercise
at
the
end
of
chapter
and
its
solution
in
part
vi
classes
and
oop
on
page
in
appendix
b
such
taxonomies
are
a
inheritance
traditional
way
to
introduce
oop
but
they
re
a
bit
removed
from
most
developers
job
descriptions
python
and
abstract
superclasses
as
of
python
and
the
prior
section
s
abstract
superclasses
a
k
a
abstract
base
classes
which
require
methods
to
be
filled
in
by
subclasses
may
also
be
implemented
with
special
class
syntax
the
way
we
code
this
varies
slightly
depending
on
the
version
in
python
we
use
a
keyword
argument
in
a
class
header
along
with
special
decorator
syntax
both
of
which
we
ll
study
in
detail
later
in
this
book
from
abc
import
abcmeta
abstractmethod
class
super
metaclass
abcmeta
abstractmethod
def
method
self
pass
but
in
python
we
use
a
class
attribute
instead
class
super
metaclass
abcmeta
abstractmethod
def
method
self
pass
either
way
the
effect
is
the
same
we
can
t
make
an
instance
unless
the
method
is
defined
lower
in
the
class
tree
in
for
example
here
is
the
special
syntax
equivalent
of
the
prior
section
s
example
from
abc
import
abcmeta
abstractmethod
class
super
metaclass
abcmeta
def
delegate
self
self
action
abstractmethod
def
action
self
pass
x
super
typeerror
can
t
instantiate
abstract
class
super
with
abstract
methods
action
class
sub
super
pass
x
sub
typeerror
can
t
instantiate
abstract
class
sub
with
abstract
methods
action
class
sub
super
def
action
self
print
spam
x
sub
x
delegate
spam
chapter
class
coding
details
coded
this
way
a
class
with
an
abstract
method
cannot
be
instantiated
that
is
we
cannot
create
an
instance
by
calling
it
unless
all
of
its
abstract
methods
have
been
defined
in
subclasses
although
this
requires
more
code
the
advantage
of
this
approach
is
that
errors
for
missing
methods
are
issued
when
we
attempt
to
make
an
instance
of
the
class
not
later
when
we
try
to
call
a
missing
method
this
feature
may
also
be
used
to
define
an
expected
interface
automatically
verified
in
client
classes
unfortunately
this
scheme
also
relies
on
two
advanced
language
tools
we
have
not
met
yet
function
decorators
introduced
in
chapter
and
covered
in
depth
in
chapter
as
well
as
metaclass
declarations
mentioned
in
chapter
and
covered
in
chapter
so
we
will
finesse
other
facets
of
this
option
here
see
python
s
standard
manuals
for
more
on
this
as
well
as
precoded
abstract
superclasses
python
provides
namespaces
the
whole
story
now
that
we
ve
examined
class
and
instance
objects
the
python
namespace
story
is
complete
for
reference
i
ll
quickly
summarize
all
the
rules
used
to
resolve
names
here
the
first
things
you
need
to
remember
are
that
qualified
and
unqualified
names
are
treated
differently
and
that
some
scopes
serve
to
initialize
object
namespaces
unqualified
names
e
g
x
deal
with
scopes
qualified
attribute
names
e
g
object
x
use
object
namespaces
some
scopes
initialize
object
namespaces
for
modules
and
classes
simple
names
global
unless
assigned
unqualified
simple
names
follow
the
legb
lexical
scoping
rule
outlined
for
functions
in
chapter
assignment
x
value
makes
names
local
creates
or
changes
the
name
x
in
the
current
local
scope
unless
declared
global
reference
x
looks
for
the
name
x
in
the
current
local
scope
then
any
and
all
enclosing
functions
then
the
current
global
scope
then
the
built
in
scope
attribute
names
object
namespaces
qualified
attribute
names
refer
to
attributes
of
specific
objects
and
obey
the
rules
for
modules
and
classes
for
class
and
instance
objects
the
reference
rules
are
augmented
to
include
the
inheritance
search
procedure
namespaces
the
whole
story
assignment
object
x
value
creates
or
alters
the
attribute
name
x
in
the
namespace
of
the
object
being
qualified
and
none
other
inheritance
tree
climbing
happens
only
on
attribute
reference
not
on
attribute
assignment
reference
object
x
for
class
based
objects
searches
for
the
attribute
name
x
in
object
then
in
all
accessible
classes
above
it
using
the
inheritance
search
procedure
for
nonclass
objects
such
as
modules
fetches
x
from
object
directly
the
zen
of
python
namespaces
assignments
classify
names
with
distinct
search
procedures
for
qualified
and
unqualified
names
and
multiple
lookup
layers
for
both
it
can
sometimes
be
difficult
to
tell
where
a
name
will
wind
up
going
in
python
the
place
where
you
assign
a
name
is
crucial
it
fully
determines
the
scope
or
object
in
which
a
name
will
reside
the
file
manynames
py
illustrates
how
this
principle
translates
to
code
and
summarizes
the
namespace
ideas
we
have
seen
throughout
this
book
manynames
py
x
global
module
name
attribute
x
or
manynames
x
def
f
print
x
access
global
x
def
g
x
print
x
class
c
x
def
m
self
x
self
x
local
function
variable
x
hides
module
x
class
attribute
c
x
local
variable
in
method
x
instance
attribute
instance
x
this
file
assigns
the
same
name
x
five
times
because
this
name
is
assigned
in
five
different
locations
though
all
five
xs
in
this
program
are
completely
different
variables
from
top
to
bottom
the
assignments
to
x
here
generate
a
module
attribute
a
local
variable
in
a
function
a
class
attribute
a
local
variable
in
a
method
and
an
instance
attribute
although
all
five
are
named
x
the
fact
that
they
are
all
assigned
at
different
places
in
the
source
code
or
to
different
objects
makes
all
of
these
unique
variables
you
should
take
the
time
to
study
this
example
carefully
because
it
collects
ideas
we
ve
been
exploring
throughout
the
last
few
parts
of
this
book
when
it
makes
sense
to
you
you
will
have
achieved
a
sort
of
python
namespace
nirvana
of
course
an
alternative
route
to
nirvana
is
to
simply
run
the
program
and
see
what
happens
here
s
the
remainder
of
this
source
file
which
makes
an
instance
and
prints
all
the
xs
that
it
can
fetch
chapter
class
coding
details
manynames
py
continued
if
name
main
print
x
f
g
print
x
module
a
k
a
manynames
x
outside
file
global
local
module
name
unchanged
obj
c
print
obj
x
make
instance
class
name
inherited
by
instance
obj
m
print
obj
x
print
c
x
attach
attribute
name
x
to
instance
now
instance
class
a
k
a
obj
x
if
no
x
in
instance
print
c
m
x
print
g
x
fails
only
visible
in
method
fails
only
visible
in
function
the
outputs
that
are
printed
when
the
file
is
run
are
noted
in
the
comments
in
the
code
trace
through
them
to
see
which
variable
named
x
is
being
accessed
each
time
notice
in
particular
that
we
can
go
through
the
class
to
fetch
its
attribute
c
x
but
we
can
never
fetch
local
variables
in
functions
or
methods
from
outside
their
def
statements
locals
are
visible
only
to
other
code
within
the
def
and
in
fact
only
live
in
memory
while
a
call
to
the
function
or
method
is
executing
some
of
the
names
defined
by
this
file
are
visible
outside
the
file
to
other
modules
but
recall
that
we
must
always
import
before
we
can
access
names
in
another
file
that
is
the
main
point
of
modules
after
all
otherfile
py
import
manynames
x
print
x
print
manynames
x
the
global
here
globals
become
attributes
after
imports
manynames
f
manynames
g
manynames
s
x
not
the
one
here
local
in
other
file
s
function
print
manynames
c
x
i
manynames
c
print
i
x
i
m
print
i
x
attribute
of
class
in
other
module
still
from
class
here
now
from
instance
notice
here
how
manynames
f
prints
the
x
in
manynames
not
the
x
assigned
in
this
file
scopes
are
always
determined
by
the
position
of
assignments
in
your
source
code
i
e
lexically
and
are
never
influenced
by
what
imports
what
or
who
imports
whom
also
notice
that
the
instance
s
own
x
is
not
created
until
we
call
i
m
attributes
like
all
variables
spring
into
existence
when
assigned
and
not
before
normally
we
create
instance
attributes
by
assigning
them
in
class
init
constructor
methods
but
this
isn
t
the
only
option
namespaces
the
whole
story
finally
as
we
learned
in
chapter
it
s
also
possible
for
a
function
to
change
names
outside
itself
with
global
and
in
python
nonlocal
statements
these
statements
provide
write
access
but
also
modify
assignment
s
namespace
binding
rules
x
global
in
module
def
g
print
x
reference
global
in
module
def
g
global
x
x
change
global
in
module
def
h
x
def
nested
print
x
def
h
x
def
nested
nonlocal
x
x
local
in
function
reference
local
in
enclosing
scope
local
in
function
python
statement
change
local
in
enclosing
scope
of
course
you
generally
shouldn
t
use
the
same
name
for
every
variable
in
your
script
but
as
this
example
demonstrates
even
if
you
do
python
s
namespaces
will
work
to
keep
names
used
in
one
context
from
accidentally
clashing
with
those
used
in
another
namespace
dictionaries
in
chapter
we
learned
that
module
namespaces
are
actually
implemented
as
dictionaries
and
exposed
with
the
built
in
dict
attribute
the
same
holds
for
class
and
instance
objects
attribute
qualification
is
really
a
dictionary
indexing
operation
internally
and
attribute
inheritance
is
just
a
matter
of
searching
linked
dictionaries
in
fact
instance
and
class
objects
are
mostly
just
dictionaries
with
links
inside
python
python
exposes
these
dictionaries
as
well
as
the
links
between
them
for
use
in
advanced
roles
e
g
for
coding
tools
to
help
you
understand
how
attributes
work
internally
let
s
work
through
an
interactive
session
that
traces
the
way
namespace
dictionaries
grow
when
classes
are
involved
we
saw
a
simpler
version
of
this
type
of
code
in
chapter
but
now
that
we
know
more
about
methods
and
superclasses
let
s
embellish
it
here
first
let
s
define
a
superclass
and
a
subclass
with
methods
that
will
store
data
in
their
instances
class
super
def
hello
self
self
data
spam
class
sub
super
def
hola
self
chapter
class
coding
details
self
data
eggs
when
we
make
an
instance
of
the
subclass
the
instance
starts
out
with
an
empty
namespace
dictionary
but
it
has
links
back
to
the
class
for
the
inheritance
search
to
follow
in
fact
the
inheritance
tree
is
explicitly
available
in
special
attributes
which
you
can
inspect
instances
have
a
class
attribute
that
links
to
their
class
and
classes
have
a
bases
attribute
that
is
a
tuple
containing
links
to
higher
superclasses
i
m
running
this
on
python
name
formats
and
some
internal
attributes
vary
slightly
in
x
sub
x
dict
instance
namespace
dict
x
class
class
main
sub
class
of
instance
sub
bases
class
main
super
superclasses
of
class
super
bases
class
object
empty
tuple
in
python
as
classes
assign
to
self
attributes
they
populate
the
instance
objects
that
is
attributes
wind
up
in
the
instances
attribute
namespace
dictionaries
not
in
the
classes
an
instance
object
s
namespace
records
data
that
can
vary
from
instance
to
instance
and
self
is
a
hook
into
that
namespace
y
sub
x
hello
x
dict
data
spam
x
hola
x
dict
data
spam
data
eggs
sub
dict
keys
module
doc
hola
super
dict
keys
dict
module
weakref
hello
doc
y
dict
notice
the
extra
underscore
names
in
the
class
dictionaries
python
sets
these
automatically
most
are
not
used
in
typical
programs
but
there
are
tools
that
use
some
of
them
e
g
doc
holds
the
docstrings
discussed
in
chapter
namespaces
the
whole
story
also
observe
that
y
a
second
instance
made
at
the
start
of
this
series
still
has
an
empty
namespace
dictionary
at
the
end
even
though
x
s
dictionary
has
been
populated
by
assignments
in
methods
again
each
instance
has
an
independent
namespace
dictionary
which
starts
out
empty
and
can
record
completely
different
attributes
than
those
recorded
by
the
namespace
dictionaries
of
other
instances
of
the
same
class
because
attributes
are
actually
dictionary
keys
inside
python
there
are
really
two
ways
to
fetch
and
assign
their
values
by
qualification
or
by
key
indexing
x
data
x
dict
data
spam
spam
x
data
toast
x
dict
data
spam
data
toast
data
eggs
x
dict
data
ham
x
data
ham
this
equivalence
applies
only
to
attributes
actually
attached
to
the
instance
though
because
attribute
fetch
qualification
also
performs
an
inheritance
search
it
can
access
attributes
that
namespace
dictionary
indexing
cannot
the
inherited
attribute
x
hello
for
instance
cannot
be
accessed
by
x
dict
hello
finally
here
is
the
built
in
dir
function
we
met
in
chapters
and
at
work
on
class
and
instance
objects
this
function
works
on
anything
with
attributes
dir
object
is
similar
to
an
object
dict
keys
call
notice
though
that
dir
sorts
its
list
and
includes
some
system
attributes
as
of
python
dir
also
collects
inherited
attributes
automatically
and
in
it
includes
names
inherited
from
the
object
class
that
is
an
implied
superclass
of
all
classes
x
dict
y
dict
data
spam
data
ham
data
eggs
list
x
dict
keys
data
data
data
need
list
in
in
python
dir
x
doc
module
data
data
data
hello
hola
dir
sub
doc
module
hello
hola
dir
super
doc
module
hello
as
you
can
see
the
contents
of
attribute
dictionaries
and
dir
call
results
may
change
over
time
for
example
because
python
now
allows
built
in
types
to
be
subclassed
like
classes
the
contents
of
dir
results
for
builtin
types
have
expanded
to
include
operator
overloading
methods
just
like
our
dir
results
here
for
user
defined
classes
under
python
in
general
attribute
names
with
leading
and
trailing
double
underscores
are
interpreter
specific
type
subclasses
will
be
discussed
further
in
chapter
chapter
class
coding
details
in
python
dir
x
class
delattr
dict
doc
eq
format
more
omitted
data
data
data
hello
hola
dir
sub
class
delattr
dict
doc
eq
format
more
omitted
hello
hola
dir
super
class
delattr
dict
doc
eq
format
more
omitted
hello
experiment
with
these
special
attributes
on
your
own
to
get
a
better
feel
for
how
namespaces
actually
do
their
attribute
business
even
if
you
will
never
use
these
in
the
kinds
of
programs
you
write
seeing
that
they
are
just
normal
dictionaries
will
help
demystify
the
notion
of
namespaces
in
general
namespace
links
the
prior
section
introduced
the
special
class
and
bases
instance
and
class
attributes
without
really
explaining
why
you
might
care
about
them
in
short
these
attributes
allow
you
to
inspect
inheritance
hierarchies
within
your
own
code
for
example
they
can
be
used
to
display
a
class
tree
as
in
the
following
example
classtree
py
climb
inheritance
trees
using
namespace
links
displaying
higher
superclasses
with
indentation
def
classtree
cls
indent
print
indent
cls
name
for
supercls
in
cls
bases
classtree
supercls
indent
print
class
name
here
recur
to
all
superclasses
may
visit
super
once
def
instancetree
inst
print
tree
of
s
inst
classtree
inst
class
show
instance
climb
to
its
class
def
selftest
class
a
class
b
a
class
c
a
class
d
b
c
class
e
class
f
d
e
pass
pass
pass
pass
pass
pass
namespaces
the
whole
story
instancetree
b
instancetree
f
if
name
main
selftest
the
classtree
function
in
this
script
is
recursive
it
prints
a
class
s
name
using
name
then
climbs
up
to
the
superclasses
by
calling
itself
this
allows
the
function
to
traverse
arbitrarily
shaped
class
trees
the
recursion
climbs
to
the
top
and
stops
at
root
superclasses
that
have
empty
bases
attributes
when
using
recursion
each
active
level
of
a
function
gets
its
own
copy
of
the
local
scope
here
this
means
that
cls
and
indent
are
different
at
each
classtree
level
most
of
this
file
is
self
test
code
when
run
standalone
in
python
it
builds
an
empty
class
tree
makes
two
instances
from
it
and
prints
their
class
tree
structures
c
misc
c
python
python
classtree
py
tree
of
main
b
instance
at
x
b
a
tree
of
main
f
instance
at
x
f
d
b
a
c
a
e
when
run
under
python
the
tree
includes
the
implied
object
superclasses
that
are
automatically
added
above
standalone
classes
because
all
classes
are
new
style
in
more
on
this
change
in
chapter
c
misc
c
python
python
classtree
py
tree
of
main
b
object
at
x
b
a
object
tree
of
main
f
object
at
x
f
d
b
a
object
c
a
object
e
object
here
indentation
marked
by
periods
is
used
to
denote
class
tree
height
of
course
we
could
improve
on
this
output
format
and
perhaps
even
sketch
it
in
a
gui
display
even
as
is
though
we
can
import
these
functions
anywhere
we
want
a
quick
class
tree
display
chapter
class
coding
details
c
misc
c
python
python
class
emp
pass
class
person
emp
pass
bob
person
import
classtree
classtree
instancetree
bob
tree
of
main
person
object
at
x
b
person
emp
object
regardless
of
whether
you
will
ever
code
or
use
such
tools
this
example
demonstrates
one
of
the
many
ways
that
you
can
make
use
of
special
attributes
that
expose
interpreter
internals
you
ll
see
another
when
we
code
the
lister
py
general
purpose
class
display
tools
in
the
section
multiple
inheritance
mix
in
classes
on
page
there
we
will
extend
this
technique
to
also
display
attributes
in
each
object
in
a
class
tree
and
in
the
last
part
of
this
book
we
ll
revisit
such
tools
in
the
context
of
python
tool
building
at
large
to
code
tools
that
implement
attribute
privacy
argument
validation
and
more
while
not
for
every
python
programmer
access
to
internals
enables
powerful
development
tools
documentation
strings
revisited
the
last
section
s
example
includes
a
docstring
for
its
module
but
remember
that
docstrings
can
be
used
for
class
components
as
well
docstrings
which
we
covered
in
detail
in
chapter
are
string
literals
that
show
up
at
the
top
of
various
structures
and
are
automatically
saved
by
python
in
the
corresponding
objects
doc
attributes
this
works
for
module
files
function
defs
and
classes
and
methods
now
that
we
know
more
about
classes
and
methods
the
following
file
docstr
py
provides
a
quick
but
comprehensive
example
that
summarizes
the
places
where
docstrings
can
show
up
in
your
code
all
of
these
can
be
triple
quoted
blocks
i
am
docstr
doc
def
func
args
i
am
docstr
func
doc
pass
class
spam
i
am
spam
doc
or
docstr
spam
doc
def
method
self
arg
i
am
spam
method
doc
or
self
method
doc
pass
documentation
strings
revisited
the
main
advantage
of
documentation
strings
is
that
they
stick
around
at
runtime
thus
if
it
s
been
coded
as
a
docstring
you
can
qualify
an
object
with
its
doc
attribute
to
fetch
its
documentation
import
docstr
docstr
doc
i
am
docstr
doc
docstr
func
doc
i
am
docstr
func
doc
docstr
spam
doc
i
am
spam
doc
or
docstr
spam
doc
docstr
spam
method
doc
i
am
spam
method
doc
or
self
method
doc
a
discussion
of
the
pydoc
tool
which
knows
how
to
format
all
these
strings
in
reports
appears
in
chapter
here
it
is
running
on
our
code
under
python
python
shows
additional
attributes
inherited
from
the
implied
object
superclass
in
the
newstyle
class
model
run
this
on
your
own
to
see
the
extras
and
watch
for
more
about
this
difference
in
chapter
help
docstr
help
on
module
docstr
name
docstr
i
am
docstr
doc
file
c
misc
docstr
py
classes
spam
class
spam
i
am
spam
doc
or
docstr
spam
doc
methods
defined
here
method
self
arg
i
am
spam
method
doc
or
self
method
doc
functions
func
args
i
am
docstr
func
doc
documentation
strings
are
available
at
runtime
but
they
are
less
flexible
syntactically
than
comments
which
can
appear
anywhere
in
a
program
both
forms
are
useful
tools
and
any
program
documentation
is
good
as
long
as
it
s
accurate
of
course
as
a
best
practice
rule
of
thumb
use
docstrings
for
functional
documentation
what
your
objects
do
and
hash
mark
comments
for
more
micro
level
documentation
how
arcane
expressions
work
chapter
class
coding
details
classes
versus
modules
let
s
wrap
up
this
chapter
by
briefly
comparing
the
topics
of
this
book
s
last
two
parts
modules
and
classes
because
they
re
both
about
namespaces
the
distinction
can
be
confusing
in
short
modules
are
data
logic
packages
are
created
by
writing
python
files
or
c
extensions
are
used
by
being
imported
classes
implement
new
objects
are
created
by
class
statements
are
used
by
being
called
always
live
within
a
module
classes
also
support
extra
features
that
modules
don
t
such
as
operator
overloading
multiple
instance
generation
and
inheritance
although
both
classes
and
modules
are
namespaces
you
should
be
able
to
tell
by
now
that
they
are
very
different
things
chapter
summary
this
chapter
took
us
on
a
second
more
in
depth
tour
of
the
oop
mechanisms
of
the
python
language
we
learned
more
about
classes
methods
and
inheritance
and
we
wrapped
up
the
namespace
story
in
python
by
extending
it
to
cover
its
application
to
classes
along
the
way
we
looked
at
some
more
advanced
concepts
such
as
abstract
superclasses
class
data
attributes
namespace
dictionaries
and
links
and
manual
calls
to
superclass
methods
and
constructors
now
that
we
ve
learned
all
about
the
mechanics
of
coding
classes
in
python
chapter
turns
to
a
specific
facet
of
those
mechanics
operator
overloading
after
that
we
ll
explore
common
design
patterns
looking
at
some
of
the
ways
that
classes
are
commonly
used
and
combined
to
optimize
code
reuse
before
you
read
ahead
though
be
sure
to
work
though
the
usual
chapter
quiz
to
review
what
we
ve
covered
here
test
your
knowledge
quiz
what
is
an
abstract
superclass
what
happens
when
a
simple
assignment
statement
appears
at
the
top
level
of
a
class
statement
test
your
knowledge
quiz
why
might
a
class
need
to
manually
call
the
init
method
in
a
superclass
how
can
you
augment
instead
of
completely
replacing
an
inherited
method
what
was
the
capital
of
assyria
test
your
knowledge
answers
an
abstract
superclass
is
a
class
that
calls
a
method
but
does
not
inherit
or
define
it
it
expects
the
method
to
be
filled
in
by
a
subclass
this
is
often
used
as
a
way
to
generalize
classes
when
behavior
cannot
be
predicted
until
a
more
specific
subclass
is
coded
oop
frameworks
also
use
this
as
a
way
to
dispatch
to
client
defined
customizable
operations
when
a
simple
assignment
statement
x
y
appears
at
the
top
level
of
a
class
statement
it
attaches
a
data
attribute
to
the
class
class
x
like
all
class
attributes
this
will
be
shared
by
all
instances
data
attributes
are
not
callable
method
functions
though
a
class
must
manually
call
the
init
method
in
a
superclass
if
it
defines
an
init
constructor
of
its
own
but
it
also
must
still
kick
off
the
superclass
s
construction
code
python
itself
automatically
runs
just
one
constructor
the
lowest
one
in
the
tree
superclass
constructors
are
called
through
the
class
name
passing
in
the
self
instance
manually
superclass
init
self
to
augment
instead
of
completely
replacing
an
inherited
method
redefine
it
in
a
subclass
but
call
back
to
the
superclass
s
version
of
the
method
manually
from
the
new
version
of
the
method
in
the
subclass
that
is
pass
the
self
instance
to
the
superclass
s
version
of
the
method
manually
superclass
method
self
ashur
or
qalat
sherqat
calah
or
nimrud
the
short
lived
dur
sharrukin
or
khorsabad
and
finally
nineveh
chapter
class
coding
details
chapter
operator
overloading
this
chapter
continues
our
in
depth
survey
of
class
mechanics
by
focusing
on
operator
overloading
we
looked
briefly
at
operator
overloading
in
prior
chapters
here
we
ll
fill
in
more
details
and
look
at
a
handful
of
commonly
used
overloading
methods
although
we
won
t
demonstrate
each
of
the
many
operator
overloading
methods
available
those
we
will
code
here
are
a
representative
sample
large
enough
to
uncover
the
possibilities
of
this
python
class
feature
the
basics
really
operator
overloading
simply
means
intercepting
built
in
operations
in
class
methods
python
automatically
invokes
your
methods
when
instances
of
the
class
appear
in
built
in
operations
and
your
method
s
return
value
becomes
the
result
of
the
corresponding
operation
here
s
a
review
of
the
key
ideas
behind
overloading
operator
overloading
lets
classes
intercept
normal
python
operations
classes
can
overload
all
python
expression
operators
classes
can
also
overload
built
in
operations
such
as
printing
function
calls
attribute
access
etc
overloading
makes
class
instances
act
more
like
built
in
types
overloading
is
implemented
by
providing
specially
named
class
methods
in
other
words
when
certain
specially
named
methods
are
provided
in
a
class
python
automatically
calls
them
when
instances
of
the
class
appear
in
their
associated
expressions
as
we
ve
learned
operator
overloading
methods
are
never
required
and
generally
don
t
have
defaults
if
you
don
t
code
or
inherit
one
it
just
means
that
your
class
does
not
support
the
corresponding
operation
when
used
though
these
methods
allow
classes
to
emulate
the
interfaces
of
built
in
objects
and
so
appear
more
consistent
constructors
and
expressions
init
and
sub
consider
the
following
simple
example
its
number
class
coded
in
the
file
number
py
provides
a
method
to
intercept
instance
construction
init
as
well
as
one
for
catching
subtraction
expressions
sub
special
methods
such
as
these
are
the
hooks
that
let
you
tie
into
built
in
operations
class
number
def
init
self
start
self
data
start
def
sub
self
other
return
number
self
data
other
on
number
start
on
instance
other
result
is
a
new
instance
fetch
class
from
module
number
init
x
number
sub
x
y
is
new
number
instance
from
number
import
number
x
number
y
x
y
data
as
discussed
previously
the
init
constructor
method
seen
in
this
code
is
the
most
commonly
used
operator
overloading
method
in
python
it
s
present
in
most
classes
in
this
chapter
we
will
tour
some
of
the
other
tools
available
in
this
domain
and
look
at
example
code
that
applies
them
in
common
use
cases
common
operator
overloading
methods
just
about
everything
you
can
do
to
built
in
objects
such
as
integers
and
lists
has
a
corresponding
specially
named
method
for
overloading
in
classes
table
lists
a
few
of
the
most
common
there
are
many
more
in
fact
many
overloading
methods
come
in
multiple
versions
e
g
add
radd
and
iadd
for
addition
which
is
one
reason
there
are
so
many
see
other
python
books
or
the
python
language
reference
manual
for
an
exhaustive
list
of
the
special
method
names
available
table
common
operator
overloading
methods
method
implements
called
for
init
constructor
object
creation
x
class
args
del
destructor
object
reclamation
of
x
add
operator
x
y
x
y
if
no
iadd
or
operator
bitwise
or
x
y
x
y
if
no
ior
repr
str
printing
conversions
print
x
repr
x
str
x
call
function
calls
x
args
kargs
getattr
attribute
fetch
x
undefined
setattr
attribute
assignment
x
any
value
delattr
attribute
deletion
del
x
any
getattribute
attribute
fetch
x
any
chapter
operator
overloading
method
implements
called
for
getitem
indexing
slicing
iteration
x
key
x
i
j
for
loops
and
other
iterations
if
no
iter
setitem
index
and
slice
assignment
x
key
value
x
i
j
sequence
delitem
index
and
slice
deletion
del
x
key
del
x
i
j
len
length
len
x
truth
tests
if
no
bool
bool
boolean
tests
bool
x
truth
tests
named
nonzero
in
lt
gt
le
ge
eq
ne
comparisons
x
y
x
y
x
y
x
y
x
y
x
y
or
else
cmp
in
only
radd
right
side
operators
other
x
iadd
in
place
augmented
operators
x
y
or
else
add
iter
next
iteration
contexts
i
iter
x
next
i
for
loops
in
if
no
contains
all
comprehensions
map
f
x
others
next
is
named
next
in
contains
membership
test
item
in
x
any
iterable
index
integer
value
hex
x
bin
x
oct
x
o
x
o
x
replaces
python
oct
hex
enter
exit
context
manager
chapter
with
obj
as
var
get
set
delete
descriptor
attributes
chapter
x
attr
x
attr
value
del
x
attr
new
creation
chapter
object
creation
before
init
all
overloading
methods
have
names
that
start
and
end
with
two
underscores
to
keep
them
distinct
from
other
names
you
define
in
your
classes
the
mappings
from
special
method
names
to
expressions
or
operations
are
predefined
by
the
python
language
and
documented
in
the
standard
language
manual
for
example
the
name
add
always
maps
to
expressions
by
python
language
definition
regardless
of
what
an
add
method
s
code
actually
does
operator
overloading
methods
may
be
inherited
from
superclasses
if
not
defined
just
like
any
other
methods
operator
overloading
methods
are
also
all
optional
if
you
don
t
code
or
inherit
one
that
operation
is
simply
unsupported
by
your
class
and
attempting
it
will
raise
an
exception
some
built
in
operations
like
printing
have
defaults
inherited
for
the
implied
object
class
in
python
but
most
built
ins
fail
for
class
instances
if
no
corresponding
operator
overloading
method
is
present
most
overloading
methods
are
used
only
in
advanced
programs
that
require
objects
to
behave
like
built
ins
the
init
constructor
tends
to
appear
in
most
classes
however
so
pay
special
attention
to
it
we
ve
already
met
the
init
initialization
time
constructor
method
and
a
few
of
the
others
in
table
let
s
explore
some
of
the
additional
methods
in
the
table
by
example
the
basics
indexing
and
slicing
getitem
and
setitem
if
defined
in
a
class
or
inherited
by
it
the
getitem
method
is
called
automatically
for
instance
indexing
operations
when
an
instance
x
appears
in
an
indexing
expression
like
x
i
python
calls
the
getitem
method
inherited
by
the
instance
passing
x
to
the
first
argument
and
the
index
in
brackets
to
the
second
argument
for
example
the
following
class
returns
the
square
of
an
index
value
class
indexer
def
getitem
self
index
return
index
x
indexer
x
for
i
in
range
print
x
i
end
x
i
calls
x
getitem
i
runs
getitem
x
i
each
time
intercepting
slices
interestingly
in
addition
to
indexing
getitem
is
also
called
for
slice
expressions
formally
speaking
built
in
types
handle
slicing
the
same
way
here
for
example
is
slicing
at
work
on
a
built
in
list
using
upper
and
lower
bounds
and
a
stride
see
chapter
if
you
need
a
refresher
on
slicing
l
l
l
l
l
slice
with
slice
syntax
really
though
slicing
bounds
are
bundled
up
into
a
slice
object
and
passed
to
the
list
s
implementation
of
indexing
in
fact
you
can
always
pass
a
slice
object
manually
slice
syntax
is
mostly
syntactic
sugar
for
indexing
with
a
slice
object
l
slice
l
slice
none
l
slice
none
l
slice
none
none
chapter
operator
overloading
slice
with
slice
objects
this
matters
in
classes
with
a
getitem
method
the
method
will
be
called
both
for
basic
indexing
with
an
index
and
for
slicing
with
a
slice
object
our
previous
class
won
t
handle
slicing
because
its
math
assumes
integer
indexes
are
passed
but
the
following
class
will
when
called
for
indexing
the
argument
is
an
integer
as
before
class
indexer
data
def
getitem
self
index
print
getitem
index
return
self
data
index
x
indexer
x
getitem
x
getitem
x
getitem
called
for
index
or
slice
perform
index
or
slice
indexing
sends
getitem
an
integer
when
called
for
slicing
though
the
method
receives
a
slice
object
which
is
simply
passed
along
to
the
embedded
list
indexer
in
a
new
index
expression
x
getitem
slice
none
x
getitem
slice
none
none
x
getitem
slice
none
none
x
getitem
slice
none
none
slicing
sends
getitem
a
slice
object
if
used
the
setitem
index
assignment
method
similarly
intercepts
both
index
and
slice
assignments
it
receives
a
slice
object
for
the
latter
which
may
be
passed
along
in
another
index
assignment
in
the
same
way
def
setitem
self
index
value
self
data
index
value
intercept
index
or
slice
assignment
assign
index
or
slice
in
fact
getitem
may
be
called
automatically
in
even
more
contexts
than
indexing
and
slicing
as
the
next
section
explains
slicing
and
indexing
in
python
prior
to
python
classes
could
also
define
getslice
and
setslice
methods
to
intercept
slice
fetches
and
assignments
specifically
they
were
passed
the
bounds
of
the
slice
expression
and
were
preferred
over
getitem
and
setitem
for
slices
indexing
and
slicing
getitem
and
setitem
these
slice
specific
methods
have
been
removed
in
so
you
should
use
getitem
and
setitem
instead
and
allow
for
both
indexes
and
slice
objects
as
arguments
in
most
classes
this
works
without
any
special
code
because
indexing
methods
can
manually
pass
along
the
slice
object
in
the
square
brackets
of
another
index
expression
as
in
our
example
see
the
section
membership
contains
iter
and
getitem
on
page
for
another
example
of
slice
interception
at
work
also
don
t
confuse
the
arguably
unfortunately
named
index
method
in
python
for
index
interception
this
method
returns
an
integer
value
for
an
instance
when
needed
and
is
used
by
built
ins
that
convert
to
digit
strings
class
c
def
index
self
return
x
c
hex
x
integer
value
xff
bin
x
b
oct
x
o
although
this
method
does
not
intercept
instance
indexing
like
getitem
it
is
also
used
in
contexts
that
require
an
integer
including
indexing
c
c
c
x
c
c
x
c
as
index
not
x
i
as
index
not
x
i
this
method
works
the
same
way
in
python
except
that
it
is
not
called
for
the
hex
and
oct
built
in
functions
use
hex
and
oct
in
instead
to
intercept
these
calls
index
iteration
getitem
here
s
a
trick
that
isn
t
always
obvious
to
beginners
but
turns
out
to
be
surprisingly
useful
the
for
statement
works
by
repeatedly
indexing
a
sequence
from
zero
to
higher
indexes
until
an
out
of
bounds
exception
is
detected
because
of
that
getitem
also
turns
out
to
be
one
way
to
overload
iteration
in
python
if
this
method
is
defined
for
loops
call
the
class
s
getitem
each
time
through
with
successively
higher
offsets
it
s
a
case
of
buy
one
get
one
free
any
built
in
or
user
defined
object
that
responds
to
indexing
also
responds
to
iteration
class
stepper
def
getitem
self
i
return
self
data
i
chapter
operator
overloading
p
s
p
x
stepper
x
data
spam
x
is
a
stepper
object
x
indexing
calls
getitem
for
item
in
x
print
item
end
for
loops
call
getitem
for
indexes
items
n
a
m
in
fact
it
s
really
a
case
of
buy
one
get
a
bunch
free
any
class
that
supports
for
loops
automatically
supports
all
iteration
contexts
in
python
many
of
which
we
ve
seen
in
earlier
chapters
iteration
contexts
were
presented
in
chapter
for
example
the
in
membership
test
list
comprehensions
the
map
built
in
list
and
tuple
assignments
and
type
constructors
will
also
call
getitem
automatically
if
it
s
defined
p
in
x
true
all
call
getitem
too
c
for
c
in
x
s
p
a
m
list
comprehension
list
map
str
upper
x
s
p
a
m
map
calls
use
list
in
a
b
c
d
x
a
c
d
s
a
m
sequence
assignments
list
x
tuple
x
join
x
s
p
a
m
s
p
a
m
spam
x
main
stepper
object
at
x
a
d
d
in
practice
this
technique
can
be
used
to
create
objects
that
provide
a
sequence
interface
and
to
add
logic
to
built
in
sequence
type
operations
we
ll
revisit
this
idea
when
extending
built
in
types
in
chapter
iterator
objects
iter
and
next
although
the
getitem
technique
of
the
prior
section
works
it
s
really
just
a
fallback
for
iteration
today
all
iteration
contexts
in
python
will
try
the
iter
method
first
before
trying
getitem
that
is
they
prefer
the
iteration
protocol
we
learned
about
in
chapter
to
repeatedly
indexing
an
object
only
if
the
object
does
not
support
the
iteration
protocol
is
indexing
attempted
instead
generally
speaking
you
should
prefer
iter
too
it
supports
general
iteration
contexts
better
than
getitem
can
technically
iteration
contexts
work
by
calling
the
iter
built
in
function
to
try
to
find
an
iter
method
which
is
expected
to
return
an
iterator
object
if
it
s
provided
python
then
repeatedly
calls
this
iterator
object
s
next
method
to
produce
items
iterator
objects
iter
and
next
until
a
stopiteration
exception
is
raised
if
no
such
iter
method
is
found
python
falls
back
on
the
getitem
scheme
and
repeatedly
indexes
by
offsets
as
before
until
an
indexerror
exception
is
raised
a
next
built
in
function
is
also
available
as
a
convenience
for
manual
iterations
next
i
is
the
same
as
i
next
version
skew
note
as
described
in
chapter
if
you
are
using
python
the
i
next
method
just
described
is
named
i
next
in
your
python
and
the
next
i
built
in
is
present
for
portability
it
calls
i
next
in
and
i
next
in
iteration
works
the
same
in
in
all
other
respects
user
defined
iterators
in
the
iter
scheme
classes
implement
user
defined
iterators
by
simply
implementing
the
iteration
protocol
introduced
in
chapters
and
refer
back
to
those
chapters
for
more
background
details
on
iterators
for
example
the
following
file
iters
py
defines
a
user
defined
iterator
class
that
generates
squares
class
squares
def
init
self
start
stop
self
value
start
self
stop
stop
def
iter
self
return
self
def
next
self
if
self
value
self
stop
raise
stopiteration
self
value
return
self
value
python
from
iters
import
squares
for
i
in
squares
print
i
end
save
state
when
created
get
iterator
object
on
iter
return
a
square
on
each
iteration
also
called
by
next
built
in
for
calls
iter
which
calls
iter
each
iteration
calls
next
here
the
iterator
object
is
simply
the
instance
self
because
the
next
method
is
part
of
this
class
in
more
complex
scenarios
the
iterator
object
may
be
defined
as
a
separate
class
and
object
with
its
own
state
information
to
support
multiple
active
iterations
over
the
same
data
we
ll
see
an
example
of
this
in
a
moment
the
end
of
the
iteration
is
signaled
with
a
python
raise
statement
more
on
raising
exceptions
in
the
next
part
of
this
book
manual
iterations
work
as
for
built
in
types
as
well
x
squares
i
iter
x
next
i
next
i
chapter
operator
overloading
iterate
manually
what
loops
do
iter
calls
iter
next
calls
next
more
omitted
next
i
next
i
stopiteration
can
catch
this
in
try
statement
an
equivalent
coding
of
this
iterator
with
getitem
might
be
less
natural
because
the
for
would
then
iterate
through
all
offsets
zero
and
higher
the
offsets
passed
in
would
be
only
indirectly
related
to
the
range
of
values
produced
n
would
need
to
map
to
start
stop
because
iter
objects
retain
explicitly
managed
state
between
next
calls
they
can
be
more
general
than
getitem
on
the
other
hand
using
iterators
based
on
iter
can
sometimes
be
more
complex
and
less
convenient
than
using
getitem
they
are
really
designed
for
iteration
not
random
indexing
in
fact
they
don
t
overload
the
indexing
expression
at
all
x
squares
x
attributeerror
squares
instance
has
no
attribute
getitem
the
iter
scheme
is
also
the
implementation
for
all
the
other
iteration
contexts
we
saw
in
action
for
getitem
membership
tests
type
constructors
sequence
assignment
and
so
on
however
unlike
our
prior
getitem
example
we
also
need
to
be
aware
that
a
class
s
iter
may
be
designed
for
a
single
traversal
not
many
for
example
the
squares
class
is
a
one
shot
iteration
once
you
ve
iterated
over
an
instance
of
that
class
it
s
empty
you
need
to
make
a
new
iterator
object
for
each
new
iteration
x
squares
n
for
n
in
x
n
for
n
in
x
n
for
n
in
squares
list
squares
exhausts
items
now
it
s
empty
make
a
new
iterator
object
notice
that
this
example
would
probably
be
simpler
if
it
were
coded
with
generator
functions
topics
or
expressions
introduced
in
chapter
and
related
to
iterators
def
gsquares
start
stop
for
i
in
range
start
stop
yield
i
for
i
in
gsquares
print
i
end
or
x
for
x
in
range
unlike
the
class
the
function
automatically
saves
its
state
between
iterations
of
course
for
this
artificial
example
you
could
in
fact
skip
both
techniques
and
simply
use
a
for
loop
map
or
a
list
comprehension
to
build
the
list
all
at
once
the
best
and
fastest
way
to
accomplish
a
task
in
python
is
often
also
the
simplest
iterator
objects
iter
and
next
x
for
x
in
range
however
classes
may
be
better
at
modeling
more
complex
iterations
especially
when
they
can
benefit
from
state
information
and
inheritance
hierarchies
the
next
section
explores
one
such
use
case
multiple
iterators
on
one
object
earlier
i
mentioned
that
the
iterator
object
may
be
defined
as
a
separate
class
with
its
own
state
information
to
support
multiple
active
iterations
over
the
same
data
consider
what
happens
when
we
step
across
a
built
in
type
like
a
string
s
ace
for
x
in
s
for
y
in
s
print
x
y
end
aa
ac
ae
ca
cc
ce
ea
ec
ee
here
the
outer
loop
grabs
an
iterator
from
the
string
by
calling
iter
and
each
nested
loop
does
the
same
to
get
an
independent
iterator
because
each
active
iterator
has
its
own
state
information
each
loop
can
maintain
its
own
position
in
the
string
regardless
of
any
other
active
loops
we
saw
related
examples
earlier
in
chapters
and
for
instance
generator
functions
and
expressions
as
well
as
built
ins
like
map
and
zip
proved
to
be
single
iterator
objects
by
contrast
the
range
built
in
and
other
built
in
types
like
lists
support
multiple
active
iterators
with
independent
positions
when
we
code
user
defined
iterators
with
classes
it
s
up
to
us
to
decide
whether
we
will
support
a
single
active
iteration
or
many
to
achieve
the
multiple
iterator
effect
iter
simply
needs
to
define
a
new
stateful
object
for
the
iterator
instead
of
returning
self
the
following
for
example
defines
an
iterator
class
that
skips
every
other
item
on
iterations
because
the
iterator
object
is
created
anew
for
each
iteration
it
supports
multiple
active
loops
class
skipiterator
def
init
self
wrapped
self
wrapped
wrapped
self
offset
def
next
self
if
self
offset
len
self
wrapped
raise
stopiteration
else
item
self
wrapped
self
offset
self
offset
return
item
class
skipobject
chapter
operator
overloading
iterator
state
information
terminate
iterations
else
return
and
skip
def
init
self
wrapped
self
wrapped
wrapped
def
iter
self
return
skipiterator
self
wrapped
if
name
main
alpha
abcdef
skipper
skipobject
alpha
i
iter
skipper
print
next
i
next
i
next
i
for
x
in
skipper
for
y
in
skipper
print
x
y
end
save
item
to
be
used
new
iterator
each
time
make
container
object
make
an
iterator
on
it
visit
offsets
for
calls
iter
automatically
nested
fors
call
iter
again
each
time
each
iterator
has
its
own
state
offset
when
run
this
example
works
like
the
nested
loops
with
built
in
strings
each
active
loop
has
its
own
position
in
the
string
because
each
obtains
an
independent
iterator
object
that
records
its
own
state
information
python
skipper
py
a
c
e
aa
ac
ae
ca
cc
ce
ea
ec
ee
by
contrast
our
earlier
squares
example
supports
just
one
active
iteration
unless
we
call
squares
again
in
nested
loops
to
obtain
new
objects
here
there
is
just
one
skipobject
with
multiple
iterator
objects
created
from
it
as
before
we
could
achieve
similar
results
with
built
in
tools
for
example
slicing
with
a
third
bound
to
skip
items
s
abcdef
for
x
in
s
for
y
in
s
print
x
y
end
aa
ac
ae
ca
cc
ce
ea
ec
ee
new
objects
on
each
iteration
this
isn
t
quite
the
same
though
for
two
reasons
first
each
slice
expression
here
will
physically
store
the
result
list
all
at
once
in
memory
iterators
on
the
other
hand
produce
just
one
value
at
a
time
which
can
save
substantial
space
for
large
result
lists
second
slices
produce
new
objects
so
we
re
not
really
iterating
over
the
same
object
in
multiple
places
here
to
be
closer
to
the
class
we
would
need
to
make
a
single
object
to
step
across
by
slicing
ahead
of
time
s
abcdef
s
s
s
ace
for
x
in
s
for
y
in
s
print
x
y
end
aa
ac
ae
ca
cc
ce
ea
ec
ee
same
object
new
iterators
iterator
objects
iter
and
next
this
is
more
similar
to
our
class
based
solution
but
it
still
stores
the
slice
result
in
memory
all
at
once
there
is
no
generator
form
of
built
in
slicing
today
and
it
s
only
equivalent
for
this
particular
case
of
skipping
every
other
item
because
iterators
can
do
anything
a
class
can
do
they
are
much
more
general
than
this
example
may
imply
regardless
of
whether
our
applications
require
such
generality
user
defined
iterators
are
a
powerful
tool
they
allow
us
to
make
arbitrary
objects
look
and
feel
like
the
other
sequences
and
iterables
we
have
met
in
this
book
we
could
use
this
technique
with
a
database
object
for
example
to
support
iterations
over
database
fetches
with
multiple
cursors
into
the
same
query
result
membership
contains
iter
and
getitem
the
iteration
story
is
even
richer
than
we
ve
seen
thus
far
operator
overloading
is
often
layered
classes
may
provide
specific
methods
or
more
general
alternatives
used
as
fallback
options
for
example
comparisons
in
python
use
specific
methods
such
as
lt
for
less
than
if
present
or
else
the
general
cmp
python
uses
only
specific
methods
not
cmp
as
discussed
later
in
this
chapter
boolean
tests
similarly
try
a
specific
bool
first
to
give
an
explicit
true
false
result
and
if
it
s
absent
fall
back
on
the
more
general
len
a
nonzero
length
means
true
as
we
ll
also
see
later
in
this
chapter
python
works
the
same
but
uses
the
name
nonzero
instead
of
bool
in
the
iterations
domain
classes
normally
implement
the
in
membership
operator
as
an
iteration
using
either
the
iter
method
or
the
getitem
method
to
support
more
specific
membership
though
classes
may
code
a
contains
method
when
present
this
method
is
preferred
over
iter
which
is
preferred
over
getitem
the
contains
method
should
define
membership
as
applying
to
keys
for
a
mapping
and
can
use
quick
lookups
and
as
a
search
for
sequences
consider
the
following
class
which
codes
all
three
methods
and
tests
membership
and
various
iteration
contexts
applied
to
an
instance
its
methods
print
trace
messages
when
called
class
iters
def
init
self
value
self
data
value
def
getitem
self
i
print
get
s
i
end
return
self
data
i
def
iter
self
print
iter
end
self
ix
return
self
def
next
self
print
next
end
chapter
operator
overloading
fallback
for
iteration
also
for
index
slice
preferred
for
iteration
allows
only
active
iterator
if
self
ix
len
self
data
raise
stopiteration
item
self
data
self
ix
self
ix
return
item
def
contains
self
x
preferred
for
in
print
contains
end
return
x
in
self
data
x
iters
print
in
x
for
i
in
x
print
i
end
print
print
i
for
i
in
x
print
list
map
bin
x
i
iter
x
while
true
try
print
next
i
end
except
stopiteration
break
make
instance
membership
for
loops
other
iteration
contexts
manual
iteration
what
other
contexts
do
when
run
as
it
is
this
script
s
output
is
as
follows
the
specific
contains
intercepts
membership
the
general
iter
catches
other
iteration
contexts
such
that
next
is
called
repeatedly
and
getitem
is
never
called
contains
true
iter
next
next
next
next
next
next
iter
next
next
next
next
next
next
iter
next
next
next
next
next
next
b
b
b
b
b
iter
next
next
next
next
next
next
watch
what
happens
to
this
code
s
output
if
we
comment
out
its
contains
method
though
membership
is
now
routed
to
the
general
iter
instead
iter
iter
iter
iter
iter
next
next
next
true
next
next
next
next
next
next
next
next
next
next
next
next
next
next
next
next
next
next
b
b
b
b
b
next
next
next
next
next
next
and
finally
here
is
the
output
if
both
contains
and
iter
are
commented
out
the
indexing
getitem
fallback
is
called
with
successively
higher
indexes
for
membership
and
other
iteration
contexts
get
get
get
true
get
get
get
get
get
get
get
get
get
get
get
get
get
get
get
get
get
get
b
b
b
b
b
get
get
get
get
get
get
membership
contains
iter
and
getitem
as
we
ve
seen
the
getitem
method
is
even
more
general
besides
iterations
it
also
intercepts
explicit
indexing
as
well
as
slicing
slice
expressions
trigger
getitem
with
a
slice
object
containing
bounds
both
for
built
in
types
and
user
defined
classes
so
slicing
is
automatic
in
our
class
x
iters
spam
x
get
s
indexing
getitem
spam
pam
spam
slice
none
pam
slice
syntax
x
get
slice
none
none
pam
x
get
slice
none
none
spa
getitem
slice
slice
object
in
more
realistic
iteration
use
cases
that
are
not
sequence
oriented
though
the
iter
method
may
be
easier
to
write
since
it
must
not
manage
an
integer
index
and
contains
allows
for
membership
optimization
as
a
special
case
attribute
reference
getattr
and
setattr
the
getattr
method
intercepts
attribute
qualifications
more
specifically
it
s
called
with
the
attribute
name
as
a
string
whenever
you
try
to
qualify
an
instance
with
an
undefined
nonexistent
attribute
name
it
is
not
called
if
python
can
find
the
attribute
using
its
inheritance
tree
search
procedure
because
of
its
behavior
getattr
is
useful
as
a
hook
for
responding
to
attribute
requests
in
a
generic
fashion
for
example
class
empty
def
getattr
self
attrname
if
attrname
age
return
else
raise
attributeerror
attrname
x
empty
x
age
x
name
error
text
omitted
attributeerror
name
here
the
empty
class
and
its
instance
x
have
no
real
attributes
of
their
own
so
the
access
to
x
age
gets
routed
to
the
getattr
method
self
is
assigned
the
instance
x
and
attrname
is
assigned
the
undefined
attribute
name
string
age
the
class
makes
age
look
like
a
real
attribute
by
returning
a
real
value
as
the
result
of
the
x
age
qualification
expression
in
effect
age
becomes
a
dynamically
computed
attribute
chapter
operator
overloading
for
attributes
that
the
class
doesn
t
know
how
to
handle
getattr
raises
the
builtin
attributeerror
exception
to
tell
python
that
these
are
bona
fide
undefined
names
asking
for
x
name
triggers
the
error
you
ll
see
getattr
again
when
we
see
delegation
and
properties
at
work
in
the
next
two
chapters
and
i
ll
say
more
about
exceptions
in
part
vii
a
related
overloading
method
setattr
intercepts
all
attribute
assignments
if
this
method
is
defined
self
attr
value
becomes
self
setattr
attr
value
this
is
a
bit
trickier
to
use
because
assigning
to
any
self
attributes
within
setattr
calls
setattr
again
causing
an
infinite
recursion
loop
and
eventually
a
stack
overflow
exception
if
you
want
to
use
this
method
be
sure
that
it
assigns
any
instance
attributes
by
indexing
the
attribute
dictionary
discussed
in
the
next
section
that
is
use
self
dict
name
x
not
self
name
x
class
accesscontrol
def
setattr
self
attr
value
if
attr
age
self
dict
attr
value
else
raise
attributeerror
attr
not
allowed
x
accesscontrol
x
age
calls
setattr
x
age
x
name
mel
text
omitted
attributeerror
name
not
allowed
these
two
attribute
access
overloading
methods
allow
you
to
control
or
specialize
access
to
attributes
in
your
objects
they
tend
to
play
highly
specialized
roles
some
of
which
we
ll
explore
later
in
this
book
other
attribute
management
tools
for
future
reference
also
note
that
there
are
other
ways
to
manage
attribute
access
in
python
the
getattribute
method
intercepts
all
attribute
fetches
not
just
those
that
are
undefined
but
when
using
it
you
must
be
more
cautious
than
with
getattr
to
avoid
loops
the
property
built
in
function
allows
us
to
associate
methods
with
fetch
and
set
operations
on
a
specific
class
attribute
descriptors
provide
a
protocol
for
associating
get
and
set
methods
of
a
class
with
accesses
to
a
specific
class
attribute
because
these
are
somewhat
advanced
tools
not
of
interest
to
every
python
programmer
we
ll
defer
a
look
at
properties
until
chapter
and
detailed
coverage
of
all
the
attribute
management
techniques
until
chapter
attribute
reference
getattr
and
setattr
emulating
privacy
for
instance
attributes
part
the
following
code
generalizes
the
previous
example
to
allow
each
subclass
to
have
its
own
list
of
private
names
that
cannot
be
assigned
to
its
instances
class
privateexc
exception
pass
class
privacy
def
setattr
self
attrname
value
if
attrname
in
self
privates
raise
privateexc
attrname
self
else
self
dict
attrname
value
more
on
exceptions
later
on
self
attrname
value
self
attrname
value
loops
class
test
privacy
privates
age
class
test
privacy
privates
name
pay
def
init
self
self
dict
name
tom
x
test
y
test
x
name
bob
y
name
sue
fails
y
age
x
age
fails
in
fact
this
is
a
first
cut
solution
for
an
implementation
of
attribute
privacy
in
python
i
e
disallowing
changes
to
attribute
names
outside
a
class
although
python
doesn
t
support
private
declarations
per
se
techniques
like
this
can
emulate
much
of
their
purpose
this
is
a
partial
solution
though
to
make
it
more
effective
it
must
be
augmented
to
allow
subclasses
to
set
private
attributes
more
naturally
too
and
to
use
getattr
and
a
wrapper
sometimes
called
a
proxy
class
to
check
for
private
attribute
fetches
we
ll
postpone
a
more
complete
solution
to
attribute
privacy
until
chapter
where
we
ll
use
class
decorators
to
intercept
and
validate
attributes
more
generally
even
though
privacy
can
be
emulated
this
way
though
it
almost
never
is
in
practice
python
programmers
are
able
to
write
large
oop
frameworks
and
applications
without
private
declarations
an
interesting
finding
about
access
controls
in
general
that
is
beyond
the
scope
of
our
purposes
here
catching
attribute
references
and
assignments
is
generally
a
useful
technique
it
supports
delegation
a
design
technique
that
allows
controller
objects
to
wrap
up
embedded
objects
add
new
behaviors
and
route
other
operations
back
to
the
wrapped
objects
more
on
delegation
and
wrapper
classes
in
chapter
chapter
operator
overloading
string
representation
repr
and
str
the
next
example
exercises
the
init
constructor
and
the
add
overload
method
both
of
which
we
ve
already
seen
as
well
as
defining
a
repr
method
that
returns
a
string
representation
for
instances
string
formatting
is
used
to
convert
the
managed
self
data
object
to
a
string
if
defined
repr
or
its
sibling
str
is
called
automatically
when
class
instances
are
printed
or
converted
to
strings
these
methods
allow
you
to
define
a
better
display
format
for
your
objects
than
the
default
instance
display
the
default
display
of
instance
objects
is
neither
useful
nor
pretty
class
adder
def
init
self
value
self
data
value
def
add
self
other
self
data
other
x
adder
print
x
main
adder
object
at
x
d
b
x
main
adder
object
at
x
d
b
initialize
data
add
other
in
place
bad
default
displays
but
coding
or
inheriting
string
representation
methods
allows
us
to
customize
the
display
class
addrepr
adder
def
repr
self
return
addrepr
s
self
data
x
addrepr
x
x
addrepr
print
x
addrepr
str
x
repr
x
addrepr
addrepr
inherit
init
add
add
string
representation
convert
to
as
code
string
runs
init
runs
add
runs
repr
runs
repr
runs
repr
for
both
so
why
two
display
methods
mostly
to
support
different
audiences
in
full
detail
str
is
tried
first
for
the
print
operation
and
the
str
built
in
function
the
internal
equivalent
of
which
print
runs
it
generally
should
return
a
user
friendly
display
repr
is
used
in
all
other
contexts
for
interactive
echoes
the
repr
function
and
nested
appearances
as
well
as
by
print
and
str
if
no
str
is
present
it
should
generally
return
an
as
code
string
that
could
be
used
to
re
create
the
object
or
a
detailed
display
for
developers
in
a
nutshell
repr
is
used
everywhere
except
by
print
and
str
when
a
str
is
defined
note
however
that
while
printing
falls
back
on
repr
if
no
str
is
string
representation
repr
and
str
defined
the
inverse
is
not
true
other
contexts
such
as
interactive
echoes
use
repr
only
and
don
t
try
str
at
all
class
addstr
adder
def
str
self
str
but
no
repr
return
value
s
self
data
convert
to
nice
string
x
addstr
x
x
default
repr
main
addstr
object
at
x
b
ef
print
x
runs
str
value
str
x
repr
x
value
main
addstr
object
at
x
b
ef
because
of
this
repr
may
be
best
if
you
want
a
single
display
for
all
contexts
by
defining
both
methods
though
you
can
support
different
displays
in
different
contexts
for
example
an
end
user
display
with
str
and
a
low
level
display
for
programmers
to
use
during
development
with
repr
in
effect
str
simply
overrides
repr
for
user
friendly
display
contexts
class
addboth
adder
def
str
self
return
value
s
self
data
def
repr
self
return
addboth
s
self
data
x
addboth
x
x
addboth
print
x
value
str
x
repr
x
value
addboth
user
friendly
string
as
code
string
runs
repr
runs
str
i
should
mention
two
usage
notes
here
first
keep
in
mind
that
str
and
repr
must
both
return
strings
other
result
types
are
not
converted
and
raise
errors
so
be
sure
to
run
them
through
a
converter
if
needed
second
depending
on
a
container
s
string
conversion
logic
the
user
friendly
display
of
str
might
only
apply
when
objects
appear
at
the
top
level
of
a
print
operation
objects
nested
in
larger
objects
might
still
print
with
their
repr
or
its
default
the
following
illustrates
both
of
these
points
class
printer
def
init
self
val
self
val
val
def
str
self
return
str
self
val
objs
printer
printer
for
x
in
objs
print
x
chapter
operator
overloading
used
for
instance
itself
convert
to
a
string
result
str
run
when
instance
printed
but
not
when
instance
in
a
list
print
objs
main
printer
object
at
x
d
f
main
printer
object
at
more
objs
main
printer
object
at
x
d
f
main
printer
object
at
more
to
ensure
that
a
custom
display
is
run
in
all
contexts
regardless
of
the
container
code
repr
not
str
the
former
is
run
in
all
cases
if
the
latter
doesn
t
apply
class
printer
def
init
self
val
self
val
val
def
repr
self
return
str
self
val
repr
used
by
print
if
no
str
repr
used
if
echoed
or
nested
objs
printer
printer
for
x
in
objs
print
x
no
str
runs
repr
runs
repr
not
str
print
objs
objs
in
practice
str
or
its
low
level
relative
repr
seems
to
be
the
second
most
commonly
used
operator
overloading
method
in
python
scripts
behind
init
any
time
you
can
print
an
object
and
see
a
custom
display
one
of
these
two
tools
is
probably
in
use
right
side
and
in
place
addition
radd
and
iadd
technically
the
add
method
that
appeared
in
the
prior
example
does
not
support
the
use
of
instance
objects
on
the
right
side
of
the
operator
to
implement
such
expressions
and
hence
support
commutative
style
operators
code
the
radd
method
as
well
python
calls
radd
only
when
the
object
on
the
right
side
of
the
is
your
class
instance
but
the
object
on
the
left
is
not
an
instance
of
your
class
the
add
method
for
the
object
on
the
left
is
called
instead
in
all
other
cases
class
commuter
def
init
self
val
self
val
val
def
add
self
other
print
add
self
val
other
return
self
val
other
def
radd
self
other
print
radd
self
val
other
return
other
self
val
x
commuter
y
commuter
right
side
and
in
place
addition
radd
and
iadd
x
add
instance
noninstance
add
y
radd
noninstance
instance
radd
x
y
add
instance
instance
triggers
radd
add
main
commuter
object
at
x
radd
notice
how
the
order
is
reversed
in
radd
self
is
really
on
the
right
of
the
and
other
is
on
the
left
also
note
that
x
and
y
are
instances
of
the
same
class
here
when
instances
of
different
classes
appear
mixed
in
an
expression
python
prefers
the
class
of
the
one
on
the
left
when
we
add
the
two
instances
together
python
runs
add
which
in
turn
triggers
radd
by
simplifying
the
left
operand
in
more
realistic
classes
where
the
class
type
may
need
to
be
propagated
in
results
things
can
become
trickier
type
testing
may
be
required
to
tell
whether
it
s
safe
to
convert
and
thus
avoid
nesting
for
instance
without
the
isinstance
test
in
the
following
we
could
wind
up
with
a
commuter
whose
val
is
another
commuter
when
two
instances
are
added
and
add
triggers
radd
class
commuter
propagate
class
type
in
results
def
init
self
val
self
val
val
def
add
self
other
if
isinstance
other
commuter
other
other
val
return
commuter
self
val
other
def
radd
self
other
return
commuter
other
self
val
def
str
self
return
commuter
s
self
val
x
commuter
y
commuter
print
x
result
is
another
commuter
instance
commuter
print
y
commuter
z
x
y
print
z
commuter
print
z
commuter
print
z
z
commuter
chapter
operator
overloading
not
nested
doesn
t
recur
to
radd
in
place
addition
to
also
implement
in
place
augmented
addition
code
either
an
iadd
or
an
add
the
latter
is
used
if
the
former
is
absent
in
fact
the
prior
section
s
commuter
class
supports
already
for
this
reason
but
iadd
allows
for
more
efficient
in
place
changes
class
number
def
init
self
val
self
val
val
def
iadd
self
other
self
val
other
return
self
iadd
explicit
x
y
usually
returns
self
x
number
x
x
x
val
class
number
def
init
self
val
self
val
val
def
add
self
other
return
number
self
val
other
add
fallback
x
x
y
propagates
class
type
x
number
x
x
x
val
every
binary
operator
has
similar
right
side
and
in
place
overloading
methods
that
work
the
same
e
g
mul
rmul
and
imul
right
side
methods
are
an
advanced
topic
and
tend
to
be
fairly
rarely
used
in
practice
you
only
code
them
when
you
need
operators
to
be
commutative
and
then
only
if
you
need
to
support
such
operators
at
all
for
instance
a
vector
class
may
use
these
tools
but
an
employee
or
button
class
probably
would
not
call
expressions
call
the
call
method
is
called
when
your
instance
is
called
no
this
isn
t
a
circular
definition
if
defined
python
runs
a
call
method
for
function
call
expressions
applied
to
your
instances
passing
along
whatever
positional
or
keyword
arguments
were
sent
class
callee
def
call
self
pargs
kargs
print
called
pargs
kargs
c
callee
c
intercept
instance
calls
accept
arbitrary
arguments
c
is
a
callable
object
call
expressions
call
called
c
x
y
called
y
x
more
formally
all
the
argument
passing
modes
we
explored
in
chapter
are
supported
by
the
call
method
whatever
is
passed
to
the
instance
is
passed
to
this
method
along
with
the
usual
implied
instance
argument
for
example
the
method
definitions
class
c
def
call
self
a
b
c
d
normals
and
defaults
class
c
def
call
self
pargs
kargs
collect
arbitrary
arguments
class
c
def
call
self
pargs
d
kargs
keyword
only
argument
all
match
all
the
following
instance
calls
x
c
x
x
x
a
b
d
x
dict
c
d
x
c
dict
d
omit
defaults
positionals
keywords
unpack
arbitrary
arguments
mixed
modes
the
net
effect
is
that
classes
and
instances
with
a
call
support
the
exact
same
argument
syntax
and
semantics
as
normal
functions
and
methods
intercepting
call
expression
like
this
allows
class
instances
to
emulate
the
look
and
feel
of
things
like
functions
but
also
retain
state
information
for
use
during
calls
we
saw
a
similar
example
while
exploring
scopes
in
chapter
but
you
should
be
more
familiar
with
operator
overloading
here
class
prod
def
init
self
value
self
value
value
def
call
self
other
return
self
value
other
x
prod
x
accept
just
one
argument
remembers
in
state
passed
state
x
in
this
example
the
call
may
seem
a
bit
gratuitous
at
first
glance
a
simple
method
can
provide
similar
utility
class
prod
def
init
self
value
self
value
value
def
comp
self
other
return
self
value
other
chapter
operator
overloading
x
prod
x
comp
x
comp
however
call
can
become
more
useful
when
interfacing
with
apis
that
expect
functions
it
allows
us
to
code
objects
that
conform
to
an
expected
function
call
interface
but
also
retain
state
information
in
fact
it
s
probably
the
third
most
commonly
used
operator
overloading
method
behind
the
init
constructor
and
the
str
and
repr
display
format
alternatives
function
interfaces
and
callback
based
code
as
an
example
the
tkinter
gui
toolkit
named
tkinter
in
python
allows
you
to
register
functions
as
event
handlers
a
k
a
callbacks
when
events
occur
tkinter
calls
the
registered
objects
if
you
want
an
event
handler
to
retain
state
between
events
you
can
register
either
a
class
s
bound
method
or
an
instance
that
conforms
to
the
expected
interface
with
call
in
this
section
s
code
both
x
comp
from
the
second
example
and
x
from
the
first
can
pass
as
function
like
objects
this
way
i
ll
have
more
to
say
about
bound
methods
in
the
next
chapter
but
for
now
here
s
a
hypothetical
example
of
call
applied
to
the
gui
domain
the
following
class
defines
an
object
that
supports
a
function
call
interface
but
also
has
state
information
that
remembers
the
color
a
button
should
change
to
when
it
is
later
pressed
class
callback
def
init
self
color
self
color
color
def
call
self
print
turn
self
color
function
state
information
support
calls
with
no
arguments
now
in
the
context
of
a
gui
we
can
register
instances
of
this
class
as
event
handlers
for
buttons
even
though
the
gui
expects
to
be
able
to
invoke
event
handlers
as
simple
functions
with
no
arguments
cb
callback
blue
cb
callback
green
remember
blue
b
button
command
cb
b
button
command
cb
register
handlers
register
handlers
when
the
button
is
later
pressed
the
instance
object
is
called
as
a
simple
function
exactly
like
in
the
following
calls
because
it
retains
state
as
instance
attributes
though
it
remembers
what
to
do
cb
cb
on
events
prints
blue
prints
green
in
fact
this
is
probably
the
best
way
to
retain
state
information
in
the
python
language
better
than
the
techniques
discussed
earlier
for
functions
global
variables
call
expressions
call
enclosing
function
scope
references
and
default
mutable
arguments
with
oop
the
state
remembered
is
made
explicit
with
attribute
assignments
before
we
move
on
there
are
two
other
ways
that
python
programmers
sometimes
tie
information
to
a
callback
function
like
this
one
option
is
to
use
default
arguments
in
lambda
functions
cb
lambda
color
red
turn
color
or
defaults
print
cb
the
other
is
to
use
bound
methods
of
a
class
a
bound
method
object
is
a
kind
of
object
that
remembers
the
self
instance
and
the
referenced
function
a
bound
method
may
therefore
be
called
as
a
simple
function
without
an
instance
later
class
callback
def
init
self
color
self
color
color
def
changecolor
self
print
turn
self
color
class
with
state
information
a
normal
named
method
cb
callback
blue
cb
callback
yellow
b
button
command
cb
changecolor
b
button
command
cb
changecolor
reference
but
don
t
call
remembers
function
self
in
this
case
when
this
button
is
later
pressed
it
s
as
if
the
gui
does
this
which
invokes
the
changecolor
method
to
process
the
object
s
state
information
object
callback
blue
cb
object
changecolor
cb
registered
event
handler
on
event
prints
blue
this
technique
is
simpler
but
less
general
than
overloading
calls
with
call
again
watch
for
more
about
bound
methods
in
the
next
chapter
you
ll
also
see
another
call
example
in
chapter
where
we
will
use
it
to
implement
something
known
as
a
function
decorator
a
callable
object
often
used
to
add
a
layer
of
logic
on
top
of
an
embedded
function
because
call
allows
us
to
attach
state
information
to
a
callable
object
it
s
a
natural
implementation
technique
for
a
function
that
must
remember
and
call
another
function
comparisons
lt
gt
and
others
as
suggested
in
table
classes
can
define
methods
to
catch
all
six
comparison
operators
and
these
methods
are
generally
straightforward
to
use
but
keep
the
following
qualifications
in
mind
chapter
operator
overloading
unlike
the
add
radd
pairings
discussed
earlier
there
are
no
right
side
variants
of
comparison
methods
instead
reflective
methods
are
used
when
only
one
operand
supports
comparison
e
g
lt
and
gt
are
each
other
s
reflection
there
are
no
implicit
relationships
among
the
comparison
operators
the
truth
of
does
not
imply
that
is
false
for
example
so
both
eq
and
ne
should
be
defined
to
ensure
that
both
operators
behave
correctly
in
python
a
cmp
method
is
used
by
all
comparisons
if
no
more
specific
comparison
methods
are
defined
it
returns
a
number
that
is
less
than
equal
to
or
greater
than
zero
to
signal
less
than
equal
and
greater
than
results
for
the
comparison
of
its
two
arguments
self
and
another
operand
this
method
often
uses
the
cmp
x
y
built
in
to
compute
its
result
both
the
cmp
method
and
the
cmp
built
in
function
are
removed
in
python
use
the
more
specific
methods
instead
we
don
t
have
space
for
an
in
depth
exploration
of
comparison
methods
but
as
a
quick
introduction
consider
the
following
class
and
test
code
class
c
data
spam
def
gt
self
other
return
self
data
other
def
lt
self
other
return
self
data
other
x
c
print
x
ham
print
x
ham
and
version
true
runs
gt
false
runs
lt
when
run
under
python
or
the
prints
at
the
end
display
the
expected
results
noted
in
their
comments
because
the
class
s
methods
intercept
and
implement
comparison
expressions
the
cmp
method
removed
in
in
python
the
cmp
method
is
used
as
a
fallback
if
more
specific
methods
are
not
defined
its
integer
result
is
used
to
evaluate
the
operator
being
run
the
following
produces
the
same
result
under
for
example
but
fails
in
because
cmp
is
no
longer
used
class
c
data
spam
def
cmp
self
other
return
cmp
self
data
other
only
cmp
not
used
in
cmp
not
defined
in
x
c
print
x
ham
print
x
ham
true
runs
cmp
false
runs
cmp
comparisons
lt
gt
and
others
notice
that
this
fails
in
because
cmp
is
no
longer
special
not
because
the
cmp
built
in
function
is
no
longer
present
if
we
change
the
prior
class
to
the
following
to
try
to
simulate
the
cmp
call
the
code
still
works
in
but
fails
in
class
c
data
spam
def
cmp
self
other
return
self
data
other
self
data
other
so
why
you
might
be
asking
did
i
just
show
you
a
comparison
method
that
is
no
longer
supported
in
while
it
would
be
easier
to
erase
history
entirely
this
book
is
designed
to
support
both
and
readers
because
cmp
may
appear
in
code
readers
must
reuse
or
maintain
it
s
fair
game
in
this
book
moreover
cmp
was
removed
more
abruptly
than
the
getslice
method
described
earlier
and
so
may
endure
longer
if
you
use
though
or
care
about
running
your
code
under
in
the
future
don
t
use
cmp
anymore
use
the
more
specific
comparison
methods
instead
boolean
tests
bool
and
len
as
mentioned
earlier
classes
may
also
define
methods
that
give
the
boolean
nature
of
their
instances
in
boolean
contexts
python
first
tries
bool
to
obtain
a
direct
boolean
value
and
then
if
that
s
missing
tries
len
to
determine
a
truth
value
from
the
object
length
the
first
of
these
generally
uses
object
state
or
other
information
to
produce
a
boolean
result
class
truth
def
bool
self
return
true
x
truth
if
x
print
yes
yes
class
truth
def
bool
self
return
false
x
truth
bool
x
false
if
this
method
is
missing
python
falls
back
on
length
because
a
nonempty
object
is
considered
true
i
e
a
nonzero
length
is
taken
to
mean
the
object
is
true
and
a
zero
length
means
it
is
false
class
truth
def
len
self
return
x
truth
if
not
x
print
no
chapter
operator
overloading
no
if
both
methods
are
present
python
prefers
bool
over
len
because
it
is
more
specific
class
truth
def
bool
self
return
true
def
len
self
return
x
truth
if
x
print
yes
yes
tries
bool
first
tries
len
first
if
neither
truth
method
is
defined
the
object
is
vacuously
considered
true
which
has
potential
implications
for
metaphysically
inclined
readers
class
truth
pass
x
truth
bool
x
true
and
now
that
we
ve
managed
to
cross
over
into
the
realm
of
philosophy
let
s
move
on
to
look
at
one
last
overloading
context
object
demise
booleans
in
python
python
users
should
use
nonzero
instead
of
bool
in
all
of
the
code
in
the
section
boolean
tests
bool
and
len
on
page
python
renamed
the
nonzero
method
to
bool
but
boolean
tests
work
the
same
otherwise
both
and
use
len
as
a
fallback
if
you
don
t
use
the
name
the
very
first
test
in
this
section
will
work
the
same
for
you
anyhow
but
only
because
bool
is
not
recognized
as
a
special
method
name
in
and
objects
are
considered
true
by
default
to
witness
this
version
difference
live
you
need
to
return
false
c
misc
c
python
python
class
c
def
bool
self
print
in
bool
return
false
x
c
bool
x
in
bool
false
if
x
print
in
bool
boolean
tests
bool
and
len
this
works
as
advertised
in
in
though
bool
is
ignored
and
the
object
is
always
considered
true
c
misc
c
python
python
class
c
def
bool
self
print
in
bool
return
false
x
c
bool
x
true
if
x
print
in
use
nonzero
for
boolean
values
or
return
from
the
len
fallback
method
to
designate
false
c
misc
c
python
python
class
c
def
nonzero
self
print
in
nonzero
return
false
x
c
bool
x
in
nonzero
false
if
x
print
in
nonzero
but
keep
in
mind
that
nonzero
works
in
only
if
used
in
it
will
be
silently
ignored
and
the
object
will
be
classified
as
true
by
default
just
like
using
bool
in
object
destruction
del
we
ve
seen
how
the
init
constructor
is
called
whenever
an
instance
is
generated
its
counterpart
the
destructor
method
del
is
run
automatically
when
an
instance
s
space
is
being
reclaimed
i
e
at
garbage
collection
time
class
life
def
init
self
name
unknown
print
hello
name
self
name
name
def
del
self
print
goodbye
self
name
brian
life
brian
hello
brian
brian
loretta
goodbye
brian
chapter
operator
overloading
here
when
brian
is
assigned
a
string
we
lose
the
last
reference
to
the
life
instance
and
so
trigger
its
destructor
method
this
works
and
it
may
be
useful
for
implementing
some
cleanup
activities
such
as
terminating
server
connections
however
destructors
are
not
as
commonly
used
in
python
as
in
some
oop
languages
for
a
number
of
reasons
for
one
thing
because
python
automatically
reclaims
all
space
held
by
an
instance
when
the
instance
is
reclaimed
destructors
are
not
necessary
for
space
management
for
another
because
you
cannot
always
easily
predict
when
an
instance
will
be
reclaimed
it
s
often
better
to
code
termination
activities
in
an
explicitly
called
method
or
try
finally
statement
described
in
the
next
part
of
the
book
in
some
cases
there
may
be
lingering
references
to
your
objects
in
system
tables
that
prevent
destructors
from
running
in
fact
del
can
be
tricky
to
use
for
even
more
subtle
reasons
exceptions
raised
within
it
for
example
simply
print
a
warning
message
to
sys
stderr
the
standard
error
stream
rather
than
triggering
an
exception
event
because
of
the
unpredictable
context
under
which
it
is
run
by
the
garbage
collector
in
addition
cyclic
a
k
a
circular
references
among
objects
may
prevent
garbage
collection
from
happening
when
you
expect
it
to
an
optional
cycle
detector
enabled
by
default
can
automatically
collect
such
objects
eventually
but
only
if
they
do
not
have
del
methods
since
this
is
relatively
obscure
we
ll
ignore
further
details
here
see
python
s
standard
manuals
coverage
of
both
del
and
the
gc
garbage
collector
module
for
more
information
chapter
summary
that
s
as
many
overloading
examples
as
we
have
space
for
here
most
of
the
other
operator
overloading
methods
work
similarly
to
the
ones
we
ve
explored
and
all
are
just
hooks
for
intercepting
built
in
type
operations
some
overloading
methods
for
example
have
unique
argument
lists
or
return
values
we
ll
see
a
few
others
in
action
later
in
the
book
chapter
uses
the
enter
and
exit
with
statement
context
manager
methods
chapter
uses
the
get
and
set
class
descriptor
fetch
set
methods
chapter
uses
the
new
object
creation
method
in
the
context
of
metaclasses
in
the
current
c
implementation
of
python
you
also
don
t
need
to
close
file
objects
held
by
the
instance
in
destructors
because
they
are
automatically
closed
when
reclaimed
however
as
mentioned
in
chapter
it
s
better
to
explicitly
call
file
close
methods
because
auto
close
on
reclaim
is
a
feature
of
the
implementation
not
of
the
language
itself
this
behavior
can
vary
under
jython
for
instance
chapter
summary
in
addition
some
of
the
methods
we
ve
studied
here
such
as
call
and
str
will
be
employed
by
later
examples
in
this
book
for
complete
coverage
though
i
ll
defer
to
other
documentation
sources
see
python
s
standard
language
manual
or
reference
books
for
details
on
additional
overloading
methods
in
the
next
chapter
we
leave
the
realm
of
class
mechanics
behind
to
explore
common
design
patterns
the
ways
that
classes
are
commonly
used
and
combined
to
optimize
code
reuse
before
you
read
on
though
take
a
moment
to
work
though
the
chapter
quiz
below
to
review
the
concepts
we
ve
covered
test
your
knowledge
quiz
what
two
operator
overloading
methods
can
you
use
to
support
iteration
in
your
classes
what
two
operator
overloading
methods
handle
printing
and
in
what
contexts
how
can
you
intercept
slice
operations
in
a
class
how
can
you
catch
in
place
addition
in
a
class
when
should
you
provide
operator
overloading
test
your
knowledge
answers
classes
can
support
iteration
by
defining
or
inheriting
getitem
or
iter
in
all
iteration
contexts
python
tries
to
use
iter
which
returns
an
object
that
supports
the
iteration
protocol
with
a
next
method
first
if
no
iter
is
found
by
inheritance
search
python
falls
back
on
the
getitem
indexing
method
which
is
called
repeatedly
with
successively
higher
indexes
the
str
and
repr
methods
implement
object
print
displays
the
former
is
called
by
the
print
and
str
built
in
functions
the
latter
is
called
by
print
and
str
if
there
is
no
str
and
always
by
the
repr
built
in
interactive
echoes
and
nested
appearances
that
is
repr
is
used
everywhere
except
by
print
and
str
when
a
str
is
defined
a
str
is
usually
used
for
user
friendly
displays
repr
gives
extra
details
or
the
object
s
as
code
form
slicing
is
caught
by
the
getitem
indexing
method
it
is
called
with
a
slice
object
instead
of
a
simple
index
in
python
getslice
defunct
in
may
be
used
as
well
in
place
addition
tries
iadd
first
and
add
with
an
assignment
second
the
same
pattern
holds
true
for
all
binary
operators
the
radd
method
is
also
available
for
right
side
addition
chapter
operator
overloading
when
a
class
naturally
matches
or
needs
to
emulate
a
built
in
type
s
interfaces
for
example
collections
might
imitate
sequence
or
mapping
interfaces
you
generally
shouldn
t
implement
expression
operators
if
they
don
t
naturally
map
to
your
objects
though
use
normally
named
methods
instead
test
your
knowledge
answers
chapter
designing
with
classes
so
far
in
this
part
of
the
book
we
ve
concentrated
on
using
python
s
oop
tool
the
class
but
oop
is
also
about
design
issues
i
e
how
to
use
classes
to
model
useful
objects
this
chapter
will
touch
on
a
few
core
oop
ideas
and
present
some
additional
examples
that
are
more
realistic
than
those
shown
so
far
along
the
way
we
ll
code
some
common
oop
design
patterns
in
python
such
as
inheritance
composition
delegation
and
factories
we
ll
also
investigate
some
designfocused
class
concepts
such
as
pseudoprivate
attributes
multiple
inheritance
and
bound
methods
many
of
the
design
terms
mentioned
here
require
more
explanation
than
i
can
provide
in
this
book
if
this
material
sparks
your
curiosity
i
suggest
exploring
a
text
on
oop
design
or
design
patterns
as
a
next
step
python
and
oop
let
s
begin
with
a
review
python
s
implementation
of
oop
can
be
summarized
by
three
ideas
inheritance
inheritance
is
based
on
attribute
lookup
in
python
in
x
name
expressions
polymorphism
in
x
method
the
meaning
of
method
depends
on
the
type
class
of
x
encapsulation
methods
and
operators
implement
behavior
data
hiding
is
a
convention
by
default
by
now
you
should
have
a
good
feel
for
what
inheritance
is
all
about
in
python
we
ve
also
talked
about
python
s
polymorphism
a
few
times
already
it
flows
from
python
s
lack
of
type
declarations
because
attributes
are
always
resolved
at
runtime
objects
that
implement
the
same
interfaces
are
interchangeable
clients
don
t
need
to
know
what
sorts
of
objects
are
implementing
the
methods
they
call
encapsulation
means
packaging
in
python
that
is
hiding
implementation
details
behind
an
object
s
interface
it
does
not
mean
enforced
privacy
though
that
can
be
implemented
with
code
as
we
ll
see
in
chapter
encapsulation
allows
the
implementation
of
an
object
s
interface
to
be
changed
without
impacting
the
users
of
that
object
overloading
by
call
signatures
or
not
some
oop
languages
also
define
polymorphism
to
mean
overloading
functions
based
on
the
type
signatures
of
their
arguments
but
because
there
are
no
type
declarations
in
python
this
concept
doesn
t
really
apply
polymorphism
in
python
is
based
on
object
interfaces
not
types
you
can
try
to
overload
methods
by
their
argument
lists
like
this
class
c
def
meth
self
x
def
meth
self
x
y
z
this
code
will
run
but
because
the
def
simply
assigns
an
object
to
a
name
in
the
class
s
scope
the
last
definition
of
the
method
function
is
the
only
one
that
will
be
retained
it
s
just
as
if
you
say
x
and
then
x
x
will
be
type
based
selections
can
always
be
coded
using
the
type
testing
ideas
we
met
in
chapters
and
or
the
argument
list
tools
introduced
in
chapter
class
c
def
meth
self
args
if
len
args
elif
type
arg
int
you
normally
shouldn
t
do
this
though
as
described
in
chapter
you
should
write
your
code
to
expect
an
object
interface
not
a
specific
data
type
that
way
it
will
be
useful
for
a
broader
category
of
types
and
applications
both
now
and
in
the
future
class
c
def
meth
self
x
x
operation
assume
x
does
the
right
thing
it
s
also
generally
considered
better
to
use
distinct
method
names
for
distinct
operations
rather
than
relying
on
call
signatures
no
matter
what
language
you
code
in
although
python
s
object
model
is
straightforward
much
of
the
art
in
oop
is
in
the
way
we
combine
classes
to
achieve
a
program
s
goals
the
next
section
begins
a
tour
of
some
of
the
ways
larger
programs
use
classes
to
their
advantage
chapter
designing
with
classes
oop
and
inheritance
is
a
relationships
we
ve
explored
the
mechanics
of
inheritance
in
depth
already
but
i
d
like
to
show
you
an
example
of
how
it
can
be
used
to
model
real
world
relationships
from
a
programmer
s
point
of
view
inheritance
is
kicked
off
by
attribute
qualifications
which
trigger
searches
for
names
in
instances
their
classes
and
then
any
superclasses
from
a
designer
s
point
of
view
inheritance
is
a
way
to
specify
set
membership
a
class
defines
a
set
of
properties
that
may
be
inherited
and
customized
by
more
specific
sets
i
e
subclasses
to
illustrate
let
s
put
that
pizza
making
robot
we
talked
about
at
the
start
of
this
part
of
the
book
to
work
suppose
we
ve
decided
to
explore
alternative
career
paths
and
open
a
pizza
restaurant
one
of
the
first
things
we
ll
need
to
do
is
hire
employees
to
serve
customers
prepare
the
food
and
so
on
being
engineers
at
heart
we
ve
decided
to
build
a
robot
to
make
the
pizzas
but
being
politically
and
cybernetically
correct
we
ve
also
decided
to
make
our
robot
a
full
fledged
employee
with
a
salary
our
pizza
shop
team
can
be
defined
by
the
four
classes
in
the
example
file
employees
py
the
most
general
class
employee
provides
common
behavior
such
as
bumping
up
salaries
giveraise
and
printing
repr
there
are
two
kinds
of
employees
and
so
two
subclasses
of
employee
chef
and
server
both
override
the
inherited
work
method
to
print
more
specific
messages
finally
our
pizza
robot
is
modeled
by
an
even
more
specific
class
pizzarobot
is
a
kind
of
chef
which
is
a
kind
of
employee
in
oop
terms
we
call
these
relationships
is
a
links
a
robot
is
a
chef
which
is
a
n
employee
here
s
the
employees
py
file
class
employee
def
init
self
name
salary
self
name
name
self
salary
salary
def
giveraise
self
percent
self
salary
self
salary
self
salary
percent
def
work
self
print
self
name
does
stuff
def
repr
self
return
employee
name
s
salary
s
self
name
self
salary
class
chef
employee
def
init
self
name
employee
init
self
name
def
work
self
print
self
name
makes
food
class
server
employee
def
init
self
name
employee
init
self
name
def
work
self
print
self
name
interfaces
with
customer
class
pizzarobot
chef
oop
and
inheritance
is
a
relationships
def
init
self
name
chef
init
self
name
def
work
self
print
self
name
makes
pizza
if
name
main
bob
pizzarobot
bob
print
bob
bob
work
bob
giveraise
print
bob
print
make
a
robot
named
bob
run
inherited
repr
run
type
specific
action
give
bob
a
raise
for
klass
in
employee
chef
server
pizzarobot
obj
klass
klass
name
obj
work
when
we
run
the
self
test
code
included
in
this
module
we
create
a
pizza
making
robot
named
bob
which
inherits
names
from
three
classes
pizzarobot
chef
and
employee
for
instance
printing
bob
runs
the
employee
repr
method
and
giving
bob
a
raise
invokes
employee
giveraise
because
that
s
where
the
inheritance
search
finds
that
method
c
python
examples
python
employees
py
employee
name
bob
salary
bob
makes
pizza
employee
name
bob
salary
employee
does
stuff
chef
makes
food
server
interfaces
with
customer
pizzarobot
makes
pizza
in
a
class
hierarchy
like
this
you
can
usually
make
instances
of
any
of
the
classes
not
just
the
ones
at
the
bottom
for
instance
the
for
loop
in
this
module
s
self
test
code
creates
instances
of
all
four
classes
each
responds
differently
when
asked
to
work
because
the
work
method
is
different
in
each
really
these
classes
just
simulate
real
world
objects
work
prints
a
message
for
the
time
being
but
it
could
be
expanded
to
do
real
work
later
oop
and
composition
has
a
relationships
the
notion
of
composition
was
introduced
in
chapter
from
a
programmer
s
point
of
view
composition
involves
embedding
other
objects
in
a
container
object
and
activating
them
to
implement
container
methods
to
a
designer
composition
is
another
way
to
represent
relationships
in
a
problem
domain
but
rather
than
set
membership
composition
has
to
do
with
components
parts
of
a
whole
composition
also
reflects
the
relationships
between
parts
called
a
has
a
relationships
some
oop
design
texts
refer
to
composition
as
aggregation
or
distinguish
between
the
two
terms
by
using
aggregation
to
describe
a
weaker
dependency
between
chapter
designing
with
classes
container
and
contained
in
this
text
a
composition
simply
refers
to
a
collection
of
embedded
objects
the
composite
class
generally
provides
an
interface
all
its
own
and
implements
it
by
directing
the
embedded
objects
now
that
we
ve
implemented
our
employees
let
s
put
them
in
the
pizza
shop
and
let
them
get
busy
our
pizza
shop
is
a
composite
object
it
has
an
oven
and
it
has
employees
like
servers
and
chefs
when
a
customer
enters
and
places
an
order
the
components
of
the
shop
spring
into
action
the
server
takes
the
order
the
chef
makes
the
pizza
and
so
on
the
following
example
the
file
pizzashop
py
simulates
all
the
objects
and
relationships
in
this
scenario
from
employees
import
pizzarobot
server
class
customer
def
init
self
name
self
name
name
def
order
self
server
print
self
name
orders
from
server
def
pay
self
server
print
self
name
pays
for
item
to
server
class
oven
def
bake
self
print
oven
bakes
class
pizzashop
def
init
self
self
server
server
pat
self
chef
pizzarobot
bob
self
oven
oven
def
order
self
name
customer
customer
name
customer
order
self
server
self
chef
work
self
oven
bake
customer
pay
self
server
if
name
main
scene
pizzashop
scene
order
homer
print
scene
order
shaggy
embed
other
objects
a
robot
named
bob
activate
other
objects
customer
orders
from
server
make
the
composite
simulate
homer
s
order
simulate
shaggy
s
order
the
pizzashop
class
is
a
container
and
controller
its
constructor
makes
and
embeds
instances
of
the
employee
classes
we
wrote
in
the
last
section
as
well
as
an
oven
class
defined
here
when
this
module
s
self
test
code
calls
the
pizzashop
order
method
the
embedded
objects
are
asked
to
carry
out
their
actions
in
turn
notice
that
we
make
a
new
customer
object
for
each
order
and
we
pass
on
the
embedded
server
object
to
customer
methods
customers
come
and
go
but
the
server
is
part
of
the
pizza
shop
composite
also
notice
that
employees
are
still
involved
in
an
inheritance
relationship
composition
and
inheritance
are
complementary
tools
oop
and
composition
has
a
relationships
when
we
run
this
module
our
pizza
shop
handles
two
orders
one
from
homer
and
then
one
from
shaggy
c
python
examples
python
pizzashop
py
homer
orders
from
employee
name
pat
salary
bob
makes
pizza
oven
bakes
homer
pays
for
item
to
employee
name
pat
salary
shaggy
orders
from
employee
name
pat
salary
bob
makes
pizza
oven
bakes
shaggy
pays
for
item
to
employee
name
pat
salary
again
this
is
mostly
just
a
toy
simulation
but
the
objects
and
interactions
are
representative
of
composites
at
work
as
a
rule
of
thumb
classes
can
represent
just
about
any
objects
and
relationships
you
can
express
in
a
sentence
just
replace
nouns
with
classes
and
verbs
with
methods
and
you
ll
have
a
first
cut
at
a
design
stream
processors
revisited
for
a
more
realistic
composition
example
recall
the
generic
data
stream
processor
function
we
partially
coded
in
the
introduction
to
oop
in
chapter
def
processor
reader
converter
writer
while
data
reader
read
if
not
data
break
data
converter
data
writer
write
data
rather
than
using
a
simple
function
here
we
might
code
this
as
a
class
that
uses
composition
to
do
its
work
to
provide
more
structure
and
support
inheritance
the
following
file
streams
py
demonstrates
one
way
to
code
the
class
class
processor
def
init
self
reader
writer
self
reader
reader
self
writer
writer
def
process
self
while
data
self
reader
readline
if
not
data
break
data
self
converter
data
self
writer
write
data
def
converter
self
data
assert
false
converter
must
be
defined
or
raise
exception
this
class
defines
a
converter
method
that
it
expects
subclasses
to
fill
in
it
s
an
example
of
the
abstract
superclass
model
we
outlined
in
chapter
more
on
assert
in
part
vii
coded
this
way
reader
and
writer
objects
are
embedded
within
the
class
instance
composition
and
we
supply
the
conversion
logic
in
a
subclass
rather
than
passing
in
a
converter
function
inheritance
the
file
converters
py
shows
how
chapter
designing
with
classes
from
streams
import
processor
class
uppercase
processor
def
converter
self
data
return
data
upper
if
name
main
import
sys
obj
uppercase
open
spam
txt
sys
stdout
obj
process
here
the
uppercase
class
inherits
the
stream
processing
loop
logic
and
anything
else
that
may
be
coded
in
its
superclasses
it
needs
to
define
only
what
is
unique
about
it
the
data
conversion
logic
when
this
file
is
run
it
makes
and
runs
an
instance
that
reads
from
the
file
spam
txt
and
writes
the
uppercase
equivalent
of
that
file
to
the
stdout
stream
c
lp
e
type
spam
txt
spam
spam
spam
c
lp
e
python
converters
py
spam
spam
spam
to
process
different
sorts
of
streams
pass
in
different
sorts
of
objects
to
the
class
construction
call
here
we
use
an
output
file
instead
of
a
stream
c
lp
e
python
import
converters
prog
converters
uppercase
open
spam
txt
open
spamup
txt
w
prog
process
c
lp
e
type
spamup
txt
spam
spam
spam
but
as
suggested
earlier
we
could
also
pass
in
arbitrary
objects
wrapped
up
in
classes
that
define
the
required
input
and
output
method
interfaces
here
s
a
simple
example
that
passes
in
a
writer
class
that
wraps
up
the
text
inside
html
tags
c
lp
e
python
from
converters
import
uppercase
class
htmlize
def
write
self
line
print
pre
s
pre
line
rstrip
uppercase
open
spam
txt
htmlize
process
pre
spam
pre
pre
spam
pre
pre
spam
pre
oop
and
composition
has
a
relationships
if
you
trace
through
this
example
s
control
flow
you
ll
see
that
we
get
both
uppercase
conversion
by
inheritance
and
html
formatting
by
composition
even
though
the
core
processing
logic
in
the
original
processor
superclass
knows
nothing
about
either
step
the
processing
code
only
cares
that
writers
have
a
write
method
and
that
a
method
named
convert
is
defined
it
doesn
t
care
what
those
methods
do
when
they
are
called
such
polymorphism
and
encapsulation
of
logic
is
behind
much
of
the
power
of
classes
as
is
the
processor
superclass
only
provides
a
file
scanning
loop
in
more
realistic
work
we
might
extend
it
to
support
additional
programming
tools
for
its
subclasses
and
in
the
process
turn
it
into
a
full
blown
framework
coding
such
a
tool
once
in
a
superclass
enables
you
to
reuse
it
in
all
of
your
programs
even
in
this
simple
example
because
so
much
is
packaged
and
inherited
with
classes
all
we
had
to
code
was
the
html
formatting
step
the
rest
was
free
for
another
example
of
composition
at
work
see
exercise
at
the
end
of
chapter
and
its
solution
in
appendix
b
it
s
similar
to
the
pizza
shop
example
we
ve
focused
on
inheritance
in
this
book
because
that
is
the
main
tool
that
the
python
language
itself
provides
for
oop
but
in
practice
composition
is
used
as
much
as
inheritance
as
a
way
to
structure
classes
especially
in
larger
systems
as
we
ve
seen
inheritance
and
composition
are
often
complementary
and
sometimes
alternative
techniques
because
composition
is
a
design
issue
outside
the
scope
of
the
python
language
and
this
book
though
i
ll
defer
to
other
resources
for
more
on
this
topic
why
you
will
care
classes
and
persistence
i
ve
mentioned
python
s
pickle
and
shelve
object
persistence
support
a
few
times
in
this
part
of
the
book
because
it
works
especially
well
with
class
instances
in
fact
these
tools
are
often
compelling
enough
to
motivate
the
use
of
classes
in
general
by
picking
or
shelving
a
class
instance
we
get
data
storage
that
contains
both
data
and
logic
combined
for
example
besides
allowing
us
to
simulate
real
world
interactions
the
pizza
shop
classes
developed
in
this
chapter
could
also
be
used
as
the
basis
of
a
persistent
restaurant
database
instances
of
classes
can
be
stored
away
on
disk
in
a
single
step
using
python
s
pickle
or
shelve
modules
we
used
shelves
to
store
instances
of
classes
in
the
oop
tutorial
in
chapter
but
the
object
pickling
interface
is
remarkably
easy
to
use
as
well
import
pickle
object
someclass
file
open
filename
wb
pickle
dump
object
file
create
external
file
save
object
in
file
import
pickle
file
open
filename
rb
object
pickle
load
file
fetch
it
back
later
chapter
designing
with
classes
pickling
converts
in
memory
objects
to
serialized
byte
streams
really
strings
which
may
be
stored
in
files
sent
across
a
network
and
so
on
unpickling
converts
back
from
byte
streams
to
identical
in
memory
objects
shelves
are
similar
but
they
automatically
pickle
objects
to
an
access
by
key
database
which
exports
a
dictionary
like
interface
import
shelve
object
someclass
dbase
shelve
open
filename
dbase
key
object
save
under
key
import
shelve
dbase
shelve
open
filename
object
dbase
key
fetch
it
back
later
in
our
pizza
shop
example
using
classes
to
model
employees
means
we
can
get
a
simple
database
of
employees
and
shops
with
little
extra
work
pickling
such
instance
objects
to
a
file
makes
them
persistent
across
python
program
executions
from
pizzashop
import
pizzashop
shop
pizzashop
shop
server
shop
chef
employee
name
pat
salary
employee
name
bob
salary
import
pickle
pickle
dump
shop
open
shopfile
dat
wb
this
stores
an
entire
composite
shop
object
in
a
file
all
at
once
to
bring
it
back
later
in
another
session
or
program
a
single
step
suffices
as
well
in
fact
objects
restored
this
way
retain
both
state
and
behavior
import
pickle
obj
pickle
load
open
shopfile
dat
rb
obj
server
obj
chef
employee
name
pat
salary
employee
name
bob
salary
obj
order
sue
sue
orders
from
employee
name
pat
salary
bob
makes
pizza
oven
bakes
sue
pays
for
item
to
employee
name
pat
salary
see
the
standard
library
manual
and
later
examples
for
more
on
pickles
and
shelves
oop
and
delegation
wrapper
objects
beside
inheritance
and
composition
object
oriented
programmers
often
also
talk
about
something
called
delegation
which
usually
implies
controller
objects
that
embed
other
objects
to
which
they
pass
off
operation
requests
the
controllers
can
take
care
of
administrative
activities
such
as
keeping
track
of
accesses
and
so
on
in
python
delegation
is
often
implemented
with
the
getattr
method
hook
because
it
intercepts
accesses
to
nonexistent
attributes
a
wrapper
class
sometimes
called
a
proxy
class
can
use
getattr
to
route
arbitrary
accesses
to
a
wrapped
object
the
wrapper
class
retains
the
interface
of
the
wrapped
object
and
may
add
additional
operations
of
its
own
oop
and
delegation
wrapper
objects
consider
the
file
trace
py
for
instance
class
wrapper
def
init
self
object
self
wrapped
object
def
getattr
self
attrname
print
trace
attrname
return
getattr
self
wrapped
attrname
save
object
trace
fetch
delegate
fetch
recall
from
chapter
that
getattr
gets
the
attribute
name
as
a
string
this
code
makes
use
of
the
getattr
built
in
function
to
fetch
an
attribute
from
the
wrapped
object
by
name
string
getattr
x
n
is
like
x
n
except
that
n
is
an
expression
that
evaluates
to
a
string
at
runtime
not
a
variable
in
fact
getattr
x
n
is
similar
to
x
dict
n
but
the
former
also
performs
an
inheritance
search
like
x
n
while
the
latter
does
not
see
namespace
dictionaries
on
page
for
more
on
the
dict
attribute
you
can
use
the
approach
of
this
module
s
wrapper
class
to
manage
access
to
any
object
with
attributes
lists
dictionaries
and
even
classes
and
instances
here
the
wrapper
class
simply
prints
a
trace
message
on
each
attribute
access
and
delegates
the
attribute
request
to
the
embedded
wrapped
object
from
trace
import
wrapper
x
wrapper
x
append
trace
append
x
wrapped
x
wrapper
a
b
x
keys
trace
keys
a
b
wrap
a
list
delegate
to
list
method
print
my
member
wrap
a
dictionary
delegate
to
dictionary
method
the
net
effect
is
to
augment
the
entire
interface
of
the
wrapped
object
with
additional
code
in
the
wrapper
class
we
can
use
this
to
log
our
method
calls
route
method
calls
to
extra
or
custom
logic
and
so
on
we
ll
revive
the
notions
of
wrapped
objects
and
delegated
operations
as
one
way
to
extend
built
in
types
in
chapter
if
you
are
interested
in
the
delegation
design
pattern
also
watch
for
the
discussions
in
chapters
and
of
function
decorators
a
strongly
related
concept
designed
to
augment
a
specific
function
or
method
call
rather
than
the
entire
interface
of
an
object
and
class
decorators
which
serve
as
a
way
to
automatically
add
such
delegation
based
wrappers
to
all
instances
of
a
class
chapter
designing
with
classes
version
skew
note
in
python
operator
overloading
methods
run
by
built
in
operations
are
routed
through
generic
attribute
interception
methods
like
getattr
printing
a
wrapped
object
directly
for
example
calls
this
method
for
repr
or
str
which
then
passes
the
call
on
to
the
wrapped
object
in
python
this
no
longer
happens
printing
does
not
trigger
getattr
and
a
default
display
is
used
instead
in
new
style
classes
look
up
operator
overloading
methods
in
classes
and
skip
the
normal
instance
lookup
entirely
we
ll
return
to
this
issue
in
chapter
in
the
context
of
managed
attributes
for
now
keep
in
mind
that
you
may
need
to
redefine
operator
overloading
methods
in
wrapper
classes
either
by
hand
by
tools
or
by
superclasses
if
you
want
them
to
be
intercepted
in
pseudoprivate
class
attributes
besides
larger
structuring
goals
class
designs
often
must
address
name
usage
too
in
part
v
we
learned
that
every
name
assigned
at
the
top
level
of
a
module
file
is
exported
by
default
the
same
holds
for
classes
data
hiding
is
a
convention
and
clients
may
fetch
or
change
any
class
or
instance
attribute
they
like
in
fact
attributes
are
all
public
and
virtual
in
c
terms
they
re
all
accessible
everywhere
and
are
looked
up
dynamically
at
runtime
that
said
python
today
does
support
the
notion
of
name
mangling
i
e
expansion
to
localize
some
names
in
classes
mangled
names
are
sometimes
misleadingly
called
private
attributes
but
really
this
is
just
a
way
to
localize
a
name
to
the
class
that
created
it
name
mangling
does
not
prevent
access
by
code
outside
the
class
this
feature
is
mostly
intended
to
avoid
namespace
collisions
in
instances
not
to
restrict
access
to
names
in
general
mangled
names
are
therefore
better
called
pseudoprivate
than
private
pseudoprivate
names
are
an
advanced
and
entirely
optional
feature
and
you
probably
won
t
find
them
very
useful
until
you
start
writing
general
tools
or
larger
class
hierarchies
for
use
in
multiprogrammer
projects
in
fact
they
are
not
always
used
even
when
they
probably
should
be
more
commonly
python
programmers
code
internal
names
with
a
single
underscore
e
g
x
which
is
just
an
informal
convention
to
let
you
know
that
a
name
shouldn
t
be
changed
it
means
nothing
to
python
itself
because
you
may
see
this
feature
in
other
people
s
code
though
you
need
to
be
somewhat
aware
of
it
even
if
you
don
t
use
it
yourself
this
tends
to
scare
people
with
a
c
background
unnecessarily
in
python
it
s
even
possible
to
change
or
completely
delete
a
class
method
at
runtime
on
the
other
hand
almost
nobody
ever
does
this
in
practical
programs
as
a
scripting
language
python
is
more
about
enabling
than
restricting
also
recall
from
our
discussion
of
operator
overloading
in
chapter
that
getattr
and
setattr
can
be
used
to
emulate
privacy
but
are
generally
not
used
for
this
purpose
in
practice
more
on
this
when
we
code
a
more
realistic
privacy
decorator
chapter
pseudoprivate
class
attributes
name
mangling
overview
here
s
how
name
mangling
works
names
inside
a
class
statement
that
start
with
two
underscores
but
don
t
end
with
two
underscores
are
automatically
expanded
to
include
the
name
of
the
enclosing
class
for
instance
a
name
like
x
within
a
class
named
spam
is
changed
to
spam
x
automatically
the
original
name
is
prefixed
with
a
single
underscore
and
the
enclosing
class
s
name
because
the
modified
name
contains
the
name
of
the
enclosing
class
it
s
somewhat
unique
it
won
t
clash
with
similar
names
created
by
other
classes
in
a
hierarchy
name
mangling
happens
only
in
class
statements
and
only
for
names
that
begin
with
two
leading
underscores
however
it
happens
for
every
name
preceded
with
double
underscores
both
class
attributes
like
method
names
and
instance
attribute
names
assigned
to
self
attributes
for
example
in
a
class
named
spam
a
method
named
meth
is
mangled
to
spam
meth
and
an
instance
attribute
reference
self
x
is
transformed
to
self
spam
x
because
more
than
one
class
may
add
attributes
to
an
instance
this
mangling
helps
avoid
clashes
but
we
need
to
move
on
to
an
example
to
see
how
why
use
pseudoprivate
attributes
one
of
the
main
problems
that
the
pseudoprivate
attribute
feature
is
meant
to
alleviate
has
to
do
with
the
way
instance
attributes
are
stored
in
python
all
instance
attributes
wind
up
in
the
single
instance
object
at
the
bottom
of
the
class
tree
this
is
different
from
the
c
model
where
each
class
gets
its
own
space
for
data
members
it
defines
within
a
class
method
in
python
whenever
a
method
assigns
to
a
self
attribute
e
g
self
attr
value
it
changes
or
creates
an
attribute
in
the
instance
inheritance
searches
happen
only
on
reference
not
on
assignment
because
this
is
true
even
if
multiple
classes
in
a
hierarchy
assign
to
the
same
attribute
collisions
are
possible
for
example
suppose
that
when
a
programmer
codes
a
class
she
assumes
that
she
owns
the
attribute
name
x
in
the
instance
in
this
class
s
methods
the
name
is
set
and
later
fetched
class
c
def
meth
self
self
x
def
meth
self
print
self
x
i
assume
x
is
mine
suppose
further
that
another
programmer
working
in
isolation
makes
the
same
assumption
in
a
class
that
he
codes
class
c
def
metha
self
self
x
def
methb
self
print
self
x
me
too
both
of
these
classes
work
by
themselves
the
problem
arises
if
the
two
classes
are
ever
mixed
together
in
the
same
class
tree
chapter
designing
with
classes
class
c
c
c
i
c
only
x
in
i
now
the
value
that
each
class
gets
back
when
it
says
self
x
will
depend
on
which
class
assigned
it
last
because
all
assignments
to
self
x
refer
to
the
same
single
instance
there
is
only
one
x
attribute
i
x
no
matter
how
many
classes
use
that
attribute
name
to
guarantee
that
an
attribute
belongs
to
the
class
that
uses
it
prefix
the
name
with
double
underscores
everywhere
it
is
used
in
the
class
as
in
this
file
private
py
class
c
def
meth
self
def
meth
self
class
c
def
metha
self
def
methb
self
self
x
print
self
x
now
x
is
mine
becomes
c
x
in
i
self
x
print
self
x
me
too
becomes
c
x
in
i
class
c
c
c
pass
i
c
two
x
names
in
i
i
meth
i
metha
print
i
dict
i
meth
i
methb
when
thus
prefixed
the
x
attributes
will
be
expanded
to
include
the
names
of
their
classes
before
being
added
to
the
instance
if
you
run
a
dir
call
on
i
or
inspect
its
namespace
dictionary
after
the
attributes
have
been
assigned
you
ll
see
the
expanded
names
c
x
and
c
x
but
not
x
because
the
expansion
makes
the
names
unique
within
the
instance
the
class
coders
can
safely
assume
that
they
truly
own
any
names
that
they
prefix
with
two
underscores
python
private
py
c
x
c
x
this
trick
can
avoid
potential
name
collisions
in
the
instance
but
note
that
it
does
not
amount
to
true
privacy
if
you
know
the
name
of
the
enclosing
class
you
can
still
access
either
of
these
attributes
anywhere
you
have
a
reference
to
the
instance
by
using
the
fully
expanded
name
e
g
i
c
x
on
the
other
hand
this
feature
makes
it
less
likely
that
you
will
accidentally
step
on
a
class
s
names
pseudoprivate
attributes
are
also
useful
in
larger
frameworks
or
tools
both
to
avoid
introducing
new
method
names
that
might
accidentally
hide
definitions
elsewhere
in
the
class
tree
and
to
reduce
the
chance
of
internal
methods
being
replaced
by
names
defined
lower
in
the
tree
if
a
method
is
intended
for
use
only
within
a
class
that
may
be
mixed
into
other
classes
the
double
underscore
prefix
ensures
that
the
method
won
t
interfere
with
other
names
in
the
tree
especially
in
multiple
inheritance
scenarios
class
super
def
method
self
a
real
application
method
class
tool
pseudoprivate
class
attributes
def
method
self
def
other
self
self
method
becomes
tool
method
use
my
internal
method
class
sub
tool
super
def
actions
self
self
method
runs
super
method
as
expected
class
sub
tool
def
init
self
self
method
doesn
t
break
tool
method
we
met
multiple
inheritance
briefly
in
chapter
and
will
explore
it
in
more
detail
later
in
this
chapter
recall
that
superclasses
are
searched
according
to
their
left
to
right
order
in
class
header
lines
here
this
means
sub
prefers
tool
attributes
to
those
in
super
although
in
this
example
we
could
force
python
to
pick
the
application
class
s
methods
first
by
switching
the
order
of
the
superclasses
listed
in
the
sub
class
header
pseudoprivate
attributes
resolve
the
issue
altogether
pseudoprivate
names
also
prevent
subclasses
from
accidentally
redefining
the
internal
method
s
names
as
in
sub
again
i
should
note
that
this
feature
tends
to
be
of
use
primarily
for
larger
multiprogrammer
projects
and
then
only
for
selected
names
don
t
be
tempted
to
clutter
your
code
unnecessarily
only
use
this
feature
for
names
that
truly
need
to
be
controlled
by
a
single
class
for
simpler
programs
it
s
probably
overkill
for
more
examples
that
make
use
of
the
x
naming
feature
see
the
lister
py
mix
in
classes
introduced
later
in
this
chapter
in
the
section
on
multiple
inheritance
as
well
as
the
discussion
of
private
class
decorators
in
chapter
if
you
care
about
privacy
in
general
you
might
want
to
review
the
emulation
of
private
instance
attributes
sketched
in
the
section
attribute
reference
getattr
and
setattr
on
page
in
chapter
and
watch
for
the
private
class
decorator
in
chapter
that
we
will
base
upon
this
special
method
although
it
s
possible
to
emulate
true
access
controls
in
python
classes
this
is
rarely
done
in
practice
even
for
large
systems
methods
are
objects
bound
or
unbound
methods
in
general
and
bound
methods
in
particular
simplify
the
implementation
of
many
design
goals
in
python
we
met
bound
methods
briefly
while
studying
call
in
chapter
the
full
story
which
we
ll
flesh
out
here
turns
out
to
be
more
general
and
flexible
than
you
might
expect
in
chapter
we
learned
how
functions
can
be
processed
as
normal
objects
methods
are
a
kind
of
object
too
and
can
be
used
generically
in
much
the
same
way
as
other
objects
they
can
be
assigned
passed
to
functions
stored
in
data
structures
and
so
on
because
class
methods
can
be
accessed
from
an
instance
or
a
class
though
they
actually
come
in
two
flavors
in
python
chapter
designing
with
classes
unbound
class
method
objects
no
self
accessing
a
function
attribute
of
a
class
by
qualifying
the
class
returns
an
unbound
method
object
to
call
the
method
you
must
provide
an
instance
object
explicitly
as
the
first
argument
in
python
an
unbound
method
is
the
same
as
a
simple
function
and
can
be
called
though
the
class
s
name
in
it
s
a
distinct
type
and
cannot
be
called
without
providing
an
instance
bound
instance
method
objects
self
function
pairs
accessing
a
function
attribute
of
a
class
by
qualifying
an
instance
returns
a
bound
method
object
python
automatically
packages
the
instance
with
the
function
in
the
bound
method
object
so
you
don
t
need
to
pass
an
instance
to
call
the
method
both
kinds
of
methods
are
full
fledged
objects
they
can
be
transferred
around
a
program
at
will
just
like
strings
and
numbers
both
also
require
an
instance
in
their
first
argument
when
run
i
e
a
value
for
self
this
is
why
we
had
to
pass
in
an
instance
explicitly
when
calling
superclass
methods
from
subclass
methods
in
the
previous
chapter
technically
such
calls
produce
unbound
method
objects
when
calling
a
bound
method
object
python
provides
an
instance
for
you
automatically
the
instance
used
to
create
the
bound
method
object
this
means
that
bound
method
objects
are
usually
interchangeable
with
simple
function
objects
and
makes
them
especially
useful
for
interfaces
originally
written
for
functions
see
the
sidebar
why
you
will
care
bound
methods
and
callbacks
on
page
for
a
realistic
example
to
illustrate
suppose
we
define
the
following
class
class
spam
def
doit
self
message
print
message
now
in
normal
operation
we
make
an
instance
and
call
its
method
in
a
single
step
to
print
the
passed
in
argument
object
spam
object
doit
hello
world
really
though
a
bound
method
object
is
generated
along
the
way
just
before
the
method
call
s
parentheses
in
fact
we
can
fetch
a
bound
method
without
actually
calling
it
an
object
name
qualification
is
an
object
expression
in
the
following
it
returns
a
bound
method
object
that
packages
the
instance
object
with
the
method
function
spam
doit
we
can
assign
this
bound
method
pair
to
another
name
and
then
call
it
as
though
it
were
a
simple
function
object
spam
x
object
doit
x
hello
world
bound
method
object
instance
function
same
effect
as
object
doit
methods
are
objects
bound
or
unbound
on
the
other
hand
if
we
qualify
the
class
to
get
to
doit
we
get
back
an
unbound
method
object
which
is
simply
a
reference
to
the
function
object
to
call
this
type
of
method
we
must
pass
in
an
instance
as
the
leftmost
argument
object
spam
t
spam
doit
t
object
howdy
unbound
method
object
a
function
in
see
ahead
pass
in
instance
if
the
method
expects
one
in
by
extension
the
same
rules
apply
within
a
class
s
method
if
we
reference
self
attributes
that
refer
to
functions
in
the
class
a
self
method
expression
is
a
bound
method
object
because
self
is
an
instance
object
class
eggs
def
m
self
n
print
n
def
m
self
x
self
m
x
another
bound
method
object
looks
like
a
simple
function
eggs
m
prints
most
of
the
time
you
call
methods
immediately
after
fetching
them
with
attribute
qualification
so
you
don
t
always
notice
the
method
objects
generated
along
the
way
but
if
you
start
writing
code
that
calls
objects
generically
you
need
to
be
careful
to
treat
unbound
methods
specially
they
normally
require
an
explicit
instance
object
to
be
passed
in
unbound
methods
are
functions
in
in
python
the
language
has
dropped
the
notion
of
unbound
methods
what
we
describe
as
an
unbound
method
here
is
treated
as
a
simple
function
in
for
most
purposes
this
makes
no
difference
to
your
code
either
way
an
instance
will
be
passed
to
a
method
s
first
argument
when
it
s
called
through
an
instance
programs
that
do
explicit
type
testing
might
be
impacted
though
if
you
print
the
type
of
an
instance
less
class
method
it
displays
unbound
method
in
and
function
in
moreover
in
it
is
ok
to
call
a
method
without
an
instance
as
long
as
the
method
does
not
expect
one
and
you
call
it
only
through
the
class
and
never
through
an
instance
that
is
python
will
pass
along
an
instance
to
methods
only
for
through
instance
calls
when
calling
through
a
class
you
must
pass
an
instance
manually
only
if
the
method
expects
one
c
misc
c
python
python
class
selfless
see
the
discussion
of
static
and
class
methods
in
chapter
for
an
optional
exception
to
this
rule
like
bound
methods
static
methods
can
masquerade
as
basic
functions
because
they
do
not
expect
instances
when
called
python
supports
three
kinds
of
class
methods
instance
static
and
class
and
allows
simple
functions
in
classes
too
chapter
designing
with
classes
def
init
self
data
self
data
data
def
selfless
arg
arg
return
arg
arg
def
normal
self
arg
arg
return
self
data
arg
arg
a
simple
function
in
instance
expected
when
called
x
selfless
x
normal
instance
passed
to
self
automatically
selfless
normal
x
self
expected
by
method
pass
manually
selfless
selfless
no
instance
works
in
fails
in
the
last
test
in
this
fails
in
because
unbound
methods
require
an
instance
to
be
passed
by
default
it
works
in
because
such
methods
are
treated
as
simple
functions
not
requiring
an
instance
although
this
removes
some
potential
error
trapping
in
what
if
a
programmer
accidentally
forgets
to
pass
an
instance
it
allows
class
methods
to
be
used
as
simple
functions
as
long
as
they
are
not
passed
and
do
not
expect
a
self
instance
argument
the
following
two
calls
still
fail
in
both
and
though
the
first
calling
through
an
instance
automatically
passes
an
instance
to
a
method
that
does
not
expect
one
while
the
second
calling
through
a
class
does
not
pass
an
instance
to
a
method
that
does
expect
one
x
selfless
typeerror
selfless
takes
exactly
positional
arguments
given
selfless
normal
typeerror
normal
takes
exactly
positional
arguments
given
because
of
this
change
the
staticmethod
decorator
described
in
the
next
chapter
is
not
needed
in
for
methods
without
a
self
argument
that
are
called
only
through
the
class
name
and
never
through
an
instance
such
methods
are
run
as
simple
functions
without
receiving
an
instance
argument
in
such
calls
are
errors
unless
an
instance
is
passed
manually
more
on
static
methods
in
the
next
chapter
it
s
important
to
be
aware
of
the
differences
in
behavior
in
but
bound
methods
are
generally
more
important
from
a
practical
perspective
anyway
because
they
pair
together
the
instance
and
function
in
a
single
object
they
can
be
treated
as
callables
generically
the
next
section
demonstrates
what
this
means
in
code
for
a
more
visual
illustration
of
unbound
method
treatment
in
python
and
see
also
the
lister
py
example
in
the
multiple
inheritance
section
later
in
this
chapter
its
classes
print
the
value
of
methods
fetched
from
both
instances
and
classes
in
both
versions
of
python
methods
are
objects
bound
or
unbound
bound
methods
and
other
callable
objects
as
mentioned
earlier
bound
methods
can
be
processed
as
generic
objects
just
like
simple
functions
they
can
be
passed
around
a
program
arbitrarily
moreover
because
bound
methods
combine
both
a
function
and
an
instance
in
a
single
package
they
can
be
treated
like
any
other
callable
object
and
require
no
special
syntax
when
invoked
the
following
for
example
stores
four
bound
method
objects
in
a
list
and
calls
them
later
with
normal
call
expressions
class
number
def
init
self
base
self
base
base
def
double
self
return
self
base
def
triple
self
return
self
base
class
instance
objects
state
methods
x
number
y
number
z
number
x
double
normal
immediate
calls
acts
x
double
y
double
y
triple
z
double
for
act
in
acts
print
act
list
of
bound
methods
calls
are
deferred
call
as
though
functions
like
simple
functions
bound
method
objects
have
introspection
information
of
their
own
including
attributes
that
give
access
to
the
instance
object
and
method
function
they
pair
calling
the
bound
method
simply
dispatches
the
pair
bound
x
double
bound
self
bound
func
main
number
object
at
x
f
function
double
at
x
a
ed
bound
self
base
bound
calls
bound
func
bound
self
in
fact
bound
methods
are
just
one
of
a
handful
of
callable
object
types
in
python
as
the
following
demonstrates
simple
functions
coded
with
a
def
or
lambda
instances
that
inherit
a
call
and
bound
instance
methods
can
all
be
treated
and
called
the
same
way
def
square
arg
return
arg
class
sum
def
init
self
val
chapter
designing
with
classes
simple
functions
def
or
lambda
callable
instances
self
val
val
def
call
self
arg
return
self
val
arg
class
product
def
init
self
val
self
val
val
def
method
self
arg
return
self
val
arg
bound
methods
sobject
sum
pobject
product
actions
square
sobject
pobject
method
function
instance
method
for
act
in
actions
print
act
actions
act
for
act
in
actions
list
map
lambda
act
act
actions
all
called
same
way
call
any
arg
callable
index
comprehensions
maps
technically
speaking
classes
belong
in
the
callable
objects
category
too
but
we
normally
call
them
to
generate
instances
rather
than
to
do
actual
work
as
shown
here
class
negate
def
init
self
val
self
val
val
def
repr
self
return
str
self
val
actions
square
sobject
pobject
method
for
act
in
actions
print
act
act
for
act
in
actions
classes
are
callables
too
but
called
for
object
not
work
instance
print
format
negate
call
a
class
too
runs
repr
not
str
table
act
act
for
act
in
actions
dict
comprehension
for
key
value
in
table
items
print
format
key
value
str
format
class
main
negate
function
square
at
x
d
bound
method
product
method
of
main
product
object
at
x
d
f
main
sum
object
at
x
d
f
methods
are
objects
bound
or
unbound
as
you
can
see
bound
methods
and
python
s
callable
objects
model
in
general
are
some
of
the
many
ways
that
python
s
design
makes
for
an
incredibly
flexible
language
you
should
now
understand
the
method
object
model
for
other
examples
of
bound
methods
at
work
see
the
upcoming
sidebar
why
you
will
care
bound
methods
and
callbacks
as
well
as
the
prior
chapter
s
discussion
of
callback
handlers
in
the
section
on
the
method
call
why
you
will
care
bound
methods
and
callbacks
because
bound
methods
automatically
pair
an
instance
with
a
class
method
function
you
can
use
them
anywhere
a
simple
function
is
expected
one
of
the
most
common
places
you
ll
see
this
idea
put
to
work
is
in
code
that
registers
methods
as
event
callback
handlers
in
the
tkinter
gui
interface
named
tkinter
in
python
here
s
the
simple
case
def
handler
use
globals
for
state
widget
button
text
spam
command
handler
to
register
a
handler
for
button
click
events
we
usually
pass
a
callable
object
that
takes
no
arguments
to
the
command
keyword
argument
function
names
and
lambdas
work
here
and
so
do
class
methods
as
long
as
they
are
bound
methods
class
mywidget
def
handler
self
use
self
attr
for
state
def
makewidgets
self
b
button
text
spam
command
self
handler
here
the
event
handler
is
self
handler
a
bound
method
object
that
remembers
both
self
and
mygui
handler
because
self
will
refer
to
the
original
instance
when
handler
is
later
invoked
on
events
the
method
will
have
access
to
instance
attributes
that
can
retain
state
between
events
with
simple
functions
state
normally
must
be
retained
in
global
variables
or
enclosing
function
scopes
instead
see
also
the
discussion
of
call
operator
overloading
in
chapter
for
another
way
to
make
classes
compatible
with
function
based
apis
multiple
inheritance
mix
in
classes
many
class
based
designs
call
for
combining
disparate
sets
of
methods
in
a
class
statement
more
than
one
superclass
can
be
listed
in
parentheses
in
the
header
line
when
you
do
this
you
use
something
called
multiple
inheritance
the
class
and
its
instances
inherit
names
from
all
the
listed
superclasses
chapter
designing
with
classes
when
searching
for
an
attribute
python
s
inheritance
search
traverses
all
superclasses
in
the
class
header
from
left
to
right
until
a
match
is
found
technically
because
any
of
the
superclasses
may
have
superclasses
of
its
own
this
search
can
be
a
bit
more
complex
for
larger
class
tress
in
classic
classes
the
default
until
python
the
attribute
search
proceeds
depthfirst
all
the
way
to
the
top
of
the
inheritance
tree
and
then
from
left
to
right
in
new
style
classes
and
all
classes
in
the
attribute
search
proceeds
across
by
tree
levels
in
a
more
breadth
first
fashion
see
the
new
style
class
discussion
in
the
next
chapter
in
either
model
though
when
a
class
has
multiple
superclasses
they
are
searched
from
left
to
right
according
to
the
order
listed
in
the
class
statement
header
lines
in
general
multiple
inheritance
is
good
for
modeling
objects
that
belong
to
more
than
one
set
for
instance
a
person
may
be
an
engineer
a
writer
a
musician
and
so
on
and
inherit
properties
from
all
such
sets
with
multiple
inheritance
objects
obtain
the
union
of
the
behavior
in
all
their
superclasses
perhaps
the
most
common
way
multiple
inheritance
is
used
is
to
mix
in
generalpurpose
methods
from
superclasses
such
superclasses
are
usually
called
mix
in
classes
they
provide
methods
you
add
to
application
classes
by
inheritance
in
a
sense
mix
in
classes
are
similar
to
modules
they
provide
packages
of
methods
for
use
in
their
client
subclasses
unlike
simple
functions
in
modules
though
methods
in
mix
ins
also
have
access
to
the
self
instance
for
using
state
information
and
other
methods
the
next
section
demonstrates
one
common
use
case
for
such
tools
coding
mix
in
display
classes
as
we
ve
seen
python
s
default
way
to
print
a
class
instance
object
isn
t
incredibly
useful
class
spam
def
init
self
self
data
food
x
spam
print
x
main
spam
object
at
x
no
repr
or
str
default
class
address
displays
instance
in
python
as
you
saw
in
chapter
when
studying
operator
overloading
you
can
provide
a
str
or
repr
method
to
implement
a
custom
string
representation
of
your
own
but
rather
than
coding
one
of
these
in
each
and
every
class
you
wish
to
print
why
not
code
it
once
in
a
general
purpose
tool
class
and
inherit
it
in
all
your
classes
that
s
what
mix
ins
are
for
defining
a
display
method
in
a
mix
in
superclass
once
enables
us
to
reuse
it
anywhere
we
want
to
see
a
custom
display
format
we
ve
already
seen
tools
that
do
related
work
multiple
inheritance
mix
in
classes
chapter
s
attrdisplay
class
formatted
instance
attributes
in
a
generic
str
method
but
it
did
not
climb
class
trees
and
was
used
in
single
inheritance
mode
only
chapter
s
classtree
py
module
defined
functions
for
climbing
and
sketching
class
trees
but
it
did
not
display
object
attributes
along
the
way
and
was
not
architected
as
an
inheritable
class
here
we
re
going
to
revisit
these
examples
techniques
and
expand
upon
them
to
code
a
set
of
three
mix
in
classes
that
serve
as
generic
display
tools
for
listing
instance
attributes
inherited
attributes
and
attributes
on
all
objects
in
a
class
tree
we
ll
also
use
our
tools
in
multiple
inheritance
mode
and
deploy
coding
techniques
that
make
classes
better
suited
to
use
as
generic
tools
listing
instance
attributes
with
dict
let
s
get
started
with
the
simple
case
listing
attributes
attached
to
an
instance
the
following
class
coded
in
the
file
lister
py
defines
a
mix
in
called
listinstance
that
overloads
the
str
method
for
all
classes
that
include
it
in
their
header
lines
because
this
is
coded
as
a
class
listinstance
is
a
generic
tool
whose
formatting
logic
can
be
used
for
instances
of
any
subclass
file
lister
py
class
listinstance
mix
in
class
that
provides
a
formatted
print
or
str
of
instances
via
inheritance
of
str
coded
here
displays
instance
attrs
only
self
is
the
instance
of
lowest
class
uses
x
names
to
avoid
clashing
with
client
s
attrs
def
str
self
return
instance
of
s
address
s
n
s
self
class
name
my
class
s
name
id
self
my
address
self
attrnames
name
value
list
def
attrnames
self
result
for
attr
in
sorted
self
dict
instance
attr
dict
result
tname
s
s
n
attr
self
dict
attr
retubrn
result
listinstance
uses
some
previously
explored
tricks
to
extract
the
instance
s
class
name
and
attributes
each
instance
has
a
built
in
class
attribute
that
references
the
class
from
which
it
was
created
and
each
class
has
a
name
attribute
that
references
the
name
in
the
header
so
the
expression
self
class
name
fetches
the
name
of
an
instance
s
class
chapter
designing
with
classes
this
class
does
most
of
its
work
by
simply
scanning
the
instance
s
attribute
dictionary
remember
it
s
exported
in
dict
to
build
up
a
string
showing
the
names
and
values
of
all
instance
attributes
the
dictionary
s
keys
are
sorted
to
finesse
any
ordering
differences
across
python
releases
in
these
respects
listinstance
is
similar
to
chapter
s
attribute
display
in
fact
it
s
largely
just
a
variation
on
a
theme
our
class
here
uses
two
additional
techniques
though
it
displays
the
instance
s
memory
address
by
calling
the
id
built
function
which
returns
any
object
s
address
by
definition
a
unique
object
identifier
which
will
be
useful
in
later
mutations
of
this
code
it
uses
the
pseudoprivate
naming
pattern
for
its
worker
method
attrnames
as
we
learned
earlier
in
his
chapter
python
automatically
localizes
any
such
name
to
its
enclosing
class
by
expanding
the
attribute
name
to
include
the
class
name
in
this
case
it
becomes
listinstance
attrnames
this
holds
true
for
both
class
attributes
like
methods
and
instance
attributes
attached
to
self
this
behavior
is
useful
in
a
general
tool
like
this
as
it
ensures
that
its
names
don
t
clash
with
any
names
used
in
its
client
subclasses
because
listinstance
defines
a
str
operator
overloading
method
instances
derived
from
this
class
display
their
attributes
automatically
when
printed
giving
a
bit
more
information
than
a
simple
address
here
is
the
class
in
action
in
single
inheritance
mode
this
code
works
the
same
in
both
python
and
from
lister
import
listinstance
class
spam
listinstance
def
init
self
self
data
food
x
spam
print
x
instance
of
spam
address
name
data
food
inherit
a
str
method
print
and
str
run
str
you
can
also
fetch
the
listing
output
as
a
string
without
printing
it
with
str
and
interactive
echoes
still
use
the
default
format
str
x
instance
of
spam
address
n
tname
data
food
n
x
the
repr
still
is
a
default
main
spam
object
at
x
f
the
listinstance
class
is
useful
for
any
classes
you
write
even
classes
that
already
have
one
or
more
superclasses
this
is
where
multiple
inheritance
comes
in
handy
by
adding
listinstance
to
the
list
of
superclasses
in
a
class
header
i
e
mixing
it
in
you
get
its
str
for
free
while
still
inheriting
from
the
existing
superclass
es
the
file
testmixin
py
demonstrates
multiple
inheritance
mix
in
classes
file
testmixin
py
from
lister
import
class
super
def
init
self
self
data
spam
def
ham
self
pass
class
sub
super
listinstance
def
init
self
super
init
self
self
data
eggs
self
data
def
spam
self
pass
if
name
main
x
sub
print
x
get
lister
tool
classes
superclass
init
create
instance
attrs
mix
in
ham
and
a
str
listers
have
access
to
self
more
instance
attrs
define
another
method
here
run
mixed
in
str
here
sub
inherits
names
from
both
super
and
listinstance
it
s
a
composite
of
its
own
names
and
names
in
both
its
superclasses
when
you
make
a
sub
instance
and
print
it
you
automatically
get
the
custom
representation
mixed
in
from
listinstance
in
this
case
this
script
s
output
is
the
same
under
both
python
and
except
for
object
addresses
c
misc
c
python
python
testmixin
py
instance
of
sub
address
name
data
spam
name
data
eggs
name
data
listinstance
works
in
any
class
it
s
mixed
into
because
self
refers
to
an
instance
of
the
subclass
that
pulls
this
class
in
whatever
that
may
be
in
a
sense
mix
in
classes
are
the
class
equivalent
of
modules
packages
of
methods
useful
in
a
variety
of
clients
for
example
here
is
lister
working
again
in
single
inheritance
mode
on
a
different
class
s
instances
with
import
and
attributes
set
outside
the
class
import
lister
class
c
lister
listinstance
pass
x
c
x
a
x
b
x
c
print
x
instance
of
c
address
name
a
name
b
name
c
chapter
designing
with
classes
besides
the
utility
they
provide
mix
ins
optimize
code
maintenance
like
all
classes
do
for
example
if
you
later
decide
to
extend
listinstance
s
str
to
also
print
all
the
class
attributes
that
an
instance
inherits
you
re
safe
because
it
s
an
inherited
method
changing
str
automatically
updates
the
display
of
each
subclass
that
imports
the
class
and
mixes
it
in
since
it
s
now
officially
later
let
s
move
on
to
the
next
section
to
see
what
such
an
extension
might
look
like
listing
inherited
attributes
with
dir
as
it
is
our
lister
mix
in
displays
instance
attributes
only
i
e
names
attached
to
the
instance
object
itself
it
s
trivial
to
extend
the
class
to
display
all
the
attributes
accessible
from
an
instance
though
both
its
own
and
those
it
inherits
from
its
classes
the
trick
is
to
use
the
dir
built
in
function
instead
of
scanning
the
instance
s
dict
dictionary
the
latter
holds
instance
attributes
only
but
the
former
also
collects
all
inherited
attributes
in
python
and
later
the
following
mutation
codes
this
scheme
i
ve
renamed
it
to
facilitate
simple
testing
but
if
this
were
to
replace
the
original
version
all
existing
clients
would
pick
up
the
new
display
automatically
file
lister
py
continued
class
listinherited
use
dir
to
collect
both
instance
attrs
and
names
inherited
from
its
classes
python
shows
more
names
than
because
of
the
implied
object
superclass
in
the
new
style
class
model
getattr
fetches
inherited
names
not
in
self
dict
use
str
not
repr
or
else
this
loops
when
printing
bound
methods
def
str
self
return
instance
of
s
address
s
n
s
self
class
name
my
class
s
name
id
self
my
address
self
attrnames
name
value
list
def
attrnames
self
result
for
attr
in
dir
self
instance
dir
if
attr
and
attr
skip
internals
result
tname
s
n
attr
else
result
tname
s
s
n
attr
getattr
self
attr
return
result
notice
that
this
code
skips
x
names
values
most
of
these
are
internal
names
that
we
don
t
generally
care
about
in
a
generic
listing
like
this
this
version
also
must
use
the
getattr
built
in
function
to
fetch
attributes
by
name
string
instead
of
using
instance
attribute
dictionary
indexing
getattr
employs
the
inheritance
search
protocol
and
some
of
the
names
we
re
listing
here
are
not
stored
on
the
instance
itself
multiple
inheritance
mix
in
classes
to
test
the
new
version
change
the
testmixin
py
file
to
use
this
new
class
instead
class
sub
super
listinherited
mix
in
a
str
this
file
s
output
varies
per
release
in
python
we
get
the
following
notice
the
name
mangling
at
work
in
the
lister
s
method
name
i
shortened
its
full
value
display
to
fit
on
this
page
c
misc
c
python
python
testmixin
py
instance
of
sub
address
name
listinherited
attrnames
bound
method
sub
attrnames
of
more
name
doc
name
init
name
module
name
str
name
data
spam
name
data
eggs
name
data
name
ham
bound
method
sub
ham
of
main
sub
instance
at
x
b
name
spam
bound
method
sub
spam
of
main
sub
instance
at
x
b
in
python
more
attributes
are
displayed
because
all
classes
are
new
style
and
inherit
names
from
the
implied
object
superclass
more
on
this
in
chapter
because
so
many
names
are
inherited
from
the
default
superclass
i
ve
omitted
many
here
run
this
on
your
own
for
the
full
listing
c
misc
c
python
python
testmixin
py
instance
of
sub
address
name
listinherited
attrnames
bound
method
sub
attrnames
of
more
name
class
name
delattr
name
dict
name
doc
name
eq
more
names
omitted
name
repr
name
setattr
name
sizeof
name
str
name
subclasshook
name
weakref
name
data
spam
name
data
eggs
name
data
name
ham
bound
method
sub
ham
of
main
sub
object
at
x
f
b
name
spam
bound
method
sub
spam
of
main
sub
object
at
x
f
b
one
caution
here
now
that
we
re
displaying
inherited
methods
too
we
have
to
use
str
instead
of
repr
to
overload
printing
with
repr
this
code
will
loop
displaying
the
value
of
a
method
triggers
the
repr
of
the
method
s
class
in
order
to
display
the
class
that
is
if
the
lister
s
repr
tries
to
display
a
method
displaying
the
method
s
class
will
trigger
the
lister
s
repr
again
subtle
but
true
change
chapter
designing
with
classes
str
to
repr
here
to
see
this
for
yourself
if
you
must
use
repr
in
such
a
context
you
can
avoid
the
loops
by
using
isinstance
to
compare
the
type
of
attribute
values
against
types
methodtype
in
the
standard
library
to
know
which
items
to
skip
listing
attributes
per
object
in
class
trees
let
s
code
one
last
extension
as
it
is
our
lister
doesn
t
tell
us
which
class
an
inherited
name
comes
from
as
we
saw
in
the
classtree
py
example
near
the
end
of
chapter
though
it
s
straightforward
to
climb
class
inheritance
trees
in
code
the
following
mixin
class
makes
use
of
this
same
technique
to
display
attributes
grouped
by
the
classes
they
live
in
it
sketches
the
full
class
tree
displaying
attributes
attached
to
each
object
along
the
way
it
does
so
by
traversing
the
inheritance
tree
from
an
instance
s
class
to
its
class
and
then
from
the
class
s
bases
to
all
superclasses
recursively
scanning
object
dicts
s
along
the
way
file
lister
py
continued
class
listtree
mix
in
that
returns
an
str
trace
of
the
entire
class
tree
and
all
its
objects
attrs
at
and
above
self
run
by
print
str
returns
constructed
string
uses
x
attr
names
to
avoid
impacting
clients
uses
generator
expr
to
recurse
to
superclasses
uses
str
format
to
make
substitutions
clearer
def
str
self
self
visited
return
instance
of
address
n
format
self
class
name
id
self
self
attrnames
self
self
listclass
self
class
def
listclass
self
aclass
indent
dots
indent
if
aclass
in
self
visited
return
n
class
address
see
above
n
format
dots
aclass
name
id
aclass
else
self
visited
aclass
true
genabove
self
listclass
c
indent
for
c
in
aclass
bases
return
n
class
address
n
n
format
dots
aclass
name
id
aclass
self
attrnames
aclass
indent
join
genabove
dots
def
attrnames
self
obj
indent
multiple
inheritance
mix
in
classes
spaces
indent
result
for
attr
in
sorted
obj
dict
if
attr
startswith
and
attr
endswith
result
spaces
n
format
attr
else
result
spaces
n
format
attr
getattr
obj
attr
return
result
note
the
use
of
a
generator
expression
to
direct
the
recursive
calls
for
superclasses
it
s
activated
by
the
nested
string
join
method
also
see
how
this
version
uses
the
python
and
string
format
method
instead
of
formatting
expressions
to
make
substitutions
clearer
when
many
substitutions
are
applied
like
this
explicit
argument
numbers
may
make
the
code
easier
to
decipher
in
short
in
this
version
we
exchange
the
first
of
the
following
lines
for
the
second
return
instance
of
s
address
s
n
s
s
expression
return
instance
of
address
n
format
method
now
change
testmixin
py
to
inherit
from
this
new
class
again
to
test
class
sub
super
listtree
mix
in
a
str
the
file
s
tree
sketcher
output
in
python
is
then
as
follows
c
misc
c
python
python
testmixin
py
instance
of
sub
address
listtree
visited
data
spam
data
eggs
data
class
sub
address
doc
init
module
spam
unbound
method
sub
spam
class
super
address
doc
init
module
ham
unbound
method
super
ham
class
listtree
address
listtree
attrnames
unbound
method
listtree
attrnames
listtree
listclass
unbound
method
listtree
listclass
doc
module
str
chapter
designing
with
classes
notice
in
this
output
how
methods
are
unbound
now
under
because
we
fetch
them
from
classes
directly
instead
of
from
instances
also
observe
how
the
lister
s
visited
table
has
its
name
mangled
in
the
instance
s
attribute
dictionary
unless
we
re
very
unlucky
this
won
t
clash
with
other
data
there
under
python
we
get
extra
attributes
and
superclasses
again
notice
that
unbound
methods
are
simple
functions
in
as
described
in
an
earlier
note
in
this
chapter
and
that
again
i
ve
deleted
most
built
in
attributes
in
object
to
save
space
here
run
this
on
your
own
for
the
complete
listing
c
misc
c
python
python
testmixin
py
instance
of
sub
address
listtree
visited
data
spam
data
eggs
data
class
sub
address
doc
init
module
spam
function
spam
at
x
d
d
class
super
address
dict
doc
init
module
weakref
ham
function
ham
at
x
d
class
object
address
class
delattr
doc
eq
more
omitted
repr
setattr
sizeof
str
subclasshook
class
listtree
address
listtree
attrnames
function
attrnames
at
x
d
listtree
listclass
function
listclass
at
x
d
a
dict
doc
module
str
weakref
multiple
inheritance
mix
in
classes
class
object
address
see
above
this
version
avoids
listing
the
same
class
object
twice
by
keeping
a
table
of
classes
visited
so
far
this
is
why
an
object
s
id
is
included
to
serve
as
a
key
for
a
previously
displayed
item
like
the
transitive
module
reloader
of
chapter
a
dictionary
works
to
avoid
repeats
and
cycles
here
because
class
objects
may
be
dictionary
keys
a
set
would
provide
similar
functionality
this
version
also
takes
care
to
avoid
large
internal
objects
by
skipping
x
names
again
if
you
comment
out
the
test
for
these
names
their
values
will
display
normally
here
s
an
excerpt
from
the
output
in
with
this
temporary
change
made
it
s
much
larger
in
its
entirety
and
it
gets
even
worse
in
which
is
why
these
names
are
probably
better
skipped
c
misc
c
python
python
testmixin
py
more
omitted
class
listtree
address
listtree
attrnames
unbound
method
listtree
attrnames
listtree
listclass
unbound
method
listtree
listclass
doc
mix
in
that
returns
the
str
trace
of
the
entire
class
tree
and
all
its
objects
attrs
at
and
above
self
run
by
print
str
returns
constructed
string
uses
x
attr
names
to
avoid
impacting
clients
uses
generator
expr
to
recurse
to
superclasses
uses
str
format
to
make
substitutions
clearer
module
lister
str
unbound
method
listtree
str
for
more
fun
try
mixing
this
class
into
something
more
substantial
like
the
button
class
of
python
s
tkinter
gui
toolkit
module
in
general
you
ll
want
to
name
list
tree
first
leftmost
in
a
class
header
so
its
str
is
picked
up
button
has
one
too
and
the
leftmost
superclass
is
searched
first
in
multiple
inheritance
the
output
of
the
following
is
fairly
massive
k
characters
so
run
this
code
on
your
own
to
see
the
full
listing
and
if
you
re
using
python
recall
that
you
should
use
tkinter
for
the
module
name
instead
of
tkinter
from
lister
import
listtree
from
tkinter
import
button
class
mybutton
listtree
button
pass
b
mybutton
text
spam
open
savetree
txt
w
write
str
b
print
b
instance
of
mybutton
address
listtree
visited
chapter
designing
with
classes
both
classes
have
a
str
listtree
first
use
its
str
save
to
a
file
for
later
viewing
print
the
display
here
name
tclcommands
much
more
omitted
of
course
there
s
much
more
we
could
do
here
sketching
the
tree
in
a
gui
might
be
a
natural
next
step
but
we
ll
leave
further
work
as
a
suggested
exercise
we
ll
also
extend
this
code
in
the
exercises
at
the
end
of
this
part
of
the
book
to
list
superclass
names
in
parentheses
at
the
start
of
instance
and
class
displays
the
main
point
here
is
that
oop
is
all
about
code
reuse
and
mix
in
classes
are
a
powerful
example
like
almost
everything
else
in
programming
multiple
inheritance
can
be
a
useful
device
when
applied
well
in
practice
though
it
is
an
advanced
feature
and
can
become
complicated
if
used
carelessly
or
excessively
we
ll
revisit
this
topic
as
a
gotcha
at
the
end
of
the
next
chapter
in
that
chapter
we
ll
also
meet
the
new
style
class
model
which
modifies
the
search
order
for
one
special
multiple
inheritance
case
supporting
slots
because
they
scan
instance
dictionaries
the
listinstance
and
listtree
classes
presented
here
don
t
directly
support
attributes
stored
in
slots
a
newer
and
relatively
rarely
used
option
we
ll
meet
in
the
next
chapter
where
instance
attributes
are
declared
in
a
slots
class
attribute
for
example
if
in
textmixin
py
we
assign
slots
data
in
super
and
slots
data
in
sub
only
the
data
attribute
is
displayed
in
the
instance
by
these
two
lister
classes
listtree
also
displays
data
and
data
but
as
attributes
of
the
super
and
sub
class
objects
and
with
a
special
format
for
their
values
technically
they
are
class
level
descriptors
to
better
support
slot
attributes
in
these
classes
change
the
dict
scanning
loops
to
also
iterate
through
slots
lists
using
code
the
next
chapter
will
present
and
use
the
getattr
built
in
function
to
fetch
values
instead
of
dict
indexing
listtree
already
does
since
instances
inherit
only
the
lowest
class
s
slots
you
may
also
need
to
come
up
with
a
policy
when
slots
lists
appear
in
multiple
superclasses
listtree
already
displays
them
as
class
attributes
listinherited
is
immune
to
all
this
because
dir
results
combine
both
dict
names
and
all
classes
slots
names
alternatively
as
a
policy
we
could
simply
let
our
code
handle
slot
based
attributes
as
it
currently
does
rather
than
complicating
it
for
a
rare
advanced
feature
slots
and
normal
instance
attributes
are
different
kinds
of
names
we
ll
investigate
slots
further
in
the
next
chapter
i
omitted
addressing
them
in
these
examples
to
avoid
a
forward
dependency
not
counting
this
note
of
course
not
exactly
a
valid
design
goal
but
reasonable
for
a
book
multiple
inheritance
mix
in
classes
classes
are
objects
generic
object
factories
sometimes
class
based
designs
require
objects
to
be
created
in
response
to
conditions
that
can
t
be
predicted
when
a
program
is
written
the
factory
design
pattern
allows
such
a
deferred
approach
due
in
large
part
to
python
s
flexibility
factories
can
take
multiple
forms
some
of
which
don
t
seem
special
at
all
because
classes
are
objects
it
s
easy
to
pass
them
around
a
program
store
them
in
data
structures
and
so
on
you
can
also
pass
classes
to
functions
that
generate
arbitrary
kinds
of
objects
such
functions
are
sometimes
called
factories
in
oop
design
circles
factories
are
a
major
undertaking
in
a
strongly
typed
language
such
as
c
but
are
almost
trivial
to
implement
in
python
the
call
syntax
we
met
in
chapter
can
call
any
class
with
any
number
of
constructor
arguments
in
one
step
to
generate
any
sort
of
instance
def
factory
aclass
args
return
aclass
args
varargs
tuple
call
aclass
or
apply
in
only
class
spam
def
doit
self
message
print
message
class
person
def
init
self
name
job
self
name
name
self
job
job
object
factory
spam
object
factory
person
guido
guru
make
a
spam
object
make
a
person
object
in
this
code
we
define
an
object
generator
function
called
factory
it
expects
to
be
passed
a
class
object
any
class
will
do
along
with
one
or
more
arguments
for
the
class
s
constructor
the
function
uses
special
varargs
call
syntax
to
call
the
function
and
return
an
instance
the
rest
of
the
example
simply
defines
two
classes
and
generates
instances
of
both
by
passing
them
to
the
factory
function
and
that
s
the
only
factory
function
you
ll
ever
need
to
write
in
python
it
works
for
any
class
and
any
constructor
arguments
one
possible
improvement
worth
noting
is
that
to
support
keyword
arguments
in
constructor
calls
the
factory
can
collect
them
with
a
args
argument
and
pass
them
along
in
the
class
call
too
def
factory
aclass
args
kwargs
return
aclass
args
kwargs
kwargs
dict
call
aclass
actually
this
syntax
can
invoke
any
callable
object
including
functions
classes
and
methods
hence
the
factory
function
here
can
also
run
any
callable
object
not
just
a
class
despite
the
argument
name
also
as
we
learned
in
chapter
python
has
an
alternative
to
aclass
args
the
apply
aclass
args
built
in
call
which
has
been
removed
in
python
because
of
its
redundancy
and
limitations
chapter
designing
with
classes
by
now
you
should
know
that
everything
is
an
object
in
python
including
things
like
classes
which
are
just
compiler
input
in
languages
like
c
however
as
mentioned
at
the
start
of
this
part
of
the
book
only
objects
derived
from
classes
are
oop
objects
in
python
why
factories
so
what
good
is
the
factory
function
besides
providing
an
excuse
to
illustrate
class
objects
in
this
book
unfortunately
it
s
difficult
to
show
applications
of
this
design
pattern
without
listing
much
more
code
than
we
have
space
for
here
in
general
though
such
a
factory
might
allow
code
to
be
insulated
from
the
details
of
dynamically
configured
object
construction
for
instance
recall
the
processor
example
presented
in
the
abstract
in
chapter
and
then
again
as
a
composition
example
in
this
chapter
it
accepts
reader
and
writer
objects
for
processing
arbitrary
data
streams
the
original
version
of
this
example
manually
passed
in
instances
of
specialized
classes
like
filewriter
and
socketreader
to
customize
the
data
streams
being
processed
later
we
passed
in
hardcoded
file
stream
and
formatter
objects
in
a
more
dynamic
scenario
external
devices
such
as
configuration
files
or
guis
might
be
used
to
configure
the
streams
in
such
a
dynamic
world
we
might
not
be
able
to
hardcode
the
creation
of
stream
interface
objects
in
our
scripts
but
might
instead
create
them
at
runtime
according
to
the
contents
of
a
configuration
file
for
example
the
file
might
simply
give
the
string
name
of
a
stream
class
to
be
imported
from
a
module
plus
an
optional
constructor
call
argument
factory
style
functions
or
code
might
come
in
handy
here
because
they
would
allow
us
to
fetch
and
pass
in
classes
that
are
not
hardcoded
in
our
program
ahead
of
time
indeed
those
classes
might
not
even
have
existed
at
all
when
we
wrote
our
code
classname
parse
from
config
file
classarg
parse
from
config
file
import
streamtypes
aclass
getattr
streamtypes
classname
reader
factory
aclass
classarg
processor
reader
customizable
code
fetch
from
module
or
aclass
classarg
here
the
getattr
built
in
is
again
used
to
fetch
a
module
attribute
given
a
string
name
it
s
like
saying
obj
attr
but
attr
is
a
string
because
this
code
snippet
assumes
a
single
constructor
argument
it
doesn
t
strictly
need
factory
or
apply
we
could
make
an
instance
with
just
aclass
classarg
they
may
prove
more
useful
in
the
presence
of
unknown
argument
lists
however
and
the
general
factory
coding
pattern
can
improve
the
code
s
flexibility
classes
are
objects
generic
object
factories
other
design
related
topics
in
this
chapter
we
ve
seen
inheritance
composition
delegation
multiple
inheritance
bound
methods
and
factories
all
common
patterns
used
to
combine
classes
in
python
programs
we
ve
really
only
scratched
the
surface
here
in
the
design
patterns
domain
though
elsewhere
in
this
book
you
ll
find
coverage
of
other
design
related
topics
such
as
abstract
superclasses
chapter
decorators
chapters
and
type
subclasses
chapter
static
and
class
methods
chapter
managed
attributes
chapter
metaclasses
chapters
and
for
more
details
on
design
patterns
though
we
ll
delegate
to
other
resources
on
oop
at
large
although
patterns
are
important
in
oop
work
and
are
often
more
natural
in
python
than
other
languages
they
are
not
specific
to
python
itself
chapter
summary
in
this
chapter
we
sampled
common
ways
to
use
and
combine
classes
to
optimize
their
reusability
and
factoring
benefits
what
are
usually
considered
design
issues
that
are
often
independent
of
any
particular
programming
language
though
python
can
make
them
easier
to
implement
we
studied
delegation
wrapping
objects
in
proxy
classes
composition
controlling
embedded
objects
and
inheritance
acquiring
behavior
from
other
classes
as
well
as
some
more
esoteric
concepts
such
as
pseudoprivate
attributes
multiple
inheritance
bound
methods
and
factories
the
next
chapter
ends
our
look
at
classes
and
oop
by
surveying
more
advanced
classrelated
topics
some
of
its
material
may
be
of
more
interest
to
tool
writers
than
application
programmers
but
it
still
merits
a
review
by
most
people
who
will
do
oop
in
python
first
though
another
quick
chapter
quiz
test
your
knowledge
quiz
what
is
multiple
inheritance
what
is
delegation
what
is
composition
chapter
designing
with
classes
what
are
bound
methods
what
are
pseudoprivate
attributes
used
for
test
your
knowledge
answers
multiple
inheritance
occurs
when
a
class
inherits
from
more
than
one
superclass
it
s
useful
for
mixing
together
multiple
packages
of
class
based
code
the
left
toright
order
in
class
statement
headers
determines
the
order
of
attribute
searches
delegation
involves
wrapping
an
object
in
a
proxy
class
which
adds
extra
behavior
and
passes
other
operations
to
the
wrapped
object
the
proxy
retains
the
interface
of
the
wrapped
object
composition
is
a
technique
whereby
a
controller
class
embeds
and
directs
a
number
of
objects
and
provides
an
interface
all
its
own
it
s
a
way
to
build
up
larger
structures
with
classes
bound
methods
combine
an
instance
and
a
method
function
you
can
call
them
without
passing
in
an
instance
object
explicitly
because
the
original
instance
is
still
available
pseudoprivate
attributes
whose
names
begin
with
two
leading
underscores
x
are
used
to
localize
names
to
the
enclosing
class
this
includes
both
class
attributes
like
methods
defined
inside
the
class
and
self
instance
attributes
assigned
inside
the
class
such
names
are
expanded
to
include
the
class
name
which
makes
them
unique
test
your
knowledge
answers
chapter
advanced
class
topics
this
chapter
concludes
our
look
at
oop
in
python
by
presenting
a
few
more
advanced
class
related
topics
we
will
survey
subclassing
built
in
types
new
style
class
changes
and
extensions
static
and
class
methods
function
decorators
and
more
as
we
ve
seen
python
s
oop
model
is
at
its
core
very
simple
and
some
of
the
topics
presented
in
this
chapter
are
so
advanced
and
optional
that
you
may
not
encounter
them
very
often
in
your
python
applications
programming
career
in
the
interest
of
completeness
though
we
ll
round
out
our
discussion
of
classes
with
a
brief
look
at
these
advanced
tools
for
oop
work
as
usual
because
this
is
the
last
chapter
in
this
part
of
the
book
it
ends
with
a
section
on
class
related
gotchas
and
the
set
of
lab
exercises
for
this
part
i
encourage
you
to
work
through
the
exercises
to
help
cement
the
ideas
we
ve
studied
here
i
also
suggest
working
on
or
studying
larger
oop
python
projects
as
a
supplement
to
this
book
as
with
much
in
computing
the
benefits
of
oop
tend
to
become
more
apparent
with
practice
content
note
this
chapter
collects
advanced
class
topics
but
some
are
even
too
advanced
for
this
chapter
to
cover
well
topics
such
as
properties
descriptors
decorators
and
metaclasses
are
only
briefly
mentioned
here
and
are
covered
more
fully
in
the
final
part
of
this
book
be
sure
to
look
ahead
for
more
complete
examples
and
extended
coverage
of
some
of
the
subjects
that
fall
into
this
chapter
s
category
extending
built
in
types
besides
implementing
new
kinds
of
objects
classes
are
sometimes
used
to
extend
the
functionality
of
python
s
built
in
types
to
support
more
exotic
data
structures
for
instance
to
add
queue
insert
and
delete
methods
to
lists
you
can
code
classes
that
wrap
embed
a
list
object
and
export
insert
and
delete
methods
that
process
the
list
specially
like
the
delegation
technique
we
studied
in
chapter
as
of
python
you
can
also
use
inheritance
to
specialize
built
in
types
the
next
two
sections
show
both
techniques
in
action
extending
types
by
embedding
remember
those
set
functions
we
wrote
in
chapters
and
here
s
what
they
look
like
brought
back
to
life
as
a
python
class
the
following
example
the
file
setwrapper
py
implements
a
new
set
object
type
by
moving
some
of
the
set
functions
to
methods
and
adding
some
basic
operator
overloading
for
the
most
part
this
class
just
wraps
a
python
list
with
extra
set
operations
but
because
it
s
a
class
it
also
supports
multiple
instances
and
customization
by
inheritance
in
subclasses
unlike
our
earlier
functions
using
classes
here
allows
us
to
make
multiple
self
contained
set
objects
with
preset
data
and
behavior
rather
than
passing
lists
into
functions
manually
class
set
def
init
self
value
self
data
self
concat
value
constructor
manages
a
list
def
intersect
self
other
res
for
x
in
self
data
if
x
in
other
res
append
x
return
set
res
other
is
any
sequence
self
is
the
subject
def
union
self
other
res
self
data
for
x
in
other
if
not
x
in
res
res
append
x
return
set
res
other
is
any
sequence
copy
of
my
list
add
items
in
other
def
concat
self
value
for
x
in
value
if
not
x
in
self
data
self
data
append
x
value
list
set
removes
duplicates
def
def
def
def
def
len
self
data
self
data
key
self
intersect
other
self
union
other
set
repr
self
data
len
self
getitem
self
key
and
self
other
or
self
other
repr
self
pick
common
items
return
a
new
set
return
return
return
return
return
len
self
self
i
self
other
self
other
print
to
use
this
class
we
make
instances
call
methods
and
run
defined
operators
as
usual
x
set
print
x
union
set
print
x
set
chapter
advanced
class
topics
prints
set
prints
set
overloading
operations
such
as
indexing
enables
instances
of
our
set
class
to
masquerade
as
real
lists
because
you
will
interact
with
and
extend
this
class
in
an
exercise
at
the
end
of
this
chapter
i
won
t
say
much
more
about
this
code
until
appendix
b
extending
types
by
subclassing
beginning
with
python
all
the
built
in
types
in
the
language
can
now
be
subclassed
directly
type
conversion
functions
such
as
list
str
dict
and
tuple
have
become
built
in
type
names
although
transparent
to
your
script
a
type
conversion
call
e
g
list
spam
is
now
really
an
invocation
of
a
type
s
object
constructor
this
change
allows
you
to
customize
or
extend
the
behavior
of
built
in
types
with
userdefined
class
statements
simply
subclass
the
new
type
names
to
customize
them
instances
of
your
type
subclasses
can
be
used
anywhere
that
the
original
built
in
type
can
appear
for
example
suppose
you
have
trouble
getting
used
to
the
fact
that
python
list
offsets
begin
at
instead
of
not
to
worry
you
can
always
code
your
own
subclass
that
customizes
this
core
behavior
of
lists
the
file
typesubclass
py
shows
how
subclass
built
in
list
type
class
map
n
to
n
call
back
to
built
in
version
class
mylist
list
def
getitem
self
offset
print
indexing
s
at
s
self
offset
return
list
getitem
self
offset
if
name
main
print
list
abc
x
mylist
abc
print
x
init
inherited
from
list
repr
inherited
from
list
print
x
print
x
mylist
getitem
customizes
list
superclass
method
x
append
spam
print
x
x
reverse
print
x
attributes
from
list
superclass
in
this
file
the
mylist
subclass
extends
the
built
in
list
s
getitem
indexing
method
only
to
map
indexes
to
n
back
to
the
required
to
n
all
it
really
does
is
decrement
the
submitted
index
and
call
back
to
the
superclass
s
version
of
indexing
but
it
s
enough
to
do
the
trick
python
typesubclass
py
a
b
c
a
b
c
indexing
a
b
c
at
a
indexing
a
b
c
at
c
a
b
c
spam
spam
c
b
a
extending
built
in
types
this
output
also
includes
tracing
text
the
class
prints
on
indexing
of
course
whether
changing
indexing
this
way
is
a
good
idea
in
general
is
another
issue
users
of
your
mylist
class
may
very
well
be
confused
by
such
a
core
departure
from
python
sequence
behavior
the
ability
to
customize
built
in
types
this
way
can
be
a
powerful
asset
though
for
instance
this
coding
pattern
gives
rise
to
an
alternative
way
to
code
a
set
as
a
subclass
of
the
built
in
list
type
rather
than
a
standalone
class
that
manages
an
embedded
list
object
as
shown
earlier
in
this
section
as
we
learned
in
chapter
python
today
comes
with
a
powerful
built
in
set
object
along
with
literal
and
comprehension
syntax
for
making
new
sets
coding
one
yourself
though
is
still
a
great
way
to
learn
about
type
subclassing
in
general
the
following
class
coded
in
the
file
setsubclass
py
customizes
lists
to
add
just
methods
and
operators
related
to
set
processing
because
all
other
behavior
is
inherited
from
the
built
in
list
superclass
this
makes
for
a
shorter
and
simpler
alternative
class
set
list
def
init
self
value
list
init
self
concat
value
constructor
customizes
list
copies
mutable
defaults
def
intersect
self
other
res
for
x
in
self
if
x
in
other
res
append
x
return
set
res
other
is
any
sequence
self
is
the
subject
def
union
self
other
res
set
self
res
concat
other
return
res
other
is
any
sequence
copy
me
and
my
list
def
concat
self
value
for
x
in
value
if
not
x
in
self
self
append
x
value
list
set
removes
duplicates
pick
common
items
return
a
new
set
def
and
self
other
return
self
intersect
other
def
or
self
other
return
self
union
other
def
repr
self
return
set
list
repr
self
if
name
main
x
set
y
set
print
x
y
len
x
print
x
intersect
y
y
union
x
print
x
y
x
y
x
reverse
print
x
chapter
advanced
class
topics
here
is
the
output
of
the
self
test
code
at
the
end
of
this
file
because
subclassing
core
types
is
an
advanced
feature
i
ll
omit
further
details
here
but
i
invite
you
to
trace
through
these
results
in
the
code
to
study
its
behavior
python
setsubclass
py
set
set
set
set
set
set
set
there
are
more
efficient
ways
to
implement
sets
with
dictionaries
in
python
which
replace
the
linear
scans
in
the
set
implementations
shown
here
with
dictionary
index
operations
hashing
and
so
run
much
quicker
for
more
details
see
programming
python
if
you
re
interested
in
sets
also
take
another
look
at
the
set
object
type
we
explored
in
chapter
this
type
provides
extensive
set
operations
as
built
in
tools
set
implementations
are
fun
to
experiment
with
but
they
are
no
longer
strictly
required
in
python
today
for
another
type
subclassing
example
see
the
implementation
of
the
bool
type
in
python
and
later
as
mentioned
earlier
in
the
book
bool
is
a
subclass
of
int
with
two
instances
true
and
false
that
behave
like
the
integers
and
but
inherit
custom
stringrepresentation
methods
that
display
their
names
the
new
style
class
model
in
release
python
introduced
a
new
flavor
of
classes
known
as
new
style
classes
classes
following
the
original
model
became
known
as
classic
classes
when
compared
to
the
new
kind
in
the
class
story
has
merged
but
it
remains
split
for
python
x
users
as
of
python
all
classes
are
automatically
what
we
used
to
call
new
style
whether
they
explicitly
inherit
from
object
or
not
all
classes
inherit
from
object
whether
implicitly
or
explicitly
and
all
objects
are
instances
of
object
in
python
and
earlier
classes
must
inherit
from
object
or
another
built
in
type
to
be
considered
new
style
and
obtain
all
new
style
features
because
all
classes
are
automatically
new
style
in
the
features
of
new
style
classes
are
simply
normal
class
features
i
ve
opted
to
keep
their
descriptions
in
this
section
separate
however
in
deference
to
users
of
python
x
code
classes
in
such
code
acquire
new
style
features
only
when
they
are
derived
from
object
in
other
words
when
python
users
see
descriptions
of
new
style
features
in
this
section
they
should
take
them
to
be
descriptions
of
existing
features
of
their
classes
for
readers
these
are
a
set
of
optional
extensions
in
python
and
earlier
the
only
syntactic
difference
for
new
style
classes
is
that
they
are
derived
from
either
a
built
in
type
such
as
list
or
a
special
built
in
class
known
the
new
style
class
model
as
object
the
built
in
name
object
is
provided
to
serve
as
a
superclass
for
new
style
classes
if
no
other
built
in
type
is
appropriate
to
use
class
newstyle
object
normal
code
any
class
derived
from
object
or
any
other
built
in
type
is
automatically
treated
as
a
new
style
class
as
long
as
a
built
in
type
is
somewhere
in
the
superclass
tree
the
new
class
is
treated
as
a
new
style
class
classes
not
derived
from
built
ins
such
as
object
are
considered
classic
new
style
classes
are
only
slightly
different
from
classic
classes
and
the
ways
in
which
they
differ
are
irrelevant
to
the
vast
majority
of
python
users
moreover
the
classic
class
model
still
available
in
works
exactly
as
it
has
for
almost
two
decades
in
fact
new
style
classes
are
almost
completely
backward
compatible
with
classic
classes
in
syntax
and
behavior
they
mostly
just
add
a
few
advanced
new
features
however
because
they
modify
a
handful
of
class
behaviors
they
had
to
be
introduced
as
a
distinct
tool
so
as
to
avoid
impacting
any
existing
code
that
depends
on
the
prior
behaviors
for
example
some
subtle
differences
such
as
diamond
pattern
inheritance
search
and
the
behavior
of
built
in
operations
with
managed
attribute
methods
such
as
getattr
can
cause
some
legacy
code
to
fail
if
left
unchanged
the
next
two
sections
provide
overviews
of
the
ways
the
new
style
classes
differ
and
the
new
tools
they
provide
again
because
all
classes
are
new
style
today
these
topics
represent
changes
to
python
x
readers
but
simply
additional
advanced
class
topics
to
python
readers
new
style
class
changes
new
style
classes
differ
from
classic
classes
in
a
number
of
ways
some
of
which
are
subtle
but
can
impact
existing
x
code
and
coding
styles
here
are
some
of
the
most
prominent
ways
they
differ
classes
and
types
merged
classes
are
now
types
and
types
are
now
classes
in
fact
the
two
are
essentially
synonyms
the
type
i
built
in
returns
the
class
an
instance
is
made
from
instead
of
a
generic
instance
type
and
is
normally
the
same
as
i
class
moreover
classes
are
instances
of
the
type
class
type
may
be
subclassed
to
customize
class
creation
and
all
classes
and
hence
types
inherit
from
object
inheritance
search
order
diamond
patterns
of
multiple
inheritance
have
a
slightly
different
search
order
roughly
they
are
searched
across
before
up
and
more
breadth
first
than
depthfirst
chapter
advanced
class
topics
attribute
fetch
for
built
ins
the
getattr
and
getattribute
methods
are
no
longer
run
for
attributes
implicitly
fetched
by
built
in
operations
this
means
that
they
are
not
called
for
x
operator
overloading
method
names
the
search
for
such
names
begins
at
classes
not
instances
new
advanced
tools
new
style
classes
have
a
set
of
new
class
tools
including
slots
properties
descriptors
and
the
getattribute
method
most
of
these
have
very
specific
toolbuilding
purposes
we
discussed
the
third
of
these
changes
briefly
in
a
sidebar
in
chapter
and
we
ll
revisit
it
in
depth
in
the
contexts
of
attribute
management
in
chapter
and
privacy
decorators
in
chapter
because
the
first
and
second
of
the
changes
just
listed
can
break
existing
x
code
though
let
s
explore
these
in
more
detail
before
moving
on
to
new
style
additions
type
model
changes
in
new
style
classes
the
distinction
between
type
and
class
has
vanished
entirely
classes
themselves
are
types
the
type
object
generates
classes
as
its
instances
and
classes
generate
instances
of
their
type
if
fact
there
is
no
real
difference
between
builtin
types
like
lists
and
strings
and
user
defined
types
coded
as
classes
this
is
why
we
can
subclass
built
in
types
as
shown
earlier
in
this
chapter
because
subclassing
a
built
in
type
such
as
list
qualifies
a
class
as
new
style
it
becomes
a
user
defined
type
besides
allowing
us
to
subclass
built
in
types
one
of
the
contexts
where
this
becomes
most
obvious
is
when
we
do
explicit
type
testing
with
python
s
classic
classes
the
type
of
a
class
instance
is
a
generic
instance
but
the
types
of
built
in
objects
are
more
specific
c
misc
c
python
python
class
c
pass
i
c
type
i
type
instance
i
class
class
main
c
at
x
a
classic
classes
in
instances
are
made
from
classes
type
c
but
classes
are
not
the
same
as
types
type
classobj
c
class
attributeerror
class
c
has
no
attribute
class
type
type
list
type
list
type
type
new
style
class
changes
list
class
type
type
but
with
new
style
classes
in
the
type
of
a
class
instance
is
the
class
it
s
created
from
since
classes
are
simply
user
defined
types
the
type
of
an
instance
is
its
class
and
the
type
of
a
user
defined
class
is
the
same
as
the
type
of
a
built
in
object
type
classes
have
a
class
attribute
now
too
because
they
are
instances
of
type
c
misc
c
python
python
class
c
object
pass
i
c
type
i
class
main
c
i
class
class
main
c
new
style
classes
in
type
of
instance
is
class
it
s
made
from
type
c
type
type
c
class
type
type
classes
are
user
defined
types
type
type
list
type
list
type
type
list
class
type
type
built
in
types
work
the
same
way
the
same
is
true
for
all
classes
in
python
since
all
classes
are
automatically
newstyle
even
if
they
have
no
explicit
superclasses
in
fact
the
distinction
between
builtin
types
and
user
defined
class
types
melts
away
altogether
in
c
misc
c
python
python
class
c
pass
i
c
type
i
class
main
c
i
class
class
main
c
all
classes
are
new
style
in
type
of
instance
is
class
it
s
made
from
type
c
class
type
c
class
class
type
class
is
a
type
and
type
is
a
class
type
class
list
type
list
class
type
list
class
class
type
classes
and
built
in
types
work
the
same
chapter
advanced
class
topics
as
you
can
see
in
classes
are
types
but
types
are
also
classes
technically
each
class
is
generated
by
a
metaclass
a
class
that
is
normally
either
type
itself
or
a
subclass
of
it
customized
to
augment
or
manage
generated
classes
besides
impacting
code
that
does
type
testing
this
turns
out
to
be
an
important
hook
for
tool
developers
we
ll
talk
more
about
metaclasses
later
in
this
chapter
and
again
in
more
detail
in
chapter
implications
for
type
testing
besides
providing
for
built
in
type
customization
and
metaclass
hooks
the
merging
of
classes
and
types
in
the
new
style
class
model
can
impact
code
that
does
type
testing
in
python
for
example
the
types
of
class
instances
compare
directly
and
meaningfully
and
in
the
same
way
as
built
in
type
objects
this
follows
from
the
fact
that
classes
are
now
types
and
an
instance
s
type
is
the
instance
s
class
c
misc
c
python
python
class
c
pass
class
d
pass
c
c
d
d
type
c
type
d
false
compares
the
instances
classes
type
c
type
d
class
main
c
class
main
d
c
class
d
class
class
main
c
class
main
d
c
c
c
c
type
c
type
c
true
with
classic
classes
in
and
earlier
though
comparing
instance
types
is
almost
useless
because
all
instances
have
the
same
instance
type
to
truly
compare
types
the
instance
class
attributes
must
be
compared
if
you
care
about
portability
this
works
in
too
but
it
s
not
required
there
c
misc
c
python
python
class
c
pass
class
d
pass
c
c
d
d
type
c
type
d
true
c
class
d
class
false
all
instances
are
same
type
must
compare
classes
explicitly
type
c
type
d
type
instance
type
instance
new
style
class
changes
c
class
d
class
class
main
c
at
x
a
class
main
d
at
x
d
and
as
you
should
expect
by
now
new
style
classes
in
work
the
same
as
all
classes
in
in
this
regard
comparing
instance
types
compares
the
instances
classes
automatically
c
misc
c
python
python
class
c
object
pass
class
d
object
pass
c
c
d
d
type
c
type
d
false
new
style
same
as
all
in
type
c
type
d
class
main
c
class
main
d
c
class
d
class
class
main
c
class
main
d
of
course
as
i
ve
pointed
out
numerous
times
in
this
book
type
checking
is
usually
the
wrong
thing
to
do
in
python
programs
we
code
to
object
interfaces
not
object
types
and
the
more
general
isinstance
built
in
is
more
likely
what
you
ll
want
to
use
in
the
rare
cases
where
instance
class
types
must
be
queried
however
knowledge
of
python
s
type
model
can
help
demystify
the
class
model
in
general
all
objects
derive
from
object
one
other
ramification
of
the
type
change
in
the
new
style
class
model
is
that
because
all
classes
derive
inherit
from
the
class
object
either
implicitly
or
explicitly
and
because
all
types
are
now
classes
every
object
derives
from
the
object
built
in
class
whether
directly
or
through
a
superclass
consider
the
following
interaction
in
python
code
an
explicit
object
superclass
in
to
make
this
work
equivalently
class
c
pass
x
c
type
x
class
main
c
type
c
class
type
type
is
now
class
instance
was
created
from
as
before
the
type
of
a
class
instance
is
the
class
it
was
made
from
and
the
type
of
a
class
is
the
type
class
because
classes
and
types
have
merged
it
is
also
true
though
that
the
instance
and
class
are
both
derived
from
the
built
in
object
class
since
this
is
an
implicit
or
explicit
superclass
of
every
class
chapter
advanced
class
topics
isinstance
x
object
true
isinstance
c
object
true
classes
always
inherit
from
object
the
same
holds
true
for
built
in
types
like
lists
and
strings
because
types
are
classes
in
the
new
style
model
built
in
types
are
now
classes
and
their
instances
derive
from
object
too
type
spam
class
str
type
str
class
type
isinstance
spam
object
true
isinstance
str
object
true
same
for
built
in
types
classes
in
fact
type
itself
derives
from
object
and
object
derives
from
type
even
though
the
two
are
different
objects
a
circular
relationship
that
caps
the
object
model
and
stems
from
the
fact
that
types
are
classes
that
generate
classes
type
type
class
type
type
object
class
type
all
classes
are
types
and
vice
versa
isinstance
type
object
true
isinstance
object
type
true
type
is
object
false
all
classes
derive
from
object
even
type
types
make
classes
and
type
is
a
class
in
practical
terms
this
model
makes
for
fewer
special
cases
than
the
prior
type
class
distinction
of
classic
classes
and
it
allows
us
to
write
code
that
assumes
and
uses
an
object
superclass
we
ll
see
examples
of
the
latter
later
in
the
book
for
now
let
s
move
on
to
explore
other
new
style
changes
diamond
inheritance
change
one
of
the
most
visible
changes
in
new
style
classes
is
their
slightly
different
inheritance
search
procedures
for
the
so
called
diamond
pattern
of
multiple
inheritance
trees
where
more
than
one
superclass
leads
to
the
same
higher
superclass
further
above
the
diamond
pattern
is
an
advanced
design
concept
is
coded
only
rarely
in
python
practice
and
has
not
been
discussed
in
this
book
so
we
won
t
dwell
on
this
topic
in
depth
in
short
though
with
classic
classes
the
inheritance
search
procedure
is
strictly
depth
first
and
then
left
to
right
python
climbs
all
the
way
to
the
top
hugging
the
left
side
of
the
tree
before
it
backs
up
and
begins
to
look
further
to
the
right
in
new
style
classes
the
search
is
more
breadth
first
in
such
cases
python
first
looks
in
any
superclasses
new
style
class
changes
to
the
right
of
the
first
one
searched
before
ascending
all
the
way
to
the
common
superclass
at
the
top
in
other
words
the
search
proceeds
across
by
levels
before
moving
up
the
search
algorithm
is
a
bit
more
complex
than
this
but
this
is
as
much
as
most
programmers
need
to
know
because
of
this
change
lower
superclasses
can
overload
attributes
of
higher
superclasses
regardless
of
the
sort
of
multiple
inheritance
trees
they
are
mixed
into
moreover
the
new
style
search
rule
avoids
visiting
the
same
superclass
more
than
once
when
it
is
accessible
from
multiple
subclasses
diamond
inheritance
example
to
illustrate
consider
this
simplistic
incarnation
of
the
diamond
multiple
inheritance
pattern
for
classic
classes
here
d
s
superclasses
b
and
c
both
lead
to
the
same
common
ancestor
a
class
a
attr
class
b
a
pass
classic
python
b
and
c
both
lead
to
a
class
c
a
attr
class
d
b
c
pass
x
d
x
attr
tries
a
before
c
searches
x
d
b
a
the
attribute
here
is
found
in
superclass
a
because
with
classic
classes
the
inheritance
search
climbs
as
high
as
it
can
before
backing
up
and
moving
right
python
will
search
d
b
a
and
then
c
but
will
stop
when
attr
is
found
in
a
above
b
however
with
new
style
classes
derived
from
a
built
in
like
object
and
all
classes
in
the
search
order
is
different
python
looks
in
c
to
the
right
of
b
before
a
above
b
that
is
it
searches
d
b
c
and
then
a
and
in
this
case
stops
in
c
class
a
object
attr
new
style
object
not
required
in
class
b
a
pass
class
c
a
attr
class
d
b
c
pass
tries
c
before
a
x
d
chapter
advanced
class
topics
x
attr
searches
x
d
b
c
this
change
in
the
inheritance
search
procedure
is
based
upon
the
assumption
that
if
you
mix
in
c
lower
in
the
tree
you
probably
intend
to
grab
its
attributes
in
preference
to
a
s
it
also
assumes
that
c
is
always
intended
to
override
a
s
attributes
in
all
contexts
which
is
probably
true
when
it
s
used
standalone
but
may
not
be
when
it
s
mixed
into
a
diamond
with
classic
classes
you
might
not
even
know
that
c
may
be
mixed
in
like
this
when
you
code
it
since
it
is
most
likely
that
the
programmer
meant
that
c
should
override
a
in
this
case
though
new
style
classes
visit
c
first
otherwise
c
could
be
essentially
pointless
in
a
diamond
context
it
could
not
customize
a
and
would
be
used
only
for
names
unique
to
c
explicit
conflict
resolution
of
course
the
problem
with
assumptions
is
that
they
assume
things
if
this
search
order
deviation
seems
too
subtle
to
remember
or
if
you
want
more
control
over
the
search
process
you
can
always
force
the
selection
of
an
attribute
from
anywhere
in
the
tree
by
assigning
or
otherwise
naming
the
one
you
want
at
the
place
where
the
classes
are
mixed
together
class
a
attr
classic
class
b
a
pass
class
c
a
attr
class
d
b
c
attr
c
attr
x
d
x
attr
choose
c
to
the
right
works
like
new
style
all
here
a
tree
of
classic
classes
is
emulating
the
search
order
of
new
style
classes
the
assignment
to
the
attribute
in
d
picks
the
version
in
c
thereby
subverting
the
normal
inheritance
search
path
d
attr
will
be
lowest
in
the
tree
new
style
classes
can
similarly
emulate
classic
classes
by
choosing
the
attribute
above
at
the
place
where
the
classes
are
mixed
together
class
a
object
attr
new
style
class
b
a
pass
class
c
a
new
style
class
changes
attr
class
d
b
c
attr
b
attr
x
d
x
attr
choose
a
attr
above
works
like
classic
default
if
you
are
willing
to
always
resolve
conflicts
like
this
you
can
largely
ignore
the
search
order
difference
and
not
rely
on
assumptions
about
what
you
meant
when
you
coded
your
classes
naturally
attributes
picked
this
way
can
also
be
method
functions
methods
are
normal
assignable
objects
class
a
def
meth
s
print
a
meth
class
c
a
def
meth
s
print
c
meth
class
b
a
pass
class
d
b
c
pass
x
d
x
meth
a
meth
use
default
search
order
will
vary
per
class
type
defaults
to
classic
order
in
class
d
b
c
meth
c
meth
x
d
x
meth
c
meth
pick
c
s
method
new
style
and
class
d
b
c
meth
b
meth
x
d
x
meth
a
meth
pick
b
s
method
classic
here
we
select
methods
by
explicitly
assigning
to
names
lower
in
the
tree
we
might
also
simply
call
the
desired
class
explicitly
in
practice
this
pattern
might
be
more
common
especially
for
things
like
constructors
class
d
b
c
def
meth
self
c
meth
self
redefine
lower
pick
c
s
method
by
calling
such
selections
by
assignment
or
call
at
mix
in
points
can
effectively
insulate
your
code
from
this
difference
in
class
flavors
explicitly
resolving
the
conflicts
this
way
ensures
that
your
code
won
t
vary
per
python
version
in
the
future
apart
from
perhaps
needing
to
derive
classes
from
object
or
a
built
in
type
for
the
new
style
tools
in
chapter
advanced
class
topics
even
without
the
classic
new
style
class
divergence
the
explicit
method
resolution
technique
shown
here
may
come
in
handy
in
multiple
inheritance
scenarios
in
general
for
instance
if
you
want
part
of
a
superclass
on
the
left
and
part
of
a
superclass
on
the
right
you
might
need
to
tell
python
which
same
named
attributes
to
choose
by
using
explicit
assignments
in
subclasses
we
ll
revisit
this
notion
in
a
gotcha
at
the
end
of
this
chapter
also
note
that
diamond
inheritance
patterns
might
be
more
problematic
in
some
cases
than
i
ve
implied
here
e
g
what
if
b
and
c
both
have
required
constructors
that
call
to
the
constructor
in
a
since
such
contexts
are
rare
in
real
world
python
we
ll
leave
this
topic
outside
this
book
s
scope
but
see
the
super
built
in
function
for
hints
besides
providing
generic
access
to
superclasses
in
single
inheritance
trees
super
supports
a
cooperative
mode
for
resolving
some
conflicts
in
multiple
inheritance
trees
scope
of
search
order
change
in
sum
by
default
the
diamond
pattern
is
searched
differently
for
classic
and
new
style
classes
and
this
is
a
nonbackward
compatible
change
keep
in
mind
though
that
this
change
primarily
affects
diamond
pattern
cases
of
multiple
inheritance
new
style
class
inheritance
works
unchanged
for
most
other
inheritance
tree
structures
further
it
s
not
impossible
that
this
entire
issue
may
be
of
more
theoretical
than
practical
importance
because
the
new
style
search
wasn
t
significant
enough
to
address
until
python
and
didn
t
become
standard
until
it
seems
unlikely
to
impact
much
python
code
having
said
that
i
should
also
note
that
even
though
you
might
not
code
diamond
patterns
in
classes
you
write
yourself
because
the
implied
object
superclass
is
above
every
class
in
every
case
of
multiple
inheritance
exhibits
the
diamond
pattern
today
that
is
in
new
style
classes
object
automatically
plays
the
role
that
the
class
a
does
in
the
example
we
just
considered
hence
the
new
style
search
rule
not
only
modifies
logical
semantics
but
also
optimizes
performance
by
avoiding
visiting
the
same
class
more
than
once
just
as
important
the
implied
object
superclass
in
the
new
style
model
provides
default
methods
for
a
variety
of
built
in
operations
including
the
str
and
repr
display
format
methods
run
a
dir
object
to
see
which
methods
are
provided
without
the
new
style
search
order
in
multiple
inheritance
cases
the
defaults
in
object
would
always
override
redefinitions
in
user
coded
classes
unless
they
were
always
made
in
the
leftmost
superclass
in
other
words
the
new
style
class
model
itself
makes
using
the
new
style
search
order
more
critical
for
a
more
visual
example
of
the
implied
object
superclass
in
and
other
examples
of
diamond
patterns
created
by
it
see
the
listtree
class
s
output
in
the
lister
py
example
in
the
preceding
chapter
as
well
as
the
classtree
py
tree
walker
example
in
chapter
new
style
class
changes
new
style
class
extensions
beyond
the
changes
described
in
the
prior
section
which
frankly
may
be
too
academic
and
obscure
to
matter
to
many
readers
of
this
book
new
style
classes
provide
a
handful
of
more
advanced
class
tools
that
have
more
direct
and
practical
application
the
following
sections
provide
an
overview
of
each
of
these
additional
features
available
for
new
style
class
in
python
and
all
classes
in
python
instance
slots
by
assigning
a
sequence
of
string
attribute
names
to
a
special
slots
class
attribute
it
is
possible
for
a
new
style
class
to
both
limit
the
set
of
legal
attributes
that
instances
of
the
class
will
have
and
optimize
memory
and
speed
performance
this
special
attribute
is
typically
set
by
assigning
a
sequence
of
string
names
to
the
variable
slots
at
the
top
level
of
a
class
statement
only
those
names
in
the
slots
list
can
be
assigned
as
instance
attributes
however
like
all
names
in
python
instance
attribute
names
must
still
be
assigned
before
they
can
be
referenced
even
if
they
re
listed
in
slots
for
example
class
limiter
object
slots
age
name
job
x
limiter
x
age
attributeerror
age
must
assign
before
use
x
age
x
age
x
ape
illegal
not
in
slots
attributeerror
limiter
object
has
no
attribute
ape
slots
are
something
of
a
break
with
python
s
dynamic
nature
which
dictates
that
any
name
may
be
created
by
assignment
however
this
feature
is
envisioned
as
both
a
way
to
catch
typo
errors
like
this
assignments
to
illegal
attribute
names
not
in
slots
are
detected
as
well
as
an
optimization
mechanism
allocating
a
namespace
dictionary
for
every
instance
object
can
become
expensive
in
terms
of
memory
if
many
instances
are
created
and
only
a
few
attributes
are
required
to
save
space
and
speed
execution
to
a
degree
that
can
vary
per
program
instead
of
allocating
a
dictionary
for
each
instance
slot
attributes
are
stored
sequentially
for
quicker
lookup
slots
and
generic
code
in
fact
some
instances
with
slots
may
not
have
a
dict
attribute
dictionary
at
all
which
can
make
some
metaprograms
more
complex
including
some
coded
in
this
book
tools
that
generically
list
attributes
or
access
attributes
by
string
name
for
example
must
be
careful
to
use
more
storage
neutral
tools
than
dict
such
as
the
chapter
advanced
class
topics
getattr
setattr
and
dir
built
in
functions
which
apply
to
attributes
based
on
either
dict
or
slots
storage
in
some
cases
both
attribute
sources
may
need
to
be
queried
for
completeness
for
example
when
slots
are
used
instances
do
not
normally
have
an
attribute
dictionary
python
uses
the
class
descriptors
feature
covered
in
chapter
to
allocate
space
for
slot
attributes
in
the
instance
instead
only
names
in
the
slots
list
can
be
assigned
to
instances
but
slot
based
attributes
can
still
be
fetched
and
set
by
name
using
generic
tools
in
python
and
in
for
classes
derived
from
object
class
c
slots
a
b
slots
means
no
dict
by
default
x
c
x
a
x
a
x
dict
attributeerror
c
object
has
no
attribute
dict
getattr
x
a
setattr
x
b
but
getattr
and
setattr
still
work
x
b
a
in
dir
x
and
dir
finds
slot
attributes
too
true
b
in
dir
x
true
without
an
attribute
namespaces
dictionary
it
s
not
possible
to
assign
new
names
to
instances
that
are
not
names
in
the
slots
list
class
d
slots
a
b
def
init
self
self
d
cannot
add
new
names
if
no
dict
x
d
attributeerror
d
object
has
no
attribute
d
however
extra
attributes
can
still
be
accommodated
by
including
dict
in
slots
in
order
to
allow
for
an
attribute
namespace
dictionary
in
this
case
both
storage
mechanisms
are
used
but
generic
tools
such
as
getattr
allow
us
to
treat
them
as
a
single
set
of
attributes
class
d
slots
a
b
dict
list
dict
to
include
one
too
c
class
attrs
work
normally
def
init
self
self
d
d
put
in
dict
a
in
slots
x
d
x
d
x
dict
some
objects
have
both
dict
and
slots
d
getattr
can
fetch
either
type
of
attr
new
style
class
extensions
x
slots
a
b
dict
x
c
x
a
all
instance
attrs
undefined
until
assigned
attributeerror
a
x
a
getattr
x
a
getattr
x
c
getattr
x
d
code
that
wishes
to
list
all
instance
attributes
generically
though
may
still
need
to
allow
for
both
storage
forms
since
dir
also
returns
inherited
attributes
this
relies
on
dictionary
iterators
to
collect
keys
for
attr
in
list
x
dict
x
slots
print
attr
getattr
x
attr
d
a
b
dict
d
since
either
can
be
omitted
this
is
more
correctly
coded
as
follows
getattr
allows
for
defaults
for
attr
in
list
getattr
x
dict
getattr
x
slots
print
attr
getattr
x
attr
d
a
b
dict
d
multiple
slot
lists
in
superclasses
note
however
that
this
code
addresses
only
slot
names
in
the
lowest
slots
attribute
inherited
by
an
instance
if
multiple
classes
in
a
class
tree
have
their
own
slots
attributes
generic
programs
must
develop
other
policies
for
listing
attributes
e
g
classifying
slot
names
as
attributes
of
classes
not
instances
slot
declarations
can
appear
in
multiple
classes
in
a
class
tree
but
they
are
subject
to
a
number
of
constraints
that
are
somewhat
difficult
to
rationalize
unless
you
understand
the
implementation
of
slots
as
class
level
descriptors
a
tool
we
ll
study
in
detail
in
the
last
part
of
this
book
if
a
subclass
inherits
from
a
superclass
without
a
slots
the
dict
attribute
of
the
superclass
will
always
be
accessible
making
a
slots
in
the
subclass
meaningless
if
a
class
defines
the
same
slot
name
as
a
superclass
the
version
of
the
name
defined
by
the
superclass
slot
will
be
accessible
only
by
fetching
its
descriptor
directly
from
the
superclass
chapter
advanced
class
topics
because
the
meaning
of
a
slots
declaration
is
limited
to
the
class
in
which
it
appears
subclasses
will
have
a
dict
unless
they
also
define
a
slots
in
terms
of
listing
instance
attributes
generically
slots
in
multiple
classes
might
require
manual
class
tree
climbs
dir
usage
or
a
policy
that
treats
slot
names
as
a
different
category
of
names
altogether
class
e
slots
c
d
superclass
has
slots
class
d
e
slots
a
dict
so
does
its
subclass
x
d
x
a
x
b
x
c
x
a
x
c
e
slots
c
d
d
slots
a
dict
x
slots
a
dict
x
dict
b
the
instance
is
the
union
but
slots
are
not
concatenated
instance
inherits
lowest
slots
and
has
its
own
an
attr
dict
for
attr
in
list
getattr
x
dict
getattr
x
slots
print
attr
getattr
x
attr
b
superclass
slots
missed
a
dict
b
dir
x
dir
includes
all
slot
names
many
names
omitted
a
b
c
d
when
such
generality
is
possible
slots
are
probably
best
treated
as
class
attributes
rather
than
trying
to
mold
them
to
appear
the
same
as
normal
instance
attributes
for
more
on
slots
in
general
see
the
python
standard
manual
set
also
watch
for
an
example
that
allows
for
attributes
based
on
both
slots
and
dict
storage
in
the
private
decorator
discussion
of
chapter
for
a
prime
example
of
why
generic
programs
may
need
to
care
about
slots
see
the
lister
py
display
mix
in
classes
example
in
the
multiple
inheritance
section
of
the
prior
chapter
a
note
there
describes
the
example
s
slot
concerns
in
such
a
tool
that
attempts
to
list
attributes
generically
slot
usage
requires
either
extra
code
or
the
implementation
of
policies
regarding
the
handling
of
slot
based
attributes
in
general
new
style
class
extensions
class
properties
a
mechanism
known
as
properties
provides
another
way
for
new
style
classes
to
define
automatically
called
methods
for
access
or
assignment
to
instance
attributes
at
least
for
specific
attributes
this
feature
is
an
alternative
to
many
current
uses
of
the
getattr
and
setattr
overloading
methods
we
studied
in
chapter
properties
have
a
similar
effect
to
these
two
methods
but
they
incur
an
extra
method
call
for
any
accesses
to
names
that
require
dynamic
computation
properties
and
slots
are
based
on
a
new
notion
of
attribute
descriptors
which
is
too
advanced
for
us
to
cover
here
in
short
a
property
is
a
type
of
object
assigned
to
a
class
attribute
name
a
property
is
generated
by
calling
the
property
built
in
with
three
methods
handlers
for
get
set
and
delete
operations
as
well
as
a
docstring
if
any
argument
is
passed
as
none
or
omitted
that
operation
is
not
supported
properties
are
typically
assigned
at
the
top
level
of
a
class
statement
e
g
name
property
when
thus
assigned
accesses
to
the
class
attribute
itself
e
g
obj
name
are
automatically
routed
to
one
of
the
accessor
methods
passed
into
the
property
for
example
the
getattr
method
allows
classes
to
intercept
undefined
attribute
references
class
classic
def
getattr
self
name
if
name
age
return
else
raise
attributeerror
x
classic
x
age
x
name
attributeerror
runs
getattr
runs
getattr
here
is
the
same
example
coded
with
properties
instead
note
that
properties
are
available
for
all
classes
but
require
the
new
style
object
derivation
in
to
work
properly
for
intercepting
attribute
assignments
class
newprops
object
def
getage
self
return
age
property
getage
none
none
none
get
set
del
docs
x
newprops
x
age
runs
getage
x
name
normal
fetch
attributeerror
newprops
instance
has
no
attribute
name
chapter
advanced
class
topics
for
some
coding
tasks
properties
can
be
less
complex
and
quicker
to
run
than
the
traditional
techniques
for
example
when
we
add
attribute
assignment
support
properties
become
more
attractive
there
s
less
code
to
type
and
no
extra
method
calls
are
incurred
for
assignments
to
attributes
we
don
t
wish
to
compute
dynamically
class
newprops
object
def
getage
self
return
def
setage
self
value
print
set
age
value
self
age
value
age
property
getage
setage
none
none
x
newprops
x
age
runs
getage
x
age
runs
setage
set
age
x
age
normal
fetch
no
getage
call
x
job
trainer
normal
assign
no
setage
call
x
job
normal
fetch
no
getage
call
trainer
the
equivalent
classic
class
incurs
extra
method
calls
for
assignments
to
attributes
not
being
managed
and
needs
to
route
attribute
assignments
through
the
attribute
dictionary
or
for
new
style
classes
to
the
object
superclass
s
setattr
to
avoid
loops
class
classic
def
getattr
self
name
if
name
age
return
else
raise
attributeerror
def
setattr
self
name
value
print
set
name
value
if
name
age
self
dict
age
value
else
self
dict
name
value
x
classic
x
age
x
age
set
age
x
age
x
job
trainer
x
job
on
undefined
reference
on
all
assignments
runs
getattr
runs
setattr
defined
no
getattr
call
runs
setattr
again
defined
no
getattr
call
new
style
class
extensions
properties
seem
like
a
win
for
this
simple
example
however
some
applications
of
getattr
and
setattr
may
still
require
more
dynamic
or
generic
interfaces
than
properties
directly
provide
for
example
in
many
cases
the
set
of
attributes
to
be
supported
cannot
be
determined
when
the
class
is
coded
and
may
not
even
exist
in
any
tangible
form
e
g
when
delegating
arbitrary
method
references
to
a
wrapped
embedded
object
generically
in
such
cases
a
generic
getattr
or
a
setattr
attribute
handler
with
a
passed
in
attribute
name
may
be
preferable
because
such
generic
handlers
can
also
handle
simpler
cases
properties
are
often
an
optional
extension
for
more
details
on
both
options
stay
tuned
for
chapter
in
the
final
part
of
this
book
as
we
ll
see
there
it
s
also
possible
to
code
properties
using
function
decorator
syntax
a
topic
introduced
later
in
this
chapter
getattribute
and
descriptors
the
getattribute
method
available
for
new
style
classes
only
allows
a
class
to
intercept
all
attribute
references
not
just
undefined
references
like
getattr
it
is
also
somewhat
trickier
to
use
than
getattr
it
is
prone
to
loops
much
like
setattr
but
in
different
ways
in
addition
to
properties
and
operator
overloading
methods
python
supports
the
notion
of
attribute
descriptors
classes
with
get
and
set
methods
assigned
to
class
attributes
and
inherited
by
instances
that
intercept
read
and
write
accesses
to
specific
attributes
descriptors
are
in
a
sense
a
more
general
form
of
properties
in
fact
properties
are
a
simplified
way
to
define
a
specific
type
of
descriptor
one
that
runs
functions
on
access
descriptors
are
also
used
to
implement
the
slots
feature
we
met
earlier
because
properties
getattribute
and
descriptors
are
somewhat
advanced
topics
we
ll
defer
the
rest
of
their
coverage
as
well
as
more
on
properties
to
chapter
in
the
final
part
of
this
book
metaclasses
most
of
the
changes
and
feature
additions
of
new
style
classes
integrate
with
the
notion
of
subclassable
types
mentioned
earlier
in
this
chapter
because
subclassable
types
and
new
style
classes
were
introduced
in
conjunction
with
a
merging
of
the
type
class
dichotomy
in
python
and
beyond
as
we
ve
seen
in
this
merging
is
complete
classes
are
now
types
and
types
are
classes
along
with
these
changes
python
also
grew
a
more
coherent
protocol
for
coding
metaclasses
which
are
classes
that
subclass
the
type
object
and
intercept
class
creation
calls
as
such
they
provide
a
well
defined
hook
for
management
and
augmentation
of
class
objects
they
are
also
an
advanced
topic
that
is
optional
for
most
python
programmers
so
we
ll
postpone
further
details
here
we
ll
meet
metaclasses
briefly
later
chapter
advanced
class
topics
in
this
chapter
in
conjunction
with
class
decorators
and
we
ll
explore
them
in
full
detail
in
chapter
in
the
final
part
of
this
book
static
and
class
methods
as
of
python
it
is
possible
to
define
two
kinds
of
methods
within
a
class
that
can
be
called
without
an
instance
static
methods
work
roughly
like
simple
instance
less
functions
inside
a
class
and
class
methods
are
passed
a
class
instead
of
an
instance
although
this
feature
was
added
in
conjunction
with
the
new
style
classes
discussed
in
the
prior
sections
static
and
class
methods
work
for
classic
classes
too
to
enable
these
method
modes
special
built
in
functions
called
staticmethod
and
classmethod
must
be
called
within
the
class
or
invoked
with
the
decoration
syntax
we
ll
meet
later
in
this
chapter
in
python
instance
less
methods
called
only
through
a
class
name
do
not
require
a
staticmethod
declaration
but
such
methods
called
through
instances
do
why
the
special
methods
as
we
ve
learned
a
class
method
is
normally
passed
an
instance
object
in
its
first
argument
to
serve
as
the
implied
subject
of
the
method
call
today
though
there
are
two
ways
to
modify
this
model
before
i
explain
what
they
are
i
should
explain
why
this
might
matter
to
you
sometimes
programs
need
to
process
data
associated
with
classes
instead
of
instances
consider
keeping
track
of
the
number
of
instances
created
from
a
class
or
maintaining
a
list
of
all
of
a
class
s
instances
that
are
currently
in
memory
this
type
of
information
and
its
processing
are
associated
with
the
class
rather
than
its
instances
that
is
the
information
is
usually
stored
on
the
class
itself
and
processed
in
the
absence
of
any
instance
for
such
tasks
simple
functions
coded
outside
a
class
can
often
suffice
because
they
can
access
class
attributes
through
the
class
name
they
have
access
to
class
data
and
never
require
access
to
an
instance
however
to
better
associate
such
code
with
a
class
and
to
allow
such
processing
to
be
customized
with
inheritance
as
usual
it
would
be
better
to
code
these
types
of
functions
inside
the
class
itself
to
make
this
work
we
need
methods
in
a
class
that
are
not
passed
and
do
not
expect
a
self
instance
argument
python
supports
such
goals
with
the
notion
of
static
methods
simple
functions
with
no
self
argument
that
are
nested
in
a
class
and
are
designed
to
work
on
class
attributes
instead
of
instance
attributes
static
methods
never
receive
an
automatic
self
argument
whether
called
through
a
class
or
an
instance
they
usually
keep
track
of
information
that
spans
all
instances
rather
than
providing
behavior
for
instances
static
and
class
methods
although
less
commonly
used
python
also
supports
the
notion
of
class
methods
methods
of
a
class
that
are
passed
a
class
object
in
their
first
argument
instead
of
an
instance
regardless
of
whether
they
are
called
through
an
instance
or
a
class
such
methods
can
access
class
data
through
their
self
class
argument
even
if
called
through
an
instance
normal
methods
now
known
in
formal
circles
as
instance
methods
still
receive
a
subject
instance
when
called
static
and
class
methods
do
not
static
methods
in
and
the
concept
of
static
methods
is
the
same
in
both
python
and
but
its
implementation
requirements
have
evolved
somewhat
in
python
since
this
book
covers
both
versions
i
need
to
explain
the
differences
in
the
two
underlying
models
before
we
get
to
the
code
really
we
already
began
this
story
in
the
preceding
chapter
when
we
explored
the
notion
of
unbound
methods
recall
that
both
python
and
always
pass
an
instance
to
a
method
that
is
called
through
an
instance
however
python
treats
methods
fetched
directly
from
a
class
differently
than
in
python
fetching
a
method
from
a
class
produces
an
unbound
method
which
cannot
be
called
without
manually
passing
an
instance
in
python
fetching
a
method
from
a
class
produces
a
simple
function
which
can
be
called
normally
with
no
instance
present
in
other
words
python
class
methods
always
require
an
instance
to
be
passed
in
whether
they
are
called
through
an
instance
or
a
class
by
contrast
in
python
we
are
required
to
pass
an
instance
to
a
method
only
if
the
method
expects
one
methods
without
a
self
instance
argument
can
be
called
through
the
class
without
passing
an
instance
that
is
allows
simple
functions
in
a
class
as
long
as
they
do
not
expect
and
are
not
passed
an
instance
argument
the
net
effect
is
that
in
python
we
must
always
declare
a
method
as
static
in
order
to
call
it
without
an
instance
whether
it
is
called
through
a
class
or
an
instance
in
python
we
need
not
declare
such
methods
as
static
if
they
will
be
called
through
a
class
only
but
we
must
do
so
in
order
to
call
them
through
an
instance
to
illustrate
suppose
we
want
to
use
class
attributes
to
count
how
many
instances
are
generated
from
a
class
the
following
file
spam
py
makes
a
first
attempt
its
class
has
a
counter
stored
as
a
class
attribute
a
constructor
that
bumps
up
the
counter
by
one
each
time
a
new
instance
is
created
and
a
method
that
displays
the
counter
s
value
remember
class
attributes
are
shared
by
all
instances
therefore
storing
the
counter
in
the
class
object
itself
ensures
that
it
effectively
spans
all
instances
class
spam
numinstances
def
init
self
spam
numinstances
spam
numinstances
chapter
advanced
class
topics
def
printnuminstances
print
number
of
instances
created
spam
numinstances
the
printnuminstances
method
is
designed
to
process
class
data
not
instance
data
it
s
about
all
the
instances
not
any
one
in
particular
because
of
that
we
want
to
be
able
to
call
it
without
having
to
pass
an
instance
indeed
we
don
t
want
to
make
an
instance
to
fetch
the
number
of
instances
because
this
would
change
the
number
of
instances
we
re
trying
to
fetch
in
other
words
we
want
a
self
less
static
method
whether
this
code
works
or
not
though
depends
on
which
python
you
use
and
which
way
you
call
the
method
through
the
class
or
through
an
instance
in
and
x
in
general
calls
to
a
self
less
method
function
through
both
the
class
and
instances
fail
i
ve
omitted
some
error
text
here
for
space
c
misc
c
python
python
from
spam
import
spam
a
spam
b
spam
c
spam
cannot
call
unbound
class
methods
in
methods
expect
a
self
object
by
default
spam
printnuminstances
typeerror
unbound
method
printnuminstances
must
be
called
with
spam
instance
as
first
argument
got
nothing
instead
a
printnuminstances
typeerror
printnuminstances
takes
no
arguments
given
the
problem
here
is
that
unbound
instance
methods
aren
t
exactly
the
same
as
simple
functions
in
even
though
there
are
no
arguments
in
the
def
header
the
method
still
expects
an
instance
to
be
passed
in
when
it
s
called
because
the
function
is
associated
with
a
class
in
python
and
later
x
releases
calls
to
self
less
methods
made
through
classes
work
but
calls
from
instances
fail
c
misc
c
python
python
from
spam
import
spam
a
spam
b
spam
c
spam
can
call
functions
in
class
in
calls
through
instances
still
pass
a
self
spam
printnuminstances
differs
in
number
of
instances
created
a
printnuminstances
typeerror
printnuminstances
takes
no
arguments
given
that
is
calls
to
instance
less
methods
like
printnuminstances
made
through
the
class
fail
in
python
but
work
in
python
on
the
other
hand
calls
made
through
an
instance
fail
in
both
pythons
because
an
instance
is
automatically
passed
to
a
method
that
does
not
have
an
argument
to
receive
it
spam
printnuminstances
instance
printnuminstances
fails
in
works
in
fails
in
both
and
if
you
re
able
to
use
and
stick
with
calling
self
less
methods
through
classes
only
you
already
have
a
static
method
feature
however
to
allow
self
less
methods
to
be
static
and
class
methods
called
through
classes
in
and
through
instances
in
both
and
you
need
to
either
adopt
other
designs
or
be
able
to
somehow
mark
such
methods
as
special
let
s
look
at
both
options
in
turn
static
method
alternatives
short
of
marking
a
self
less
method
as
special
there
are
a
few
different
coding
structures
that
can
be
tried
if
you
want
to
call
functions
that
access
class
members
without
an
instance
perhaps
the
simplest
idea
is
to
just
make
them
simple
functions
outside
the
class
not
class
methods
this
way
an
instance
isn
t
expected
in
the
call
for
example
the
following
mutation
of
spam
py
works
the
same
in
python
and
albeit
displaying
extra
parentheses
in
for
its
print
statement
def
printnuminstances
print
number
of
instances
created
spam
numinstances
class
spam
numinstances
def
init
self
spam
numinstances
spam
numinstances
import
spam
a
spam
spam
b
spam
spam
c
spam
spam
spam
printnuminstances
number
of
instances
created
spam
spam
numinstances
but
function
may
be
too
far
removed
and
cannot
be
changed
via
inheritance
because
the
class
name
is
accessible
to
the
simple
function
as
a
global
variable
this
works
fine
also
note
that
the
name
of
the
function
becomes
global
but
only
to
this
single
module
it
will
not
clash
with
names
in
other
files
of
the
program
prior
to
static
methods
in
python
this
structure
was
the
general
prescription
because
python
already
provides
modules
as
a
namespace
partitioning
tool
one
could
argue
that
there
s
not
typically
any
need
to
package
functions
in
classes
unless
they
implement
object
behavior
simple
functions
within
modules
like
the
one
here
do
much
of
what
instance
less
class
methods
could
and
are
already
associated
with
the
class
because
they
live
in
the
same
module
unfortunately
this
approach
is
still
less
than
ideal
for
one
thing
it
adds
to
this
file
s
scope
an
extra
name
that
is
used
only
for
processing
a
single
class
for
another
the
function
is
much
less
directly
associated
with
the
class
in
fact
its
definition
could
be
hundreds
of
lines
away
perhaps
worse
simple
functions
like
this
cannot
be
customized
by
inheritance
since
they
live
outside
a
class
s
namespace
subclasses
cannot
directly
replace
or
extend
such
a
function
by
redefining
it
chapter
advanced
class
topics
we
might
try
to
make
this
example
work
in
a
version
neutral
way
by
using
a
normal
method
and
always
calling
it
through
or
with
an
instance
as
usual
class
spam
numinstances
def
init
self
spam
numinstances
spam
numinstances
def
printnuminstances
self
print
number
of
instances
created
spam
numinstances
from
spam
import
spam
a
b
c
spam
spam
spam
a
printnuminstances
number
of
instances
created
spam
printnuminstances
a
number
of
instances
created
spam
printnuminstances
number
of
instances
created
but
fetching
counter
changes
counter
unfortunately
as
mentioned
earlier
such
an
approach
is
completely
unworkable
if
we
don
t
have
an
instance
available
and
making
an
instance
changes
the
class
data
as
illustrated
in
the
last
line
here
a
better
solution
would
be
to
somehow
mark
a
method
inside
a
class
as
never
requiring
an
instance
the
next
section
shows
how
using
static
and
class
methods
today
there
is
another
option
for
coding
simple
functions
associated
with
a
class
that
may
be
called
through
either
the
class
or
its
instances
as
of
python
we
can
code
classes
with
static
and
class
methods
neither
of
which
requires
an
instance
argument
to
be
passed
in
when
invoked
to
designate
such
methods
classes
call
the
built
in
functions
staticmethod
and
classmethod
as
hinted
in
the
earlier
discussion
of
new
style
classes
both
mark
a
function
object
as
special
i
e
as
requiring
no
instance
if
static
and
requiring
a
class
argument
if
a
class
method
for
example
class
methods
def
imeth
self
x
print
self
x
normal
instance
method
passed
a
self
def
smeth
x
print
x
static
no
instance
passed
def
cmeth
cls
x
print
cls
x
class
gets
class
not
instance
smeth
staticmethod
smeth
cmeth
classmethod
cmeth
make
smeth
a
static
method
make
cmeth
a
class
method
notice
how
the
last
two
assignments
in
this
code
simply
reassign
the
method
names
smeth
and
cmeth
attributes
are
created
and
changed
by
any
assignment
in
a
class
statement
so
these
final
assignments
simply
overwrite
the
assignments
made
earlier
by
the
defs
static
and
class
methods
technically
python
now
supports
three
kinds
of
class
related
methods
instance
static
and
class
moreover
python
extends
this
model
by
also
allowing
simple
functions
in
a
class
to
serve
the
role
of
static
methods
without
extra
protocol
when
called
through
a
class
instance
methods
are
the
normal
and
default
case
that
we
ve
seen
in
this
book
an
instance
method
must
always
be
called
with
an
instance
object
when
you
call
it
through
an
instance
python
passes
the
instance
to
the
first
leftmost
argument
automatically
when
you
call
it
through
a
class
you
must
pass
along
the
instance
manually
for
simplicity
i
ve
omitted
some
class
imports
in
interactive
sessions
like
this
one
obj
methods
make
an
instance
obj
imeth
main
methods
object
normal
method
call
through
instance
becomes
imeth
obj
methods
imeth
obj
main
methods
object
normal
method
call
through
class
instance
passed
explicitly
by
contrast
static
methods
are
called
without
an
instance
argument
unlike
simple
functions
outside
a
class
their
names
are
local
to
the
scopes
of
the
classes
in
which
they
are
defined
and
they
may
be
looked
up
by
inheritance
instance
less
functions
can
be
called
through
a
class
normally
in
python
but
never
by
default
in
using
the
staticmethod
built
in
allows
such
methods
to
also
be
called
through
an
instance
in
and
through
both
a
class
and
an
instance
in
python
the
first
of
these
works
in
without
staticmethod
but
the
second
does
not
methods
smeth
static
method
call
through
class
no
instance
passed
or
expected
obj
smeth
static
method
call
through
instance
instance
not
passed
class
methods
are
similar
but
python
automatically
passes
the
class
not
an
instance
in
to
a
class
method
s
first
leftmost
argument
whether
it
is
called
through
a
class
or
an
instance
methods
cmeth
class
main
methods
class
method
call
through
class
becomes
cmeth
methods
obj
cmeth
class
main
methods
class
method
call
through
instance
becomes
cmeth
methods
counting
instances
with
static
methods
now
given
these
built
ins
here
is
the
static
method
equivalent
of
this
section
s
instance
counting
example
it
marks
the
method
as
special
so
it
will
never
be
passed
an
instance
automatically
chapter
advanced
class
topics
class
spam
numinstances
use
static
method
for
class
data
def
init
self
spam
numinstances
def
printnuminstances
print
number
of
instances
spam
numinstances
printnuminstances
staticmethod
printnuminstances
using
the
static
method
built
in
our
code
now
allows
the
self
less
method
to
be
called
through
the
class
or
any
instance
of
it
in
both
python
and
a
spam
b
spam
c
spam
spam
printnuminstances
number
of
instances
a
printnuminstances
number
of
instances
call
as
simple
function
instance
argument
not
passed
compared
to
simply
moving
printnuminstances
outside
the
class
as
prescribed
earlier
this
version
requires
an
extra
staticmethod
call
however
it
localizes
the
function
name
in
the
class
scope
so
it
won
t
clash
with
other
names
in
the
module
moves
the
function
code
closer
to
where
it
is
used
inside
the
class
statement
and
allows
subclasses
to
customize
the
static
method
with
inheritance
a
more
convenient
approach
than
importing
functions
from
the
files
in
which
superclasses
are
coded
the
following
subclass
and
new
testing
session
illustrate
class
sub
spam
def
printnuminstances
override
a
static
method
print
extra
stuff
but
call
back
to
original
spam
printnuminstances
printnuminstances
staticmethod
printnuminstances
a
sub
b
sub
a
printnuminstances
extra
stuff
number
of
instances
sub
printnuminstances
extra
stuff
number
of
instances
spam
printnuminstances
number
of
instances
call
from
subclass
instance
call
from
subclass
itself
moreover
classes
can
inherit
the
static
method
without
redefining
it
it
is
run
without
an
instance
regardless
of
where
it
is
defined
in
a
class
tree
class
other
spam
pass
inherit
static
method
verbatim
c
other
c
printnuminstances
number
of
instances
static
and
class
methods
counting
instances
with
class
methods
interestingly
a
class
method
can
do
similar
work
here
the
following
has
the
same
behavior
as
the
static
method
version
listed
earlier
but
it
uses
a
class
method
that
receives
the
instance
s
class
in
its
first
argument
rather
than
hardcoding
the
class
name
the
class
method
uses
the
automatically
passed
class
object
generically
class
spam
numinstances
use
class
method
instead
of
static
def
init
self
spam
numinstances
def
printnuminstances
cls
print
number
of
instances
cls
numinstances
printnuminstances
classmethod
printnuminstances
this
class
is
used
in
the
same
way
as
the
prior
versions
but
its
printnuminstances
method
receives
the
class
not
the
instance
when
called
from
both
the
class
and
an
instance
a
b
spam
spam
a
printnuminstances
number
of
instances
spam
printnuminstances
number
of
instances
passes
class
to
first
argument
also
passes
class
to
first
argument
when
using
class
methods
though
keep
in
mind
that
they
receive
the
most
specific
i
e
lowest
class
of
the
call
s
subject
this
has
some
subtle
implications
when
trying
to
update
class
data
through
the
passed
in
class
for
example
if
in
module
test
py
we
subclass
to
customize
as
before
augment
spam
printnuminstances
to
also
display
its
cls
argument
and
start
a
new
testing
session
class
spam
numinstances
trace
class
passed
in
def
init
self
spam
numinstances
def
printnuminstances
cls
print
number
of
instances
cls
numinstances
cls
printnuminstances
classmethod
printnuminstances
class
sub
spam
def
printnuminstances
cls
override
a
class
method
print
extra
stuff
cls
but
call
back
to
original
spam
printnuminstances
printnuminstances
classmethod
printnuminstances
class
other
spam
pass
inherit
class
method
verbatim
the
lowest
class
is
passed
in
whenever
a
class
method
is
run
even
for
subclasses
that
have
no
class
methods
of
their
own
x
y
sub
spam
x
printnuminstances
extra
stuff
class
test
sub
number
of
instances
class
test
spam
chapter
advanced
class
topics
call
from
subclass
instance
sub
printnuminstances
extra
stuff
class
test
sub
number
of
instances
class
test
spam
y
printnuminstances
number
of
instances
class
test
spam
call
from
subclass
itself
in
the
first
call
here
a
class
method
call
is
made
through
an
instance
of
the
sub
subclass
and
python
passes
the
lowest
class
sub
to
the
class
method
all
is
well
in
this
case
since
sub
s
redefinition
of
the
method
calls
the
spam
superclass
s
version
explicitly
the
superclass
method
in
spam
receives
itself
in
its
first
argument
but
watch
what
happens
for
an
object
that
simply
inherits
the
class
method
z
other
z
printnuminstances
number
of
instances
class
test
other
this
last
call
here
passes
other
to
spam
s
class
method
this
works
in
this
example
because
fetching
the
counter
finds
it
in
spam
by
inheritance
if
this
method
tried
to
assign
to
the
passed
class
s
data
though
it
would
update
object
not
spam
in
this
specific
case
spam
is
probably
better
off
hardcoding
its
own
class
name
to
update
its
data
rather
than
relying
on
the
passed
in
class
argument
counting
instances
per
class
with
class
methods
in
fact
because
class
methods
always
receive
the
lowest
class
in
an
instance
s
tree
static
methods
and
explicit
class
names
may
be
a
better
solution
for
processing
data
local
to
a
class
class
methods
may
be
better
suited
to
processing
data
that
may
differ
for
each
class
in
a
hierarchy
code
that
needs
to
manage
per
class
instance
counters
for
example
might
be
best
off
leveraging
class
methods
in
the
following
the
top
level
superclass
uses
a
class
method
to
manage
state
information
that
varies
for
and
is
stored
on
each
class
in
the
tree
similar
in
spirit
to
the
way
instance
methods
manage
state
information
in
class
instances
class
spam
numinstances
def
count
cls
cls
numinstances
def
init
self
self
count
count
classmethod
count
class
sub
spam
numinstances
def
init
self
spam
init
self
class
other
spam
numinstances
per
class
instance
counters
cls
is
lowest
class
above
instance
passes
self
class
to
count
redefines
init
inherits
init
static
and
class
methods
x
spam
y
y
sub
sub
z
z
z
other
other
other
x
numinstances
y
numinstances
z
numinstances
spam
numinstances
sub
numinstances
other
numinstances
static
and
class
methods
have
additional
advanced
roles
which
we
will
finesse
here
see
other
resources
for
more
use
cases
in
recent
python
versions
though
the
static
and
class
method
designations
have
become
even
simpler
with
the
advent
of
function
decoration
syntax
a
way
to
apply
one
function
to
another
that
has
roles
well
beyond
the
static
method
use
case
that
was
its
motivation
this
syntax
also
allows
us
to
augment
classes
in
python
and
to
initialize
data
like
the
numinstances
counter
in
the
last
example
for
instance
the
next
section
explains
how
decorators
and
metaclasses
part
because
the
staticmethod
call
technique
described
in
the
prior
section
initially
seemed
obscure
to
some
users
a
feature
was
eventually
added
to
make
the
operation
simpler
function
decorators
provide
a
way
to
specify
special
operation
modes
for
functions
by
wrapping
them
in
an
extra
layer
of
logic
implemented
as
another
function
function
decorators
turn
out
to
be
general
tools
they
are
useful
for
adding
many
types
of
logic
to
functions
besides
the
static
method
use
case
for
instance
they
may
be
used
to
augment
functions
with
code
that
logs
calls
made
to
them
checks
the
types
of
passed
arguments
during
debugging
and
so
on
in
some
ways
function
decorators
are
similar
to
the
delegation
design
pattern
we
explored
in
chapter
but
they
are
designed
to
augment
a
specific
function
or
method
call
not
an
entire
object
interface
python
provides
some
built
in
function
decorators
for
operations
such
as
marking
static
methods
but
programmers
can
also
code
arbitrary
decorators
of
their
own
although
they
are
not
strictly
tied
to
classes
user
defined
function
decorators
often
are
coded
as
classes
to
save
the
original
functions
along
with
other
data
as
state
information
there
s
also
a
more
recent
related
extension
available
in
python
and
class
decorators
are
directly
tied
to
the
class
model
and
their
roles
overlap
with
metaclasses
function
decorator
basics
syntactically
a
function
decorator
is
a
sort
of
runtime
declaration
about
the
function
that
follows
a
function
decorator
is
coded
on
a
line
by
itself
just
before
the
def
statement
that
defines
a
function
or
method
it
consists
of
the
symbol
followed
by
what
we
call
a
metafunction
a
function
or
other
callable
object
that
manages
another
function
static
methods
today
for
example
may
be
coded
with
decorator
syntax
like
this
chapter
advanced
class
topics
class
c
staticmethod
def
meth
decoration
syntax
internally
this
syntax
has
the
same
effect
as
the
following
passing
the
function
through
the
decorator
and
assigning
the
result
back
to
the
original
name
class
c
def
meth
meth
staticmethod
meth
rebind
name
decoration
rebinds
the
method
name
to
the
decorator
s
result
the
net
effect
is
that
calling
the
method
function
s
name
later
actually
triggers
the
result
of
its
staticmethod
decorator
first
because
a
decorator
can
return
any
sort
of
object
this
allows
the
decorator
to
insert
a
layer
of
logic
to
be
run
on
every
call
the
decorator
function
is
free
to
return
either
the
original
function
itself
or
a
new
object
that
saves
the
original
function
passed
to
the
decorator
to
be
invoked
indirectly
after
the
extra
logic
layer
runs
with
this
addition
here
s
a
better
way
to
code
our
static
method
example
from
the
prior
section
in
either
python
or
the
classmethod
decorator
is
used
the
same
way
class
spam
numinstances
def
init
self
spam
numinstances
spam
numinstances
staticmethod
def
printnuminstances
print
number
of
instances
created
spam
numinstances
a
spam
b
spam
c
spam
spam
printnuminstances
a
printnuminstances
calls
from
both
classes
and
instances
work
now
both
print
number
of
instances
created
keep
in
mind
that
staticmethod
is
still
a
built
in
function
it
may
be
used
in
decoration
syntax
just
because
it
takes
a
function
as
argument
and
returns
a
callable
in
fact
any
such
function
can
be
used
in
this
way
even
user
defined
functions
we
code
ourselves
as
the
next
section
explains
a
first
function
decorator
example
although
python
provides
a
handful
of
built
in
functions
that
can
be
used
as
decorators
we
can
also
write
custom
decorators
of
our
own
because
of
their
wide
utility
we
re
going
to
devote
an
entire
chapter
to
coding
decorators
in
the
next
part
of
this
book
as
a
quick
example
though
let
s
look
at
a
simple
user
defined
decorator
at
work
decorators
and
metaclasses
part
recall
from
chapter
that
the
call
operator
overloading
method
implements
a
function
call
interface
for
class
instances
the
following
code
uses
this
to
define
a
class
that
saves
the
decorated
function
in
the
instance
and
catches
calls
to
the
original
name
because
this
is
a
class
it
also
has
state
information
a
counter
of
calls
made
class
tracer
def
init
self
func
self
calls
self
func
func
def
call
self
args
self
calls
print
call
s
to
s
self
calls
self
func
name
self
func
args
tracer
def
spam
a
b
c
print
a
b
c
same
as
spam
tracer
spam
wrap
spam
in
a
decorator
object
spam
spam
a
b
c
spam
really
calls
the
tracer
wrapper
object
invokes
call
in
class
call
adds
logic
and
runs
original
object
because
the
spam
function
is
run
through
the
tracer
decorator
when
the
original
spam
name
is
called
it
actually
triggers
the
call
method
in
the
class
this
method
counts
and
logs
the
call
and
then
dispatches
it
to
the
original
wrapped
function
note
how
the
name
argument
syntax
is
used
to
pack
and
unpack
the
passed
in
arguments
because
of
this
this
decorator
can
be
used
to
wrap
any
function
with
any
number
of
positional
arguments
the
net
effect
again
is
to
add
a
layer
of
logic
to
the
original
spam
function
here
is
the
script
s
output
the
first
line
comes
from
the
tracer
class
and
the
second
comes
from
the
spam
function
call
to
spam
call
to
spam
a
b
c
call
to
spam
trace
through
this
example
s
code
for
more
insight
as
it
is
this
decorator
works
for
any
function
that
takes
positional
arguments
but
it
does
not
return
the
decorated
function
s
result
doesn
t
handle
keyword
arguments
and
cannot
decorate
class
method
functions
in
short
for
methods
its
call
would
be
passed
a
tracer
instance
only
as
we
ll
see
in
part
viii
there
are
a
variety
of
ways
to
code
function
decorators
including
nested
def
statements
some
of
the
alternatives
are
better
suited
to
methods
than
the
version
shown
here
chapter
advanced
class
topics
class
decorators
and
metaclasses
function
decorators
turned
out
to
be
so
useful
that
python
and
expanded
the
model
allowing
decorators
to
be
applied
to
classes
as
well
as
functions
in
short
class
decorators
are
similar
to
function
decorators
but
they
are
run
at
the
end
of
a
class
statement
to
rebind
a
class
name
to
a
callable
as
such
they
can
be
used
to
either
manage
classes
just
after
they
are
created
or
insert
a
layer
of
wrapper
logic
to
manage
instances
when
they
are
later
created
symbolically
the
code
structure
def
decorator
aclass
decorator
class
c
is
mapped
to
the
following
equivalent
def
decorator
aclass
class
c
c
decorator
c
the
class
decorator
is
free
to
augment
the
class
itself
or
return
an
object
that
intercepts
later
instance
construction
calls
for
instance
in
the
example
in
the
section
counting
instances
per
class
with
class
methods
on
page
we
could
use
this
hook
to
automatically
augment
the
classes
with
instance
counters
and
any
other
data
required
def
count
aclass
aclass
numinstances
return
aclass
return
class
itself
instead
of
a
wrapper
count
class
spam
same
as
spam
count
spam
count
class
sub
spam
numinstances
not
needed
here
count
class
other
spam
metaclasses
are
a
similarly
advanced
class
based
tool
whose
roles
often
intersect
with
those
of
class
decorators
they
provide
an
alternate
model
which
routes
the
creation
of
a
class
object
to
a
subclass
of
the
top
level
type
class
at
the
conclusion
of
a
class
statement
class
meta
type
def
new
meta
classname
supers
classdict
class
c
metaclass
meta
decorators
and
metaclasses
part
in
python
the
effect
is
the
same
but
the
coding
differs
use
a
class
attribute
instead
of
a
keyword
argument
in
the
class
header
class
c
metaclass
meta
the
metaclass
generally
redefines
the
new
or
init
method
of
the
type
class
in
order
to
assume
control
of
the
creation
or
initialization
of
a
new
class
object
the
net
effect
as
with
class
decorators
is
to
define
code
to
be
run
automatically
at
class
creation
time
both
schemes
are
free
to
augment
a
class
or
return
an
arbitrary
object
to
replace
it
a
protocol
with
almost
limitless
class
based
possibilities
for
more
details
naturally
there
s
much
more
to
the
decorator
and
metaclass
stories
than
i
ve
shown
here
although
they
are
a
general
mechanism
decorators
and
metaclasses
are
advanced
features
of
interest
primarily
to
tool
writers
not
application
programmers
so
we
ll
defer
additional
coverage
until
the
final
part
of
this
book
chapter
shows
how
to
code
properties
using
function
decorator
syntax
chapter
has
much
more
on
decorators
including
more
comprehensive
examples
chapter
covers
metaclasses
and
more
on
the
class
and
instance
management
story
although
these
chapters
cover
advanced
topics
they
ll
also
provide
us
with
a
chance
to
see
python
at
work
in
more
substantial
examples
than
much
of
the
rest
of
the
book
was
able
to
provide
class
gotchas
most
class
issues
can
be
boiled
down
to
namespace
issues
which
makes
sense
given
that
classes
are
just
namespaces
with
a
few
extra
tricks
some
of
the
topics
we
ll
cover
in
this
section
are
more
like
case
studies
of
advanced
class
usage
than
real
problems
and
one
or
two
of
these
gotchas
have
been
eased
by
recent
python
releases
changing
class
attributes
can
have
side
effects
theoretically
speaking
classes
and
class
instances
are
mutable
objects
like
built
in
lists
and
dictionaries
they
can
be
changed
in
place
by
assigning
to
their
attributes
and
as
with
lists
and
dictionaries
this
means
that
changing
a
class
or
instance
object
may
impact
multiple
references
to
it
chapter
advanced
class
topics
that
s
usually
what
we
want
and
is
how
objects
change
their
state
in
general
but
awareness
of
this
issue
becomes
especially
critical
when
changing
class
attributes
because
all
instances
generated
from
a
class
share
the
class
s
namespace
any
changes
at
the
class
level
are
reflected
in
all
instances
unless
they
have
their
own
versions
of
the
changed
class
attributes
because
classes
modules
and
instances
are
all
just
objects
with
attribute
namespaces
you
can
normally
change
their
attributes
at
runtime
by
assignments
consider
the
following
class
inside
the
class
body
the
assignment
to
the
name
a
generates
an
attribute
x
a
which
lives
in
the
class
object
at
runtime
and
will
be
inherited
by
all
of
x
s
instances
class
x
a
class
attribute
i
x
i
a
inherited
by
instance
x
a
so
far
so
good
this
is
the
normal
case
but
notice
what
happens
when
we
change
the
class
attribute
dynamically
outside
the
class
statement
it
also
changes
the
attribute
in
every
object
that
inherits
from
the
class
moreover
new
instances
created
from
the
class
during
this
session
or
program
run
also
get
the
dynamically
set
value
regardless
of
what
the
class
s
source
code
says
x
a
i
a
may
change
more
than
x
i
changes
too
j
x
j
a
j
inherits
from
x
s
runtime
values
but
assigning
to
j
a
changes
a
in
j
not
x
or
i
is
this
a
useful
feature
or
a
dangerous
trap
you
be
the
judge
as
we
learned
in
chapter
you
can
actually
get
work
done
by
changing
class
attributes
without
ever
making
a
single
instance
this
technique
can
simulate
the
use
of
records
or
structs
in
other
languages
as
a
refresher
consider
the
following
unusual
but
legal
python
program
class
x
pass
class
y
pass
make
a
few
attribute
namespaces
x
a
x
b
x
c
y
a
use
class
attributes
as
variables
no
instances
anywhere
to
be
found
x
a
x
b
x
c
for
x
i
in
range
y
a
print
x
i
prints
here
the
classes
x
and
y
work
like
fileless
modules
namespaces
for
storing
variables
we
don
t
want
to
clash
this
is
a
perfectly
legal
python
programming
trick
but
it
s
less
appropriate
when
applied
to
classes
written
by
others
you
can
t
always
be
sure
that
class
attributes
you
change
aren
t
critical
to
the
class
s
internal
behavior
if
you
re
out
class
gotchas
to
simulate
a
c
struct
you
may
be
better
off
changing
instances
than
classes
as
that
way
only
one
object
is
affected
class
record
pass
x
record
x
name
bob
x
job
pizza
maker
changing
mutable
class
attributes
can
have
side
effects
too
this
gotcha
is
really
an
extension
of
the
prior
because
class
attributes
are
shared
by
all
instances
if
a
class
attribute
references
a
mutable
object
changing
that
object
in
place
from
any
instance
impacts
all
instances
at
once
class
c
shared
def
init
self
self
perobj
x
c
y
c
y
shared
y
perobj
class
attribute
instance
attribute
two
instances
implicitly
share
class
attrs
x
shared
append
spam
x
perobj
append
spam
x
shared
x
perobj
spam
spam
impacts
y
s
view
too
impacts
x
s
data
only
y
shared
y
perobj
spam
c
shared
spam
y
sees
change
made
through
x
stored
on
class
and
shared
this
effect
is
no
different
than
many
we
ve
seen
in
this
book
already
mutable
objects
are
shared
by
simple
variables
globals
are
shared
by
functions
module
level
objects
are
shared
by
multiple
importers
and
mutable
function
arguments
are
shared
by
the
caller
and
the
callee
all
of
these
are
cases
of
general
behavior
multiple
references
to
a
mutable
object
and
all
are
impacted
if
the
shared
object
is
changed
in
place
from
any
reference
here
this
occurs
in
class
attributes
shared
by
all
instances
via
inheritance
but
it
s
the
same
phenomenon
at
work
it
may
be
made
more
subtle
by
the
different
behavior
of
assignments
to
instance
attributes
themselves
x
shared
append
spam
x
shared
spam
changes
shared
object
attached
to
class
in
place
changed
or
creates
instance
attribute
attached
to
x
but
again
this
is
not
a
problem
it
s
just
something
to
be
aware
of
shared
mutable
class
attributes
can
have
many
valid
uses
in
python
programs
chapter
advanced
class
topics
multiple
inheritance
order
matters
this
may
be
obvious
by
now
but
it
s
worth
underscoring
if
you
use
multiple
inheritance
the
order
in
which
superclasses
are
listed
in
the
class
statement
header
can
be
critical
python
always
searches
superclasses
from
left
to
right
according
to
their
order
in
the
header
line
for
instance
in
the
multiple
inheritance
example
we
studied
in
chapter
suppose
that
the
super
class
implemented
a
str
method
too
class
listtree
def
str
self
class
super
def
str
self
class
sub
listtree
super
get
listtree
s
str
by
listing
it
first
x
sub
inheritance
searches
listtree
before
super
which
class
would
we
inherit
it
from
listtree
or
super
as
inheritance
searches
proceed
from
left
to
right
we
would
get
the
method
from
whichever
class
is
listed
first
leftmost
in
sub
s
class
header
presumably
we
would
list
listtree
first
because
its
whole
purpose
is
its
custom
str
indeed
we
had
to
do
this
in
chapter
when
mixing
this
class
with
a
tkinter
button
that
had
a
str
of
its
own
but
now
suppose
super
and
listtree
have
their
own
versions
of
other
same
named
attributes
too
if
we
want
one
name
from
super
and
another
from
listtree
the
order
in
which
we
list
them
in
the
class
header
won
t
help
we
will
have
to
override
inheritance
by
manually
assigning
to
the
attribute
name
in
the
sub
class
class
listtree
def
str
self
def
other
self
class
super
def
str
self
def
other
self
class
sub
listtree
super
other
super
other
def
init
self
get
listtree
s
str
by
listing
it
first
but
explicitly
pick
super
s
version
of
other
x
sub
inheritance
searches
sub
before
listtree
super
here
the
assignment
to
other
within
the
sub
class
creates
sub
other
a
reference
back
to
the
super
other
object
because
it
is
lower
in
the
tree
sub
other
effectively
hides
listtree
other
the
attribute
that
the
inheritance
search
would
normally
find
similarly
if
we
listed
super
first
in
the
class
header
to
pick
up
its
other
we
would
need
to
select
listtree
s
method
explicitly
class
gotchas
get
super
s
other
by
order
explicitly
pick
lister
str
class
sub
super
listtree
str
lister
str
multiple
inheritance
is
an
advanced
tool
even
if
you
understood
the
last
paragraph
it
s
still
a
good
idea
to
use
it
sparingly
and
carefully
otherwise
the
meaning
of
a
name
may
come
to
depend
on
the
order
in
which
classes
are
mixed
in
an
arbitrarily
far
removed
subclass
for
another
example
of
the
technique
shown
here
in
action
see
the
discussion
of
explicit
conflict
resolution
in
the
new
style
class
model
on
page
as
a
rule
of
thumb
multiple
inheritance
works
best
when
your
mix
in
classes
are
as
self
contained
as
possible
because
they
may
be
used
in
a
variety
of
contexts
they
should
not
make
assumptions
about
names
related
to
other
classes
in
a
tree
the
pseudoprivate
x
attributes
feature
we
studied
in
chapter
can
help
by
localizing
names
that
a
class
relies
on
owning
and
limiting
the
names
that
your
mix
in
classes
add
to
the
mix
in
this
example
for
instance
if
listtree
only
means
to
export
its
custom
str
it
can
name
its
other
method
other
to
avoid
clashing
with
like
named
classes
in
the
tree
methods
classes
and
nested
scopes
this
gotcha
went
away
in
python
with
the
introduction
of
nested
function
scopes
but
i
ve
retained
it
here
for
historical
perspective
for
readers
working
with
older
python
releases
and
because
it
demonstrates
what
happens
to
the
new
nested
function
scope
rules
when
one
layer
of
the
nesting
is
a
class
classes
introduce
local
scopes
just
as
functions
do
so
the
same
sorts
of
scope
behavior
can
happen
in
a
class
statement
body
moreover
methods
are
further
nested
functions
so
the
same
issues
apply
confusion
seems
to
be
especially
common
when
classes
are
nested
in
the
following
example
the
file
nester
py
the
generate
function
returns
an
instance
of
the
nested
spam
class
within
its
code
the
class
name
spam
is
assigned
in
the
generate
function
s
local
scope
however
in
versions
of
python
prior
to
within
the
class
s
method
function
the
class
name
spam
is
not
visible
method
has
access
only
to
its
own
local
scope
the
module
surrounding
generate
and
built
in
names
def
generate
class
spam
count
def
method
self
print
spam
count
return
spam
fails
prior
to
python
works
later
name
spam
not
visible
not
local
def
global
module
built
in
generate
method
c
python
examples
python
nester
py
error
text
omitted
chapter
advanced
class
topics
print
spam
count
nameerror
spam
not
local
def
global
module
built
in
this
example
works
in
python
and
later
because
the
local
scopes
of
all
enclosing
function
defs
are
automatically
visible
to
nested
defs
including
nested
method
defs
as
in
this
example
however
it
doesn
t
work
before
we
ll
look
at
some
possible
solutions
momentarily
note
that
even
in
and
later
method
defs
cannot
see
the
local
scope
of
the
enclosing
class
they
can
only
see
the
local
scopes
of
enclosing
defs
that
s
why
methods
must
go
through
the
self
instance
or
the
class
name
to
reference
methods
and
other
attributes
defined
in
the
enclosing
class
statement
for
example
code
in
the
method
must
use
self
count
or
spam
count
not
just
count
if
you
re
using
a
release
prior
to
there
are
a
variety
of
ways
to
get
the
preceding
example
to
work
one
of
the
simplest
is
to
move
the
name
spam
out
to
the
enclosing
module
s
scope
with
a
global
declaration
because
method
sees
global
names
in
the
enclosing
module
references
to
spam
will
work
def
generate
global
spam
class
spam
count
def
method
self
print
spam
count
return
spam
generate
method
force
spam
to
module
scope
works
in
global
enclosing
module
prints
a
better
alternative
would
be
to
restructure
the
code
such
that
the
class
spam
is
defined
at
the
top
level
of
the
module
by
virtue
of
its
nesting
level
rather
than
using
global
declarations
the
nested
method
function
and
the
top
level
generate
will
then
find
spam
in
their
global
scopes
def
generate
return
spam
class
spam
count
def
method
self
print
spam
count
define
at
top
level
of
module
works
in
global
enclosing
module
generate
method
in
fact
this
approach
is
recommended
for
all
python
releases
code
tends
to
be
simpler
in
general
if
you
avoid
nesting
classes
and
functions
if
you
want
to
get
complicated
and
tricky
you
can
also
get
rid
of
the
spam
reference
in
method
altogether
by
using
the
special
class
attribute
which
returns
an
instance
s
class
object
def
generate
class
spam
class
gotchas
count
def
method
self
print
self
class
count
return
spam
works
qualify
to
get
class
generate
method
delegation
based
classes
in
getattr
and
built
ins
we
met
this
issue
briefly
in
our
class
tutorial
in
chapter
and
our
delegation
coverage
in
chapter
classes
that
use
the
getattr
operator
overloading
method
to
delegate
attribute
fetches
to
wrapped
objects
will
fail
in
python
unless
operator
overloading
methods
are
redefined
in
the
wrapper
class
in
python
and
when
new
style
classes
are
used
the
names
of
operator
overloading
methods
implicitly
fetched
by
built
in
operations
are
not
routed
through
generic
attribute
interception
methods
the
str
method
used
by
printing
for
example
never
invokes
getattr
instead
python
looks
up
such
names
in
classes
and
skips
the
normal
runtime
instance
lookup
mechanism
entirely
to
work
around
this
such
methods
must
be
redefined
in
wrapper
classes
either
by
hand
with
tools
or
by
definition
in
superclasses
we
ll
revisit
this
gotcha
in
chapters
and
overwrapping
itis
when
used
well
the
code
reuse
features
of
oop
make
it
excel
at
cutting
development
time
sometimes
though
oop
s
abstraction
potential
can
be
abused
to
the
point
of
making
code
difficult
to
understand
if
classes
are
layered
too
deeply
code
can
become
obscure
you
may
have
to
search
through
many
classes
to
discover
what
an
operation
does
for
example
i
once
worked
in
a
c
shop
with
thousands
of
classes
some
machinegenerated
and
up
to
levels
of
inheritance
deciphering
method
calls
in
such
a
complex
system
was
often
a
monumental
task
multiple
classes
had
to
be
consulted
for
even
the
most
basic
of
operations
in
fact
the
logic
of
the
system
was
so
deeply
wrapped
that
understanding
a
piece
of
code
in
some
cases
required
days
of
wading
through
related
files
the
most
general
rule
of
thumb
of
python
programming
applies
here
too
don
t
make
things
complicated
unless
they
truly
must
be
wrapping
your
code
in
multiple
layers
of
classes
to
the
point
of
incomprehensibility
is
always
a
bad
idea
abstraction
is
the
basis
of
polymorphism
and
encapsulation
and
it
can
be
a
very
effective
tool
when
used
well
however
you
ll
simplify
debugging
and
aid
maintainability
if
you
make
your
class
interfaces
intuitive
avoid
making
your
code
overly
abstract
and
keep
your
class
hierarchies
short
and
flat
unless
there
is
a
good
reason
to
do
otherwise
chapter
advanced
class
topics
chapter
summary
this
chapter
presented
a
handful
of
advanced
class
related
topics
including
subclassing
built
in
types
new
style
classes
static
methods
and
decorators
most
of
these
are
optional
extensions
to
the
oop
model
in
python
but
they
may
become
more
useful
as
you
start
writing
larger
object
oriented
programs
as
mentioned
earlier
our
discussion
of
some
of
the
more
advanced
class
tools
continues
in
the
final
part
of
this
book
be
sure
to
look
ahead
if
you
need
more
details
on
properties
descriptors
decorators
and
metaclasses
this
is
the
end
of
the
class
part
of
this
book
so
you
ll
find
the
usual
lab
exercises
at
the
end
of
the
chapter
be
sure
to
work
through
them
to
get
some
practice
coding
real
classes
in
the
next
chapter
we
ll
begin
our
look
at
our
last
core
language
topic
exceptions
exceptions
are
python
s
mechanism
for
communicating
errors
and
other
conditions
to
your
code
this
is
a
relatively
lightweight
topic
but
i
ve
saved
it
for
last
because
exceptions
are
supposed
to
be
coded
as
classes
today
before
we
tackle
that
final
core
subject
though
take
a
look
at
this
chapter
s
quiz
and
the
lab
exercises
test
your
knowledge
quiz
name
two
ways
to
extend
a
built
in
object
type
what
are
function
decorators
used
for
how
do
you
code
a
new
style
class
how
are
new
style
and
classic
classes
different
how
are
normal
and
static
methods
different
how
long
should
you
wait
before
lobbing
a
holy
hand
grenade
test
your
knowledge
answers
you
can
embed
a
built
in
object
in
a
wrapper
class
or
subclass
the
built
in
type
directly
the
latter
approach
tends
to
be
simpler
as
most
original
behavior
is
automatically
inherited
function
decorators
are
generally
used
to
add
to
an
existing
function
a
layer
of
logic
that
is
run
each
time
the
function
is
called
they
can
be
used
to
log
or
count
calls
to
a
function
check
its
argument
types
and
so
on
they
are
also
used
to
declare
static
methods
simple
functions
in
a
class
that
are
not
passed
an
instance
when
called
test
your
knowledge
answers
new
style
classes
are
coded
by
inheriting
from
the
object
built
in
class
or
any
other
built
in
type
in
python
all
classes
are
new
style
automatically
so
this
derivation
is
not
required
in
classes
with
this
derivation
are
new
style
and
those
without
it
are
classic
new
style
classes
search
the
diamond
pattern
of
multiple
inheritance
trees
differently
they
essentially
search
breadth
first
across
instead
of
depth
first
up
new
style
classes
also
change
the
result
of
the
type
built
in
for
instances
and
classes
do
not
run
generic
attribute
fetch
methods
such
as
getattr
for
builtin
operation
methods
and
support
a
set
of
advanced
extra
tools
including
properties
descriptors
and
slots
instance
attribute
lists
normal
instance
methods
receive
a
self
argument
the
implied
instance
but
static
methods
do
not
static
methods
are
simple
functions
nested
in
class
objects
to
make
a
method
static
it
must
either
be
run
through
a
special
built
in
function
or
be
decorated
with
decorator
syntax
python
allows
simple
functions
in
a
class
to
be
called
through
the
class
without
this
step
but
calls
through
instances
still
require
static
method
declaration
three
seconds
or
more
accurately
and
the
lord
spake
saying
first
shalt
thou
take
out
the
holy
pin
then
shalt
thou
count
to
three
no
more
no
less
three
shalt
be
the
number
thou
shalt
count
and
the
number
of
the
counting
shall
be
three
four
shalt
thou
not
count
nor
either
count
thou
two
excepting
that
thou
then
proceed
to
three
five
is
right
out
once
the
number
three
being
the
third
number
be
reached
then
lobbest
thou
thy
holy
hand
grenade
of
antioch
towards
thy
foe
who
being
naughty
in
my
sight
shall
snuff
it
test
your
knowledge
part
vi
exercises
these
exercises
ask
you
to
write
a
few
classes
and
experiment
with
some
existing
code
of
course
the
problem
with
existing
code
is
that
it
must
be
existing
to
work
with
the
set
class
in
exercise
either
pull
the
class
source
code
off
this
book
s
website
see
the
preface
for
a
pointer
or
type
it
up
by
hand
it
s
fairly
brief
these
programs
are
starting
to
get
more
sophisticated
so
be
sure
to
check
the
solutions
at
the
end
of
the
book
for
pointers
you
ll
find
them
in
appendix
b
under
part
vi
classes
and
oop
on
page
inheritance
write
a
class
called
adder
that
exports
a
method
add
self
x
y
that
prints
a
not
implemented
message
then
define
two
subclasses
of
adder
that
implement
the
add
method
listadder
with
an
add
method
that
returns
the
concatenation
of
its
two
list
arguments
this
quote
is
from
monty
python
and
the
holy
grail
chapter
advanced
class
topics
dictadder
with
an
add
method
that
returns
a
new
dictionary
containing
the
items
in
both
its
two
dictionary
arguments
any
definition
of
addition
will
do
experiment
by
making
instances
of
all
three
of
your
classes
interactively
and
calling
their
add
methods
now
extend
your
adder
superclass
to
save
an
object
in
the
instance
with
a
constructor
e
g
assign
self
data
a
list
or
a
dictionary
and
overload
the
operator
with
an
add
method
to
automatically
dispatch
to
your
add
methods
e
g
x
y
triggers
x
add
x
data
y
where
is
the
best
place
to
put
the
constructors
and
operator
overloading
methods
i
e
in
which
classes
what
sorts
of
objects
can
you
add
to
your
class
instances
in
practice
you
might
find
it
easier
to
code
your
add
methods
to
accept
just
one
real
argument
e
g
add
self
y
and
add
that
one
argument
to
the
instance
s
current
data
e
g
self
data
y
does
this
make
more
sense
than
passing
two
arguments
to
add
would
you
say
this
makes
your
classes
more
object
oriented
operator
overloading
write
a
class
called
mylist
that
shadows
wraps
a
python
list
it
should
overload
most
list
operators
and
operations
including
indexing
iteration
slicing
and
list
methods
such
as
append
and
sort
see
the
python
reference
manual
for
a
list
of
all
possible
methods
to
support
also
provide
a
constructor
for
your
class
that
takes
an
existing
list
or
a
mylist
instance
and
copies
its
components
into
an
instance
member
experiment
with
your
class
interactively
things
to
explore
a
why
is
copying
the
initial
value
important
here
b
can
you
use
an
empty
slice
e
g
start
to
copy
the
initial
value
if
it
s
a
mylist
instance
c
is
there
a
general
way
to
route
list
method
calls
to
the
wrapped
list
d
can
you
add
a
mylist
and
a
regular
list
how
about
a
list
and
a
mylist
instance
e
what
type
of
object
should
operations
like
and
slicing
return
what
about
indexing
operations
f
if
you
are
working
with
a
more
recent
python
release
version
or
later
you
may
implement
this
sort
of
wrapper
class
by
embedding
a
real
list
in
a
standalone
class
or
by
extending
the
built
in
list
type
with
a
subclass
which
is
easier
and
why
subclassing
make
a
subclass
of
mylist
from
exercise
called
mylistsub
which
extends
mylist
to
print
a
message
to
stdout
before
each
overloaded
operation
is
called
and
counts
the
number
of
calls
mylistsub
should
inherit
basic
method
behavior
from
mylist
adding
a
sequence
to
a
mylistsub
should
print
a
message
increment
the
counter
for
calls
and
perform
the
superclass
s
method
also
introduce
a
new
method
that
prints
the
operation
counters
to
stdout
and
experiment
with
your
class
interactively
do
your
counters
count
calls
per
instance
or
per
class
for
all
instances
of
the
class
how
would
you
program
the
other
option
test
your
knowledge
part
vi
exercises
hint
it
depends
on
which
object
the
count
members
are
assigned
to
class
members
are
shared
by
instances
but
self
members
are
per
instance
data
metaclass
methods
write
a
class
called
meta
with
methods
that
intercept
every
attribute
qualification
both
fetches
and
assignments
and
print
messages
listing
their
arguments
to
stdout
create
a
meta
instance
and
experiment
with
qualifying
it
interactively
what
happens
when
you
try
to
use
the
instance
in
expressions
try
adding
indexing
and
slicing
the
instance
of
your
class
note
a
fully
generic
approach
based
upon
getattr
will
work
in
but
not
for
reasons
noted
in
chapter
and
restated
in
the
solution
to
this
exercise
set
objects
experiment
with
the
set
class
described
in
extending
types
by
embedding
on
page
run
commands
to
do
the
following
sorts
of
operations
a
create
two
sets
of
integers
and
compute
their
intersection
and
union
by
using
and
operator
expressions
b
create
a
set
from
a
string
and
experiment
with
indexing
your
set
which
methods
in
the
class
are
called
c
try
iterating
through
the
items
in
your
string
set
using
a
for
loop
which
methods
run
this
time
d
try
computing
the
intersection
and
union
of
your
string
set
and
a
simple
python
string
does
it
work
e
now
extend
your
set
by
subclassing
to
handle
arbitrarily
many
operands
using
the
args
argument
form
hint
see
the
function
versions
of
these
algorithms
in
chapter
compute
intersections
and
unions
of
multiple
operands
with
your
set
subclass
how
can
you
intersect
three
or
more
sets
given
that
has
only
two
sides
f
how
would
you
go
about
emulating
other
list
operations
in
the
set
class
hint
add
can
catch
concatenation
and
getattr
can
pass
most
list
method
calls
to
the
wrapped
list
class
tree
links
in
namespaces
the
whole
story
on
page
in
chapter
and
in
multiple
inheritance
mix
in
classes
on
page
in
chapter
i
mentioned
that
classes
have
a
bases
attribute
that
returns
a
tuple
of
their
superclass
objects
the
ones
listed
in
parentheses
in
the
class
header
use
bases
to
extend
the
lister
py
mix
in
classes
we
wrote
in
chapter
so
that
they
print
the
names
of
the
immediate
superclasses
of
the
instance
s
class
when
you
re
done
the
first
line
of
the
string
representation
should
look
like
this
your
address
may
vary
instance
of
sub
super
lister
address
composition
simulate
a
fast
food
ordering
scenario
by
defining
four
classes
lunch
a
container
and
controller
class
chapter
advanced
class
topics
customer
the
actor
who
buys
food
employee
the
actor
from
whom
a
customer
orders
food
what
the
customer
buys
to
get
you
started
here
are
the
classes
and
methods
you
ll
be
defining
class
lunch
def
init
self
def
order
self
foodname
def
result
self
make
embed
customer
and
employee
start
a
customer
order
simulation
ask
the
customer
what
food
it
has
class
customer
def
init
self
initialize
my
food
to
none
def
placeorder
self
foodname
employee
place
order
with
an
employee
def
printfood
self
print
the
name
of
my
food
class
employee
def
takeorder
self
foodname
return
a
food
with
requested
name
class
food
def
init
self
name
store
food
name
the
order
simulation
should
work
as
follows
a
the
lunch
class
s
constructor
should
make
and
embed
an
instance
of
customer
and
an
instance
of
employee
and
it
should
export
a
method
called
order
when
called
this
order
method
should
ask
the
customer
to
place
an
order
by
calling
its
placeorder
method
the
customer
s
placeorder
method
should
in
turn
ask
the
employee
object
for
a
new
food
object
by
calling
employee
s
takeorder
method
b
food
objects
should
store
a
food
name
string
e
g
burritos
passed
down
from
lunch
order
to
customer
placeorder
to
employee
takeorder
and
finally
to
food
s
constructor
the
top
level
lunch
class
should
also
export
a
method
called
result
which
asks
the
customer
to
print
the
name
of
the
food
it
received
from
the
employee
via
the
order
this
can
be
used
to
test
your
simulation
note
that
lunch
needs
to
pass
either
the
employee
or
itself
to
the
customer
to
allow
the
customer
to
call
employee
methods
experiment
with
your
classes
interactively
by
importing
the
lunch
class
calling
its
order
method
to
run
an
interaction
and
then
calling
its
result
method
to
verify
that
the
customer
got
what
he
or
she
ordered
if
you
prefer
you
can
also
simply
code
test
cases
as
self
test
code
in
the
file
where
your
classes
are
defined
using
the
module
name
trick
of
chapter
in
this
simulation
the
customer
is
the
active
agent
how
would
your
classes
change
if
employee
were
the
object
that
initiated
customer
employee
interaction
instead
test
your
knowledge
part
vi
exercises
figure
a
zoo
hierarchy
composed
of
classes
linked
into
a
tree
to
be
searched
by
attribute
inheritance
animal
has
a
common
reply
method
but
each
class
may
have
its
own
custom
speak
method
called
by
reply
zoo
animal
hierarchy
consider
the
class
tree
shown
in
figure
code
a
set
of
six
class
statements
to
model
this
taxonomy
with
python
inheritance
then
add
a
speak
method
to
each
of
your
classes
that
prints
a
unique
message
and
a
reply
method
in
your
top
level
animal
superclass
that
simply
calls
self
speak
to
invoke
the
category
specific
message
printer
in
a
subclass
below
this
will
kick
off
an
independent
inheritance
search
from
self
finally
remove
the
speak
method
from
your
hacker
class
so
that
it
picks
up
the
default
above
it
when
you
re
finished
your
classes
should
work
this
way
python
from
zoo
import
cat
hacker
spot
cat
spot
reply
meow
data
hacker
data
reply
hello
world
animal
reply
calls
cat
speak
animal
reply
calls
primate
speak
the
dead
parrot
sketch
consider
the
object
embedding
structure
captured
in
figure
code
a
set
of
python
classes
to
implement
this
structure
with
composition
code
your
scene
object
to
define
an
action
method
and
embed
instances
of
the
customer
clerk
and
parrot
classes
each
of
which
should
define
a
line
method
that
prints
a
unique
message
the
embedded
objects
may
either
inherit
from
a
common
superclass
that
defines
line
and
simply
provide
message
text
or
define
line
themselves
in
the
end
your
classes
should
operate
like
this
python
import
parrot
parrot
scene
action
customer
that
s
one
ex
bird
chapter
advanced
class
topics
activate
nested
objects
clerk
no
it
isn
t
parrot
none
figure
a
scene
composite
with
a
controller
class
scene
that
embeds
and
directs
instances
of
three
other
classes
customer
clerk
parrot
the
embedded
instance
s
classes
may
also
participate
in
an
inheritance
hierarchy
composition
and
inheritance
are
often
equally
useful
ways
to
structure
classes
for
code
reuse
why
you
will
care
oop
by
the
masters
when
i
teach
python
classes
i
invariably
find
that
about
halfway
through
the
class
people
who
have
used
oop
in
the
past
are
following
along
intensely
while
people
who
have
not
are
beginning
to
glaze
over
or
nod
off
completely
the
point
behind
the
technology
just
isn
t
apparent
in
a
book
like
this
i
have
the
luxury
of
including
material
like
the
new
big
picture
overview
in
chapter
and
the
gradual
tutorial
of
chapter
in
fact
you
should
probably
review
that
section
if
you
re
starting
to
feel
like
oop
is
just
some
computer
science
mumbo
jumbo
in
real
classes
however
to
help
get
the
newcomers
on
board
and
keep
them
awake
i
have
been
known
to
stop
and
ask
the
experts
in
the
audience
why
they
use
oop
the
answers
they
ve
given
might
help
shed
some
light
on
the
purpose
of
oop
if
you
re
new
to
the
subject
here
then
with
only
a
few
embellishments
are
the
most
common
reasons
to
use
oop
as
cited
by
my
students
over
the
years
code
reuse
this
one
s
easy
and
is
the
main
reason
for
using
oop
by
supporting
inheritance
classes
allow
you
to
program
by
customization
instead
of
starting
each
project
from
scratch
encapsulation
wrapping
up
implementation
details
behind
object
interfaces
insulates
users
of
a
class
from
code
changes
structure
classes
provide
new
local
scopes
which
minimizes
name
clashes
they
also
provide
a
natural
place
to
write
and
look
for
implementation
code
and
to
manage
object
state
test
your
knowledge
part
vi
exercises
maintenance
classes
naturally
promote
code
factoring
which
allows
us
to
minimize
redundancy
thanks
both
to
the
structure
and
code
reuse
support
of
classes
usually
only
one
copy
of
the
code
needs
to
be
changed
consistency
classes
and
inheritance
allow
you
to
implement
common
interfaces
and
hence
create
a
common
look
and
feel
in
your
code
this
eases
debugging
comprehension
and
maintenance
polymorphism
this
is
more
a
property
of
oop
than
a
reason
for
using
it
but
by
supporting
code
generality
polymorphism
makes
code
more
flexible
and
widely
applicable
and
hence
more
reusable
other
and
of
course
the
number
one
reason
students
gave
for
using
oop
it
looks
good
on
a
r√©sum√©
ok
i
threw
this
one
in
as
a
joke
but
it
is
important
to
be
familiar
with
oop
if
you
plan
to
work
in
the
software
field
today
finally
keep
in
mind
what
i
said
at
the
beginning
of
this
part
of
the
book
you
won
t
fully
appreciate
oop
until
you
ve
used
it
for
awhile
pick
a
project
study
larger
examples
work
through
the
exercises
do
whatever
it
takes
to
get
your
feet
wet
with
oo
code
it
s
worth
the
effort
chapter
advanced
class
topics
part
vii
exceptions
and
tools
chapter
exception
basics
this
part
of
the
book
deals
with
exceptions
which
are
events
that
can
modify
the
flow
of
control
through
a
program
in
python
exceptions
are
triggered
automatically
on
errors
and
they
can
be
triggered
and
intercepted
by
your
code
they
are
processed
by
four
statements
we
ll
study
in
this
part
the
first
of
which
has
two
variations
listed
separately
here
and
the
last
of
which
was
an
optional
extension
until
python
and
try
except
catch
and
recover
from
exceptions
raised
by
python
or
by
you
try
finally
perform
cleanup
actions
whether
exceptions
occur
or
not
raise
trigger
an
exception
manually
in
your
code
assert
conditionally
trigger
an
exception
in
your
code
with
as
implement
context
managers
in
python
and
optional
in
this
topic
was
saved
until
nearly
the
end
of
the
book
because
you
need
to
know
about
classes
to
code
exceptions
of
your
own
with
a
few
exceptions
pun
intended
though
you
ll
find
that
exception
handling
is
simple
in
python
because
it
s
integrated
into
the
language
itself
as
another
high
level
tool
why
use
exceptions
in
a
nutshell
exceptions
let
us
jump
out
of
arbitrarily
large
chunks
of
a
program
consider
the
hypothetical
pizza
making
robot
we
discussed
earlier
in
the
book
suppose
we
took
the
idea
seriously
and
actually
built
such
a
machine
to
make
a
pizza
our
culinary
automaton
would
need
to
execute
a
plan
which
we
would
implement
as
a
python
program
it
would
take
an
order
prepare
the
dough
add
toppings
bake
the
pie
and
so
on
now
suppose
that
something
goes
very
wrong
during
the
bake
the
pie
step
perhaps
the
oven
is
broken
or
perhaps
our
robot
miscalculates
its
reach
and
spontaneously
combusts
clearly
we
want
to
be
able
to
jump
to
code
that
handles
such
states
quickly
as
we
have
no
hope
of
finishing
the
pizza
task
in
such
unusual
cases
we
might
as
well
abandon
the
entire
plan
that
s
exactly
what
exceptions
let
you
do
you
can
jump
to
an
exception
handler
in
a
single
step
abandoning
all
function
calls
begun
since
the
exception
handler
was
entered
code
in
the
exception
handler
can
then
respond
to
the
raised
exception
as
appropriate
by
calling
the
fire
department
for
instance
one
way
to
think
of
an
exception
is
as
a
sort
of
structured
super
go
to
an
exception
handler
try
statement
leaves
a
marker
and
executes
some
code
somewhere
further
ahead
in
the
program
an
exception
is
raised
that
makes
python
jump
back
to
that
marker
abandoning
any
active
functions
that
were
called
after
the
marker
was
left
this
protocol
provides
a
coherent
way
to
respond
to
unusual
events
moreover
because
python
jumps
to
the
handler
statement
immediately
your
code
is
simpler
there
is
usually
no
need
to
check
status
codes
after
every
call
to
a
function
that
could
possibly
fail
exception
roles
in
python
programs
exceptions
are
typically
used
for
a
variety
of
purposes
here
are
some
of
their
most
common
roles
error
handling
python
raises
exceptions
whenever
it
detects
errors
in
programs
at
runtime
you
can
catch
and
respond
to
the
errors
in
your
code
or
ignore
the
exceptions
that
are
raised
if
an
error
is
ignored
python
s
default
exception
handling
behavior
kicks
in
it
stops
the
program
and
prints
an
error
message
if
you
don
t
want
this
default
behavior
code
a
try
statement
to
catch
and
recover
from
the
exception
python
will
jump
to
your
try
handler
when
the
error
is
detected
and
your
program
will
resume
execution
after
the
try
event
notification
exceptions
can
also
be
used
to
signal
valid
conditions
without
you
having
to
pass
result
flags
around
a
program
or
test
them
explicitly
for
instance
a
search
routine
might
raise
an
exception
on
failure
rather
than
returning
an
integer
result
code
and
hoping
that
the
code
will
never
be
a
valid
result
special
case
handling
sometimes
a
condition
may
occur
so
rarely
that
it
s
hard
to
justify
convoluting
your
code
to
handle
it
you
can
often
eliminate
special
case
code
by
handling
unusual
cases
in
exception
handlers
in
higher
levels
of
your
program
chapter
exception
basics
termination
actions
as
you
ll
see
the
try
finally
statement
allows
you
to
guarantee
that
required
closing
time
operations
will
be
performed
regardless
of
the
presence
or
absence
of
exceptions
in
your
programs
unusual
control
flows
finally
because
exceptions
are
a
sort
of
high
level
go
to
you
can
use
them
as
the
basis
for
implementing
exotic
control
flows
for
instance
although
the
language
does
not
explicitly
support
backtracking
it
can
be
implemented
in
python
by
using
exceptions
and
a
bit
of
support
logic
to
unwind
assignments
there
is
no
go
to
statement
in
python
thankfully
but
exceptions
can
sometimes
serve
similar
roles
we
ll
see
such
typical
use
cases
in
action
later
in
this
part
of
the
book
for
now
let
s
get
started
with
a
look
at
python
s
exception
processing
tools
exceptions
the
short
story
compared
to
some
other
core
language
topics
we
ve
met
in
this
book
exceptions
are
a
fairly
lightweight
tool
in
python
because
they
are
so
simple
let
s
jump
right
into
some
code
default
exception
handler
suppose
we
write
the
following
function
def
fetcher
obj
index
return
obj
index
there
s
not
much
to
this
function
it
simply
indexes
an
object
on
a
passed
in
index
in
normal
operation
it
returns
the
result
of
a
legal
index
x
spam
fetcher
x
m
like
x
however
if
we
ask
this
function
to
index
off
the
end
of
the
string
an
exception
will
be
triggered
when
the
function
tries
to
run
obj
index
python
detects
out
of
bounds
indexing
for
sequences
and
reports
it
by
raising
triggering
the
built
in
indexerror
exception
true
backtracking
is
an
advanced
topic
that
is
not
part
of
the
python
language
so
i
won
t
say
much
more
about
it
here
even
the
generator
functions
and
expressions
we
met
in
chapter
are
not
true
backtracking
they
simply
respond
to
next
g
requests
roughly
backtracking
undoes
all
computations
before
it
jumps
python
exceptions
do
not
i
e
variables
assigned
between
the
time
a
try
statement
is
entered
and
the
time
an
exception
is
raised
are
not
reset
to
their
prior
values
see
a
book
on
artificial
intelligence
or
the
prolog
or
icon
programming
languages
if
you
re
curious
exceptions
the
short
story
fetcher
x
traceback
most
recent
call
last
file
stdin
line
in
module
file
stdin
line
in
fetcher
indexerror
string
index
out
of
range
default
handler
shell
interface
because
our
code
does
not
explicitly
catch
this
exception
it
filters
back
up
to
the
top
level
of
the
program
and
invokes
the
default
exception
handler
which
simply
prints
the
standard
error
message
by
this
point
in
the
book
you
ve
probably
seen
your
share
of
standard
error
messages
they
include
the
exception
that
was
raised
along
with
a
stack
trace
a
list
of
all
the
lines
and
functions
that
were
active
when
the
exception
occurred
the
error
message
text
here
was
printed
by
python
it
can
vary
slightly
per
release
and
even
per
interactive
shell
when
coding
interactively
in
the
basic
shell
interface
the
filename
is
just
stdin
meaning
the
standard
input
stream
when
working
in
the
idle
gui
s
interactive
shell
the
filename
is
pyshell
and
source
lines
are
displayed
too
either
way
file
line
numbers
are
not
very
meaningful
when
there
is
no
file
we
ll
see
more
interesting
error
messages
later
in
this
part
of
the
book
fetcher
x
default
handler
idle
gui
interface
traceback
most
recent
call
last
file
pyshell
line
in
module
fetcher
x
file
pyshell
line
in
fetcher
return
obj
index
indexerror
string
index
out
of
range
in
a
more
realistic
program
launched
outside
the
interactive
prompt
after
printing
an
error
message
the
default
handler
at
the
top
also
terminates
the
program
immediately
that
course
of
action
makes
sense
for
simple
scripts
errors
often
should
be
fatal
and
the
best
you
can
do
when
they
occur
is
inspect
the
standard
error
message
catching
exceptions
sometimes
this
isn
t
what
you
want
though
server
programs
for
instance
typically
need
to
remain
active
even
after
internal
errors
if
you
don
t
want
the
default
exception
behavior
wrap
the
call
in
a
try
statement
to
catch
exceptions
yourself
try
fetcher
x
except
indexerror
print
got
exception
got
exception
catch
and
recover
now
python
jumps
to
your
handler
the
block
under
the
except
clause
that
names
the
exception
raised
automatically
when
an
exception
is
triggered
while
the
try
block
is
running
when
working
interactively
like
this
after
the
except
clause
runs
we
wind
up
back
at
the
python
prompt
in
a
more
realistic
program
try
statements
not
only
catch
exceptions
but
also
recover
from
them
chapter
exception
basics
def
catcher
try
fetcher
x
except
indexerror
print
got
exception
print
continuing
catcher
got
exception
continuing
this
time
after
the
exception
is
caught
and
handled
the
program
resumes
execution
after
the
entire
try
statement
that
caught
it
which
is
why
we
get
the
continuing
message
here
we
don
t
see
the
standard
error
message
and
the
program
continues
on
its
way
normally
raising
exceptions
so
far
we
ve
been
letting
python
raise
exceptions
for
us
by
making
mistakes
on
purpose
this
time
but
our
scripts
can
raise
exceptions
too
that
is
exceptions
can
be
raised
by
python
or
by
your
program
and
can
be
caught
or
not
to
trigger
an
exception
manually
simply
run
a
raise
statement
user
triggered
exceptions
are
caught
the
same
way
as
those
python
raises
the
following
may
not
be
the
most
useful
python
code
ever
penned
but
it
makes
the
point
try
raise
indexerror
except
indexerror
print
got
exception
got
exception
trigger
exception
manually
as
usual
if
they
re
not
caught
user
triggered
exceptions
are
propagated
up
to
the
toplevel
default
exception
handler
and
terminate
the
program
with
a
standard
error
message
raise
indexerror
traceback
most
recent
call
last
file
stdin
line
in
module
indexerror
as
we
ll
see
in
the
next
chapter
the
assert
statement
can
be
used
to
trigger
exceptions
too
it
s
a
conditional
raise
used
mostly
for
debugging
purposes
during
development
assert
false
nobody
expects
the
spanish
inquisition
traceback
most
recent
call
last
file
stdin
line
in
module
assertionerror
nobody
expects
the
spanish
inquisition
exceptions
the
short
story
user
defined
exceptions
the
raise
statement
introduced
in
the
prior
section
raises
a
built
in
exception
defined
in
python
s
built
in
scope
as
you
ll
learn
later
in
this
part
of
the
book
you
can
also
define
new
exceptions
of
your
own
that
are
specific
to
your
programs
user
defined
exceptions
are
coded
with
classes
which
inherit
from
a
built
in
exception
class
usually
the
class
named
exception
class
based
exceptions
allow
scripts
to
build
exception
categories
inherit
behavior
and
have
attached
state
information
got
class
bad
exception
pass
def
doomed
raise
bad
user
defined
exception
raise
an
instance
try
doomed
except
bad
print
got
bad
catch
class
name
bad
termination
actions
finally
try
statements
can
say
finally
that
is
they
may
include
finally
blocks
these
look
like
except
handlers
for
exceptions
but
the
try
finally
combination
specifies
termination
actions
that
always
execute
on
the
way
out
regardless
of
whether
an
exception
occurs
in
the
try
block
try
fetcher
x
finally
print
after
fetch
m
after
fetch
termination
actions
here
if
the
try
block
finishes
without
an
exception
the
finally
block
will
run
and
the
program
will
resume
after
the
entire
try
in
this
case
this
statement
seems
a
bit
silly
we
might
as
well
have
simply
typed
the
print
right
after
a
call
to
the
function
and
skipped
the
try
altogether
fetcher
x
print
after
fetch
there
is
a
problem
with
coding
this
way
though
if
the
function
call
raises
an
exception
the
print
will
never
be
reached
the
try
finally
combination
avoids
this
pitfall
when
an
exception
does
occur
in
a
try
block
finally
blocks
are
executed
while
the
program
is
being
unwound
chapter
exception
basics
def
after
try
fetcher
x
finally
print
after
fetch
print
after
try
after
after
fetch
traceback
most
recent
call
last
file
stdin
line
in
module
file
stdin
line
in
after
file
stdin
line
in
fetcher
indexerror
string
index
out
of
range
here
we
don
t
get
the
after
try
message
because
control
does
not
resume
after
the
try
finally
block
when
an
exception
occurs
instead
python
jumps
back
to
run
the
finally
action
and
then
propagates
the
exception
up
to
a
prior
handler
in
this
case
to
the
default
handler
at
the
top
if
we
change
the
call
inside
this
function
so
as
not
to
trigger
an
exception
the
finally
code
still
runs
but
the
program
continues
after
the
try
def
after
try
fetcher
x
finally
print
after
fetch
print
after
try
after
after
fetch
after
try
in
practice
try
except
combinations
are
useful
for
catching
and
recovering
from
exceptions
and
try
finally
combinations
come
in
handy
to
guarantee
that
termination
actions
will
fire
regardless
of
any
exceptions
that
may
occur
in
the
try
block
s
code
for
instance
you
might
use
try
except
to
catch
errors
raised
by
code
that
you
import
from
a
third
party
library
and
try
finally
to
ensure
that
calls
to
close
files
or
terminate
server
connections
are
always
run
we
ll
see
some
such
practical
examples
later
in
this
part
of
the
book
although
they
serve
conceptually
distinct
purposes
as
of
python
we
can
now
mix
except
and
finally
clauses
in
the
same
try
statement
the
finally
is
run
on
the
way
out
regardless
of
whether
an
exception
was
raised
and
regardless
of
whether
the
exception
was
caught
by
an
except
clause
as
we
ll
learn
in
the
next
chapter
python
and
provide
an
alternative
to
try
finally
when
using
some
types
of
objects
the
with
as
statement
runs
an
object
s
context
management
logic
to
guarantee
that
termination
actions
occur
exceptions
the
short
story
with
open
lumberjack
txt
w
as
file
file
write
the
larch
n
always
close
file
on
exit
although
this
option
requires
fewer
lines
of
code
it
s
only
applicable
when
processing
certain
object
types
so
try
finally
is
a
more
general
termination
structure
on
the
other
hand
with
as
may
also
run
startup
actions
and
supports
user
defined
context
management
code
why
you
will
care
error
checks
one
way
to
see
how
exceptions
are
useful
is
to
compare
coding
styles
in
python
and
languages
without
exceptions
for
instance
if
you
want
to
write
robust
programs
in
the
c
language
you
generally
have
to
test
return
values
or
status
codes
after
every
operation
that
could
possibly
go
astray
and
propagate
the
results
of
the
tests
as
your
programs
run
dostuff
c
program
if
dofirstthing
error
detect
errors
everywhere
return
error
even
if
not
handled
here
if
donextthing
error
return
error
return
dolastthing
main
if
dostuff
error
badending
else
goodending
in
fact
realistic
c
programs
often
have
as
much
code
devoted
to
error
detection
as
to
doing
actual
work
but
in
python
you
don
t
have
to
be
so
methodical
and
neurotic
you
can
instead
wrap
arbitrarily
vast
pieces
of
a
program
in
exception
handlers
and
simply
write
the
parts
that
do
the
actual
work
assuming
all
is
well
def
dostuff
dofirstthing
donextthing
dolastthing
python
code
we
don
t
care
about
exceptions
here
so
we
don
t
need
to
detect
them
if
name
main
try
dostuff
this
is
where
we
care
about
results
except
so
it
s
the
only
place
we
must
check
badending
else
goodending
chapter
exception
basics
because
control
jumps
immediately
to
a
handler
when
an
exception
occurs
there
s
no
need
to
instrument
all
your
code
to
guard
for
errors
moreover
because
python
detects
errors
automatically
your
code
usually
doesn
t
need
to
check
for
errors
in
the
first
place
the
upshot
is
that
exceptions
let
you
largely
ignore
the
unusual
cases
and
avoid
error
checking
code
chapter
summary
and
that
is
the
majority
of
the
exception
story
exceptions
really
are
a
simple
tool
to
summarize
python
exceptions
are
a
high
level
control
flow
device
they
may
be
raised
by
python
or
by
your
own
programs
in
both
cases
they
may
be
ignored
to
trigger
the
default
error
message
or
caught
by
try
statements
to
be
processed
by
your
code
the
try
statement
comes
in
two
logical
formats
that
as
of
python
can
be
combined
one
that
handles
exceptions
and
one
that
executes
finalization
code
regardless
of
whether
exceptions
occur
or
not
python
s
raise
and
assert
statements
trigger
exceptions
on
demand
both
built
ins
and
new
exceptions
we
define
with
classes
the
with
as
statement
is
an
alternative
way
to
ensure
that
termination
actions
are
carried
out
for
objects
that
support
it
in
the
rest
of
this
part
of
the
book
we
ll
fill
in
some
of
the
details
about
the
statements
involved
examine
the
other
sorts
of
clauses
that
can
appear
under
a
try
and
discuss
class
based
exception
objects
the
next
chapter
begins
our
tour
by
taking
a
closer
look
at
the
statements
we
introduced
here
before
you
turn
the
page
though
here
are
a
few
quiz
questions
to
review
test
your
knowledge
quiz
name
three
things
that
exception
processing
is
good
for
what
happens
to
an
exception
if
you
don
t
do
anything
special
to
handle
it
how
can
your
script
recover
from
an
exception
name
two
ways
to
trigger
exceptions
in
your
script
name
two
ways
to
specify
actions
to
be
run
at
termination
time
whether
an
exception
occurs
or
not
test
your
knowledge
answers
exception
processing
is
useful
for
error
handling
termination
actions
and
event
notification
it
can
also
simplify
the
handling
of
special
cases
and
can
be
used
to
implement
alternative
control
flows
in
general
exception
processing
also
cuts
test
your
knowledge
answers
down
on
the
amount
of
error
checking
code
your
program
may
require
because
all
errors
filter
up
to
handlers
you
may
not
need
to
test
the
outcome
of
every
operation
any
uncaught
exception
eventually
filters
up
to
the
default
exception
handler
python
provides
at
the
top
of
your
program
this
handler
prints
the
familiar
error
message
and
shuts
down
your
program
if
you
don
t
want
the
default
message
and
shutdown
you
can
code
try
except
statements
to
catch
and
recover
from
exceptions
that
are
raised
once
an
exception
is
caught
the
exception
is
terminated
and
your
program
continues
the
raise
and
assert
statements
can
be
used
to
trigger
an
exception
exactly
as
if
it
had
been
raised
by
python
itself
in
principle
you
can
also
raise
an
exception
by
making
a
programming
mistake
but
that
s
not
usually
an
explicit
goal
the
try
finally
statement
can
be
used
to
ensure
actions
are
run
after
a
block
of
code
exits
regardless
of
whether
it
raises
an
exception
or
not
the
with
as
statement
can
also
be
used
to
ensure
termination
actions
are
run
but
only
when
processing
object
types
that
support
it
chapter
exception
basics
chapter
exception
coding
details
in
the
prior
chapter
we
took
a
quick
look
at
exception
related
statements
in
action
here
we
re
going
to
dig
a
bit
deeper
this
chapter
provides
a
more
formal
introduction
to
exception
processing
syntax
in
python
specifically
we
ll
explore
the
details
behind
the
try
raise
assert
and
with
statements
as
we
ll
see
although
these
statements
are
mostly
straightforward
they
offer
powerful
tools
for
dealing
with
exceptions
in
python
code
one
procedural
note
up
front
the
exception
story
has
changed
in
major
ways
in
recent
years
as
of
python
the
finally
clause
can
appear
in
the
same
try
statement
as
except
and
else
clauses
previously
they
could
not
be
combined
also
as
of
python
and
the
new
with
context
manager
statement
has
become
official
and
user
defined
exceptions
must
now
be
coded
as
class
instances
which
should
inherit
from
a
built
in
exception
superclass
moreover
sports
slightly
modified
syntax
for
the
raise
statement
and
except
clauses
i
will
focus
on
the
state
of
exceptions
in
python
and
in
this
edition
but
because
you
are
still
very
likely
to
see
the
original
techniques
in
code
for
some
time
to
come
along
the
way
i
ll
point
out
how
things
have
evolved
in
this
domain
the
try
except
else
statement
now
that
we
ve
seen
the
basics
it
s
time
for
the
details
in
the
following
discussion
i
ll
first
present
try
except
else
and
try
finally
as
separate
statements
because
in
versions
of
python
prior
to
they
serve
distinct
roles
and
cannot
be
combined
as
mentioned
in
the
preceding
note
in
python
and
later
except
and
finally
can
be
mixed
in
a
single
try
statement
i
ll
explain
the
implications
of
this
change
after
we
ve
explored
the
two
original
forms
in
isolation
the
try
is
a
compound
statement
its
most
complete
form
is
sketched
below
it
starts
with
a
try
header
line
followed
by
a
block
of
usually
indented
statements
then
one
or
more
except
clauses
that
identify
exceptions
to
be
caught
and
an
optional
else
clause
at
the
end
the
words
try
except
and
else
are
associated
by
indenting
them
to
the
same
level
i
e
lining
them
up
vertically
for
reference
here
s
the
general
format
in
python
try
statements
except
name
statements
except
name
name
statements
except
name
as
data
statements
except
statements
else
statements
run
this
main
action
first
run
if
name
is
raised
during
try
block
run
if
any
of
these
exceptions
occur
run
if
name
is
raised
and
get
instance
raised
run
for
all
other
exceptions
raised
run
if
no
exception
was
raised
during
try
block
in
this
statement
the
block
under
the
try
header
represents
the
main
action
of
the
statement
the
code
you
re
trying
to
run
the
except
clauses
define
handlers
for
exceptions
raised
during
the
try
block
and
the
else
clause
if
coded
provides
a
handler
to
be
run
if
no
exceptions
occur
the
data
entry
here
has
to
do
with
a
feature
of
raise
statements
and
exception
classes
which
we
will
discuss
later
in
this
chapter
here
s
how
try
statements
work
when
a
try
statement
is
entered
python
marks
the
current
program
context
so
it
can
return
to
it
if
an
exception
occurs
the
statements
nested
under
the
try
header
are
run
first
what
happens
next
depends
on
whether
exceptions
are
raised
while
the
try
block
s
statements
are
running
if
an
exception
does
occur
while
the
try
block
s
statements
are
running
python
jumps
back
to
the
try
and
runs
the
statements
under
the
first
except
clause
that
matches
the
raised
exception
control
resumes
below
the
entire
try
statement
after
the
except
block
runs
unless
the
except
block
raises
another
exception
if
an
exception
happens
in
the
try
block
and
no
except
clause
matches
the
exception
is
propagated
up
to
the
last
matching
try
statement
that
was
entered
in
the
program
or
if
it
s
the
first
such
statement
to
the
top
level
of
the
process
in
which
case
python
kills
the
program
and
prints
a
default
error
message
if
no
exception
occurs
while
the
statements
under
the
try
header
run
python
runs
the
statements
under
the
else
line
if
present
and
control
then
resumes
below
the
entire
try
statement
in
other
words
except
clauses
catch
any
exceptions
that
happen
while
the
try
block
is
running
and
the
else
clause
runs
only
if
no
exceptions
happen
while
the
try
block
runs
except
clauses
are
focused
exception
handlers
they
catch
exceptions
that
occur
only
within
the
statements
in
the
associated
try
block
however
as
the
try
block
s
state
ments
can
call
functions
coded
elsewhere
in
a
program
the
source
of
an
exception
may
be
outside
the
try
statement
itself
i
ll
have
more
to
say
about
this
when
we
explore
try
nesting
in
chapter
chapter
exception
coding
details
try
statement
clauses
when
you
write
a
try
statement
a
variety
of
clauses
can
appear
after
the
try
header
table
summarizes
all
the
possible
forms
you
must
use
at
least
one
we
ve
already
met
some
of
these
as
you
know
except
clauses
catch
exceptions
finally
clauses
run
on
the
way
out
and
else
clauses
run
if
no
exceptions
are
encountered
syntactically
there
may
be
any
number
of
except
clauses
but
you
can
code
else
only
if
there
is
at
least
one
except
and
there
can
be
only
one
else
and
one
finally
through
python
the
finally
clause
must
appear
alone
without
else
or
except
the
try
finally
is
really
a
different
statement
as
of
python
however
a
finally
can
appear
in
the
same
statement
as
except
and
else
more
on
the
ordering
rules
later
in
this
chapter
when
we
meet
the
unified
try
statement
table
try
statement
clause
forms
clause
form
interpretation
except
catch
all
or
all
other
exception
types
except
name
catch
a
specific
exception
only
except
name
as
value
catch
the
listed
exception
and
its
instance
except
name
name
catch
any
of
the
listed
exceptions
except
name
name
as
value
catch
any
listed
exception
and
its
instance
else
run
if
no
exceptions
are
raised
finally
always
perform
this
block
we
ll
explore
the
entries
with
the
extra
as
value
part
when
we
meet
the
raise
statement
they
provide
access
to
the
objects
that
are
raised
as
exceptions
the
first
and
fourth
entries
in
table
are
new
here
except
clauses
that
list
no
exception
name
except
catch
all
exceptions
not
previously
listed
in
the
try
statement
except
clauses
that
list
a
set
of
exceptions
in
parentheses
except
e
e
e
catch
any
of
the
listed
exceptions
because
python
looks
for
a
match
within
a
given
try
by
inspecting
the
except
clauses
from
top
to
bottom
the
parenthesized
version
has
the
same
effect
as
listing
each
exception
in
its
own
except
clause
but
you
have
to
code
the
statement
body
only
once
here
s
an
example
of
multiple
except
clauses
at
work
which
demonstrates
just
how
specific
your
handlers
can
be
try
action
except
nameerror
except
indexerror
the
try
except
else
statement
except
keyerror
except
attributeerror
typeerror
syntaxerror
else
in
this
example
if
an
exception
is
raised
while
the
call
to
the
action
function
is
running
python
returns
to
the
try
and
searches
for
the
first
except
that
names
the
exception
raised
it
inspects
the
except
clauses
from
top
to
bottom
and
left
to
right
and
runs
the
statements
under
the
first
one
that
matches
if
none
match
the
exception
is
propagated
past
this
try
note
that
the
else
runs
only
when
no
exception
occurs
in
action
it
does
not
run
when
an
exception
without
a
matching
except
is
raised
if
you
really
want
a
general
catch
all
clause
an
empty
except
does
the
trick
try
action
except
nameerror
except
indexerror
except
else
handle
nameerror
handle
indexerror
handle
all
other
exceptions
handle
the
no
exception
case
the
empty
except
clause
is
a
sort
of
wildcard
feature
because
it
catches
everything
it
allows
your
handlers
to
be
as
general
or
specific
as
you
like
in
some
scenarios
this
form
may
be
more
convenient
than
listing
all
possible
exceptions
in
a
try
for
example
the
following
catches
everything
without
listing
anything
try
action
except
catch
all
possible
exceptions
empty
excepts
also
raise
some
design
issues
though
although
convenient
they
may
catch
unexpected
system
exceptions
unrelated
to
your
code
and
they
may
inadvertently
intercept
exceptions
meant
for
another
handler
for
example
even
system
exit
calls
in
python
trigger
exceptions
and
you
usually
want
these
to
pass
that
said
this
structure
may
also
catch
genuine
programming
mistakes
for
you
which
you
probably
want
to
see
an
error
message
we
ll
revisit
this
as
a
gotcha
at
the
end
of
this
part
of
the
book
for
now
i
ll
just
say
use
with
care
python
introduced
an
alternative
that
solves
one
of
these
problems
catching
an
exception
named
exception
has
almost
the
same
effect
as
an
empty
except
but
ignores
exceptions
related
to
system
exits
try
action
except
exception
catch
all
possible
exceptions
except
exits
chapter
exception
coding
details
this
has
most
of
the
same
convenience
of
the
empty
except
but
also
most
of
the
same
dangers
we
ll
explore
how
this
form
works
its
voodoo
in
the
next
chapter
when
we
study
exception
classes
version
skew
note
python
requires
the
except
e
as
v
handler
clause
form
listed
in
table
and
used
in
this
book
rather
than
the
older
except
e
v
form
the
latter
form
is
still
available
but
not
recommended
in
python
if
used
it
s
converted
to
the
former
the
change
was
made
to
eliminate
errors
that
occur
when
confusing
the
older
form
with
two
alternate
exceptions
properly
coded
in
as
except
e
e
because
supports
the
as
form
only
commas
in
a
handler
clause
are
always
taken
to
mean
a
tuple
regardless
of
whether
parentheses
are
used
or
not
and
the
values
are
interpreted
as
alternative
exceptions
to
be
caught
this
change
also
modifies
the
scoping
rules
with
the
new
as
syntax
the
variable
v
is
deleted
at
the
end
of
the
except
block
the
try
else
clause
the
purpose
of
the
else
clause
is
not
always
immediately
obvious
to
python
newcomers
without
it
though
there
is
no
way
to
tell
without
setting
and
checking
boolean
flags
whether
the
flow
of
control
has
proceeded
past
a
try
statement
because
no
exception
was
raised
or
because
an
exception
occurred
and
was
handled
try
run
code
except
indexerror
handle
exception
did
we
get
here
because
the
try
failed
or
not
much
like
the
way
else
clauses
in
loops
make
the
exit
cause
more
apparent
the
else
clause
provides
syntax
in
a
try
that
makes
what
has
happened
obvious
and
unambiguous
try
run
code
except
indexerror
handle
exception
else
no
exception
occurred
you
can
almost
emulate
an
else
clause
by
moving
its
code
into
the
try
block
try
run
code
no
exception
occurred
except
indexerror
handle
exception
this
can
lead
to
incorrect
exception
classifications
though
if
the
no
exception
occurred
action
triggers
an
indexerror
it
will
register
as
a
failure
of
the
try
block
and
the
try
except
else
statement
erroneously
trigger
the
exception
handler
below
the
try
subtle
but
true
by
using
an
explicit
else
clause
instead
you
make
the
logic
more
obvious
and
guarantee
that
except
handlers
will
run
only
for
real
failures
in
the
code
you
re
wrapping
in
a
try
not
for
failures
in
the
else
case
s
action
example
default
behavior
because
the
control
flow
through
a
program
is
easier
to
capture
in
python
than
in
english
let
s
run
some
examples
that
further
illustrate
exception
basics
i
ve
mentioned
that
exceptions
not
caught
by
try
statements
percolate
up
to
the
top
level
of
the
python
process
and
run
python
s
default
exception
handling
logic
i
e
python
terminates
the
running
program
and
prints
a
standard
error
message
let
s
look
at
an
example
running
the
following
module
file
bad
py
generates
a
divide
by
zero
exception
def
gobad
x
y
return
x
y
def
gosouth
x
print
gobad
x
gosouth
because
the
program
ignores
the
exception
it
triggers
python
kills
the
program
and
prints
a
message
python
bad
py
traceback
most
recent
call
last
file
bad
py
line
in
module
gosouth
file
bad
py
line
in
gosouth
print
gobad
x
file
bad
py
line
in
gobad
return
x
y
zerodivisionerror
int
division
or
modulo
by
zero
i
ran
this
in
a
shell
widow
with
python
the
message
consists
of
a
stack
trace
traceback
and
the
name
of
and
details
about
the
exception
that
was
raised
the
stack
trace
lists
all
lines
active
when
the
exception
occurred
from
oldest
to
newest
note
that
because
we
re
not
working
at
the
interactive
prompt
in
this
case
the
file
and
line
number
information
is
more
useful
for
example
here
we
can
see
that
the
bad
divide
happens
at
the
last
entry
in
the
trace
line
of
the
file
bad
py
a
return
statement
because
python
detects
and
reports
all
errors
at
runtime
by
raising
exceptions
exceptions
are
intimately
bound
up
with
the
ideas
of
error
handling
and
debugging
in
general
as
mentioned
in
the
prior
chapter
the
text
of
error
messages
and
stack
traces
tends
to
vary
slightly
over
time
and
shells
don
t
be
alarmed
if
your
error
messages
don
t
exactly
match
mine
when
i
ran
this
example
in
python
s
idle
gui
for
instance
its
error
message
text
showed
filenames
with
full
absolute
directory
paths
chapter
exception
coding
details
if
you
ve
worked
through
this
book
s
examples
you
ve
undoubtedly
seen
an
exception
or
two
along
the
way
even
typos
usually
generate
a
syntaxerror
or
other
exception
when
a
file
is
imported
or
executed
that
s
when
the
compiler
is
run
by
default
you
get
a
useful
error
display
like
the
one
just
shown
which
helps
you
track
down
the
problem
often
this
standard
error
message
is
all
you
need
to
resolve
problems
in
your
code
for
more
heavy
duty
debugging
jobs
you
can
catch
exceptions
with
try
statements
or
use
one
of
the
debugging
tools
that
i
introduced
in
chapter
and
will
summarize
again
in
chapter
such
as
the
pdb
standard
library
module
example
catching
built
in
exceptions
python
s
default
exception
handling
is
often
exactly
what
you
want
especially
for
code
in
a
top
level
script
file
an
error
generally
should
terminate
your
program
immediately
for
many
programs
there
is
no
need
to
be
more
specific
about
errors
in
your
code
sometimes
though
you
ll
want
to
catch
errors
and
recover
from
them
instead
if
you
don
t
want
your
program
terminated
when
python
raises
an
exception
simply
catch
it
by
wrapping
the
program
logic
in
a
try
this
is
an
important
capability
for
programs
such
as
network
servers
which
must
keep
running
persistently
for
example
the
following
code
catches
and
recovers
from
the
typeerror
python
raises
immediately
when
you
try
to
concatenate
a
list
and
a
string
the
operator
expects
the
same
sequence
type
on
both
sides
def
kaboom
x
y
print
x
y
trigger
typeerror
try
kaboom
spam
except
typeerror
print
hello
world
print
resuming
here
catch
and
recover
here
continue
here
if
exception
or
not
when
the
exception
occurs
in
the
function
kaboom
control
jumps
to
the
try
statement
s
except
clause
which
prints
a
message
since
an
exception
is
dead
after
it
s
been
caught
like
this
the
program
continues
executing
below
the
try
rather
than
being
terminated
by
python
in
effect
the
code
processes
and
clears
the
error
and
your
script
recovers
python
kaboom
py
hello
world
resuming
here
notice
that
once
you
ve
caught
an
error
control
resumes
at
the
place
where
you
caught
it
i
e
after
the
try
there
is
no
direct
way
to
go
back
to
the
place
where
the
exception
occurred
here
in
the
function
kaboom
in
a
sense
this
makes
exceptions
more
like
the
try
except
else
statement
simple
jumps
than
function
calls
there
is
no
way
to
return
to
the
code
that
triggered
the
error
the
try
finally
statement
the
other
flavor
of
the
try
statement
is
a
specialization
that
has
to
do
with
finalization
actions
if
a
finally
clause
is
included
in
a
try
python
will
always
run
its
block
of
statements
on
the
way
out
of
the
try
statement
whether
an
exception
occurred
while
the
try
block
was
running
or
not
its
general
form
is
try
statements
finally
statements
run
this
action
first
always
run
this
code
on
the
way
out
with
this
variant
python
begins
by
running
the
statement
block
associated
with
the
try
header
line
what
happens
next
depends
on
whether
an
exception
occurs
during
the
try
block
if
no
exception
occurs
while
the
try
block
is
running
python
jumps
back
to
run
the
finally
block
and
then
continues
execution
past
below
the
try
statement
if
an
exception
does
occur
during
the
try
block
s
run
python
still
comes
back
and
runs
the
finally
block
but
it
then
propagates
the
exception
up
to
a
higher
try
or
the
top
level
default
handler
the
program
does
not
resume
execution
below
the
try
statement
that
is
the
finally
block
is
run
even
if
an
exception
is
raised
but
unlike
an
except
the
finally
does
not
terminate
the
exception
it
continues
being
raised
after
the
finally
block
runs
the
try
finally
form
is
useful
when
you
want
to
be
completely
sure
that
an
action
will
happen
after
some
code
runs
regardless
of
the
exception
behavior
of
the
program
in
practice
it
allows
you
to
specify
cleanup
actions
that
always
must
occur
such
as
file
closes
and
server
disconnects
note
that
the
finally
clause
cannot
be
used
in
the
same
try
statement
as
except
and
else
in
python
and
earlier
so
the
try
finally
is
best
thought
of
as
a
distinct
statement
form
if
you
are
using
an
older
release
in
python
and
later
however
finally
can
appear
in
the
same
statement
as
except
and
else
so
today
there
is
really
a
single
try
statement
with
many
optional
clauses
more
about
this
shortly
whichever
version
you
use
though
the
finally
clause
still
serves
the
same
purpose
to
specify
cleanup
actions
that
must
always
be
run
regardless
of
any
exceptions
as
we
ll
also
see
later
in
this
chapter
in
python
and
the
new
with
statement
and
its
context
managers
provide
an
object
based
way
to
do
similar
work
for
exit
actions
unlike
finally
this
new
statement
also
supports
entry
actions
but
it
is
limited
in
scope
to
objects
that
implement
the
context
manager
protocol
chapter
exception
coding
details
example
coding
termination
actions
with
try
finally
we
saw
some
simple
try
finally
examples
in
the
prior
chapter
here
s
a
more
realistic
example
that
illustrates
a
typical
role
for
this
statement
class
myerror
exception
pass
def
stuff
file
raise
myerror
file
open
data
w
try
stuff
file
finally
file
close
print
not
reached
open
an
output
file
raises
exception
always
close
file
to
flush
output
buffers
continue
here
only
if
no
exception
in
this
code
we
ve
wrapped
a
call
to
a
file
processing
function
in
a
try
with
a
finally
clause
to
make
sure
that
the
file
is
always
closed
and
thus
finalized
whether
the
function
triggers
an
exception
or
not
this
way
later
code
can
be
sure
that
the
file
s
output
buffer
s
content
has
been
flushed
from
memory
to
disk
a
similar
code
structure
can
guarantee
that
server
connections
are
closed
and
so
on
as
we
learned
in
chapter
file
objects
are
automatically
closed
on
garbage
collection
this
is
especially
useful
for
temporary
files
that
we
don
t
assign
to
variables
however
it
s
not
always
easy
to
predict
when
garbage
collection
will
occur
especially
in
larger
programs
the
try
statement
makes
file
closes
more
explicit
and
predictable
and
pertains
to
a
specific
block
of
code
it
ensures
that
the
file
will
be
closed
on
block
exit
regardless
of
whether
an
exception
occurs
or
not
this
particular
example
s
function
isn
t
all
that
useful
it
just
raises
an
exception
but
wrapping
calls
in
try
finally
statements
is
a
good
way
to
ensure
that
your
closing
time
i
e
termination
activities
always
run
again
python
always
runs
the
code
in
your
finally
blocks
regardless
of
whether
an
exception
happens
in
the
try
block
when
the
function
here
raises
its
exception
the
control
flow
jumps
back
and
runs
the
finally
block
to
close
the
file
the
exception
is
then
propagated
on
to
either
another
try
or
the
default
top
level
handler
which
prints
the
standard
error
message
and
shuts
down
the
program
the
statement
after
this
try
is
never
reached
if
the
function
here
did
not
raise
an
exception
the
program
would
still
execute
the
finally
block
to
close
the
file
but
it
would
then
continue
below
the
entire
try
statement
notice
that
the
user
defined
exception
here
is
again
defined
with
a
class
as
we
ll
see
in
the
next
chapter
exceptions
today
must
all
be
class
instances
in
both
and
unless
python
crashes
completely
of
course
it
does
a
good
job
of
avoiding
this
though
by
checking
all
possible
errors
as
a
program
runs
when
a
program
does
crash
hard
it
is
usually
due
to
a
bug
in
linked
in
c
extension
code
outside
of
python
s
scope
the
try
finally
statement
unified
try
except
finally
in
all
versions
of
python
prior
to
release
for
its
first
years
of
life
more
or
less
the
try
statement
came
in
two
flavors
and
was
really
two
separate
statements
we
could
either
use
a
finally
to
ensure
that
cleanup
code
was
always
run
or
write
except
blocks
to
catch
and
recover
from
specific
exceptions
and
optionally
specify
an
else
clause
to
be
run
if
no
exceptions
occurred
that
is
the
finally
clause
could
not
be
mixed
with
except
and
else
this
was
partly
because
of
implementation
issues
and
partly
because
the
meaning
of
mixing
the
two
seemed
obscure
catching
and
recovering
from
exceptions
seemed
a
disjoint
concept
from
performing
cleanup
actions
in
python
and
later
though
including
and
the
versions
used
in
this
book
the
two
statements
have
merged
today
we
can
mix
finally
except
and
else
clauses
in
the
same
statement
that
is
we
can
now
write
a
statement
of
this
form
try
merged
form
main
action
except
exception
handler
except
exception
handler
else
else
block
finally
finally
block
the
code
in
this
statement
s
main
action
block
is
executed
first
as
usual
if
that
code
raises
an
exception
all
the
except
blocks
are
tested
one
after
another
looking
for
a
match
to
the
exception
raised
if
the
exception
raised
is
exception
the
handler
block
is
executed
if
it
s
exception
handler
is
run
and
so
on
if
no
exception
is
raised
the
else
block
is
executed
no
matter
what
s
happened
previously
the
finally
block
is
executed
once
the
main
action
block
is
complete
and
any
raised
exceptions
have
been
handled
in
fact
the
code
in
the
finally
block
will
be
run
even
if
there
is
an
error
in
an
exception
handler
or
the
else
block
and
a
new
exception
is
raised
as
always
the
finally
clause
does
not
end
the
exception
if
an
exception
is
active
when
the
finally
block
is
executed
it
continues
to
be
propagated
after
the
finallyblock
runs
and
control
jumps
somewhere
else
in
the
program
to
another
try
or
to
the
default
top
level
handler
if
no
exception
is
active
when
the
finally
is
run
control
resumes
after
the
entire
try
statement
the
net
effect
is
that
the
finally
is
always
run
regardless
of
whether
an
exception
occurred
in
the
main
action
and
was
handled
an
exception
occurred
in
the
main
action
and
was
not
handled
chapter
exception
coding
details
no
exceptions
occurred
in
the
main
action
a
new
exception
was
triggered
in
one
of
the
handlers
again
the
finally
serves
to
specify
cleanup
actions
that
must
always
occur
on
the
way
out
of
the
try
regardless
of
what
exceptions
have
been
raised
or
handled
unified
try
statement
syntax
when
combined
like
this
the
try
statement
must
have
either
an
except
or
a
finally
and
the
order
of
its
parts
must
be
like
this
try
except
else
finally
where
the
else
and
finally
are
optional
and
there
may
be
zero
or
more
except
but
there
must
be
at
least
one
except
if
an
else
appears
really
the
try
statement
consists
of
two
parts
excepts
with
an
optional
else
and
or
the
finally
in
fact
it
s
more
accurate
to
describe
the
merged
statement
s
syntactic
form
this
way
square
brackets
mean
optional
and
star
means
zero
or
more
here
try
statements
except
type
as
value
statements
except
type
as
value
statements
else
statements
finally
statements
try
format
type
value
in
python
format
statements
finally
statements
because
of
these
rules
the
else
can
appear
only
if
there
is
at
least
one
except
and
it
s
always
possible
to
mix
except
and
finally
regardless
of
whether
an
else
appears
or
not
it
s
also
possible
to
mix
finally
and
else
but
only
if
an
except
appears
too
though
the
except
can
omit
an
exception
name
to
catch
everything
and
run
a
raise
statement
described
later
to
reraise
the
current
exception
if
you
violate
any
of
these
ordering
rules
python
will
raise
a
syntax
error
exception
before
your
code
runs
combining
finally
and
except
by
nesting
prior
to
python
it
is
actually
possible
to
combine
finally
and
except
clauses
in
a
try
by
syntactically
nesting
a
try
except
in
the
try
block
of
a
try
finally
statement
we
ll
explore
this
technique
more
fully
in
chapter
in
fact
the
following
has
the
same
effect
as
the
new
merged
form
shown
at
the
start
of
this
section
unified
try
except
finally
nested
equivalent
to
merged
form
try
try
main
action
except
exception
handler
except
exception
handler
else
no
error
finally
cleanup
again
the
finally
block
is
always
run
on
the
way
out
regardless
of
what
happened
in
the
main
action
and
regardless
of
any
exception
handlers
run
in
the
nested
try
trace
through
the
four
cases
listed
previously
to
see
how
this
works
the
same
since
an
else
always
requires
an
except
this
nested
form
even
sports
the
same
mixing
constraints
of
the
unified
statement
form
outlined
in
the
preceding
section
however
this
nested
equivalent
is
more
obscure
and
requires
more
code
than
the
new
merged
form
one
four
character
line
at
least
mixing
finally
into
the
same
statement
makes
your
code
easier
to
write
and
read
so
this
is
the
generally
preferred
technique
today
unified
try
example
here
s
a
demonstration
of
the
merged
try
statement
form
at
work
the
following
file
mergedexc
py
codes
four
common
scenarios
with
print
statements
that
describe
the
meaning
of
each
sep
n
print
sep
exception
raised
and
caught
try
x
spam
except
indexerror
print
except
run
finally
print
finally
run
print
after
run
print
sep
no
exception
raised
try
x
spam
except
indexerror
print
except
run
finally
print
finally
run
print
after
run
print
sep
no
exception
raised
with
else
try
chapter
exception
coding
details
x
spam
except
indexerror
print
except
run
else
print
else
run
finally
print
finally
run
print
after
run
print
sep
exception
raised
but
not
caught
try
x
except
indexerror
print
except
run
finally
print
finally
run
print
after
run
when
this
code
is
run
the
following
output
is
produced
in
python
actually
its
behavior
and
output
are
the
same
in
because
the
print
calls
each
print
a
single
item
trace
through
the
code
to
see
how
exception
handling
produces
the
output
of
each
of
the
four
tests
here
c
misc
c
python
python
mergedexc
py
exception
raised
and
caught
except
run
finally
run
after
run
no
exception
raised
finally
run
after
run
no
exception
raised
with
else
else
run
finally
run
after
run
exception
raised
but
not
caught
finally
run
traceback
most
recent
call
last
file
mergedexc
py
line
in
module
x
zerodivisionerror
int
division
or
modulo
by
zero
this
example
uses
built
in
operations
in
the
main
action
to
trigger
exceptions
or
not
and
it
relies
on
the
fact
that
python
always
checks
for
errors
as
code
is
running
the
next
section
shows
how
to
raise
exceptions
manually
instead
unified
try
except
finally
the
raise
statement
to
trigger
exceptions
explicitly
you
can
code
raise
statements
their
general
form
is
simple
a
raise
statement
consists
of
the
word
raise
optionally
followed
by
the
class
to
be
raised
or
an
instance
of
it
raise
instance
raise
class
raise
raise
instance
of
class
make
and
raise
instance
of
class
reraise
the
most
recent
exception
as
mentioned
earlier
exceptions
are
always
instances
of
classes
in
python
and
hence
the
first
raise
form
here
is
the
most
common
we
provide
an
instance
directly
either
created
before
the
raise
or
within
the
raise
statement
itself
if
we
pass
a
class
instead
python
calls
the
class
with
no
constructor
arguments
to
create
an
instance
to
be
raised
this
form
is
equivalent
to
adding
parentheses
after
the
class
reference
the
last
form
reraises
the
most
recently
raised
exception
it
s
commonly
used
in
exception
handlers
to
propagate
exceptions
that
have
been
caught
to
make
this
clearer
let
s
look
at
some
examples
with
built
in
exceptions
the
following
two
forms
are
equivalent
both
raise
an
instance
of
the
exception
class
named
but
the
first
creates
the
instance
implicitly
raise
indexerror
raise
indexerror
class
instance
created
instance
created
in
statement
we
can
also
create
the
instance
ahead
of
time
because
the
raise
statement
accepts
any
kind
of
object
reference
the
following
two
examples
raise
indexerror
just
like
the
prior
two
exc
indexerror
raise
exc
create
instance
ahead
of
time
excs
indexerror
typeerror
raise
excs
when
an
exception
is
raised
python
sends
the
raised
instance
along
with
the
exception
if
a
try
includes
an
except
name
as
x
clause
the
variable
x
will
be
assigned
the
instance
provided
in
the
raise
try
except
indexerror
as
x
x
assigned
the
raised
instance
object
the
as
is
optional
in
a
try
handler
if
it
s
omitted
the
instance
is
simply
not
assigned
to
a
name
but
including
it
allows
the
handler
to
access
both
data
in
the
instance
and
methods
in
the
exception
class
this
model
works
the
same
for
user
defined
exceptions
we
code
with
classes
the
following
for
example
passes
to
the
exception
class
constructor
arguments
that
become
available
in
the
handler
through
the
assigned
instance
chapter
exception
coding
details
class
myexc
exception
pass
raise
myexc
spam
exception
class
with
constructor
args
try
except
myexc
as
x
instance
attributes
available
in
handler
print
x
args
because
this
encroaches
on
the
next
chapter
s
topic
though
i
ll
defer
further
details
until
then
regardless
of
how
you
name
them
exceptions
are
always
identified
by
instance
objects
and
at
most
one
is
active
at
any
given
time
once
caught
by
an
except
clause
anywhere
in
the
program
an
exception
dies
i
e
won
t
propagate
to
another
try
unless
it
s
reraised
by
another
raise
statement
or
error
propagating
exceptions
with
raise
a
raise
statement
that
does
not
include
an
exception
name
or
extra
data
value
simply
reraises
the
current
exception
this
form
is
typically
used
if
you
need
to
catch
and
handle
an
exception
but
don
t
want
the
exception
to
die
in
your
code
try
raise
indexerror
spam
except
indexerror
print
propagating
raise
propagating
traceback
most
recent
call
last
file
stdin
line
in
module
indexerror
spam
exceptions
remember
arguments
reraise
most
recent
exception
running
a
raise
this
way
reraises
the
exception
and
propagates
it
to
a
higher
handler
or
the
default
handler
at
the
top
which
stops
the
program
with
a
standard
error
message
notice
how
the
argument
we
passed
to
the
exception
class
shows
up
in
the
error
messages
you
ll
learn
why
this
happens
in
the
next
chapter
python
exception
chaining
raise
from
python
but
not
also
allows
raise
statements
to
have
an
optional
from
clause
raise
exception
from
otherexception
when
the
from
is
used
the
second
expression
specifies
another
exception
class
or
instance
to
attach
to
the
raised
exception
s
cause
attribute
if
the
raised
exception
is
not
caught
python
prints
both
exceptions
as
part
of
the
standard
error
message
try
except
exception
as
e
the
raise
statement
raise
typeerror
bad
from
e
traceback
most
recent
call
last
file
stdin
line
in
module
zerodivisionerror
int
division
or
modulo
by
zero
the
above
exception
was
the
direct
cause
of
the
following
exception
traceback
most
recent
call
last
file
stdin
line
in
module
typeerror
bad
when
an
exception
is
raised
inside
an
exception
handler
a
similar
procedure
is
followed
implicitly
the
previous
exception
is
attached
to
the
new
exception
s
context
attribute
and
is
again
displayed
in
the
standard
error
message
if
the
exception
goes
uncaught
this
is
an
advanced
and
still
somewhat
obscure
extension
so
see
python
s
manuals
for
more
details
version
skew
note
python
no
longer
supports
the
raise
exc
args
form
that
is
still
available
in
python
in
use
the
raise
exc
args
instance
creation
call
form
described
in
this
book
instead
the
equivalent
comma
form
in
is
legacy
syntax
provided
for
compatibility
with
the
now
defunct
string
based
exceptions
model
and
it
s
deprecated
in
if
used
it
is
converted
to
the
call
form
as
in
earlier
releases
a
raise
exc
form
is
also
allowed
it
is
converted
to
raise
exc
in
both
versions
calling
the
class
constructor
with
no
arguments
the
assert
statement
as
a
somewhat
special
case
for
debugging
purposes
python
includes
the
assert
statement
it
is
mostly
just
syntactic
shorthand
for
a
common
raise
usage
pattern
and
an
assert
can
be
thought
of
as
a
conditional
raise
statement
a
statement
of
the
form
assert
test
data
the
data
part
is
optional
works
like
the
following
code
if
debug
if
not
test
raise
assertionerror
data
in
other
words
if
the
test
evaluates
to
false
python
raises
an
exception
the
data
item
if
it
s
provided
is
used
as
the
exception
s
constructor
argument
like
all
exceptions
the
assertionerror
exception
will
kill
your
program
if
it
s
not
caught
with
a
try
in
which
case
the
data
item
shows
up
as
part
of
the
error
message
as
an
added
feature
assert
statements
may
be
removed
from
a
compiled
program
s
byte
code
if
the
o
python
command
line
flag
is
used
thereby
optimizing
the
program
assertionerror
is
a
built
in
exception
and
the
debug
flag
is
a
built
in
name
that
is
chapter
exception
coding
details
automatically
set
to
true
unless
the
o
flag
is
used
use
a
command
line
like
python
o
main
py
to
run
in
optimized
mode
and
disable
asserts
example
trapping
constraints
but
not
errors
assertions
are
typically
used
to
verify
program
conditions
during
development
when
displayed
their
error
message
text
automatically
includes
source
code
line
information
and
the
value
listed
in
the
assert
statement
consider
the
file
asserter
py
def
f
x
assert
x
x
must
be
negative
return
x
python
import
asserter
asserter
f
traceback
most
recent
call
last
file
stdin
line
in
module
file
asserter
py
line
in
f
assert
x
x
must
be
negative
assertionerror
x
must
be
negative
it
s
important
to
keep
in
mind
that
assert
is
mostly
intended
for
trapping
user
defined
constraints
not
for
catching
genuine
programming
errors
because
python
traps
programming
errors
itself
there
is
usually
no
need
to
code
asserts
to
catch
things
like
outof
bounds
indexes
type
mismatches
and
zero
divides
def
reciprocal
x
assert
x
return
x
a
useless
assert
python
checks
for
zero
automatically
such
asserts
are
generally
superfluous
because
python
raises
exceptions
on
errors
automatically
you
might
as
well
let
it
do
the
job
for
you
for
another
example
of
common
assert
usage
see
the
abstract
superclass
example
in
chapter
there
we
used
assert
to
make
calls
to
undefined
methods
fail
with
a
message
with
as
context
managers
python
and
introduced
a
new
exception
related
statement
the
with
and
its
optional
as
clause
this
statement
is
designed
to
work
with
context
manager
objects
which
support
a
new
method
based
protocol
this
feature
is
also
available
as
an
option
in
enabled
with
an
import
of
this
form
from
future
import
with
statement
in
most
cases
at
least
as
suggested
earlier
in
the
book
if
a
function
has
to
perform
long
running
or
unrecoverable
actions
before
it
reaches
the
place
where
an
exception
will
be
triggered
you
still
might
want
to
test
for
errors
even
in
this
case
though
be
careful
not
to
make
your
tests
overly
specific
or
restrictive
or
you
will
limit
your
code
s
utility
with
as
context
managers
in
short
the
with
as
statement
is
designed
to
be
an
alternative
to
a
common
try
finally
usage
idiom
like
that
statement
it
is
intended
for
specifying
termination
time
or
cleanup
activities
that
must
run
regardless
of
whether
an
exception
occurs
in
a
processing
step
unlike
try
finally
though
the
with
statement
supports
a
richer
object
based
protocol
for
specifying
both
entry
and
exit
actions
around
a
block
of
code
python
enhances
some
built
in
tools
with
context
managers
such
as
files
that
automatically
close
themselves
and
thread
locks
that
automatically
lock
and
unlock
but
programmers
can
code
context
managers
of
their
own
with
classes
too
basic
usage
the
basic
format
of
the
with
statement
looks
like
this
with
expression
as
variable
with
block
the
expression
here
is
assumed
to
return
an
object
that
supports
the
context
management
protocol
more
on
this
protocol
in
a
moment
this
object
may
also
return
a
value
that
will
be
assigned
to
the
name
variable
if
the
optional
as
clause
is
present
note
that
the
variable
is
not
necessarily
assigned
the
result
of
the
expression
the
result
of
the
expression
is
the
object
that
supports
the
context
protocol
and
the
variable
may
be
assigned
something
else
intended
to
be
used
inside
the
statement
the
object
returned
by
the
expression
may
then
run
startup
code
before
the
with
block
is
started
as
well
as
termination
code
after
the
block
is
done
regardless
of
whether
the
block
raised
an
exception
or
not
some
built
in
python
objects
have
been
augmented
to
support
the
context
management
protocol
and
so
can
be
used
with
the
with
statement
for
example
file
objects
covered
in
chapter
have
a
context
manager
that
automatically
closes
the
file
after
the
with
block
regardless
of
whether
an
exception
is
raised
with
open
r
c
misc
data
as
myfile
for
line
in
myfile
print
line
more
code
here
here
the
call
to
open
returns
a
simple
file
object
that
is
assigned
to
the
name
myfile
we
can
use
myfile
with
the
usual
file
tools
in
this
case
the
file
iterator
reads
line
by
line
in
the
for
loop
however
this
object
also
supports
the
context
management
protocol
used
by
the
with
statement
after
this
with
statement
has
run
the
context
management
machinery
guarantees
that
the
file
object
referenced
by
myfile
is
automatically
closed
even
if
the
for
loop
raised
an
exception
while
processing
the
file
although
file
objects
are
automatically
closed
on
garbage
collection
it
s
not
always
straightforward
to
know
when
that
will
occur
the
with
statement
in
this
role
is
an
alternative
that
allows
us
to
be
sure
that
the
close
will
occur
after
execution
of
a
specific
chapter
exception
coding
details
block
of
code
as
we
saw
earlier
we
can
achieve
a
similar
effect
with
the
more
general
and
explicit
try
finally
statement
but
it
requires
four
lines
of
administrative
code
instead
of
one
in
this
case
myfile
open
r
c
misc
data
try
for
line
in
myfile
print
line
more
code
here
finally
myfile
close
we
won
t
cover
python
s
multithreading
modules
in
this
book
for
more
on
that
topic
see
follow
up
application
level
texts
such
as
programming
python
but
the
lock
and
condition
synchronization
objects
they
define
may
also
be
used
with
the
with
statement
because
they
support
the
context
management
protocol
lock
threading
lock
with
lock
critical
section
of
code
access
shared
resources
here
the
context
management
machinery
guarantees
that
the
lock
is
automatically
acquired
before
the
block
is
executed
and
released
once
the
block
is
complete
regardless
of
exception
outcomes
as
introduced
in
chapter
the
decimal
module
also
uses
context
managers
to
simplify
saving
and
restoring
the
current
decimal
context
which
specifies
the
precision
and
rounding
characteristics
for
calculations
with
decimal
localcontext
as
ctx
ctx
prec
x
decimal
decimal
decimal
decimal
after
this
statement
runs
the
current
thread
s
context
manager
state
is
automatically
restored
to
what
it
was
before
the
statement
began
to
do
the
same
with
a
try
finally
we
would
need
to
save
the
context
before
and
restore
it
manually
the
context
management
protocol
although
some
built
in
types
come
with
context
managers
we
can
also
write
new
ones
of
our
own
to
implement
context
managers
classes
use
special
methods
that
fall
into
the
operator
overloading
category
to
tap
into
the
with
statement
the
interface
expected
of
objects
used
in
with
statements
is
somewhat
complex
and
most
programmers
only
need
to
know
how
to
use
existing
context
managers
for
tool
builders
who
might
want
to
write
new
application
specific
context
managers
though
let
s
take
a
quick
look
at
what
s
involved
here
s
how
the
with
statement
actually
works
with
as
context
managers
the
expression
is
evaluated
resulting
in
an
object
known
as
a
context
manager
that
must
have
enter
and
exit
methods
the
context
manager
s
enter
method
is
called
the
value
it
returns
is
assigned
to
the
variable
in
the
as
clause
if
present
or
simply
discarded
otherwise
the
code
in
the
nested
with
block
is
executed
if
the
with
block
raises
an
exception
the
exit
type
value
traceback
method
is
called
with
the
exception
details
note
that
these
are
the
same
values
returned
by
sys
exc
info
described
in
the
python
manuals
and
later
in
this
part
of
the
book
if
this
method
returns
a
false
value
the
exception
is
reraised
otherwise
the
exception
is
terminated
the
exception
should
normally
be
reraised
so
that
it
is
propagated
outside
the
with
statement
if
the
with
block
does
not
raise
an
exception
the
exit
method
is
still
called
but
its
type
value
and
traceback
arguments
are
all
passed
in
as
none
let
s
look
at
a
quick
demo
of
the
protocol
in
action
the
following
defines
a
context
manager
object
that
traces
the
entry
and
exit
of
the
with
block
in
any
with
statement
it
is
used
for
class
traceblock
def
message
self
arg
print
running
arg
def
enter
self
print
starting
with
block
return
self
def
exit
self
exc
type
exc
value
exc
tb
if
exc
type
is
none
print
exited
normally
n
else
print
raise
an
exception
exc
type
return
false
propagate
with
traceblock
as
action
action
message
test
print
reached
with
traceblock
as
action
action
message
test
raise
typeerror
print
not
reached
notice
that
this
class
s
exit
method
returns
false
to
propagate
the
exception
deleting
the
return
statement
would
have
the
same
effect
as
the
default
none
return
value
of
functions
is
false
by
definition
also
notice
that
the
enter
method
returns
self
as
the
object
to
assign
to
the
as
variable
in
other
use
cases
this
might
return
a
completely
different
object
instead
when
run
the
context
manager
traces
the
entry
and
exit
of
the
with
statement
block
with
its
enter
and
exit
methods
here
s
the
script
in
action
being
run
under
python
it
runs
in
too
but
prints
some
extra
tuple
parentheses
chapter
exception
coding
details
python
withas
py
starting
with
block
running
test
reached
exited
normally
starting
with
block
running
test
raise
an
exception
class
typeerror
traceback
most
recent
call
last
file
withas
py
line
in
module
raise
typeerror
typeerror
context
managers
are
somewhat
advanced
devices
for
tool
builders
so
we
ll
skip
additional
details
here
see
python
s
standard
manuals
for
the
full
story
for
example
there
s
a
new
contextlib
standard
module
that
provides
additional
tools
for
coding
context
managers
for
simpler
purposes
the
try
finally
statement
provides
sufficient
support
for
termination
time
activities
in
the
upcoming
python
release
the
with
statement
may
also
specify
multiple
sometimes
referred
to
as
nested
context
managers
with
new
comma
syntax
in
the
following
for
example
both
files
exit
actions
are
automatically
run
when
the
statement
block
exits
regardless
of
exception
outcomes
with
open
data
as
fin
open
res
w
as
fout
for
line
in
fin
if
some
key
in
line
fout
write
line
any
number
of
context
manager
items
may
be
listed
and
multiple
items
work
the
same
as
nested
with
statements
in
general
the
and
later
code
with
a
as
a
b
as
b
statements
is
equivalent
to
the
following
which
works
in
and
with
a
as
a
with
b
as
b
statements
see
python
release
notes
for
additional
details
chapter
summary
in
this
chapter
we
took
a
more
detailed
look
at
exception
processing
by
exploring
the
statements
related
to
exceptions
in
python
try
to
catch
them
raise
to
trigger
them
assert
to
raise
them
conditionally
and
with
to
wrap
code
blocks
in
context
managers
that
specify
entry
and
exit
actions
chapter
summary
so
far
exceptions
probably
seem
like
a
fairly
lightweight
tool
and
in
fact
they
are
the
only
substantially
complex
thing
about
them
is
how
they
are
identified
the
next
chapter
continues
our
exploration
by
describing
how
to
implement
exception
objects
of
your
own
as
you
ll
see
classes
allow
you
to
code
new
exceptions
specific
to
your
programs
before
we
move
ahead
though
let
s
work
though
the
following
short
quiz
on
the
basics
covered
here
test
your
knowledge
quiz
what
is
the
try
statement
for
what
are
the
two
common
variations
of
the
try
statement
what
is
the
raise
statement
for
what
is
the
assert
statement
designed
to
do
and
what
other
statement
is
it
like
what
is
the
with
as
statement
designed
to
do
and
what
other
statement
is
it
like
test
your
knowledge
answers
the
try
statement
catches
and
recovers
from
exceptions
it
specifies
a
block
of
code
to
run
and
one
or
more
handlers
for
exceptions
that
may
be
raised
during
the
block
s
execution
the
two
common
variations
on
the
try
statement
are
try
except
else
for
catching
exceptions
and
try
finally
for
specifying
cleanup
actions
that
must
occur
whether
an
exception
is
raised
or
not
in
python
these
were
separate
statements
that
could
be
combined
by
syntactic
nesting
in
and
later
except
and
finally
blocks
may
be
mixed
in
the
same
statement
so
the
two
statement
forms
are
merged
in
the
merged
form
the
finally
is
still
run
on
the
way
out
of
the
try
regardless
of
what
exceptions
may
have
been
raised
or
handled
the
raise
statement
raises
triggers
an
exception
python
raises
built
in
exceptions
on
errors
internally
but
your
scripts
can
trigger
built
in
or
user
defined
exceptions
with
raise
too
the
assert
statement
raises
an
assertionerror
exception
if
a
condition
is
false
it
works
like
a
conditional
raise
statement
wrapped
up
in
an
if
statement
the
with
as
statement
is
designed
to
automate
startup
and
termination
activities
that
must
occur
around
a
block
of
code
it
is
roughly
like
a
try
finally
statement
in
that
its
exit
actions
run
whether
an
exception
occurred
or
not
but
it
allows
a
richer
object
based
protocol
for
specifying
entry
and
exit
actions
chapter
exception
coding
details
chapter
exception
objects
so
far
i
ve
been
deliberately
vague
about
what
an
exception
actually
is
as
suggested
in
the
prior
chapter
in
python
and
both
built
in
and
user
defined
exceptions
are
identified
by
class
instance
objects
although
this
means
you
must
use
objectoriented
programming
to
define
new
exceptions
in
your
programs
classes
and
oop
in
general
offer
a
number
of
benefits
here
are
some
of
the
advantages
of
class
based
exceptions
they
can
be
organized
into
categories
exception
classes
support
future
changes
by
providing
categories
adding
new
exceptions
in
the
future
won
t
generally
require
changes
in
try
statements
they
have
attached
state
information
exception
classes
provide
a
natural
place
for
us
to
store
context
information
for
use
in
the
try
handler
they
may
have
both
attached
state
information
and
callable
methods
accessible
through
instances
they
support
inheritance
class
based
exceptions
can
participate
in
inheritance
hierarchies
to
obtain
and
customize
common
behavior
inherited
display
methods
for
example
can
provide
a
common
look
and
feel
for
error
messages
because
of
these
advantages
class
based
exceptions
support
program
evolution
and
larger
systems
well
in
fact
all
built
in
exceptions
are
identified
by
classes
and
are
organized
into
an
inheritance
tree
for
the
reasons
just
listed
you
can
do
the
same
with
user
defined
exceptions
of
your
own
in
python
user
defined
exceptions
inherit
from
built
in
exception
superclasses
as
we
ll
see
here
because
these
superclasses
provide
useful
defaults
for
printing
and
state
retention
the
task
of
coding
user
defined
exceptions
also
involves
understanding
the
roles
of
these
built
ins
version
skew
note
python
and
both
require
exceptions
to
be
defined
by
classes
in
addition
requires
exception
classes
to
be
derived
from
the
baseexception
built
in
exception
superclass
either
directly
or
indirectly
as
we
ll
see
most
programs
inherit
from
this
class
s
exception
subclass
to
support
catchall
handlers
for
normal
exception
types
naming
it
in
a
handler
will
catch
everything
most
programs
should
python
allows
standalone
classic
classes
to
serve
as
exceptions
too
but
it
requires
new
style
classes
to
be
derived
from
built
in
exception
classes
the
same
as
exceptions
back
to
the
future
once
upon
a
time
well
prior
to
python
and
it
was
possible
to
define
exceptions
in
two
different
ways
this
complicated
try
statements
raise
statements
and
python
in
general
today
there
is
only
one
way
to
do
it
this
is
a
good
thing
it
removes
from
the
language
substantial
cruft
accumulated
for
the
sake
of
backward
compatibility
because
the
old
way
helps
explain
why
exceptions
are
as
they
are
today
though
and
because
it
s
not
really
possible
to
completely
erase
the
history
of
something
that
has
been
used
by
a
million
people
over
the
course
of
nearly
two
decades
let
s
begin
our
exploration
of
the
present
with
a
brief
look
at
the
past
string
exceptions
are
right
out
prior
to
python
and
it
was
possible
to
define
exceptions
with
both
class
instances
and
string
objects
string
based
exceptions
began
issuing
deprecation
warnings
in
and
were
removed
in
and
so
today
you
should
use
class
based
exceptions
as
shown
in
this
book
if
you
work
with
legacy
code
though
you
might
still
come
across
string
exceptions
they
might
also
appear
in
tutorials
and
web
resources
written
a
few
years
ago
which
qualifies
as
an
eternity
in
python
years
string
exceptions
were
straightforward
to
use
any
string
would
do
and
they
matched
by
object
identity
not
value
that
is
using
is
not
c
misc
c
python
python
myexc
my
exception
string
try
raise
myexc
except
myexc
print
caught
caught
were
we
ever
this
young
this
form
of
exception
was
removed
because
it
was
not
as
good
as
classes
for
larger
programs
and
code
maintenance
although
you
can
t
use
string
exceptions
today
they
actually
provide
a
natural
vehicle
for
introducing
the
class
based
exceptions
model
chapter
exception
objects
class
based
exceptions
strings
were
a
simple
way
to
define
exceptions
as
described
earlier
however
classes
have
some
added
advantages
that
merit
a
quick
look
most
prominently
they
allow
us
to
identify
exception
categories
that
are
more
flexible
to
use
and
maintain
than
simple
strings
moreover
classes
naturally
allow
for
attached
exception
details
and
support
inheritance
because
they
are
the
better
approach
they
are
now
required
coding
details
aside
the
chief
difference
between
string
and
class
exceptions
has
to
do
with
the
way
that
exceptions
raised
are
matched
against
except
clauses
in
try
statements
string
exceptions
were
matched
by
simple
object
identity
the
raised
exception
was
matched
to
except
clauses
by
python
s
is
test
class
exceptions
are
matched
by
superclass
relationships
the
raised
exception
matches
an
except
clause
if
that
except
clause
names
the
exception
s
class
or
any
superclass
of
it
that
is
when
a
try
statement
s
except
clause
lists
a
superclass
it
catches
instances
of
that
superclass
as
well
as
instances
of
all
its
subclasses
lower
in
the
class
tree
the
net
effect
is
that
class
exceptions
support
the
construction
of
exception
hierarchies
superclasses
become
category
names
and
subclasses
become
specific
kinds
of
exceptions
within
a
category
by
naming
a
general
exception
superclass
an
except
clause
can
catch
an
entire
category
of
exceptions
any
more
specific
subclass
will
match
string
exceptions
had
no
such
concept
because
they
were
matched
by
simple
object
identity
there
was
no
direct
way
to
organize
exceptions
into
more
flexible
categories
or
groups
the
net
result
was
that
exception
handlers
were
coupled
with
exception
sets
in
a
way
that
made
changes
difficult
in
addition
to
this
category
idea
class
based
exceptions
better
support
exception
state
information
attached
to
instances
and
allow
exceptions
to
participate
in
inheritance
hierarchies
to
obtain
common
behaviors
because
they
offer
all
the
benefits
of
classes
and
oop
in
general
they
provide
a
more
powerful
alternative
to
the
now
defunct
stringbased
exceptions
model
in
exchange
for
a
small
amount
of
additional
code
coding
exceptions
classes
let
s
look
at
an
example
to
see
how
class
exceptions
translate
to
code
in
the
following
file
classexc
py
we
define
a
superclass
called
general
and
two
subclasses
called
specific
and
specific
this
example
illustrates
the
notion
of
exception
categories
general
is
a
category
name
and
its
two
subclasses
are
specific
types
of
exceptions
within
the
category
handlers
that
catch
general
will
also
catch
any
subclasses
of
it
including
specific
and
specific
class
general
exception
pass
class
specific
general
pass
exceptions
back
to
the
future
class
specific
general
pass
def
raiser
x
general
raise
x
raise
superclass
instance
def
raiser
x
specific
raise
x
raise
subclass
instance
def
raiser
x
specific
raise
x
raise
different
subclass
instance
for
func
in
raiser
raiser
raiser
try
func
except
general
match
general
or
any
subclass
of
it
import
sys
print
caught
sys
exc
info
c
python
python
classexc
py
caught
class
main
general
caught
class
main
specific
caught
class
main
specific
this
code
is
mostly
straightforward
but
here
are
a
few
implementation
notes
exception
superclass
classes
used
to
build
exception
category
trees
have
very
few
requirements
in
fact
in
this
example
they
are
mostly
empty
with
bodies
that
do
nothing
but
pass
notice
though
how
the
top
level
class
here
inherits
from
the
built
in
exception
class
this
is
required
in
python
python
allows
standalone
classic
classes
to
serve
as
exceptions
too
but
it
requires
new
style
classes
to
be
derived
from
built
in
exception
classes
just
like
in
although
we
don
t
employ
it
here
because
exception
provides
some
useful
behavior
we
ll
meet
later
it
s
a
good
idea
to
inherit
from
it
in
either
python
raising
instances
in
this
code
we
call
classes
to
make
instances
for
the
raise
statements
in
the
class
exception
model
we
always
raise
and
catch
a
class
instance
object
if
we
list
a
class
name
without
parentheses
in
a
raise
python
calls
the
class
with
no
constructor
argument
to
make
an
instance
for
us
exception
instances
can
be
created
before
the
raise
as
done
here
or
within
the
raise
statement
itself
catching
categories
this
code
includes
functions
that
raise
instances
of
all
three
of
our
classes
as
exceptions
as
well
as
a
top
level
try
that
calls
the
functions
and
catches
general
exceptions
the
same
try
also
catches
the
two
specific
exceptions
because
they
are
subclasses
of
general
chapter
exception
objects
exception
details
the
exception
handler
here
uses
the
sys
exc
info
call
as
we
ll
see
in
more
detail
in
the
next
chapter
it
s
how
we
can
grab
hold
of
the
most
recently
raised
exception
in
a
generic
fashion
briefly
the
first
item
in
its
result
is
the
class
of
the
exception
raised
and
the
second
is
the
actual
instance
raised
in
a
general
except
clause
like
the
one
here
that
catches
all
classes
in
a
category
sys
exc
info
is
one
way
to
determine
exactly
what
s
occurred
in
this
particular
case
it
s
equivalent
to
fetching
the
instance
s
class
attribute
as
we
ll
see
in
the
next
chapter
the
sys
exc
info
scheme
is
also
commonly
used
with
empty
except
clauses
that
catch
everything
the
last
point
merits
further
explanation
when
an
exception
is
caught
we
can
be
sure
that
the
instance
raised
is
an
instance
of
the
class
listed
in
the
except
or
one
of
its
more
specific
subclasses
because
of
this
the
class
attribute
of
the
instance
also
gives
the
exception
type
the
following
variant
for
example
works
the
same
as
the
prior
example
class
general
exception
pass
class
specific
general
pass
class
specific
general
pass
def
raiser
raise
general
def
raiser
raise
specific
def
raiser
raise
specific
for
func
in
raiser
raiser
raiser
try
func
except
general
as
x
print
caught
x
class
x
is
the
raised
instance
same
as
sys
exc
info
because
class
can
be
used
like
this
to
determine
the
specific
type
of
exception
raised
sys
exc
info
is
more
useful
for
empty
except
clauses
that
do
not
otherwise
have
a
way
to
access
the
instance
or
its
class
furthermore
more
realistic
programs
usually
should
not
have
to
care
about
which
specific
exception
was
raised
at
all
by
calling
methods
of
the
instance
generically
we
automatically
dispatch
to
behavior
tailored
for
the
exception
raised
more
on
this
and
sys
exc
info
in
the
next
chapter
also
see
chapter
and
part
vi
at
large
if
you
ve
forgotten
what
class
means
in
an
instance
why
exception
hierarchies
because
there
are
only
three
possible
exceptions
in
the
prior
section
s
example
it
doesn
t
really
do
justice
to
the
utility
of
class
exceptions
in
fact
we
could
achieve
the
same
effects
by
coding
a
list
of
exception
names
in
parentheses
within
the
except
clause
try
func
except
general
specific
specific
catch
any
of
these
why
exception
hierarchies
this
approach
worked
for
the
defunct
string
exception
model
too
for
large
or
high
exception
hierarchies
however
it
may
be
easier
to
catch
categories
using
class
based
categories
than
to
list
every
member
of
a
category
in
a
single
except
clause
perhaps
more
importantly
you
can
extend
exception
hierarchies
by
adding
new
subclasses
without
breaking
existing
code
suppose
for
example
you
code
a
numeric
programming
library
in
python
to
be
used
by
a
large
number
of
people
while
you
are
writing
your
library
you
identify
two
things
that
can
go
wrong
with
numbers
in
your
code
division
by
zero
and
numeric
overflow
you
document
these
as
the
two
exceptions
that
your
library
may
raise
mathlib
py
class
divzero
exception
pass
class
oflow
exception
pass
def
func
raise
divzero
now
when
people
use
your
library
they
typically
wrap
calls
to
your
functions
or
classes
in
try
statements
that
catch
your
two
exceptions
if
they
do
not
catch
your
exceptions
exceptions
from
the
library
will
kill
their
code
client
py
import
mathlib
try
mathlib
func
except
mathlib
divzero
mathlib
oflow
handle
and
recover
this
works
fine
and
lots
of
people
start
using
your
library
six
months
down
the
road
though
you
revise
it
as
programmers
are
prone
to
do
along
the
way
you
identify
a
new
thing
that
can
go
wrong
underflow
and
add
that
as
a
new
exception
mathlib
py
class
divzero
exception
pass
class
oflow
exception
pass
class
uflow
exception
pass
unfortunately
when
you
re
release
your
code
you
create
a
maintenance
problem
for
your
users
if
they
ve
listed
your
exceptions
explicitly
they
now
have
to
go
back
and
change
every
place
they
call
your
library
to
include
the
newly
added
exception
name
client
py
try
mathlib
func
except
mathlib
divzero
mathlib
oflow
mathlib
uflow
handle
and
recover
chapter
exception
objects
this
may
not
be
the
end
of
the
world
if
your
library
is
used
only
in
house
you
can
make
the
changes
yourself
you
might
also
ship
a
python
script
that
tries
to
fix
such
code
automatically
it
would
probably
be
only
a
few
dozen
lines
and
it
would
guess
right
at
least
some
of
the
time
if
many
people
have
to
change
all
their
try
statements
each
time
you
alter
your
exception
set
though
this
is
not
exactly
the
most
polite
of
upgrade
policies
your
users
might
try
to
avoid
this
pitfall
by
coding
empty
except
clauses
to
catch
all
possible
exceptions
client
py
try
mathlib
func
except
handle
and
recover
catch
everything
here
but
this
workaround
might
catch
more
than
they
bargained
for
things
like
running
out
of
memory
keyboard
interrupts
ctrl
c
system
exits
and
even
typos
in
their
own
try
block
s
code
will
all
trigger
exceptions
and
such
things
should
pass
not
be
caught
and
erroneously
classified
as
library
errors
and
really
in
this
scenario
users
want
to
catch
and
recover
from
only
the
specific
exceptions
the
library
is
defined
and
documented
to
raise
if
any
other
exception
occurs
during
a
library
call
it
s
likely
a
genuine
bug
in
the
library
and
probably
time
to
contact
the
vendor
as
a
rule
of
thumb
it
s
usually
better
to
be
specific
than
general
in
exception
handlers
an
idea
we
ll
revisit
as
a
gotcha
in
the
next
chapter
so
what
to
do
then
class
exception
hierarchies
fix
this
dilemma
completely
rather
than
defining
your
library
s
exceptions
as
a
set
of
autonomous
classes
arrange
them
into
a
class
tree
with
a
common
superclass
to
encompass
the
entire
category
mathlib
py
class
numerr
exception
pass
class
divzero
numerr
pass
class
oflow
numerr
pass
def
func
raise
divzero
this
way
users
of
your
library
simply
need
to
list
the
common
superclass
i
e
category
to
catch
all
of
your
library
s
exceptions
both
now
and
in
the
future
as
a
clever
student
of
mine
suggested
the
library
module
could
also
provide
a
tuple
object
that
contains
all
the
exceptions
the
library
can
possibly
raise
the
client
could
then
import
the
tuple
and
name
it
in
an
except
clause
to
catch
all
the
library
s
exceptions
recall
that
including
a
tuple
in
an
except
means
catch
any
of
its
exceptions
when
new
exceptions
are
added
later
the
library
can
just
expand
the
exported
tuple
this
would
work
but
you
d
still
need
to
keep
the
tuple
up
to
date
with
raised
exceptions
inside
the
library
module
also
class
hierarchies
offer
more
benefits
than
just
categories
they
also
support
inherited
state
and
methods
and
a
customization
model
that
individual
exceptions
do
not
why
exception
hierarchies
client
py
import
mathlib
try
mathlib
func
except
mathlib
numerr
report
and
recover
when
you
go
back
and
hack
your
code
again
you
can
add
new
exceptions
as
new
subclasses
of
the
common
superclass
mathlib
py
class
uflow
numerr
pass
the
end
result
is
that
user
code
that
catches
your
library
s
exceptions
will
keep
working
unchanged
in
fact
you
are
free
to
add
delete
and
change
exceptions
arbitrarily
in
the
future
as
long
as
clients
name
the
superclass
they
are
insulated
from
changes
in
your
exceptions
set
in
other
words
class
exceptions
provide
a
better
answer
to
maintenance
issues
than
strings
do
class
based
exception
hierarchies
also
support
state
retention
and
inheritance
in
ways
that
make
them
ideal
in
larger
programs
to
understand
these
roles
though
we
first
need
to
see
how
user
defined
exception
classes
relate
to
the
built
in
exceptions
from
which
they
inherit
built
in
exception
classes
i
didn
t
really
pull
the
prior
section
s
examples
out
of
thin
air
all
built
in
exceptions
that
python
itself
may
raise
are
predefined
class
objects
moreover
they
are
organized
into
a
shallow
hierarchy
with
general
superclass
categories
and
specific
subclass
types
much
like
the
exceptions
class
tree
we
developed
earlier
in
python
all
the
familiar
exceptions
you
ve
seen
e
g
syntaxerror
are
really
just
predefined
classes
available
as
built
in
names
in
the
module
named
builtins
in
python
they
instead
live
in
builtin
and
are
also
attributes
of
the
standard
library
module
exceptions
in
addition
python
organizes
the
built
in
exceptions
into
a
hierarchy
to
support
a
variety
of
catching
modes
for
example
baseexception
the
top
level
root
superclass
of
exceptions
this
class
is
not
supposed
to
be
directly
inherited
by
user
defined
classes
use
exception
instead
it
provides
default
printing
and
state
retention
behavior
inherited
by
subclasses
if
the
str
built
in
is
called
on
an
instance
of
this
class
e
g
by
print
the
class
returns
the
display
strings
of
the
constructor
arguments
passed
when
the
instance
was
created
or
an
empty
string
if
there
were
no
arguments
in
addition
unless
subclasses
replace
this
class
s
chapter
exception
objects
constructor
all
of
the
arguments
passed
to
this
class
at
instance
construction
time
are
stored
in
its
args
attribute
as
a
tuple
exception
the
top
level
root
superclass
of
application
related
exceptions
this
is
an
immediate
subclass
of
baseexception
and
is
superclass
to
every
other
built
in
exception
except
the
system
exit
event
classes
systemexit
keyboardinterrupt
and
generatorexit
almost
all
user
defined
classes
should
inherit
from
this
class
not
baseexception
when
this
convention
is
followed
naming
exception
in
a
try
statement
s
handler
ensures
that
your
program
will
catch
everything
but
system
exit
events
which
should
normally
be
allowed
to
pass
in
effect
exception
becomes
a
catchall
in
try
statements
and
is
more
accurate
than
an
empty
except
arithmeticerror
the
superclass
of
all
numeric
errors
and
a
subclass
of
exception
overflowerror
a
subclass
of
arithmeticerror
that
identifies
a
specific
numeric
error
and
so
on
you
can
read
further
about
this
structure
in
reference
texts
such
as
python
pocket
reference
or
the
python
library
manual
note
that
the
exceptions
class
tree
differs
slightly
between
python
and
also
note
that
you
can
see
the
class
tree
in
the
help
text
of
the
exceptions
module
in
python
only
this
module
is
removed
in
see
chapters
and
for
help
on
help
import
exceptions
help
exceptions
lots
of
text
omitted
built
in
exception
categories
the
built
in
class
tree
allows
you
to
choose
how
specific
or
general
your
handlers
will
be
for
example
the
built
in
exception
arithmeticerror
is
a
superclass
for
more
specific
exceptions
such
as
overflowerror
and
zerodivisionerror
by
listing
arithmeticerror
in
a
try
you
will
catch
any
kind
of
numeric
error
raised
by
listing
just
overflowerror
you
will
intercept
just
that
specific
type
of
error
and
no
others
similarly
because
exception
is
the
superclass
of
all
application
level
exceptions
in
python
you
can
generally
use
it
as
a
catchall
the
effect
is
much
like
an
empty
except
but
it
allows
system
exit
exceptions
to
pass
as
they
usually
should
try
action
except
exception
handle
all
application
exceptions
else
handle
no
exception
case
built
in
exception
classes
this
doesn
t
quite
work
universally
in
python
however
because
standalone
userdefined
exceptions
coded
as
classic
classes
are
not
required
to
be
subclasses
of
the
exception
root
class
this
technique
is
more
reliable
in
python
since
it
requires
all
classes
to
derive
from
built
in
exceptions
even
in
python
though
this
scheme
suffers
most
of
the
same
potential
pitfalls
as
the
empty
except
as
described
in
the
prior
chapter
it
might
intercept
exceptions
intended
for
elsewhere
and
it
might
mask
genuine
programming
errors
since
this
is
such
a
common
issue
we
ll
revisit
it
as
a
gotcha
in
the
next
chapter
whether
or
not
you
will
leverage
the
categories
in
the
built
in
class
tree
it
serves
as
a
good
example
by
using
similar
techniques
for
class
exceptions
in
your
own
code
you
can
provide
exception
sets
that
are
flexible
and
easily
modified
default
printing
and
state
built
in
exceptions
also
provide
default
print
displays
and
state
retention
which
is
often
as
much
logic
as
user
defined
classes
require
unless
you
redefine
the
constructors
your
classes
inherit
from
them
any
constructor
arguments
you
pass
to
these
classes
are
saved
in
the
instance
s
args
tuple
attribute
and
are
automatically
displayed
when
the
instance
is
printed
an
empty
tuple
and
display
string
are
used
if
no
constructor
arguments
are
passed
this
explains
why
arguments
passed
to
built
in
exception
classes
show
up
in
error
messages
any
constructor
arguments
are
attached
to
the
instance
and
displayed
when
the
instance
is
printed
raise
indexerror
traceback
most
recent
call
last
file
stdin
line
in
module
indexerror
same
as
indexerror
no
arguments
raise
indexerror
spam
traceback
most
recent
call
last
file
stdin
line
in
module
indexerror
spam
constructor
argument
attached
printed
i
indexerror
spam
i
args
spam
available
in
object
attribute
the
same
holds
true
for
user
defined
exceptions
because
they
inherit
the
constructor
and
display
methods
present
in
their
built
in
superclasses
class
e
exception
pass
try
raise
e
spam
except
e
as
x
print
x
x
args
spam
spam
chapter
exception
objects
displays
and
saves
constructor
arguments
try
raise
e
spam
eggs
ham
except
e
as
x
print
x
x
args
spam
eggs
ham
spam
eggs
ham
note
that
exception
instance
objects
are
not
strings
themselves
but
use
the
str
operator
overloading
protocol
we
studied
in
chapter
to
provide
display
strings
when
printed
to
concatenate
with
real
strings
perform
manual
conversions
str
x
string
although
this
automatic
state
and
display
support
is
useful
by
itself
for
more
specific
display
and
state
retention
needs
you
can
always
redefine
inherited
methods
such
as
str
and
init
in
exception
subclasses
the
next
section
shows
how
custom
print
displays
as
we
saw
in
the
preceding
section
by
default
instances
of
class
based
exceptions
display
whatever
you
passed
to
the
class
constructor
when
they
are
caught
and
printed
class
mybad
exception
pass
try
raise
mybad
sorry
my
mistake
except
mybad
as
x
print
x
sorry
my
mistake
this
inherited
default
display
model
is
also
used
if
the
exception
is
displayed
as
part
of
an
error
message
when
the
exception
is
not
caught
raise
mybad
sorry
my
mistake
traceback
most
recent
call
last
file
stdin
line
in
module
main
mybad
sorry
my
mistake
for
many
roles
this
is
sufficient
to
provide
a
more
custom
display
though
you
can
define
one
of
two
string
representation
overloading
methods
in
your
class
repr
or
str
to
return
the
string
you
want
to
display
for
your
exception
the
string
the
method
returns
will
be
displayed
if
the
exception
either
is
caught
and
printed
or
reaches
the
default
handler
class
mybad
exception
def
str
self
return
always
look
on
the
bright
side
of
life
try
raise
mybad
except
mybad
as
x
print
x
custom
print
displays
always
look
on
the
bright
side
of
life
raise
mybad
traceback
most
recent
call
last
file
stdin
line
in
module
main
mybad
always
look
on
the
bright
side
of
life
a
subtle
point
to
note
here
is
that
you
generally
must
redefine
str
for
this
purpose
because
the
built
in
superclasses
already
have
a
str
method
and
str
is
preferred
to
repr
in
most
contexts
including
printing
if
you
define
a
repr
printing
will
happily
call
the
superclass
s
str
instead
see
chapter
for
more
details
on
these
special
methods
whatever
your
method
returns
is
included
in
error
messages
for
uncaught
exceptions
and
used
when
exceptions
are
printed
explicitly
the
method
returns
a
hardcoded
string
here
to
illustrate
but
it
can
also
perform
arbitrary
text
processing
possibly
using
state
information
attached
to
the
instance
object
the
next
section
looks
at
state
information
options
custom
data
and
behavior
besides
supporting
flexible
hierarchies
exception
classes
also
provide
storage
for
extra
state
information
as
instance
attributes
as
we
saw
earlier
built
in
exception
superclasses
provide
a
default
constructor
that
automatically
saves
constructor
arguments
in
an
instance
tuple
attribute
named
args
although
the
default
constructor
is
adequate
for
many
cases
for
more
custom
needs
we
can
provide
a
constructor
of
our
own
in
addition
classes
may
define
methods
for
use
in
handlers
that
provide
precoded
exception
processing
logic
providing
exception
details
when
an
exception
is
raised
it
may
cross
arbitrary
file
boundaries
the
raise
statement
that
triggers
an
exception
and
the
try
statement
that
catches
it
may
be
in
completely
different
module
files
it
is
not
generally
feasible
to
store
extra
details
in
global
variables
because
the
try
statement
might
not
know
which
file
the
globals
reside
in
passing
extra
state
information
along
in
the
exception
itself
allows
the
try
statement
to
access
it
more
reliably
with
classes
this
is
nearly
automatic
as
we
ve
seen
when
an
exception
is
raised
python
passes
the
class
instance
object
along
with
the
exception
code
in
try
statements
can
access
the
raised
instance
by
listing
an
extra
variable
after
the
as
keyword
in
an
except
handler
this
provides
a
natural
hook
for
supplying
data
and
behavior
to
the
handler
chapter
exception
objects
for
example
a
program
that
parses
data
files
might
signal
a
formatting
error
by
raising
an
exception
instance
that
is
filled
out
with
extra
details
about
the
error
class
formaterror
exception
def
init
self
line
file
self
line
line
self
file
file
def
parser
raise
formaterror
file
spam
txt
try
parser
except
formaterror
as
x
print
error
at
x
file
x
line
error
at
spam
txt
when
error
found
in
the
except
clause
here
the
variable
x
is
assigned
a
reference
to
the
instance
that
was
generated
when
the
exception
was
raised
this
gives
access
to
the
attributes
attached
to
the
instance
by
the
custom
constructor
although
we
could
rely
on
the
default
state
retention
of
built
in
superclasses
it
s
less
relevant
to
our
application
class
formaterror
exception
pass
def
parser
raise
formaterror
spam
txt
try
parser
except
formaterror
as
x
print
error
at
x
args
x
args
error
at
spam
txt
inherited
constructor
no
keywords
allowed
not
specific
to
this
app
providing
exception
methods
besides
enabling
application
specific
state
information
custom
constructors
also
better
support
extra
behavior
for
exception
objects
that
is
the
exception
class
can
also
define
methods
to
be
called
in
the
handler
the
following
for
example
adds
a
method
that
uses
exception
state
information
to
log
errors
to
a
file
class
formaterror
exception
logfile
formaterror
txt
def
init
self
line
file
self
line
line
self
file
file
as
suggested
earlier
the
raised
instance
object
is
also
available
generically
as
the
second
item
in
the
result
tuple
of
the
sys
exc
info
call
a
tool
that
returns
information
about
the
most
recently
raised
exception
this
interface
must
be
used
if
you
do
not
list
an
exception
name
in
an
except
clause
but
still
need
access
to
the
exception
that
occurred
or
to
any
of
its
attached
state
information
or
methods
more
on
sys
exc
info
in
the
next
chapter
custom
data
and
behavior
def
logerror
self
log
open
self
logfile
a
print
error
at
self
file
self
line
file
log
def
parser
raise
formaterror
spam
txt
try
parser
except
formaterror
as
exc
exc
logerror
when
run
this
script
writes
its
error
message
to
a
file
in
response
to
method
calls
in
the
exception
handler
c
misc
c
python
python
parse
py
c
misc
type
formaterror
txt
error
at
spam
txt
in
such
a
class
methods
like
logerror
may
also
be
inherited
from
superclasses
and
instance
attributes
like
line
and
file
provide
a
place
to
save
state
information
that
provides
extra
context
for
use
in
later
method
calls
moreover
exception
classes
are
free
to
customize
and
extend
inherited
behavior
in
other
words
because
they
are
defined
with
classes
all
the
benefits
of
oop
that
we
studied
in
part
vi
are
available
for
use
with
exceptions
in
python
chapter
summary
in
this
chapter
we
explored
coding
user
defined
exceptions
as
we
learned
exceptions
are
implemented
as
class
instance
objects
in
python
and
an
earlier
string
based
exception
model
alternative
was
available
in
earlier
releases
but
has
now
been
deprecated
exception
classes
support
the
concept
of
exception
hierarchies
that
ease
maintenance
allow
data
and
behavior
to
be
attached
to
exceptions
as
instance
attributes
and
methods
and
allow
exceptions
to
inherit
data
and
behavior
from
superclasses
we
saw
that
in
a
try
statement
catching
a
superclass
catches
that
class
as
well
as
all
subclasses
below
it
in
the
class
tree
superclasses
become
exception
category
names
and
subclasses
become
more
specific
exception
types
within
those
categories
we
also
saw
that
the
built
in
exception
superclasses
we
must
inherit
from
provide
usable
defaults
for
printing
and
state
retention
which
we
can
override
if
desired
the
next
chapter
wraps
up
this
part
of
the
book
by
exploring
some
common
use
cases
for
exceptions
and
surveying
tools
commonly
used
by
python
programmers
before
we
get
there
though
here
s
this
chapter
s
quiz
chapter
exception
objects
test
your
knowledge
quiz
what
are
the
two
new
constraints
on
user
defined
exceptions
in
python
how
are
raised
class
based
exceptions
matched
to
handlers
name
two
ways
that
you
can
attach
context
information
to
exception
objects
name
two
ways
that
you
can
specify
the
error
message
text
for
exception
objects
why
should
you
not
use
string
based
exceptions
anymore
today
test
your
knowledge
answers
in
exceptions
must
be
defined
by
classes
that
is
a
class
instance
object
is
raised
and
caught
in
addition
exception
classes
must
be
derived
from
the
built
in
class
baseexception
most
programs
inherit
from
its
exception
subclass
to
support
catchall
handlers
for
normal
kinds
of
exceptions
class
based
exceptions
match
by
superclass
relationships
naming
a
superclass
in
an
exception
handler
will
catch
instances
of
that
class
as
well
as
instances
of
any
of
its
subclasses
lower
in
the
class
tree
because
of
this
you
can
think
of
superclasses
as
general
exception
categories
and
subclasses
as
more
specific
types
of
exceptions
within
those
categories
you
can
attach
context
information
to
class
based
exceptions
by
filling
out
instance
attributes
in
the
instance
object
raised
usually
in
a
custom
class
constructor
for
simpler
needs
built
in
exception
superclasses
provide
a
constructor
that
stores
its
arguments
on
the
instance
automatically
in
the
attribute
args
in
exception
handlers
you
list
a
variable
to
be
assigned
to
the
raised
instance
then
go
through
this
name
to
access
attached
state
information
and
call
any
methods
defined
in
the
class
the
error
message
text
in
class
based
exceptions
can
be
specified
with
a
custom
str
operator
overloading
method
for
simpler
needs
built
in
exception
superclasses
automatically
display
anything
you
pass
to
the
class
constructor
operations
like
print
and
str
automatically
fetch
the
display
string
of
an
exception
object
when
is
it
printed
either
explicitly
or
as
part
of
an
error
message
because
guido
said
so
they
have
been
removed
in
both
python
and
really
there
are
good
reasons
for
this
string
based
exceptions
did
not
support
categories
state
information
or
behavior
inheritance
in
the
way
class
based
exceptions
do
in
practice
this
made
string
based
exceptions
easier
to
use
at
first
when
programs
were
small
but
more
complex
to
use
as
programs
grew
larger
test
your
knowledge
answers
chapter
designing
with
exceptions
this
chapter
rounds
out
this
part
of
the
book
with
a
collection
of
exception
design
topics
and
common
use
case
examples
followed
by
this
part
s
gotchas
and
exercises
because
this
chapter
also
closes
out
the
fundamentals
portion
of
the
book
at
large
it
includes
a
brief
overview
of
development
tools
as
well
to
help
you
as
you
make
the
migration
from
python
beginner
to
python
application
developer
nesting
exception
handlers
our
examples
so
far
have
used
only
a
single
try
to
catch
exceptions
but
what
happens
if
one
try
is
physically
nested
inside
another
for
that
matter
what
does
it
mean
if
a
try
calls
a
function
that
runs
another
try
technically
try
statements
can
nest
in
terms
of
syntax
and
the
runtime
control
flow
through
your
code
both
of
these
cases
can
be
understood
if
you
realize
that
python
stacks
try
statements
at
runtime
when
an
exception
is
raised
python
returns
to
the
most
recently
entered
try
statement
with
a
matching
except
clause
because
each
try
statement
leaves
a
marker
python
can
jump
back
to
earlier
trys
by
inspecting
the
stacked
markers
this
nesting
of
active
handlers
is
what
we
mean
when
we
talk
about
propagating
exceptions
up
to
higher
handlers
such
handlers
are
simply
try
statements
entered
earlier
in
the
program
s
execution
flow
figure
illustrates
what
occurs
when
try
statements
with
except
clauses
nest
at
runtime
the
amount
of
code
that
goes
into
a
try
block
can
be
substantial
and
it
may
contain
function
calls
that
invoke
other
code
watching
for
the
same
exceptions
when
an
exception
is
eventually
raised
python
jumps
back
to
the
most
recently
entered
try
statement
that
names
that
exception
runs
that
statement
s
except
clause
and
then
resumes
execution
after
that
try
once
the
exception
is
caught
its
life
is
over
control
does
not
jump
back
to
all
matching
trys
that
name
the
exception
only
the
first
one
is
given
the
opportunity
to
handle
it
in
figure
for
instance
the
raise
statement
in
the
function
func
sends
control
back
to
the
handler
in
func
and
then
the
program
continues
within
func
figure
nested
try
except
statements
when
an
exception
is
raised
by
you
or
by
python
control
jumps
back
to
the
most
recently
entered
try
statement
with
a
matching
except
clause
and
the
program
resumes
after
that
try
statement
except
clauses
intercept
and
stop
the
exception
they
are
where
you
process
and
recover
from
exceptions
by
contrast
when
try
statements
that
contain
only
finally
clauses
are
nested
each
finally
block
is
run
in
turn
when
an
exception
occurs
python
continues
propagating
the
exception
up
to
other
trys
and
eventually
perhaps
to
the
top
level
default
handler
the
standard
error
message
printer
as
figure
illustrates
the
finally
clauses
do
not
kill
the
exception
they
just
specify
code
to
be
run
on
the
way
out
of
each
try
during
the
exception
propagation
process
if
there
are
many
try
finally
clauses
active
when
an
exception
occurs
they
will
all
be
run
unless
a
try
except
catches
the
exception
somewhere
along
the
way
figure
nested
try
finally
statements
when
an
exception
is
raised
here
control
returns
to
the
most
recently
entered
try
to
run
its
finally
statement
but
then
the
exception
keeps
propagating
to
all
finallys
in
all
active
try
statements
and
eventually
reaches
the
default
top
level
handler
where
an
error
message
is
printed
finally
clauses
intercept
but
do
not
stop
an
exception
they
are
for
actions
to
be
performed
on
the
way
out
in
other
words
where
the
program
goes
when
an
exception
is
raised
depends
entirely
upon
where
it
has
been
it
s
a
function
of
the
runtime
flow
of
control
through
the
script
not
just
its
syntax
the
propagation
of
an
exception
essentially
proceeds
backward
through
time
to
try
statements
that
have
been
entered
but
not
yet
exited
this
propagation
stops
as
soon
as
control
is
unwound
to
a
matching
except
clause
but
not
as
it
passes
through
finally
clauses
on
the
way
chapter
designing
with
exceptions
example
control
flow
nesting
let
s
turn
to
an
example
to
make
this
nesting
concept
more
concrete
the
following
module
file
nestexc
py
defines
two
functions
action
is
coded
to
trigger
an
exception
you
can
t
add
numbers
and
sequences
and
action
wraps
a
call
to
action
in
a
try
handler
to
catch
the
exception
def
action
print
def
action
try
action
except
typeerror
print
inner
try
generate
typeerror
most
recent
matching
try
try
action
except
typeerror
print
outer
try
here
only
if
action
re
raises
python
nestexc
py
inner
try
notice
though
that
the
top
level
module
code
at
the
bottom
of
the
file
wraps
a
call
to
action
in
a
try
handler
too
when
action
triggers
the
typeerror
exception
there
will
be
two
active
try
statements
the
one
in
action
and
the
one
at
the
top
level
of
the
module
file
python
picks
and
runs
just
the
most
recent
try
with
a
matching
except
which
in
this
case
is
the
try
inside
action
as
i
ve
mentioned
the
place
where
an
exception
winds
up
jumping
to
depends
on
the
control
flow
through
the
program
at
runtime
because
of
this
to
know
where
you
will
go
you
need
to
know
where
you
ve
been
in
this
case
where
exceptions
are
handled
is
more
a
function
of
control
flow
than
of
statement
syntax
however
we
can
also
nest
exception
handlers
syntactically
an
equivalent
case
we
ll
look
at
next
example
syntactic
nesting
as
i
mentioned
when
we
looked
at
the
new
unified
try
except
finally
statement
in
chapter
it
is
possible
to
nest
try
statements
syntactically
by
their
position
in
your
source
code
try
try
action
except
typeerror
print
inner
try
except
typeerror
print
outer
try
most
recent
matching
try
here
only
if
nested
handler
re
raises
nesting
exception
handlers
really
this
code
just
sets
up
the
same
handler
nesting
structure
as
and
behaves
identically
to
the
prior
example
in
fact
syntactic
nesting
works
just
like
the
cases
sketched
in
figures
and
the
only
difference
is
that
the
nested
handlers
are
physically
embedded
in
a
try
block
not
coded
in
functions
called
elsewhere
for
example
nested
finally
handlers
all
fire
on
an
exception
whether
they
are
nested
syntactically
or
by
means
of
the
runtime
flow
through
physically
separated
parts
of
your
code
try
try
raise
indexerror
finally
print
spam
finally
print
spam
spam
spam
traceback
most
recent
call
last
file
stdin
line
in
module
indexerror
see
figure
for
a
graphic
illustration
of
this
code
s
operation
the
effect
is
the
same
but
the
function
logic
has
been
inlined
as
nested
statements
here
for
a
more
useful
example
of
syntactic
nesting
at
work
consider
the
following
file
except
finally
py
def
raise
raise
indexerror
def
noraise
return
def
raise
raise
syntaxerror
for
func
in
raise
noraise
raise
print
n
func
sep
try
try
func
except
indexerror
print
caught
indexerror
finally
print
finally
run
this
code
catches
an
exception
if
one
is
raised
and
performs
a
finally
terminationtime
action
regardless
of
whether
an
exception
occurs
this
may
take
a
few
moments
to
digest
but
the
effect
is
much
like
combining
an
except
and
a
finally
clause
in
a
single
try
statement
in
python
and
later
python
except
finally
py
function
raise
at
x
eca
caught
indexerror
finally
run
function
noraise
at
x
eca
finally
run
function
raise
at
x
ecbb
finally
run
chapter
designing
with
exceptions
traceback
most
recent
call
last
file
except
finally
py
line
in
module
func
file
except
finally
py
line
in
raise
def
raise
raise
syntaxerror
syntaxerror
none
as
we
saw
in
chapter
as
of
python
except
and
finally
clauses
can
be
mixed
in
the
same
try
statement
this
makes
some
of
the
syntactic
nesting
described
in
this
section
unnecessary
though
it
still
works
may
appear
in
code
written
prior
to
python
that
you
may
encounter
and
can
be
used
as
a
technique
for
implementing
alternative
exception
handling
behaviors
exception
idioms
we
ve
seen
the
mechanics
behind
exceptions
now
let
s
take
a
look
at
some
of
the
other
ways
they
are
typically
used
exceptions
aren
t
always
errors
in
python
all
errors
are
exceptions
but
not
all
exceptions
are
errors
for
instance
we
saw
in
chapter
that
file
object
read
methods
return
an
empty
string
at
the
end
of
a
file
in
contrast
the
built
in
input
function
which
we
first
met
in
chapter
and
deployed
in
an
interactive
loop
in
chapter
reads
a
line
of
text
from
the
standard
input
stream
sys
stdin
at
each
call
and
raises
the
built
in
eoferror
at
end
of
file
this
function
is
known
as
raw
input
in
python
unlike
file
methods
this
function
does
not
return
an
empty
string
an
empty
string
from
input
means
an
empty
line
despite
its
name
the
eoferror
exception
is
just
a
signal
in
this
context
not
an
error
because
of
this
behavior
unless
the
end
of
file
should
terminate
a
script
input
often
appears
wrapped
in
a
try
handler
and
nested
in
a
loop
as
in
the
following
code
while
true
try
line
input
read
line
from
stdin
except
eoferror
break
exit
loop
at
end
of
file
else
process
next
line
here
several
other
built
in
exceptions
are
similarly
signals
not
errors
calling
sys
exit
and
pressing
ctrl
c
on
your
keyboard
respectively
raise
systemexit
and
key
boardinterrupt
for
example
python
also
has
a
set
of
built
in
exceptions
that
represent
warnings
rather
than
errors
some
of
these
are
used
to
signal
use
of
deprecated
phased
out
language
features
see
the
standard
library
manual
s
description
of
built
in
exceptions
for
more
information
and
consult
the
warnings
module
s
documentation
for
more
on
warnings
exception
idioms
functions
can
signal
conditions
with
raise
user
defined
exceptions
can
also
signal
nonerror
conditions
for
instance
a
search
routine
can
be
coded
to
raise
an
exception
when
a
match
is
found
instead
of
returning
a
status
flag
for
the
caller
to
interpret
in
the
following
the
try
except
else
exception
handler
does
the
work
of
an
if
else
return
value
tester
class
found
exception
pass
def
searcher
if
success
raise
found
else
return
try
searcher
except
found
success
else
failure
exception
if
item
was
found
else
returned
not
found
more
generally
such
a
coding
structure
may
also
be
useful
for
any
function
that
cannot
return
a
sentinel
value
to
designate
success
or
failure
for
instance
if
all
objects
are
potentially
valid
return
values
it
s
impossible
for
any
return
value
to
signal
unusual
conditions
exceptions
provide
a
way
to
signal
results
without
a
return
value
class
failure
exception
pass
def
searcher
if
success
return
founditem
else
raise
failure
try
item
searcher
except
failure
report
else
use
item
here
because
python
is
dynamically
typed
and
polymorphic
to
the
core
exceptions
rather
than
sentinel
return
values
are
the
generally
preferred
way
to
signal
such
conditions
closing
files
and
server
connections
we
encountered
examples
in
this
category
in
chapter
as
a
summary
though
exception
processing
tools
are
also
commonly
used
to
ensure
that
system
resources
are
finalized
regardless
of
whether
an
error
occurs
during
processing
or
not
chapter
designing
with
exceptions
for
example
some
servers
require
connections
to
be
closed
in
order
to
terminate
a
session
similarly
output
files
may
require
close
calls
to
flush
their
buffers
to
disk
and
input
files
may
consume
file
descriptors
if
not
closed
although
file
objects
are
automatically
closed
when
garbage
collected
if
still
open
it
s
sometimes
difficult
to
be
sure
when
that
will
occur
the
most
general
and
explicit
way
to
guarantee
termination
actions
for
a
specific
block
of
code
is
the
try
finally
statement
myfile
open
r
c
misc
script
w
try
process
myfile
finally
myfile
close
as
we
saw
in
chapter
some
objects
make
this
easier
in
python
and
by
providing
context
managers
run
by
the
with
as
statement
that
terminate
or
close
the
objects
for
us
automatically
with
open
r
c
misc
script
w
as
myfile
process
myfile
so
which
option
is
better
here
as
usual
it
depends
on
your
programs
compared
to
the
try
finally
context
managers
are
more
implicit
which
runs
contrary
to
python
s
general
design
philosophy
context
managers
are
also
arguably
less
general
they
are
available
only
for
select
objects
and
writing
user
defined
context
managers
to
handle
general
termination
requirements
is
more
complex
than
coding
a
try
finally
on
the
other
hand
using
existing
context
managers
requires
less
code
than
using
try
finally
as
shown
by
the
preceding
examples
moreover
the
context
manager
protocol
supports
entry
actions
in
addition
to
exit
actions
although
the
try
finally
is
perhaps
the
more
widely
applicable
technique
context
managers
may
be
more
appropriate
where
they
are
already
available
or
where
their
extra
complexity
is
warranted
debugging
with
outer
try
statements
you
can
also
make
use
of
exception
handlers
to
replace
python
s
default
top
level
exception
handling
behavior
by
wrapping
an
entire
program
or
a
call
to
it
in
an
outer
try
in
your
top
level
code
you
can
catch
any
exception
that
may
occur
while
your
program
runs
thereby
subverting
the
default
program
termination
in
the
following
the
empty
except
clause
catches
any
uncaught
exception
raised
while
the
program
runs
to
get
hold
of
the
actual
exception
that
occurred
fetch
the
sys
exc
info
function
call
result
from
the
built
in
sys
module
it
returns
a
tuple
whose
first
two
items
contain
the
current
exception
s
class
and
the
instance
object
raised
more
on
sys
exc
info
in
a
moment
exception
idioms
try
run
program
except
all
uncaught
exceptions
come
here
import
sys
print
uncaught
sys
exc
info
sys
exc
info
this
structure
is
commonly
used
during
development
to
keep
programs
active
even
after
errors
occur
it
allows
you
to
run
additional
tests
without
having
to
restart
it
s
also
used
when
testing
other
program
code
as
described
in
the
next
section
running
in
process
tests
you
might
combine
some
of
the
coding
patterns
we
ve
just
looked
at
in
a
test
driver
application
that
tests
other
code
within
the
same
process
import
sys
log
open
testlog
a
from
testapi
import
moretests
runnexttest
testname
def
testdriver
while
moretests
try
runnexttest
except
print
failed
testname
sys
exc
info
file
log
else
print
passed
testname
file
log
testdriver
the
testdriver
function
here
cycles
through
a
series
of
test
calls
the
module
testapi
is
left
abstract
in
this
example
because
an
uncaught
exception
in
a
test
case
would
normally
kill
this
test
driver
you
need
to
wrap
test
case
calls
in
a
try
if
you
want
to
continue
the
testing
process
after
a
test
fails
the
empty
except
catches
any
uncaught
exception
generated
by
a
test
case
as
usual
and
it
uses
sys
exc
info
to
log
the
exception
to
a
file
the
else
clause
is
run
when
no
exception
occurs
the
test
success
case
such
boilerplate
code
is
typical
of
systems
that
test
functions
modules
and
classes
by
running
them
in
the
same
process
as
the
test
driver
in
practice
however
testing
can
be
much
more
sophisticated
than
this
for
instance
to
test
external
programs
you
could
instead
check
status
codes
or
outputs
generated
by
program
launching
tools
such
as
os
system
and
os
popen
covered
in
the
standard
library
manual
such
tools
do
not
generally
raise
exceptions
for
errors
in
the
external
programs
in
fact
the
test
cases
may
run
in
parallel
with
the
test
driver
at
the
end
of
this
chapter
we
ll
also
meet
some
more
complete
testing
frameworks
provided
by
python
such
as
doctest
and
pyunit
which
provide
tools
for
comparing
expected
outputs
with
actual
results
chapter
designing
with
exceptions
more
on
sys
exc
info
the
sys
exc
info
result
used
in
the
last
two
sections
allows
an
exception
handler
to
gain
access
to
the
most
recently
raised
exception
generically
this
is
especially
useful
when
using
the
empty
except
clause
to
catch
everything
blindly
to
determine
what
was
raised
try
except
sys
exc
info
are
the
exception
class
and
instance
if
no
exception
is
being
handled
this
call
it
returns
a
tuple
containing
three
none
values
otherwise
the
values
returned
are
type
value
traceback
where
type
is
the
exception
class
of
the
exception
being
handled
value
is
the
exception
class
instance
that
was
raised
traceback
is
a
traceback
object
that
represents
the
call
stack
at
the
point
where
the
exception
originally
occurred
see
the
traceback
module
s
documentation
for
tools
that
may
be
used
in
conjunction
with
this
object
to
generate
error
messages
manually
as
we
saw
in
the
prior
chapter
sys
exc
info
can
also
sometimes
be
useful
to
determine
the
specific
exception
type
when
catching
exception
category
superclasses
as
we
saw
though
because
in
this
case
you
can
also
get
the
exception
type
by
fetching
the
class
attribute
of
the
instance
obtained
with
the
as
clause
sys
exc
info
is
mostly
used
by
the
empty
except
today
try
except
general
as
instance
instance
class
is
the
exception
class
that
said
using
the
instance
object
s
interfaces
and
polymorphism
is
often
a
better
approach
than
testing
exception
types
exception
methods
can
be
defined
per
class
and
run
generically
try
except
general
as
instance
instance
method
does
the
right
thing
for
this
instance
as
usual
being
too
specific
in
python
can
limit
your
code
s
flexibility
a
polymorphic
approach
like
the
last
example
here
generally
supports
future
evolution
better
exception
idioms
version
skew
note
in
python
the
older
tools
sys
exc
type
and
sys
exc
value
still
work
to
fetch
the
most
recent
exception
type
and
value
but
they
can
manage
only
a
single
global
exception
for
the
entire
process
these
two
names
have
been
removed
in
python
the
newer
and
preferred
sys
exc
info
call
available
in
both
and
instead
keeps
track
of
each
thread
s
exception
information
and
so
is
threadspecific
of
course
this
distinction
matters
only
when
using
multiple
threads
in
python
programs
a
subject
beyond
this
book
s
scope
but
forces
the
issue
see
other
resources
for
more
details
exception
design
tips
and
gotchas
i
m
lumping
design
tips
and
gotchas
together
in
this
chapter
because
it
turns
out
that
the
most
common
gotchas
largely
stem
from
design
issues
by
and
large
exceptions
are
easy
to
use
in
python
the
real
art
behind
them
is
in
deciding
how
specific
or
general
your
except
clauses
should
be
and
how
much
code
to
wrap
up
in
try
statements
let
s
address
the
second
of
these
concerns
first
what
should
be
wrapped
in
principle
you
could
wrap
every
statement
in
your
script
in
its
own
try
but
that
would
just
be
silly
the
try
statements
would
then
need
to
be
wrapped
in
try
statements
what
to
wrap
is
really
a
design
issue
that
goes
beyond
the
language
itself
and
it
will
become
more
apparent
with
use
but
for
now
here
are
a
few
rules
of
thumb
operations
that
commonly
fail
should
generally
be
wrapped
in
try
statements
for
example
operations
that
interface
with
system
state
file
opens
socket
calls
and
the
like
are
prime
candidates
for
trys
however
there
are
exceptions
to
the
prior
rule
in
a
simple
script
you
may
want
failures
of
such
operations
to
kill
your
program
instead
of
being
caught
and
ignored
this
is
especially
true
if
the
failure
is
a
showstopper
failures
in
python
typically
result
in
useful
error
messages
not
hard
crashes
and
this
is
often
the
best
outcome
you
could
hope
for
you
should
implement
termination
actions
in
try
finally
statements
to
guarantee
their
execution
unless
a
context
manager
is
available
as
a
with
as
option
the
try
finally
statement
form
allows
you
to
run
code
whether
exceptions
occur
or
not
in
arbitrary
scenarios
it
is
sometimes
more
convenient
to
wrap
the
call
to
a
large
function
in
a
single
try
statement
rather
than
littering
the
function
itself
with
many
try
statements
that
way
all
exceptions
in
the
function
percolate
up
to
the
try
around
the
call
and
you
reduce
the
amount
of
code
within
the
function
the
types
of
programs
you
write
will
probably
influence
the
amount
of
exception
handling
you
code
as
well
servers
for
instance
must
generally
keep
running
persistently
chapter
designing
with
exceptions
and
so
will
likely
require
try
statements
to
catch
and
recover
from
exceptions
inprocess
testing
programs
of
the
kind
we
saw
in
this
chapter
will
probably
handle
exceptions
as
well
simpler
one
shot
scripts
though
will
often
ignore
exception
handling
completely
because
failure
at
any
step
requires
script
shutdown
catching
too
much
avoid
empty
except
and
exception
on
to
the
issue
of
handler
generality
python
lets
you
pick
and
choose
which
exceptions
to
catch
but
you
sometimes
have
to
be
careful
to
not
be
too
inclusive
for
example
you
ve
seen
that
an
empty
except
clause
catches
every
exception
that
might
be
raised
while
the
code
in
the
try
block
runs
that
s
easy
to
code
and
sometimes
desirable
but
you
may
also
wind
up
intercepting
an
error
that
s
expected
by
a
try
handler
higher
up
in
the
exception
nesting
structure
for
example
an
exception
handler
such
as
the
following
catches
and
stops
every
exception
that
reaches
it
regardless
of
whether
another
handler
is
waiting
for
it
def
func
try
except
try
func
except
indexerror
indexerror
is
raised
in
here
but
everything
comes
here
and
dies
exception
should
be
processed
here
perhaps
worse
such
code
might
also
catch
unrelated
system
exceptions
even
things
like
memory
errors
genuine
programming
mistakes
iteration
stops
keyboard
interrupts
and
system
exits
raise
exceptions
in
python
such
exceptions
should
not
usually
be
intercepted
for
example
scripts
normally
exit
when
control
falls
off
the
end
of
the
top
level
file
however
python
also
provides
a
built
in
sys
exit
statuscode
call
to
allow
early
terminations
this
actually
works
by
raising
a
built
in
systemexit
exception
to
end
the
program
so
that
try
finally
handlers
run
on
the
way
out
and
special
types
of
programs
can
intercept
the
event
because
of
this
a
try
with
an
empty
except
might
unknowingly
prevent
a
crucial
exit
as
in
the
following
file
exiter
py
import
sys
def
bye
sys
exit
try
bye
except
print
got
it
crucial
error
abort
now
oops
we
ignored
the
exit
a
related
call
os
exit
also
ends
a
program
but
via
an
immediate
termination
it
skips
cleanup
actions
and
cannot
be
intercepted
with
try
except
or
try
finally
blocks
it
is
usually
only
used
in
spawned
child
processes
a
topic
beyond
this
book
s
scope
see
the
library
manual
or
follow
up
texts
for
details
exception
design
tips
and
gotchas
print
continuing
python
exiter
py
got
it
continuing
you
simply
might
not
expect
all
the
kinds
of
exceptions
that
could
occur
during
an
operation
using
the
built
in
exception
classes
of
the
prior
chapter
can
help
in
this
particular
case
because
the
exception
superclass
is
not
a
superclass
of
systemexit
try
bye
except
exception
won
t
catch
exits
but
will
catch
many
others
in
other
cases
though
this
scheme
is
no
better
than
an
empty
except
clause
because
exception
is
a
superclass
above
all
built
in
exceptions
except
system
exit
events
it
still
has
the
potential
to
catch
exceptions
meant
for
elsewhere
in
the
program
probably
worst
of
all
both
an
empty
except
and
catching
the
exception
class
will
also
catch
genuine
programming
errors
which
should
be
allowed
to
pass
most
of
the
time
in
fact
these
two
techniques
can
effectively
turn
off
python
s
error
reporting
machinery
making
it
difficult
to
notice
mistakes
in
your
code
consider
this
code
for
example
mydictionary
try
x
myditctionary
spam
except
x
none
continue
here
with
x
oops
misspelled
assume
we
got
keyerror
the
coder
here
assumes
that
the
only
sort
of
error
that
can
happen
when
indexing
a
dictionary
is
a
missing
key
error
but
because
the
name
myditctionary
is
misspelled
it
should
say
mydictionary
python
raises
a
nameerror
instead
for
the
undefined
name
reference
which
the
handler
will
silently
catch
and
ignore
the
event
handler
will
incorrectly
fill
in
a
default
for
the
dictionary
access
masking
the
program
error
moreover
catching
exception
here
would
have
the
exact
same
effect
as
an
empty
except
if
this
happens
in
code
that
is
far
removed
from
the
place
where
the
fetched
values
are
used
it
might
make
for
a
very
interesting
debugging
task
as
a
rule
of
thumb
be
as
specific
in
your
handlers
as
you
can
be
empty
except
clauses
and
exception
catchers
are
handy
but
potentially
error
prone
in
the
last
example
for
instance
you
would
be
better
off
saying
except
keyerror
to
make
your
intentions
explicit
and
avoid
intercepting
unrelated
events
in
simpler
scripts
the
potential
for
problems
might
not
be
significant
enough
to
outweigh
the
convenience
of
a
catchall
but
in
general
general
handlers
are
generally
trouble
chapter
designing
with
exceptions
catching
too
little
use
class
based
categories
on
the
other
hand
neither
should
handlers
be
too
specific
when
you
list
specific
exceptions
in
a
try
you
catch
only
what
you
actually
list
this
isn
t
necessarily
a
bad
thing
but
if
a
system
evolves
to
raise
other
exceptions
in
the
future
you
may
need
to
go
back
and
add
them
to
exception
lists
elsewhere
in
your
code
we
saw
this
phenomenon
at
work
in
the
prior
chapter
for
instance
the
following
handler
is
written
to
treat
myexcept
and
myexcept
as
normal
cases
and
everything
else
as
an
error
therefore
if
you
add
a
myexcept
in
the
future
it
will
be
processed
as
an
error
unless
you
update
the
exception
list
try
except
myexcept
myexcept
else
breaks
if
you
add
a
myexcept
non
errors
assumed
to
be
an
error
luckily
careful
use
of
the
class
based
exceptions
we
discussed
in
chapter
can
make
this
trap
go
away
completely
as
we
saw
if
you
catch
a
general
superclass
you
can
add
and
raise
more
specific
subclasses
in
the
future
without
having
to
extend
except
clause
lists
manually
the
superclass
becomes
an
extendible
exceptions
category
try
except
successcategoryname
else
ok
if
i
add
a
myerror
subclass
non
errors
assumed
to
be
an
error
in
other
words
a
little
design
goes
a
long
way
the
moral
of
the
story
is
to
be
careful
to
be
neither
too
general
nor
too
specific
in
exception
handlers
and
to
pick
the
granularity
of
your
try
statement
wrappings
wisely
especially
in
larger
systems
exception
policies
should
be
a
part
of
the
overall
design
core
language
summary
congratulations
this
concludes
your
look
at
the
core
python
programming
language
if
you
ve
gotten
this
far
you
may
consider
yourself
an
official
python
programmer
and
should
feel
free
to
add
python
to
your
r√©sum√©
the
next
time
you
dig
it
out
you
ve
already
seen
just
about
everything
there
is
to
see
in
the
language
itself
and
all
in
much
more
depth
than
many
practicing
python
programmers
initially
do
you
ve
studied
built
in
types
statements
and
exceptions
as
well
as
tools
used
to
build
up
larger
program
units
functions
modules
and
classes
you
ve
even
explored
important
design
issues
oop
program
architecture
and
more
core
language
summary
the
python
toolset
from
this
point
forward
your
future
python
career
will
largely
consist
of
becoming
proficient
with
the
toolset
available
for
application
level
python
programming
you
ll
find
this
to
be
an
ongoing
task
the
standard
library
for
example
contains
hundreds
of
modules
and
the
public
domain
offers
still
more
tools
it
s
possible
to
spend
a
decade
or
more
seeking
proficiency
with
all
these
tools
especially
as
new
ones
are
constantly
appearing
trust
me
on
this
speaking
generally
python
provides
a
hierarchy
of
toolsets
built
ins
built
in
types
like
strings
lists
and
dictionaries
make
it
easy
to
write
simple
programs
fast
python
extensions
for
more
demanding
tasks
you
can
extend
python
by
writing
your
own
functions
modules
and
classes
compiled
extensions
although
we
don
t
cover
this
topic
in
this
book
python
can
also
be
extended
with
modules
written
in
an
external
language
like
c
or
c
because
python
layers
its
toolsets
you
can
decide
how
deeply
your
programs
need
to
delve
into
this
hierarchy
for
any
given
task
you
can
use
built
ins
for
simple
scripts
add
python
coded
extensions
for
larger
systems
and
code
compiled
extensions
for
advanced
work
we
ve
only
covered
the
first
two
of
these
categories
in
this
book
and
that
s
plenty
to
get
you
started
doing
substantial
programming
in
python
table
summarizes
some
of
the
sources
of
built
in
or
existing
functionality
available
to
python
programmers
and
some
topics
you
ll
probably
be
busy
exploring
for
the
remainder
of
your
python
career
up
until
now
most
of
our
examples
have
been
very
small
and
self
contained
they
were
written
that
way
on
purpose
to
help
you
master
the
basics
but
now
that
you
know
all
about
the
core
language
it
s
time
to
start
learning
how
to
use
python
s
built
in
interfaces
to
do
real
work
you
ll
find
that
with
a
simple
language
like
python
common
tasks
are
often
much
easier
than
you
might
expect
table
python
s
toolbox
categories
category
examples
object
types
lists
dictionaries
files
strings
functions
len
range
open
exceptions
indexerror
keyerror
modules
os
tkinter
pickle
re
attributes
dict
name
class
peripheral
tools
numpy
swig
jython
ironpython
django
etc
chapter
designing
with
exceptions
development
tools
for
larger
projects
once
you
ve
mastered
the
basics
you
ll
find
your
python
programs
becoming
substantially
larger
than
the
examples
you
ve
experimented
with
so
far
for
developing
larger
systems
a
set
of
development
tools
is
available
in
python
and
the
public
domain
you
ve
seen
some
of
these
in
action
and
i
ve
mentioned
a
few
others
to
help
you
on
your
way
here
is
a
summary
of
some
of
the
most
commonly
used
tools
in
this
domain
pydoc
and
docstrings
pydoc
s
help
function
and
html
interfaces
were
introduced
in
chapter
pydoc
provides
a
documentation
system
for
your
modules
and
objects
and
integrates
with
python
s
docstrings
feature
it
is
a
standard
part
of
the
python
system
see
the
library
manual
for
more
details
be
sure
to
also
refer
back
to
the
documentation
source
hints
listed
in
chapter
for
information
on
other
python
information
resources
pychecker
and
pylint
because
python
is
such
a
dynamic
language
some
programming
errors
are
not
reported
until
your
program
runs
e
g
syntax
errors
are
caught
when
a
file
is
run
or
imported
this
isn
t
a
big
drawback
as
with
most
languages
it
just
means
that
you
have
to
test
your
python
code
before
shipping
it
at
worst
with
python
you
essentially
trade
a
compile
phase
for
an
initial
testing
phase
furthermore
python
s
dynamic
nature
automatic
error
messages
and
exception
model
make
it
easier
and
quicker
to
find
and
fix
errors
in
python
than
it
is
in
some
other
languages
unlike
c
for
example
python
does
not
crash
on
errors
the
pychecker
and
pylint
systems
provide
support
for
catching
a
large
set
of
common
errors
ahead
of
time
before
your
script
runs
they
serve
similar
roles
to
the
lint
program
in
c
development
some
python
groups
run
their
code
through
pychecker
prior
to
testing
or
delivery
to
catch
any
lurking
potential
problems
in
fact
the
python
standard
library
is
regularly
run
through
pychecker
before
release
pychecker
and
pylint
are
third
party
open
source
packages
you
can
find
them
at
http
www
python
org
or
the
pypi
website
or
via
your
friendly
neighborhood
web
search
engine
pyunit
a
k
a
unittest
in
chapter
we
learned
how
to
add
self
test
code
to
a
python
file
by
using
the
name
main
trick
at
the
bottom
of
the
file
for
more
advanced
testing
purposes
python
comes
with
two
testing
support
tools
the
first
pyunit
called
unittest
in
the
library
manual
provides
an
object
oriented
class
framework
for
specifying
and
customizing
test
cases
and
expected
results
it
mimics
the
junit
framework
for
java
this
is
a
sophisticated
class
based
unit
testing
system
see
the
python
library
manual
for
details
doctest
the
doctest
standard
library
module
provides
a
second
and
simpler
approach
to
regression
testing
based
upon
python
s
docstrings
feature
roughly
to
use
core
language
summary
doctest
you
cut
and
paste
a
log
of
an
interactive
testing
session
into
the
docstrings
of
your
source
files
doctest
then
extracts
your
docstrings
parses
out
the
test
cases
and
results
and
reruns
the
tests
to
verify
the
expected
results
doctest
s
operation
can
be
tailored
in
a
variety
of
ways
see
the
library
manual
for
more
details
ides
we
discussed
ides
for
python
in
chapter
ides
such
as
idle
provide
a
graphical
environment
for
editing
running
debugging
and
browsing
your
python
programs
some
advanced
ides
such
as
eclipse
komodo
netbeans
and
wing
ide
may
support
additional
development
tasks
including
source
control
integration
code
refactoring
project
management
tools
and
more
see
chapter
the
text
editors
page
at
http
www
python
org
and
your
favorite
web
search
engine
for
more
on
available
ides
and
gui
builders
for
python
profilers
because
python
is
so
high
level
and
dynamic
intuitions
about
performance
gleaned
from
experience
with
other
languages
usually
don
t
apply
to
python
code
to
truly
isolate
performance
bottlenecks
in
your
code
you
need
to
add
timing
logic
with
clock
tools
in
the
time
or
timeit
modules
or
run
your
code
under
the
profile
module
we
saw
an
example
of
the
timing
modules
at
work
when
comparing
iteration
tools
speeds
in
chapter
profiling
is
usually
your
first
optimization
step
profile
to
isolate
bottlenecks
then
time
alternative
codings
of
them
profile
is
a
standard
library
module
that
implements
a
source
code
profiler
for
python
it
runs
a
string
of
code
you
provide
e
g
a
script
file
import
or
a
call
to
a
function
and
then
by
default
prints
a
report
to
the
standard
output
stream
that
gives
performance
statistics
number
of
calls
to
each
function
time
spent
in
each
function
and
more
the
profile
module
can
be
run
as
a
script
or
imported
and
it
may
be
customized
in
various
ways
for
example
it
can
save
run
statistics
to
a
file
to
be
analyzed
later
with
the
pstats
module
to
profile
interactively
import
the
profile
module
and
call
profile
run
code
passing
in
the
code
you
wish
to
profile
as
a
string
e
g
a
call
to
a
function
or
an
import
of
an
entire
file
to
profile
from
a
system
shell
command
line
use
a
command
of
the
form
python
m
profile
main
py
args
see
appendix
a
for
more
on
this
format
also
see
python
s
standard
library
manuals
for
other
profiling
options
the
cprofile
module
for
example
has
identical
interfaces
to
profile
but
runs
with
less
overhead
so
it
may
be
better
suited
to
profiling
long
running
programs
debuggers
we
also
discussed
debugging
options
in
chapter
see
its
sidebar
debugging
python
code
on
page
as
a
review
most
development
ides
for
python
support
gui
based
debugging
and
the
python
standard
library
also
includes
a
source
code
debugger
module
called
pdb
this
module
provides
a
command
line
interface
and
works
much
like
common
c
language
debuggers
e
g
dbx
gdb
chapter
designing
with
exceptions
much
like
the
profiler
the
pdb
debugger
can
be
run
either
interactively
or
from
a
command
line
and
can
be
imported
and
called
from
a
python
program
to
use
it
interactively
import
the
module
start
running
code
by
calling
a
pdb
function
e
g
pdb
run
main
and
then
type
debugging
commands
from
pdb
s
interactive
prompt
to
launch
pdb
from
a
system
shell
command
line
use
a
command
of
the
form
python
m
pdb
main
py
args
see
appendix
a
for
more
on
this
format
pdb
also
includes
a
useful
postmortem
analysis
call
pdb
pm
which
starts
the
debugger
after
an
exception
has
been
encountered
because
ides
such
as
idle
also
include
point
and
click
debugging
interfaces
pdb
isn
t
a
critical
a
tool
today
except
when
a
gui
isn
t
available
or
when
more
control
is
desired
see
chapter
for
tips
on
using
idle
s
debugging
gui
interfaces
really
neither
pdb
nor
ides
seem
to
be
used
much
in
practice
as
noted
in
chapter
most
programmers
either
insert
print
statements
or
simply
read
python
s
error
messages
not
the
most
high
tech
of
approaches
but
the
practical
tends
to
win
the
day
in
the
python
world
shipping
options
in
chapter
we
introduced
common
tools
for
packaging
python
programs
py
exe
pyinstaller
and
freeze
can
package
byte
code
and
the
python
virtual
machine
into
frozen
binary
standalone
executables
which
don
t
require
that
python
be
installed
on
the
target
machine
and
fully
hide
your
system
s
code
in
addition
we
learned
in
chapter
that
python
programs
may
be
shipped
in
their
source
py
or
byte
code
pyc
forms
and
that
import
hooks
support
special
packaging
techniques
such
as
automatic
extraction
of
zip
files
and
byte
code
encryption
we
also
briefly
met
the
standard
library
s
distutils
modules
which
provide
packaging
options
for
python
modules
and
packages
and
c
coded
extensions
see
the
python
manuals
for
more
details
the
emerging
python
eggs
third
party
packaging
system
provides
another
alternative
that
also
accounts
for
dependencies
search
the
web
for
more
details
optimization
options
there
are
a
couple
of
options
for
optimizing
your
programs
the
psyco
system
described
in
chapter
provides
a
just
in
time
compiler
for
translating
python
byte
code
to
binary
machine
code
and
shedskin
offers
a
python
to
c
translator
you
may
also
occasionally
see
pyo
optimized
byte
code
files
generated
and
run
with
the
o
python
command
line
flag
discussed
in
chapters
and
because
this
provides
a
very
modest
performance
boost
however
it
is
not
commonly
used
as
a
last
resort
you
can
also
move
parts
of
your
program
to
a
compiled
language
such
as
c
to
boost
performance
see
the
book
programming
python
and
the
python
standard
manuals
for
more
on
c
extensions
in
general
python
s
speed
also
improves
over
time
so
be
sure
to
upgrade
to
the
faster
releases
when
possible
core
language
summary
other
hints
for
larger
projects
we
ve
met
a
variety
of
language
features
in
this
text
that
will
tend
to
become
more
useful
once
you
start
coding
larger
projects
these
include
module
packages
chapter
class
based
exceptions
chapter
class
pseudoprivate
attributes
chapter
documentation
strings
chapter
module
path
configuration
files
chapter
hiding
names
from
from
with
all
lists
and
x
style
names
chapter
adding
self
test
code
with
the
name
main
trick
chapter
using
common
design
rules
for
functions
and
modules
chapters
and
using
object
oriented
design
patterns
chapter
and
others
and
so
on
to
learn
about
other
large
scale
python
development
tools
available
in
the
public
domain
be
sure
to
browse
the
pages
at
the
pypi
website
at
http
www
python
org
and
the
web
at
large
chapter
summary
this
chapter
wrapped
up
the
exceptions
part
of
the
book
with
a
survey
of
related
statements
a
look
at
common
exception
use
cases
and
a
brief
summary
of
commonly
used
development
tools
this
chapter
also
wrapped
up
the
core
material
of
this
book
at
this
point
you
ve
been
exposed
to
the
full
subset
of
python
that
most
programmers
use
in
fact
if
you
have
read
this
far
you
should
feel
free
to
consider
yourself
an
official
python
programmer
be
sure
to
pick
up
a
t
shirt
the
next
time
you
re
online
the
next
and
final
part
of
this
book
is
a
collection
of
chapters
dealing
with
topics
that
are
advanced
but
still
in
the
core
language
category
these
chapters
are
all
optional
reading
because
not
every
python
programmer
must
delve
into
their
subjects
indeed
most
of
you
can
stop
here
and
begin
exploring
python
s
roles
in
your
application
domains
frankly
application
libraries
tend
to
be
more
important
in
practice
than
advanced
and
to
some
esoteric
language
features
on
the
other
hand
if
you
do
need
to
care
about
things
like
unicode
or
binary
data
have
to
deal
with
api
building
tools
such
as
descriptors
decorators
and
metaclasses
or
just
want
to
dig
a
bit
further
in
general
the
next
part
of
the
book
will
help
you
get
started
the
larger
examples
in
the
final
part
will
also
give
you
a
chance
to
see
the
concepts
you
ve
already
learned
being
applied
in
more
realistic
ways
as
this
is
the
end
of
the
core
material
of
this
book
you
get
a
break
on
the
chapter
quiz
just
one
question
this
time
as
always
though
be
sure
to
work
through
this
part
s
closing
exercises
to
cement
what
you
ve
learned
in
the
past
few
chapters
because
the
next
part
is
optional
reading
this
is
the
final
end
of
part
exercises
session
if
you
want
to
see
some
examples
of
how
what
you
ve
learned
comes
together
in
real
scripts
drawn
from
common
applications
check
out
the
solution
to
exercise
in
appendix
b
chapter
designing
with
exceptions
test
your
knowledge
quiz
this
question
is
a
repeat
from
the
first
quiz
in
chapter
see
i
told
you
it
would
be
easy
why
does
spam
show
up
in
so
many
python
examples
in
books
and
on
the
web
test
your
knowledge
answers
because
python
is
named
after
the
british
comedy
group
monty
python
based
on
surveys
i
ve
conducted
in
classes
this
is
a
much
too
well
kept
secret
in
the
python
world
the
spam
reference
comes
from
a
monty
python
skit
where
a
couple
who
are
trying
to
order
food
in
a
cafeteria
keep
getting
drowned
out
by
a
chorus
of
vikings
singing
a
song
about
spam
no
really
and
if
i
could
insert
an
audio
clip
of
that
song
here
i
would
test
your
knowledge
part
vii
exercises
as
we
ve
reached
the
end
of
this
part
of
the
book
it
s
time
for
a
few
exception
exercises
to
give
you
a
chance
to
practice
the
basics
exceptions
really
are
simple
tools
if
you
get
these
you
ve
probably
mastered
exceptions
see
part
vii
exceptions
and
tools
on
page
in
appendix
b
for
the
solutions
try
except
write
a
function
called
oops
that
explicitly
raises
an
indexerror
exception
when
called
then
write
another
function
that
calls
oops
inside
a
try
except
statement
to
catch
the
error
what
happens
if
you
change
oops
to
raise
a
keyerror
instead
of
an
indexerror
where
do
the
names
keyerror
and
indexerror
come
from
hint
recall
that
all
unqualified
names
come
from
one
of
four
scopes
exception
objects
and
lists
change
the
oops
function
you
just
wrote
to
raise
an
exception
you
define
yourself
called
myerror
identify
your
exception
with
a
class
then
extend
the
try
statement
in
the
catcher
function
to
catch
this
exception
and
its
instance
in
addition
to
indexerror
and
print
the
instance
you
catch
error
handling
write
a
function
called
safe
func
args
that
runs
any
function
with
any
number
of
arguments
by
using
the
name
arbitrary
arguments
call
syntax
catches
any
exception
raised
while
the
function
runs
and
prints
the
exception
using
the
exc
info
call
in
the
sys
module
then
use
your
safe
function
to
run
your
oops
function
from
exercise
or
put
safe
in
a
module
file
called
tools
py
and
pass
it
the
oops
function
interactively
what
kind
of
error
messages
do
you
get
finally
expand
safe
to
also
print
a
python
stack
trace
when
an
error
occurs
by
calling
the
built
in
print
exc
function
in
the
standard
traceback
module
see
the
python
library
reference
manual
for
details
test
your
knowledge
part
vii
exercises
self
study
examples
at
the
end
of
appendix
b
i
ve
included
a
handful
of
example
scripts
developed
as
group
exercises
in
live
python
classes
for
you
to
study
and
run
on
your
own
in
conjunction
with
python
s
standard
manual
set
these
are
not
described
and
they
use
tools
in
the
python
standard
library
that
you
ll
have
to
research
on
your
own
still
for
many
readers
it
helps
to
see
how
the
concepts
we
ve
discussed
in
this
book
come
together
in
real
programs
if
these
whet
your
appetite
for
more
you
can
find
a
wealth
of
larger
and
more
realistic
application
level
python
program
examples
in
follow
up
books
like
programming
python
and
on
the
web
chapter
designing
with
exceptions
part
viii
advanced
topics
chapter
unicode
and
byte
strings
in
the
strings
chapter
in
the
core
types
part
of
this
book
chapter
i
deliberately
limited
the
scope
to
the
subset
of
string
topics
that
most
python
programmers
need
to
know
about
because
the
vast
majority
of
programmers
deal
with
simple
forms
of
text
like
ascii
they
can
happily
work
with
python
s
basic
str
string
type
and
its
associated
operations
and
don
t
need
to
come
to
grips
with
more
advanced
string
concepts
in
fact
such
programmers
can
largely
ignore
the
string
changes
in
python
and
continue
to
use
strings
as
they
may
have
in
the
past
on
the
other
hand
some
programmers
deal
with
more
specialized
types
of
data
nonascii
character
sets
image
file
contents
and
so
on
for
those
programmers
and
others
who
may
join
them
some
day
in
this
chapter
we
re
going
to
fill
in
the
rest
of
the
python
string
story
and
look
at
some
more
advanced
concepts
in
python
s
string
model
specifically
we
ll
explore
the
basics
of
python
s
support
for
unicode
text
wide
character
strings
used
in
internationalized
applications
as
well
as
binary
data
strings
that
represent
absolute
byte
values
as
we
ll
see
the
advanced
string
representation
story
has
diverged
in
recent
versions
of
python
python
provides
an
alternative
string
type
for
binary
data
and
supports
unicode
text
in
its
normal
string
type
ascii
is
treated
as
a
simple
type
of
unicode
python
provides
an
alternative
string
type
for
non
ascii
unicode
text
and
supports
both
simple
text
and
binary
data
in
its
normal
string
type
in
addition
because
python
s
string
model
has
a
direct
impact
on
how
you
process
non
ascii
files
we
ll
explore
the
fundamentals
of
that
related
topic
here
as
well
finally
we
ll
take
a
brief
look
at
some
advanced
string
and
binary
tools
such
as
pattern
matching
object
pickling
binary
data
packing
and
xml
parsing
and
the
ways
in
which
they
are
impacted
by
s
string
changes
this
is
officially
an
advanced
topics
chapter
because
not
all
programmers
will
need
to
delve
into
the
worlds
of
unicode
encodings
or
binary
data
if
you
ever
need
to
care
about
processing
either
of
these
though
you
ll
find
that
python
s
string
models
provide
the
support
you
need
string
changes
in
one
of
the
most
noticeable
changes
in
is
the
mutation
of
string
object
types
in
a
nutshell
x
s
str
and
unicode
types
have
morphed
into
s
str
and
bytes
types
and
a
new
mutable
bytearray
type
has
been
added
the
bytearray
type
is
technically
available
in
python
too
though
not
earlier
but
it
s
a
back
port
from
and
does
not
as
clearly
distinguish
between
text
and
binary
content
in
especially
if
you
process
data
that
is
either
unicode
or
binary
in
nature
these
changes
can
have
substantial
impacts
on
your
code
in
fact
as
a
general
rule
of
thumb
how
much
you
need
to
care
about
this
topic
depends
in
large
part
upon
which
of
the
following
categories
you
fall
into
if
you
deal
with
non
ascii
unicode
text
for
instance
in
the
context
of
internationalized
applications
and
the
results
of
some
xml
parsers
you
will
find
support
for
text
encodings
to
be
different
in
but
also
probably
more
direct
accessible
and
seamless
than
in
if
you
deal
with
binary
data
for
example
in
the
form
of
image
or
audio
files
or
packed
data
processed
with
the
struct
module
you
will
need
to
understand
s
new
bytes
object
and
s
different
and
sharper
distinction
between
text
and
binary
data
and
files
if
you
fall
into
neither
of
the
prior
two
categories
you
can
generally
use
strings
in
much
as
you
would
in
with
the
general
str
string
type
text
files
and
all
the
familiar
string
operations
we
studied
earlier
your
strings
will
be
encoded
and
decoded
using
your
platform
s
default
encoding
e
g
ascii
or
utf
on
windows
in
the
u
s
sys
getdefaultencoding
gives
your
default
if
you
care
to
check
but
you
probably
won
t
notice
in
other
words
if
your
text
is
always
ascii
you
can
get
by
with
normal
string
objects
and
text
files
and
can
avoid
most
of
the
following
story
as
we
ll
see
in
a
moment
ascii
is
a
simple
kind
of
unicode
and
a
subset
of
other
encodings
so
string
operations
and
files
just
work
if
your
programs
process
ascii
text
even
if
you
fall
into
the
last
of
the
three
categories
just
mentioned
though
a
basic
understanding
of
s
string
model
can
help
both
to
demystify
some
of
the
underlying
behavior
now
and
to
make
mastering
unicode
or
binary
data
issues
easier
if
they
impact
you
in
the
future
python
s
support
for
unicode
and
binary
data
is
also
available
in
albeit
in
different
forms
although
our
main
focus
in
this
chapter
is
on
string
types
in
we
ll
explore
some
differences
along
the
way
too
regardless
of
which
version
you
use
the
tools
we
ll
explore
here
can
become
important
in
many
types
of
programs
chapter
unicode
and
byte
strings
string
basics
before
we
look
at
any
code
let
s
begin
with
a
general
overview
of
python
s
string
model
to
understand
why
changed
the
way
it
did
on
this
front
we
have
to
start
with
a
brief
look
at
how
characters
are
actually
represented
in
computers
character
encoding
schemes
most
programmers
think
of
strings
as
series
of
characters
used
to
represent
textual
data
the
way
characters
are
stored
in
a
computer
s
memory
can
vary
though
depending
on
what
sort
of
character
set
must
be
recorded
the
ascii
standard
was
created
in
the
u
s
and
it
defines
many
u
s
programmers
notion
of
text
strings
ascii
defines
character
codes
from
through
and
allows
each
character
to
be
stored
in
one
bit
byte
only
bits
of
which
are
actually
used
for
example
the
ascii
standard
maps
the
character
a
to
the
integer
value
x
in
hex
which
is
stored
in
a
single
byte
in
memory
and
files
if
you
wish
to
see
how
this
works
python
s
ord
built
in
function
gives
the
binary
value
for
a
character
and
chr
returns
the
character
for
a
given
integer
code
value
ord
a
hex
x
chr
a
a
is
a
byte
with
binary
value
in
ascii
binary
value
stands
for
character
a
sometimes
one
byte
per
character
isn
t
enough
though
various
symbols
and
accented
characters
for
instance
do
not
fit
into
the
range
of
possible
characters
defined
by
ascii
to
accommodate
special
characters
some
standards
allow
all
possible
values
in
an
bit
byte
through
to
represent
characters
and
assign
the
values
through
outside
ascii
s
range
to
special
characters
one
such
standard
known
as
latin
is
widely
used
in
western
europe
in
latin
character
codes
above
are
assigned
to
accented
and
otherwise
special
characters
the
character
assigned
to
byte
value
for
example
is
a
specially
marked
non
ascii
character
xc
chr
√Ñ
this
standard
allows
for
a
wide
array
of
extra
special
characters
still
some
alphabets
define
so
many
characters
that
it
is
impossible
to
represent
each
of
them
as
one
byte
unicode
allows
more
flexibility
unicode
text
is
commonly
referred
to
as
wide
character
strings
because
each
character
may
be
represented
with
multiple
bytes
unicode
is
typically
used
in
internationalized
programs
to
represent
european
and
asian
character
sets
that
have
more
characters
than
bit
bytes
can
represent
string
basics
to
store
such
rich
text
in
computer
memory
we
say
that
characters
are
translated
to
and
from
raw
bytes
using
an
encoding
the
rules
for
translating
a
string
of
unicode
characters
into
a
sequence
of
bytes
and
extracting
a
string
from
a
sequence
of
bytes
more
procedurally
this
translation
back
and
forth
between
bytes
and
strings
is
defined
by
two
terms
encoding
is
the
process
of
translating
a
string
of
characters
into
its
raw
bytes
form
according
to
a
desired
encoding
name
decoding
is
the
process
of
translating
a
raw
string
of
bytes
into
is
character
string
form
according
to
its
encoding
name
that
is
we
encode
from
string
to
raw
bytes
and
decode
from
raw
bytes
to
string
for
some
encodings
the
translation
process
is
trivial
ascii
and
latin
for
instance
map
each
character
to
a
single
byte
so
no
translation
work
is
required
for
other
encodings
the
mapping
can
be
more
complex
and
yield
multiple
bytes
per
character
the
widely
used
utf
encoding
for
example
allows
a
wide
range
of
characters
to
be
represented
by
employing
a
variable
number
of
bytes
scheme
character
codes
less
than
are
represented
as
a
single
byte
codes
between
and
x
ff
are
turned
into
two
bytes
where
each
byte
has
a
value
between
and
and
codes
above
x
ff
are
turned
into
three
or
four
byte
sequences
having
values
between
and
this
keeps
simple
ascii
strings
compact
sidesteps
byte
ordering
issues
and
avoids
null
zero
bytes
that
can
cause
problems
for
c
libraries
and
networking
because
encodings
character
maps
assign
characters
to
the
same
codes
for
compatibility
ascii
is
a
subset
of
both
latin
and
utf
that
is
a
valid
ascii
character
string
is
also
a
valid
latin
and
utf
encoded
string
this
is
also
true
when
the
data
is
stored
in
files
every
ascii
file
is
a
valid
utf
file
because
ascii
is
a
bit
subset
of
utf
conversely
the
utf
encoding
is
binary
compatible
with
ascii
for
all
character
codes
less
than
latin
and
utf
simply
allow
for
additional
characters
latin
for
characters
mapped
to
values
through
within
a
byte
and
utf
for
characters
that
may
be
represented
with
multiple
bytes
other
encodings
allow
wider
character
sets
in
similar
ways
but
all
of
these
ascii
latin
utf
and
many
others
are
considered
to
be
unicode
to
python
programmers
encodings
are
specified
as
strings
containing
the
encoding
s
name
python
comes
with
roughly
different
encodings
see
the
python
library
reference
for
a
complete
list
importing
the
module
encodings
and
running
help
encodings
shows
you
many
encoding
names
as
well
some
are
implemented
in
python
and
some
in
c
some
encodings
have
multiple
names
too
for
example
latin
iso
and
are
all
synonyms
for
the
same
encoding
latin
we
ll
revisit
encodings
later
in
this
chapter
when
we
study
techniques
for
writing
unicode
strings
in
a
script
chapter
unicode
and
byte
strings
for
more
on
the
unicode
story
see
the
python
standard
manual
set
it
includes
a
unicode
howto
in
its
python
howtos
section
which
provides
additional
background
that
we
will
skip
here
in
the
interest
of
space
python
s
string
types
at
a
more
concrete
level
the
python
language
provides
string
data
types
to
represent
character
text
in
your
scripts
the
string
types
you
will
use
in
your
scripts
depend
upon
the
version
of
python
you
re
using
python
x
has
a
general
string
type
for
representing
binary
data
and
simple
bit
text
like
ascii
along
with
a
specific
type
for
representing
multibyte
unicode
text
str
for
representing
bit
text
and
binary
data
unicode
for
representing
wide
character
unicode
text
python
x
s
two
string
types
are
different
unicode
allows
for
the
extra
size
of
characters
and
has
extra
support
for
encoding
and
decoding
but
their
operation
sets
largely
overlap
the
str
string
type
in
x
is
used
for
text
that
can
be
represented
with
bit
bytes
as
well
as
binary
data
that
represents
absolute
byte
values
by
contrast
python
x
comes
with
three
string
object
types
one
for
textual
data
and
two
for
binary
data
str
for
representing
unicode
text
both
bit
and
wider
bytes
for
representing
binary
data
bytearray
a
mutable
flavor
of
the
bytes
type
as
mentioned
earlier
bytearray
is
also
available
in
python
but
it
s
simply
a
backport
from
with
less
content
specific
behavior
and
is
generally
considered
a
type
all
three
string
types
in
support
similar
operation
sets
but
they
have
different
roles
the
main
goal
behind
this
change
in
x
was
to
merge
the
normal
and
unicode
string
types
of
x
into
a
single
string
type
that
supports
both
normal
and
unicode
text
developers
wanted
to
remove
the
x
string
dichotomy
and
make
unicode
processing
more
natural
given
that
ascii
and
other
bit
text
is
really
a
simple
kind
of
unicode
this
convergence
seems
logically
sound
to
achieve
this
the
str
type
is
defined
as
an
immutable
sequence
of
characters
not
necessarily
bytes
which
may
be
either
normal
text
such
as
ascii
with
one
byte
per
character
or
richer
character
set
text
such
as
utf
unicode
that
may
include
multibyte
characters
strings
processed
by
your
script
with
this
type
are
encoded
per
the
platform
default
but
explicit
encoding
names
may
be
provided
to
translate
str
objects
to
and
from
different
schemes
both
in
memory
and
when
transferring
to
and
from
files
while
s
new
str
type
does
achieve
the
desired
string
unicode
merging
many
programs
still
need
to
process
raw
binary
data
that
is
not
encoded
per
any
text
format
image
and
audio
files
as
well
as
packed
data
used
to
interface
with
devices
or
c
string
basics
programs
you
might
process
with
python
s
struct
module
fall
into
this
category
to
support
processing
of
truly
binary
data
therefore
a
new
type
bytes
also
was
introduced
in
x
the
general
str
type
filled
this
binary
data
role
because
strings
were
just
sequences
of
bytes
the
separate
unicode
type
handles
wide
character
strings
in
the
bytes
type
is
defined
as
an
immutable
sequence
of
bit
integers
representing
absolute
byte
values
moreover
the
bytes
type
supports
almost
all
the
same
operations
that
the
str
type
does
this
includes
string
methods
sequence
operations
and
even
re
module
pattern
matching
but
not
string
formatting
a
bytes
object
really
is
a
sequence
of
small
integers
each
of
which
is
in
the
range
through
indexing
a
bytes
returns
an
int
slicing
one
returns
another
bytes
and
running
the
list
built
in
on
one
returns
a
list
of
integers
not
characters
when
processed
with
operations
that
assume
characters
though
the
contents
of
bytes
objects
are
assumed
to
be
ascii
encoded
bytes
e
g
the
isalpha
method
assumes
each
byte
is
an
ascii
character
code
further
bytes
objects
are
printed
as
character
strings
instead
of
integers
for
convenience
while
they
were
at
it
python
developers
also
added
a
bytearray
type
in
bytearray
is
a
variant
of
bytes
that
is
mutable
and
so
supports
in
place
changes
it
supports
the
usual
string
operations
that
str
and
bytes
do
as
well
as
many
of
the
same
in
place
change
operations
as
lists
e
g
the
append
and
extend
methods
and
assignment
to
indexes
assuming
your
strings
can
be
treated
as
raw
bytes
bytearray
finally
adds
direct
in
place
mutability
for
string
data
something
not
possible
without
conversion
to
a
mutable
type
in
python
and
not
supported
by
python
s
str
or
bytes
although
python
and
offer
much
the
same
functionality
they
package
it
differently
in
fact
the
mapping
from
to
string
types
is
not
direct
s
str
equates
to
both
str
and
bytes
in
and
s
str
equates
to
both
str
and
unicode
in
moreover
the
mutability
of
s
bytearray
is
unique
in
practice
though
this
asymmetry
is
not
as
daunting
as
it
might
sound
it
boils
down
to
the
following
in
you
will
use
str
for
simple
text
and
binary
data
and
unicode
for
more
advanced
forms
of
text
in
you
ll
use
str
for
any
kind
of
text
simple
and
unicode
and
bytes
or
bytearray
for
binary
data
in
practice
the
choice
is
often
made
for
you
by
the
tools
you
use
especially
in
the
case
of
file
processing
tools
the
topic
of
the
next
section
text
and
binary
files
file
i
o
input
and
output
has
also
been
revamped
in
to
reflect
the
str
bytes
distinction
and
automatically
support
encoding
unicode
text
python
now
makes
a
sharp
platform
independent
distinction
between
text
files
and
binary
files
chapter
unicode
and
byte
strings
text
files
when
a
file
is
opened
in
text
mode
reading
its
data
automatically
decodes
its
content
per
a
platform
default
or
a
provided
encoding
name
and
returns
it
as
a
str
writing
takes
a
str
and
automatically
encodes
it
before
transferring
it
to
the
file
text
mode
files
also
support
universal
end
of
line
translation
and
additional
encoding
specification
arguments
depending
on
the
encoding
name
text
files
may
also
automatically
process
the
byte
order
mark
sequence
at
the
start
of
a
file
more
on
this
momentarily
binary
files
when
a
file
is
opened
in
binary
mode
by
adding
a
b
lowercase
only
to
the
mode
string
argument
in
the
built
in
open
call
reading
its
data
does
not
decode
it
in
any
way
but
simply
returns
its
content
raw
and
unchanged
as
a
bytes
object
writing
similarly
takes
a
bytes
object
and
transfers
it
to
the
file
unchanged
binary
mode
files
also
accept
a
bytearray
object
for
the
content
to
be
written
to
the
file
because
the
language
sharply
differentiates
between
str
and
bytes
you
must
decide
whether
your
data
is
text
or
binary
in
nature
and
use
either
str
or
bytes
objects
to
represent
its
content
in
your
script
as
appropriate
ultimately
the
mode
in
which
you
open
a
file
will
dictate
which
type
of
object
your
script
will
use
to
represent
its
content
if
you
are
processing
image
files
packed
data
created
by
other
programs
whose
content
you
must
extract
or
some
device
data
streams
chances
are
good
that
you
will
want
to
deal
with
it
using
bytes
and
binary
mode
files
you
might
also
opt
for
bytearray
if
you
wish
to
update
the
data
without
making
copies
of
it
in
memory
if
instead
you
are
processing
something
that
is
textual
in
nature
such
as
program
output
html
internationalized
text
or
csv
or
xml
files
you
ll
probably
want
to
use
str
and
text
mode
files
notice
that
the
mode
string
argument
to
built
in
function
open
its
second
argument
becomes
fairly
crucial
in
python
its
content
not
only
specifies
a
file
processing
mode
but
also
implies
a
python
object
type
by
adding
a
b
to
the
mode
string
you
specify
binary
mode
and
will
receive
or
must
provide
a
bytes
object
to
represent
the
file
s
content
when
reading
or
writing
without
the
b
your
file
is
processed
in
text
mode
and
you
ll
use
str
objects
to
represent
its
content
in
your
script
for
example
the
modes
rb
wb
and
rb
imply
bytes
r
w
and
rt
the
default
imply
str
text
mode
files
also
handle
the
byte
order
marker
bom
sequence
that
may
appear
at
the
start
of
files
under
certain
encoding
schemes
in
the
utf
and
utf
encodings
for
example
the
bom
specifies
big
or
little
endian
format
essentially
which
end
of
a
bitstring
is
most
significant
a
utf
text
file
may
also
include
a
bom
to
declare
that
it
is
utf
in
general
but
this
isn
t
guaranteed
when
reading
and
writing
data
using
these
encoding
schemes
python
automatically
skips
or
writes
the
bom
if
it
is
implied
by
a
general
encoding
name
or
if
you
provide
a
more
specific
encoding
name
to
force
the
issue
for
example
the
bom
is
always
processed
for
utf
the
more
specific
encoding
name
utf
le
species
little
endian
utf
format
and
the
more
string
basics
specific
encoding
name
utf
sig
forces
python
to
both
skip
and
write
a
bom
on
input
and
output
respectively
for
utf
text
the
general
name
utf
does
not
we
ll
learn
more
about
boms
and
files
in
general
in
the
section
handling
the
bom
in
on
page
first
let
s
explore
the
implications
of
python
s
new
unicode
string
model
python
strings
in
action
let
s
step
through
a
few
examples
that
demonstrate
how
the
string
types
are
used
one
note
up
front
the
code
in
this
section
was
run
with
and
applies
to
only
still
basic
string
operations
are
generally
portable
across
python
versions
simple
ascii
strings
represented
with
the
str
type
work
the
same
in
and
and
exactly
as
we
saw
in
chapter
of
this
book
moreover
although
there
is
no
bytes
type
in
python
it
has
just
the
general
str
it
can
usually
run
code
that
thinks
there
is
in
the
call
bytes
x
is
present
as
a
synonym
for
str
x
and
the
new
literal
form
b
is
taken
to
be
the
same
as
the
normal
string
literal
you
may
still
run
into
version
skew
in
some
isolated
cases
though
the
bytes
call
for
instance
does
not
allow
the
second
argument
encoding
name
required
by
s
bytes
literals
and
basic
properties
python
string
objects
originate
when
you
call
a
built
in
function
such
as
str
or
bytes
process
a
file
created
by
calling
open
described
in
the
next
section
or
code
literal
syntax
in
your
script
for
the
latter
a
new
literal
form
b
xxx
and
equivalently
b
xxx
is
used
to
create
bytes
objects
in
and
bytearray
objects
may
be
created
by
calling
the
bytearray
function
with
a
variety
of
possible
arguments
more
formally
in
all
the
current
string
literal
forms
xxx
xxx
and
triple
quoted
blocks
generate
a
str
adding
a
b
or
b
just
before
any
of
them
creates
a
bytes
instead
this
new
b
bytes
literal
is
similar
in
form
to
the
r
raw
string
used
to
suppresses
backslash
escapes
consider
the
following
run
in
c
misc
c
python
python
b
b
spam
s
eggs
make
a
bytes
object
bit
bytes
make
a
str
object
unicode
characters
bit
or
wider
type
b
type
s
class
bytes
class
str
b
b
spam
s
eggs
prints
as
a
character
string
really
sequence
of
ints
chapter
unicode
and
byte
strings
the
bytes
object
is
actually
a
sequence
of
short
integers
though
it
prints
its
content
as
characters
whenever
possible
b
s
e
indexing
returns
an
int
for
bytes
str
for
str
b
s
b
pam
ggs
slicing
makes
another
bytes
or
str
object
list
b
list
s
e
g
g
s
bytes
is
really
ints
the
bytes
object
is
immutable
just
like
str
though
bytearray
described
later
is
not
you
cannot
assign
a
str
bytes
or
integer
to
an
offset
of
a
bytes
object
the
bytes
prefix
also
works
for
any
string
literal
form
b
x
both
are
immutable
typeerror
bytes
object
does
not
support
item
assignment
s
x
typeerror
str
object
does
not
support
item
assignment
b
b
xxxx
yyyy
b
b
nxxxx
nyyyy
n
bytes
prefix
works
on
single
double
triple
quotes
as
mentioned
earlier
in
python
the
b
xxx
literal
is
present
for
compatibility
but
is
the
same
as
xxx
and
makes
a
str
and
bytes
is
just
a
synonym
for
str
as
you
ve
seen
in
both
of
these
address
the
distinct
bytes
type
also
note
that
the
u
xxx
and
u
xxx
unicode
string
literal
forms
in
are
gone
in
use
xxx
instead
since
all
strings
are
unicode
even
if
they
contain
all
ascii
characters
more
on
writing
nonascii
unicode
text
in
the
section
coding
non
ascii
text
on
page
conversions
although
python
x
allowed
str
and
unicode
type
objects
to
be
mixed
freely
if
the
strings
contained
only
bit
ascii
text
draws
a
much
sharper
distinction
str
and
bytes
type
objects
never
mix
automatically
in
expressions
and
never
are
converted
to
one
another
automatically
when
passed
to
functions
a
function
that
expects
an
argument
to
be
a
str
object
won
t
generally
accept
a
bytes
and
vice
versa
because
of
this
python
basically
requires
that
you
commit
to
one
type
or
the
other
or
perform
manual
explicit
conversions
str
encode
and
bytes
s
encoding
translate
a
string
to
its
raw
bytes
form
and
create
a
bytes
from
a
str
in
the
process
bytes
decode
and
str
b
encoding
translate
raw
bytes
into
its
string
form
and
create
a
str
from
a
bytes
in
the
process
python
strings
in
action
these
encode
and
decode
methods
as
well
as
file
objects
described
in
the
next
section
use
either
a
default
encoding
for
your
platform
or
an
explicitly
passed
in
encoding
name
for
example
in
s
eggs
s
encode
b
eggs
bytes
s
encoding
ascii
b
eggs
b
b
spam
b
decode
spam
str
b
encoding
ascii
spam
str
to
bytes
encode
text
into
raw
bytes
str
to
bytes
alternative
bytes
to
str
decode
raw
bytes
into
text
bytes
to
str
alternative
two
cautions
here
first
of
all
your
platform
s
default
encoding
is
available
in
the
sys
module
but
the
encoding
argument
to
bytes
is
not
optional
even
though
it
is
in
str
encode
and
bytes
decode
second
although
calls
to
str
do
not
require
the
encoding
argument
like
bytes
does
leaving
it
off
in
str
calls
does
not
mean
it
defaults
instead
a
str
call
without
an
encoding
returns
the
bytes
object
s
print
string
not
its
str
converted
form
this
is
usually
not
what
you
ll
want
assuming
b
and
s
are
still
as
in
the
prior
listing
import
sys
sys
platform
win
sys
getdefaultencoding
utf
underlying
platform
default
encoding
for
str
here
bytes
s
typeerror
string
argument
without
an
encoding
str
b
b
spam
len
str
b
len
str
b
encoding
ascii
str
without
encoding
a
print
string
not
conversion
use
encoding
to
convert
to
str
coding
unicode
strings
encoding
and
decoding
become
more
meaningful
when
you
start
dealing
with
actual
non
ascii
unicode
text
to
code
arbitrary
unicode
characters
in
your
strings
some
of
which
you
might
not
even
be
able
to
type
on
your
keyboard
python
string
literals
support
both
xnn
hex
byte
value
escapes
and
unnnn
and
unnnnnnnn
unicode
escapes
in
string
literals
in
unicode
escapes
the
first
form
gives
four
hex
digits
to
chapter
unicode
and
byte
strings
encode
a
byte
bit
character
code
and
the
second
gives
eight
hex
digits
for
a
byte
bit
code
coding
ascii
text
let
s
step
through
some
examples
that
demonstrate
text
coding
basics
as
we
ve
seen
ascii
text
is
a
simple
type
of
unicode
stored
as
a
sequence
of
byte
values
that
represent
characters
c
misc
c
python
python
ord
x
chr
x
x
has
binary
value
in
the
default
encoding
s
xyz
s
xyz
len
s
ord
c
for
c
in
s
a
unicode
string
of
ascii
text
stands
for
character
x
characters
long
bytes
with
integer
ordinal
values
normal
bit
ascii
text
like
this
is
represented
with
one
character
per
byte
under
each
of
the
unicode
encoding
schemes
described
earlier
in
this
chapter
s
encode
ascii
b
xyz
s
encode
latin
b
xyz
s
encode
utf
b
xyz
values
in
byte
bits
each
values
in
byte
bits
each
values
in
byte
in
others
or
in
fact
the
bytes
objects
returned
by
encoding
ascii
text
this
way
is
really
a
sequence
of
short
integers
which
just
happen
to
print
as
ascii
characters
when
possible
s
encode
latin
list
s
encode
latin
coding
non
ascii
text
to
code
non
ascii
characters
you
may
use
hex
or
unicode
escapes
in
your
strings
hex
escapes
are
limited
to
a
single
byte
s
value
but
unicode
escapes
can
name
characters
with
values
two
and
four
bytes
wide
the
hex
values
xcd
and
xe
for
instance
are
codes
for
two
special
accented
characters
outside
the
bit
range
of
ascii
but
we
can
embed
them
in
str
objects
because
str
supports
unicode
today
coding
unicode
strings
chr
xc
√Ñ
chr
xe
√®
xc
xe
characters
outside
ascii
s
range
s
xc
xe
s
√Ñ√®
single
byte
bit
hex
escapes
s
u
c
u
e
s
√Ñ√®
len
s
bit
unicode
escapes
characters
long
not
number
of
bytes
encoding
and
decoding
non
ascii
text
now
if
we
try
to
encode
a
non
ascii
string
into
raw
bytes
using
as
ascii
we
ll
get
an
error
encoding
as
latin
works
though
and
allocates
one
byte
per
character
encoding
as
utf
allocates
bytes
per
character
instead
if
you
write
this
string
to
a
file
the
raw
bytes
shown
here
is
what
is
actually
stored
on
the
file
for
the
encoding
types
given
s
u
c
u
e
s
√Ñ√®
len
s
s
encode
ascii
unicodeencodeerror
ascii
codec
can
t
encode
characters
in
position
ordinal
not
in
range
s
encode
latin
b
xc
xe
one
byte
per
character
s
encode
utf
b
xc
x
xc
xa
two
bytes
per
character
len
s
encode
latin
len
s
encode
utf
bytes
in
latin
in
utf
note
that
you
can
also
go
the
other
way
reading
raw
bytes
from
a
file
and
decoding
them
back
to
a
unicode
string
however
as
we
ll
see
later
the
encoding
mode
you
give
to
the
open
call
causes
this
decoding
to
be
done
for
you
automatically
on
input
and
avoids
issues
that
may
arise
from
reading
partial
character
sequences
when
reading
by
blocks
of
bytes
b
b
xc
xe
b
b
xc
xe
chapter
unicode
and
byte
strings
len
b
b
decode
latin
√Ñ√®
b
b
xc
x
xc
xa
len
b
b
decode
utf
√Ñ√®
len
b
decode
utf
raw
bytes
characters
decode
to
latin
text
raw
bytes
unicode
characters
other
unicode
coding
techniques
some
encodings
use
even
larger
byte
sequences
to
represent
characters
when
needed
you
can
specify
both
and
bit
unicode
values
for
characters
in
your
strings
use
u
with
four
hex
digits
for
the
former
and
u
with
eight
hex
digits
for
the
latter
s
a
u
c
b
u
e
c
s
a√Ñb√®c
len
s
s
encode
latin
b
a
xc
b
xe
c
len
s
encode
latin
s
encode
utf
b
a
xc
x
b
xc
xa
c
len
s
encode
utf
a
b
c
and
non
ascii
characters
characters
long
bytes
in
latin
bytes
in
utf
interestingly
some
other
encodings
may
use
very
different
byte
formats
the
cp
ebcdic
encoding
for
example
doesn
t
even
encode
ascii
the
same
way
as
the
encodings
we
ve
been
using
so
far
since
python
encodes
and
decodes
for
us
we
only
generally
need
to
care
about
this
when
providing
encoding
names
s
a√Ñb√®c
s
encode
cp
b
xc
c
xc
t
xc
s
encode
cp
b
a
x
eb
x
ac
s
spam
s
encode
latin
b
spam
s
encode
utf
b
spam
s
encode
cp
two
other
western
european
encodings
bytes
each
ascii
text
is
the
same
in
most
but
not
in
cp
ibm
ebcdic
coding
unicode
strings
b
xa
x
x
x
s
encode
cp
b
spam
technically
speaking
you
can
also
build
unicode
strings
piecemeal
using
chr
instead
of
unicode
or
hex
escapes
but
this
might
become
tedious
for
large
strings
s
a
chr
xc
b
chr
xe
c
s
a√Ñb√®c
two
cautions
here
first
python
allows
special
characters
to
be
coded
with
both
hex
and
unicode
escapes
in
str
strings
but
only
with
hex
escapes
in
bytes
strings
unicode
escape
sequences
are
silently
taken
verbatim
in
bytes
literals
not
as
escapes
in
fact
bytes
must
be
decoded
to
str
strings
to
print
their
non
ascii
characters
properly
s
a
xc
b
xe
c
s
a√Ñb√®c
str
recognizes
hex
and
unicode
escapes
s
a
u
c
b
u
e
c
s
a√Ñb√®c
b
b
a
xc
b
xe
c
b
b
a
xc
b
xe
c
bytes
recognizes
hex
but
not
unicode
b
b
a
u
c
b
u
e
c
b
b
a
u
c
b
u
e
c
escape
sequences
taken
literally
b
b
a
xc
b
xe
c
b
b
a
xc
b
xe
c
print
b
b
a
xc
b
xe
c
b
decode
latin
a√Ñb√®c
use
hex
escapes
for
bytes
prints
non
ascii
as
hex
decode
as
latin
to
interpret
as
text
second
bytes
literals
require
characters
either
to
be
either
ascii
characters
or
if
their
values
are
greater
than
to
be
escaped
str
stings
on
the
other
hand
allow
literals
containing
any
character
in
the
source
character
set
which
as
discussed
later
defaults
to
utf
unless
an
encoding
declaration
is
given
in
the
source
file
s
a√Ñb√®c
s
a√Ñb√®c
chars
from
utf
if
no
encoding
declaration
b
b
a√Ñb√®c
syntaxerror
bytes
can
only
contain
ascii
literal
characters
b
b
a
xc
b
xe
c
b
chapter
unicode
and
byte
strings
chars
must
be
ascii
or
escapes
b
a
xc
b
xe
c
b
decode
latin
a√Ñb√®c
s
encode
b
a
xc
x
b
xc
xa
c
s
encode
utf
b
a
xc
x
b
xc
xa
c
source
code
encoded
per
utf
by
default
uses
system
default
to
encode
unless
passed
b
decode
raw
bytes
do
not
correspond
to
utf
unicodedecodeerror
utf
codec
can
t
decode
bytes
in
position
converting
encodings
so
far
we
ve
been
encoding
and
decoding
strings
to
inspect
their
structure
more
generally
we
can
always
convert
a
string
to
a
different
encoding
than
the
source
character
set
default
but
we
must
provide
an
explicit
encoding
name
to
encode
to
and
decode
from
s
a√Ñb√®c
s
a√Ñb√®c
s
encode
b
a
xc
x
b
xc
xa
c
default
utf
encoding
t
s
encode
cp
t
b
xc
c
xc
t
xc
convert
to
ebcdic
u
t
decode
cp
u
a√Ñb√®c
convert
back
to
unicode
u
encode
b
a
xc
x
b
xc
xa
c
default
utf
encoding
again
keep
in
mind
that
the
special
unicode
and
hex
character
escapes
are
only
necessary
when
you
code
non
ascii
unicode
strings
manually
in
practice
you
ll
often
load
such
text
from
files
instead
as
we
ll
see
later
in
this
chapter
s
file
object
created
with
the
open
built
in
function
automatically
decodes
text
strings
as
they
are
read
and
encodes
them
when
they
are
written
because
of
this
your
script
can
often
deal
with
strings
generically
without
having
to
code
special
characters
directly
later
in
this
chapter
we
ll
also
see
that
it
s
possible
to
convert
between
encodings
when
transferring
strings
to
and
from
files
using
a
technique
very
similar
to
that
in
the
last
example
although
you
ll
still
need
to
provide
explicit
encoding
names
when
opening
a
file
the
file
interface
does
most
of
the
conversion
work
for
you
automatically
coding
unicode
strings
coding
unicode
strings
in
python
now
that
i
ve
shown
you
the
basics
of
unicode
strings
in
i
need
to
explain
that
you
can
do
much
the
same
in
though
the
tools
differ
unicode
is
available
in
python
but
it
is
a
distinct
data
type
from
str
and
it
allows
free
mixing
of
normal
and
unicode
strings
when
they
are
compatible
in
fact
you
can
essentially
pretend
s
str
is
s
bytes
when
it
comes
to
decoding
raw
bytes
into
a
unicode
string
as
long
as
it
s
in
the
proper
form
here
is
in
action
all
other
sections
in
this
chapter
are
run
under
c
misc
c
python
python
import
sys
sys
version
r
oct
msc
v
bit
intel
s
a
xc
b
xe
c
print
s
a√Ñb√®c
string
of
bit
bytes
some
are
non
ascii
s
decode
latin
u
a
xc
b
xe
c
decode
byte
to
latin
unicode
s
decode
utf
not
formatted
as
utf
unicodedecodeerror
utf
codec
can
t
decode
bytes
in
position
invalid
data
s
decode
ascii
outside
ascii
range
unicodedecodeerror
ascii
codec
can
t
decode
byte
xc
in
position
ordinal
not
in
range
to
store
arbitrarily
encoded
unicode
text
make
a
unicode
object
with
the
u
xxx
literal
form
this
literal
is
no
longer
available
in
since
all
strings
support
unicode
in
u
u
a
xc
b
xe
c
u
u
a
xc
b
xe
c
print
u
a√Ñb√®c
make
unicode
string
hex
escapes
once
you
ve
created
it
you
can
convert
unicode
text
to
different
raw
byte
encodings
similar
to
encoding
str
objects
into
bytes
objects
in
u
encode
latin
a
xc
b
xe
c
u
encode
utf
a
xc
x
b
xc
xa
c
encode
per
latin
bit
bytes
encode
per
utf
multibyte
non
ascii
characters
can
be
coded
with
hex
or
unicode
escapes
in
string
literals
in
just
as
in
however
as
with
bytes
in
the
u
and
u
escapes
are
recognized
only
for
unicode
strings
in
not
bit
str
strings
c
misc
c
python
python
u
u
a
xc
b
xe
c
u
u
a
xc
b
xe
c
chapter
unicode
and
byte
strings
hex
escapes
for
non
ascii
print
u
a√Ñb√®c
u
u
a
u
c
b
u
e
c
u
u
a
xc
b
xe
c
print
u
a√Ñb√®c
unicode
escapes
for
non
ascii
u
bits
u
bits
s
a
xc
b
xe
c
s
a
xc
b
xe
c
print
s
a
bfc
print
s
decode
latin
a√Ñb√®c
hex
escapes
work
s
a
u
c
b
u
e
c
s
a
u
c
b
u
e
c
print
s
a
u
c
b
u
e
c
len
s
not
unicode
escapes
taken
literally
but
some
print
oddly
unless
decoded
like
s
str
and
bytes
s
unicode
and
str
share
nearly
identical
operation
sets
so
unless
you
need
to
convert
to
other
encodings
you
can
often
treat
unicode
as
though
it
were
str
one
of
the
primary
differences
between
and
though
is
that
unicode
and
non
unicode
str
objects
can
be
freely
mixed
in
expressions
and
as
long
as
the
str
is
compatible
with
the
unicode
s
encoding
python
will
automatically
convert
it
up
to
unicode
in
str
and
bytes
never
mix
automatically
and
require
manual
conversions
u
ab
cd
u
abcd
can
mix
if
compatible
in
ab
b
cd
not
allowed
in
in
fact
the
difference
in
types
is
often
trivial
to
your
code
in
like
normal
strings
unicode
strings
may
be
concatenated
indexed
sliced
matched
with
the
re
module
and
so
on
and
they
cannot
be
changed
in
place
if
you
ever
need
to
convert
between
the
two
types
explicitly
you
can
use
the
built
in
str
and
unicode
functions
str
u
spam
spam
unicode
spam
u
spam
unicode
to
normal
normal
to
unicode
however
this
liberal
approach
to
mixing
string
types
in
only
works
if
the
string
is
compatible
with
the
unicode
object
s
encoding
type
s
a
xc
b
xe
c
can
t
mix
if
incompatible
u
u
a
xc
b
xe
c
s
u
unicodedecodeerror
ascii
codec
can
t
decode
byte
xc
in
position
ordinal
not
in
range
coding
unicode
strings
s
decode
latin
u
u
a
xc
b
xe
ca
xc
b
xe
c
manual
conversion
still
required
print
s
decode
latin
u
a√Ñb√®ca√Ñb√®c
finally
as
we
ll
see
in
more
detail
later
in
this
chapter
s
open
call
supports
only
files
of
bit
bytes
returning
their
contents
as
str
strings
it
s
up
to
you
to
interpret
the
contents
as
text
or
binary
data
and
decode
if
needed
to
read
and
write
unicode
files
and
encode
or
decode
their
content
automatically
use
s
codecs
open
call
documented
in
the
library
manual
this
call
provides
much
the
same
functionality
as
s
open
and
uses
unicode
objects
to
represent
file
content
reading
a
file
translates
encoded
bytes
into
decoded
unicode
characters
and
writing
translates
strings
to
the
desired
encoding
specified
when
the
file
is
opened
source
file
character
set
encoding
declarations
unicode
escape
codes
are
fine
for
the
occasional
unicode
character
in
string
literals
but
they
can
become
tedious
if
you
need
to
embed
non
ascii
text
in
your
strings
frequently
for
strings
you
code
within
your
script
files
python
uses
the
utf
encoding
by
default
but
it
allows
you
to
change
this
to
support
arbitrary
character
sets
by
including
a
comment
that
names
your
desired
encoding
the
comment
must
be
of
this
form
and
must
appear
as
either
the
first
or
second
line
in
your
script
in
either
python
or
coding
latin
when
a
comment
of
this
form
is
present
python
will
recognize
strings
represented
natively
in
the
given
encoding
this
means
you
can
edit
your
script
file
in
a
text
editor
that
accepts
and
displays
accented
and
other
non
ascii
characters
correctly
and
python
will
decode
them
correctly
in
your
string
literals
for
example
notice
how
the
comment
at
the
top
of
the
following
file
text
py
allows
latin
characters
to
be
embedded
in
strings
coding
latin
any
of
the
following
string
literal
forms
work
in
latin
changing
the
encoding
above
to
either
ascii
or
utf
fails
because
the
xc
and
xe
in
mystr
are
not
valid
in
either
mystr
a√Ñb√®c
mystr
a
u
c
b
u
e
c
mystr
a
chr
xc
b
chr
xe
c
import
sys
print
default
encoding
sys
getdefaultencoding
for
astr
in
mystr
mystr
mystr
chapter
unicode
and
byte
strings
print
strlen
format
astr
len
astr
end
bytes
astr
encode
bytes
astr
encode
latin
bytes
astr
encode
ascii
per
default
utf
bytes
for
non
ascii
one
byte
per
char
ascii
fails
outside
range
print
byteslen
byteslen
format
len
bytes
len
bytes
when
run
this
script
produces
the
following
output
c
misc
c
python
python
text
py
default
encoding
utf
a√Ñb√®c
strlen
byteslen
byteslen
a√Ñb√®c
strlen
byteslen
byteslen
a√Ñb√®c
strlen
byteslen
byteslen
since
most
programmers
are
likely
to
fall
back
on
the
standard
utf
encoding
i
ll
defer
to
python
s
standard
manual
set
for
more
details
on
this
option
and
other
advanced
unicode
support
topics
such
as
properties
and
character
name
escapes
in
strings
using
bytes
objects
we
studied
a
wide
variety
of
operations
available
for
python
s
general
str
string
type
in
chapter
the
basic
string
type
works
identically
in
and
so
we
won
t
rehash
this
topic
instead
let
s
dig
a
bit
deeper
into
the
operation
sets
provided
by
the
new
bytes
type
in
as
mentioned
previously
the
bytes
object
is
a
sequence
of
small
integers
each
of
which
is
in
the
range
through
that
happens
to
print
as
ascii
characters
when
displayed
it
supports
sequence
operations
and
most
of
the
same
methods
available
on
str
objects
and
present
in
x
s
str
type
however
bytes
does
not
support
the
for
mat
method
or
the
formatting
expression
and
you
cannot
mix
and
match
bytes
and
str
type
objects
without
explicit
conversions
you
generally
will
use
all
str
type
objects
and
text
files
for
text
data
and
all
bytes
type
objects
and
binary
files
for
binary
data
method
calls
if
you
really
want
to
see
what
attributes
str
has
that
bytes
doesn
t
you
can
always
check
their
dir
built
in
function
results
the
output
can
also
tell
you
something
about
the
expression
operators
they
support
e
g
mod
and
rmod
implement
the
operator
c
misc
c
python
python
attributes
unique
to
str
set
dir
abc
set
dir
b
abc
isprintable
format
mod
encode
isidentifier
formatter
field
name
split
isnumeric
rmod
isdecimal
using
bytes
objects
formatter
parser
maketrans
attributes
unique
to
bytes
set
dir
b
abc
set
dir
abc
decode
fromhex
as
you
can
see
str
and
bytes
have
almost
identical
functionality
their
unique
attributes
are
generally
methods
that
don
t
apply
to
the
other
for
instance
decode
translates
a
raw
bytes
into
its
str
representation
and
encode
translates
a
string
into
its
raw
bytes
representation
most
of
the
methods
are
the
same
though
bytes
methods
require
bytes
arguments
again
string
types
don
t
mix
also
recall
that
bytes
objects
are
immutable
just
like
str
objects
in
both
and
error
messages
here
have
been
shortened
for
brevity
b
b
spam
b
find
b
pa
b
bytes
literal
b
replace
b
pa
b
xy
b
sxym
bytes
methods
expect
bytes
arguments
b
split
b
pa
b
s
b
m
b
b
spam
b
x
typeerror
bytes
object
does
not
support
item
assignment
one
notable
difference
is
that
string
formatting
works
only
on
str
objects
in
not
on
bytes
objects
see
chapter
for
more
on
string
formatting
expressions
and
methods
b
s
typeerror
unsupported
operand
type
s
for
bytes
and
int
s
b
format
attributeerror
bytes
object
has
no
attribute
format
format
sequence
operations
besides
method
calls
all
the
usual
generic
sequence
operations
you
know
and
possibly
love
from
python
x
strings
and
lists
work
as
expected
on
both
str
and
bytes
in
this
includes
indexing
slicing
concatenation
and
so
on
notice
in
the
following
that
chapter
unicode
and
byte
strings
indexing
a
bytes
object
returns
an
integer
giving
the
byte
s
binary
value
bytes
really
is
a
sequence
of
bit
integers
but
it
prints
as
a
string
of
ascii
coded
characters
when
displayed
as
a
whole
for
convenience
to
check
a
given
byte
s
value
use
the
chr
builtin
to
convert
it
back
to
its
character
as
in
the
following
b
b
spam
b
b
spam
a
sequence
of
small
ints
prints
as
ascii
characters
b
b
indexing
yields
an
int
chr
b
s
list
b
show
character
for
int
show
all
the
byte
s
int
values
b
b
b
pam
b
spa
len
b
b
b
lmn
b
spamlmn
b
b
spamspamspamspam
other
ways
to
make
bytes
objects
so
far
we
ve
been
mostly
making
bytes
objects
with
the
b
literal
syntax
they
can
also
be
created
by
calling
the
bytes
constructor
with
a
str
and
an
encoding
name
calling
the
bytes
constructor
with
an
iterable
of
integers
representing
byte
values
or
encoding
a
str
object
per
the
default
or
passed
in
encoding
as
we
ve
seen
encoding
takes
a
str
and
returns
the
raw
binary
byte
values
of
the
string
according
to
the
encoding
specification
conversely
decoding
takes
a
raw
bytes
sequence
and
encodes
it
to
its
string
representation
a
series
of
possibly
wide
characters
both
operations
create
new
string
objects
b
b
abc
b
b
abc
b
bytes
abc
ascii
b
b
abc
ord
a
b
bytes
using
bytes
objects
b
b
abc
b
spam
encode
b
b
spam
s
b
decode
s
spam
or
bytes
or
str
from
a
larger
perspective
the
last
two
of
these
operations
are
really
tools
for
converting
between
str
and
bytes
a
topic
introduced
earlier
and
expanded
upon
in
the
next
section
mixing
string
types
in
the
replace
call
of
the
section
method
calls
on
page
we
had
to
pass
in
two
bytes
objects
str
types
won
t
work
there
although
python
x
automatically
converts
str
to
and
from
unicode
when
possible
i
e
when
the
str
is
bit
ascii
text
python
requires
specific
string
types
in
some
contexts
and
expects
manual
conversions
if
needed
must
pass
expected
types
to
function
and
method
calls
b
b
spam
b
replace
pa
xy
typeerror
expected
an
object
with
the
buffer
interface
b
replace
b
pa
b
xy
b
sxym
b
b
spam
b
replace
bytes
pa
bytes
xy
typeerror
string
argument
without
an
encoding
b
replace
bytes
pa
ascii
bytes
xy
utf
b
sxym
must
convert
manually
in
mixed
type
expressions
b
ab
cd
typeerror
can
t
concat
bytes
to
str
b
ab
decode
cd
abcd
bytes
to
str
b
ab
cd
encode
b
abcd
str
to
bytes
chapter
unicode
and
byte
strings
b
ab
bytes
cd
ascii
b
abcd
str
to
bytes
although
you
can
create
bytes
objects
yourself
to
represent
packed
binary
data
they
can
also
be
made
automatically
by
reading
files
opened
in
binary
mode
as
we
ll
see
in
more
detail
later
in
this
chapter
first
though
we
should
introduce
bytes
s
very
close
and
mutable
cousin
using
and
bytearray
objects
so
far
we
ve
focused
on
str
and
bytes
since
they
subsume
python
s
unicode
and
str
python
has
a
third
string
type
though
bytearray
a
mutable
sequence
of
integers
in
the
range
through
is
essentially
a
mutable
variant
of
bytes
as
such
it
supports
the
same
string
methods
and
sequence
operations
as
bytes
as
well
as
many
of
the
mutable
in
place
change
operations
supported
by
lists
the
bytearray
type
is
also
available
in
python
as
a
back
port
from
but
it
does
not
enforce
the
strict
text
binary
distinction
there
that
it
does
in
let
s
take
a
quick
tour
bytearray
objects
may
be
created
by
calling
the
bytearray
builtin
in
python
any
string
may
be
used
to
initialize
creation
in
a
mutable
sequence
of
small
ints
s
spam
c
bytearray
s
c
bytearray
b
spam
a
back
port
from
in
b
in
str
in
python
an
encoding
name
or
byte
string
is
required
because
text
and
binary
strings
do
not
mix
though
byte
strings
may
reflect
encoded
unicode
text
creation
in
text
binary
do
not
mix
s
spam
c
bytearray
s
typeerror
string
argument
without
an
encoding
c
bytearray
s
latin
c
bytearray
b
spam
a
content
specific
type
in
b
b
spam
c
bytearray
b
c
bytearray
b
spam
b
in
bytes
str
once
created
bytearray
objects
are
sequences
of
small
integers
like
bytes
and
are
mutable
like
lists
though
they
require
an
integer
for
index
assignments
not
a
string
all
of
the
following
is
a
continuation
of
this
session
and
is
run
under
python
unless
otherwise
noted
see
comments
for
usage
notes
using
and
bytearray
objects
mutable
but
must
assign
ints
not
strings
c
c
x
typeerror
an
integer
is
required
this
and
the
next
work
in
c
b
x
typeerror
an
integer
is
required
c
ord
x
c
bytearray
b
xpam
c
b
y
c
bytearray
b
xyam
processing
bytearray
objects
borrows
from
both
strings
and
lists
since
they
are
mutable
byte
strings
besides
named
methods
the
iadd
and
setitem
methods
in
bytearray
implement
in
place
concatenation
and
index
assignment
respectively
methods
overlap
with
both
str
and
bytes
but
also
has
list
s
mutable
methods
set
dir
b
abc
set
dir
bytearray
b
abc
getnewargs
set
dir
bytearray
b
abc
set
dir
b
abc
insert
alloc
reverse
extend
delitem
pop
setitem
iadd
remove
append
imul
you
can
change
a
bytearray
in
place
with
both
index
assignment
as
you
ve
just
seen
and
list
like
methods
like
those
shown
here
to
change
text
in
place
in
you
would
need
to
convert
to
and
then
from
a
list
with
list
str
and
join
list
mutable
method
calls
c
bytearray
b
xyam
c
append
b
lmn
typeerror
an
integer
is
required
c
append
ord
l
c
bytearray
b
xyaml
c
extend
b
mno
c
bytearray
b
xyamlmno
chapter
unicode
and
byte
strings
requires
string
of
size
all
the
usual
sequence
operations
and
string
methods
work
on
bytearrays
as
you
would
expect
notice
that
like
bytes
objects
their
expressions
and
methods
expect
bytes
arguments
not
str
arguments
sequence
operations
and
string
methods
c
b
bytearray
b
xyamlmno
c
c
bytearray
b
yamlmno
len
c
c
bytearray
b
xyamlmno
c
replace
xy
sp
this
works
in
typeerror
type
str
doesn
t
support
the
buffer
api
c
replace
b
xy
b
sp
bytearray
b
spamlmno
c
bytearray
b
xyamlmno
c
bytearray
b
xyamlmnoxyamlmnoxyamlmnoxyamlmno
finally
by
way
of
summary
the
following
examples
demonstrate
how
bytes
and
bytearray
objects
are
sequences
of
ints
and
str
objects
are
sequences
of
characters
binary
versus
text
b
b
spam
list
b
b
is
same
as
s
in
c
bytearray
b
xyamlmno
list
c
s
spam
list
s
s
p
a
m
using
and
bytearray
objects
although
all
three
python
string
types
can
contain
character
values
and
support
many
of
the
same
operations
again
you
should
always
use
str
for
textual
data
use
bytes
for
binary
data
use
bytearray
for
binary
data
you
wish
to
change
in
place
related
tools
such
as
files
the
next
section
s
topic
often
make
the
choice
for
you
using
text
and
binary
files
this
section
expands
on
the
impact
of
python
s
string
model
on
the
file
processing
basics
introduced
earlier
in
the
book
as
mentioned
earlier
the
mode
in
which
you
open
a
file
is
crucial
it
determines
which
object
type
you
will
use
to
represent
the
file
s
content
in
your
script
text
mode
implies
str
objects
and
binary
mode
implies
bytes
objects
text
mode
files
interpret
file
contents
according
to
a
unicode
encoding
either
the
default
for
your
platform
or
one
whose
name
you
pass
in
by
passing
in
an
encoding
name
to
open
you
can
force
conversions
for
various
types
of
unicode
files
textmode
files
also
perform
universal
line
end
translations
by
default
all
line
end
forms
map
to
the
single
n
character
in
your
script
regardless
of
the
platform
on
which
you
run
it
as
described
earlier
text
files
also
handle
reading
and
writing
the
byte
order
mark
bom
stored
at
the
start
of
file
in
some
unicode
encoding
schemes
binary
mode
files
instead
return
file
content
to
you
raw
as
a
sequence
of
integers
representing
byte
values
with
no
encoding
or
decoding
and
no
line
end
translations
the
second
argument
to
open
determines
whether
you
want
text
or
binary
processing
just
as
it
does
in
x
python
adding
a
b
to
this
string
implies
binary
mode
e
g
rb
to
read
binary
data
files
the
default
mode
is
rt
this
is
the
same
as
r
which
means
text
input
just
as
in
x
in
though
this
mode
argument
to
open
also
implies
an
object
type
for
file
content
representation
regardless
of
the
underlying
platform
text
files
return
a
str
for
reads
and
expect
one
for
writes
but
binary
files
return
a
bytes
for
reads
and
expect
one
or
a
bytearray
for
writes
text
file
basics
to
demonstrate
let
s
begin
with
basic
file
i
o
as
long
as
you
re
processing
basic
text
files
e
g
ascii
and
don
t
care
about
circumventing
the
platform
default
encoding
of
strings
files
in
look
and
feel
much
as
they
do
in
x
for
that
matter
so
do
strings
in
general
the
following
for
instance
writes
one
line
of
text
to
a
file
and
reads
it
back
chapter
unicode
and
byte
strings
in
exactly
as
it
would
in
note
that
file
is
no
longer
a
built
in
name
in
so
it
s
perfectly
ok
to
use
it
as
a
variable
here
c
misc
c
python
python
basic
text
files
and
strings
work
the
same
as
in
x
file
open
temp
w
size
file
write
abc
n
file
close
returns
number
of
bytes
written
manual
close
to
flush
output
buffer
default
mode
is
r
rt
text
input
file
open
temp
text
file
read
text
abc
n
print
text
abc
text
and
binary
modes
in
in
python
there
is
no
major
distinction
between
text
and
binary
files
both
accept
and
return
content
as
str
strings
the
only
major
difference
is
that
text
files
automatically
map
n
end
of
line
characters
to
and
from
r
n
on
windows
while
binary
files
do
not
i
m
stringing
operations
together
into
one
liners
here
just
for
brevity
c
misc
c
python
python
open
temp
w
write
abd
n
open
temp
r
read
abd
n
open
temp
rb
read
abd
r
n
open
temp
wb
write
abc
n
open
temp
r
read
abc
n
open
temp
rb
read
abc
n
write
in
text
mode
adds
r
read
in
text
mode
drops
r
read
in
binary
mode
verbatim
write
in
binary
mode
n
not
expanded
to
r
n
in
python
things
are
bit
more
complex
because
of
the
distinction
between
str
for
text
data
and
bytes
for
binary
data
to
demonstrate
let
s
write
a
text
file
and
read
it
back
in
both
modes
in
notice
that
we
are
required
to
provide
a
str
for
writing
but
reading
gives
us
a
str
or
a
bytes
depending
on
the
open
mode
c
misc
c
python
python
write
and
read
a
text
file
open
temp
w
write
abc
n
text
mode
output
provide
a
str
open
temp
r
read
abc
n
text
mode
input
returns
a
str
using
text
and
binary
files
open
temp
rb
read
b
abc
r
n
binary
mode
input
returns
a
bytes
notice
how
on
windows
text
mode
files
translate
the
n
end
of
line
character
to
r
n
on
output
on
input
text
mode
translates
the
r
n
back
to
n
but
binary
mode
does
not
this
is
the
same
in
and
it
s
what
we
want
for
binary
data
no
translations
should
occur
although
you
can
control
this
behavior
with
extra
open
arguments
in
if
desired
now
let
s
do
the
same
again
but
with
a
binary
file
we
provide
a
bytes
to
write
in
this
case
and
we
still
get
back
a
str
or
a
bytes
depending
on
the
input
mode
write
and
read
a
binary
file
open
temp
wb
write
b
abc
n
binary
mode
output
provide
a
bytes
open
temp
r
read
abc
n
text
mode
input
returns
a
str
open
temp
rb
read
b
abc
n
binary
mode
input
returns
a
bytes
note
that
the
n
end
of
line
character
is
not
expanded
to
r
n
in
binary
mode
output
again
a
desired
result
for
binary
data
type
requirements
and
file
behavior
are
the
same
even
if
the
data
we
re
writing
to
the
binary
file
is
truly
binary
in
nature
in
the
following
for
example
the
x
is
a
binary
zero
byte
and
not
a
printable
character
write
and
read
truly
binary
data
open
temp
wb
write
b
a
x
c
provide
a
bytes
open
temp
r
read
a
x
c
receive
a
str
open
temp
rb
read
b
a
x
c
receive
a
bytes
binary
mode
files
always
return
contents
as
a
bytes
object
but
accept
either
a
bytes
or
bytearray
object
for
writing
this
naturally
follows
given
that
bytearray
is
basically
just
a
mutable
variant
of
bytes
in
fact
most
apis
in
python
that
accept
a
bytes
also
allow
a
bytearray
bytearrays
work
too
ba
bytearray
b
x
x
x
open
temp
wb
write
ba
open
temp
r
read
x
x
x
chapter
unicode
and
byte
strings
open
temp
rb
read
b
x
x
x
type
and
content
mismatches
notice
that
you
cannot
get
away
with
violating
python
s
str
bytes
type
distinction
when
it
comes
to
files
as
the
following
examples
illustrate
we
get
errors
shortened
here
if
we
try
to
write
a
bytes
to
a
text
file
or
a
str
to
a
binary
file
types
are
not
flexible
for
file
content
open
temp
w
write
abc
n
text
mode
makes
and
requires
str
open
temp
w
write
b
abc
n
typeerror
can
t
write
bytes
to
text
stream
open
temp
wb
write
b
abc
n
binary
mode
makes
and
requires
bytes
open
temp
wb
write
abc
n
typeerror
can
t
write
str
to
binary
stream
this
makes
sense
text
has
no
meaning
in
binary
terms
before
it
is
encoded
although
it
is
often
possible
to
convert
between
the
types
by
encoding
str
and
decoding
bytes
as
described
earlier
in
this
chapter
you
will
usually
want
to
stick
to
either
str
for
text
data
or
bytes
for
binary
data
because
the
str
and
bytes
operation
sets
largely
intersect
the
choice
won
t
be
much
of
a
dilemma
for
most
programs
see
the
string
tools
coverage
in
the
final
section
of
this
chapter
for
some
prime
examples
of
this
in
addition
to
type
constraints
file
content
can
matter
in
text
mode
output
files
require
a
str
instead
of
a
bytes
for
content
so
there
is
no
way
in
to
write
truly
binary
data
to
a
text
mode
file
depending
on
the
encoding
rules
bytes
outside
the
default
character
set
can
sometimes
be
embedded
in
a
normal
string
and
they
can
always
be
written
in
binary
mode
however
because
text
mode
input
files
in
must
be
able
to
decode
content
per
a
unicode
encoding
there
is
no
way
to
read
truly
binary
data
in
text
mode
can
t
read
truly
binary
data
in
text
mode
chr
xff
ff
is
a
valid
char
fe
is
not
√ø
chr
xfe
unicodeencodeerror
charmap
codec
can
t
encode
character
xfe
in
position
open
temp
w
write
b
xff
xfe
xfd
typeerror
can
t
write
bytes
to
text
stream
can
t
use
arbitrary
bytes
open
temp
w
write
xff
xfe
xfd
open
temp
wb
write
b
xff
xfe
xfd
can
write
if
embeddable
in
str
open
temp
rb
read
can
always
read
as
binary
bytes
can
also
write
in
binary
mode
using
text
and
binary
files
b
xff
xfe
xfd
open
temp
r
read
can
t
read
text
unless
decodable
unicodeencodeerror
charmap
codec
can
t
encode
characters
in
position
this
last
error
stems
from
the
fact
that
all
text
files
in
are
really
unicode
text
files
as
the
next
section
describes
using
unicode
files
so
far
we
ve
been
reading
and
writing
basic
text
and
binary
files
but
what
about
processing
unicode
files
it
turns
out
to
be
easy
to
read
and
write
unicode
text
stored
in
files
because
the
open
call
accepts
an
encoding
for
text
files
which
does
the
encoding
and
decoding
for
us
automatically
as
data
is
transferred
this
allows
us
to
process
unicode
text
created
with
different
encodings
than
the
default
for
the
platform
and
store
in
different
encodings
to
convert
reading
and
writing
unicode
in
in
fact
we
can
convert
a
string
to
different
encodings
both
manually
with
method
calls
and
automatically
on
file
input
and
output
we
ll
use
the
following
unicode
string
in
this
section
to
demonstrate
c
misc
c
python
python
s
a
xc
b
xe
c
s
a√Ñb√®c
len
s
character
string
non
ascii
manual
encoding
as
we
ve
already
learned
we
can
always
encode
such
a
string
to
raw
bytes
according
to
the
target
encoding
name
encode
manually
with
methods
l
s
encode
latin
l
b
a
xc
b
xe
c
len
l
bytes
when
encoded
as
latin
u
s
encode
utf
u
b
a
xc
x
b
xc
xa
c
len
u
bytes
when
encoded
as
utf
chapter
unicode
and
byte
strings
file
output
encoding
now
to
write
our
string
to
a
text
file
in
a
particular
encoding
we
can
simply
pass
the
desired
encoding
name
to
open
although
we
could
manually
encode
first
and
write
in
binary
mode
there
s
no
need
to
encoding
automatically
when
written
open
latindata
w
encoding
latin
write
s
open
utf
data
w
encoding
utf
write
s
write
as
latin
open
latindata
rb
read
b
a
xc
b
xe
c
read
raw
bytes
open
utf
data
rb
read
b
a
xc
x
b
xc
xa
c
different
in
files
write
as
utf
file
input
decoding
similarly
to
read
arbitrary
unicode
data
we
simply
pass
in
the
file
s
encoding
type
name
to
open
and
it
decodes
from
raw
bytes
to
strings
automatically
we
could
read
raw
bytes
and
decode
manually
too
but
that
can
be
tricky
when
reading
in
blocks
we
might
read
an
incomplete
character
and
it
isn
t
necessary
decoding
automatically
when
read
open
latindata
r
encoding
latin
read
a√Ñb√®c
open
utf
data
r
encoding
utf
read
a√Ñb√®c
decoded
on
input
x
open
latindata
rb
read
x
decode
latin
a√Ñb√®c
x
open
utf
data
rb
read
x
decode
a√Ñb√®c
manual
decoding
not
necessary
per
encoding
type
utf
is
default
decoding
mismatches
finally
keep
in
mind
that
this
behavior
of
files
in
limits
the
kind
of
content
you
can
load
as
text
as
suggested
in
the
prior
section
python
really
must
be
able
to
decode
the
data
in
text
files
into
a
str
string
according
to
either
the
default
or
a
passed
in
unicode
encoding
name
trying
to
open
a
truly
binary
data
file
in
text
mode
for
example
is
unlikely
to
work
in
even
if
you
use
the
correct
object
types
file
open
python
exe
r
text
file
read
unicodedecodeerror
charmap
codec
can
t
decode
byte
x
in
position
file
open
python
exe
rb
using
unicode
files
data
file
read
data
b
mz
x
x
x
x
x
x
x
x
x
x
xff
xff
x
x
xb
x
x
x
the
first
of
these
examples
might
not
fail
in
python
x
normal
files
do
not
decode
text
even
though
it
probably
should
reading
the
file
may
return
corrupted
data
in
the
string
due
to
automatic
end
of
line
translations
in
text
mode
any
embedded
r
n
bytes
will
be
translated
to
n
on
windows
when
read
to
treat
file
content
as
unicode
text
in
we
need
to
use
special
tools
instead
of
the
general
open
built
in
function
as
we
ll
see
in
a
moment
first
though
let
s
turn
to
a
more
explosive
topic
handling
the
bom
in
as
described
earlier
in
this
chapter
some
encoding
schemes
store
a
special
byte
order
marker
bom
sequence
at
the
start
of
files
to
specify
data
endianness
or
declare
the
encoding
type
python
both
skips
this
marker
on
input
and
writes
it
on
output
if
the
encoding
name
implies
it
but
we
sometimes
must
use
a
specific
encoding
name
to
force
bom
processing
explicitly
for
example
when
you
save
a
text
file
in
windows
notepad
you
can
specify
its
encoding
type
in
a
drop
down
list
simple
ascii
text
utf
or
little
or
big
endian
utf
if
a
one
line
text
file
named
spam
txt
is
saved
in
notepad
as
the
encoding
type
ansi
for
instance
it
s
written
as
simple
ascii
text
without
a
bom
when
this
file
is
read
in
binary
mode
in
python
we
can
see
the
actual
bytes
stored
in
the
file
when
it
s
read
as
text
python
performs
end
of
line
translation
by
default
we
can
decode
it
as
explicit
utf
text
since
ascii
is
a
subset
of
this
scheme
and
utf
is
python
s
default
encoding
c
misc
c
python
python
file
saved
in
notepad
import
sys
sys
getdefaultencoding
utf
open
spam
txt
rb
read
ascii
utf
text
file
b
spam
r
nspam
r
n
open
spam
txt
r
read
text
mode
translates
line
end
spam
nspam
n
open
spam
txt
r
encoding
utf
read
spam
nspam
n
if
this
file
is
instead
saved
as
utf
in
notepad
it
is
prepended
with
a
three
byte
utf
bom
sequence
and
we
need
to
give
a
more
specific
encoding
name
utf
sig
to
force
python
to
skip
the
marker
open
spam
txt
rb
read
utf
with
byte
bom
b
xef
xbb
xbfspam
r
nspam
r
n
open
spam
txt
r
read
√Ø
spam
nspam
n
open
spam
txt
r
encoding
utf
read
ufeffspam
nspam
n
open
spam
txt
r
encoding
utf
sig
read
spam
nspam
n
chapter
unicode
and
byte
strings
if
the
file
is
stored
as
unicode
big
endian
in
notepad
we
get
utf
format
data
in
the
file
prepended
with
a
two
byte
bom
sequence
the
encoding
name
utf
in
python
skips
the
bom
because
it
is
implied
since
all
utf
files
have
a
bom
and
utf
be
handles
the
big
endian
format
but
does
not
skip
the
bom
open
spam
txt
rb
read
b
xfe
xff
x
s
x
p
x
a
x
m
x
r
x
n
x
s
x
p
x
a
x
m
x
r
x
n
open
spam
txt
r
read
unicodeencodeerror
charmap
codec
can
t
encode
character
xfe
in
position
open
spam
txt
r
encoding
utf
read
spam
nspam
n
open
spam
txt
r
encoding
utf
be
read
ufeffspam
nspam
n
the
same
is
generally
true
for
output
when
writing
a
unicode
file
in
python
code
we
need
a
more
explicit
encoding
name
to
force
the
bom
in
utf
utf
does
not
write
or
skip
the
bom
but
utf
sig
does
open
temp
txt
w
encoding
utf
write
spam
nspam
n
open
temp
txt
rb
read
no
bom
b
spam
r
nspam
r
n
open
temp
txt
w
encoding
utf
sig
write
spam
nspam
n
open
temp
txt
rb
read
wrote
bom
b
xef
xbb
xbfspam
r
nspam
r
n
open
temp
txt
r
read
√Ø
spam
nspam
n
open
temp
txt
r
encoding
utf
read
ufeffspam
nspam
n
open
temp
txt
r
encoding
utf
sig
read
spam
nspam
n
keeps
bom
skips
bom
notice
that
although
utf
does
not
drop
the
bom
data
without
a
bom
can
be
read
with
both
utf
and
utf
sig
use
the
latter
for
input
if
you
re
not
sure
whether
a
bom
is
present
in
a
file
and
don
t
read
this
paragraph
out
loud
in
an
airport
security
line
open
temp
txt
open
temp
txt
b
spam
r
nspam
r
n
open
temp
txt
spam
nspam
n
open
temp
txt
spam
nspam
n
open
temp
txt
spam
nspam
n
w
write
spam
nspam
n
rb
read
data
without
bom
r
read
any
utf
works
r
encoding
utf
read
r
encoding
utf
sig
read
finally
for
the
encoding
name
utf
the
bom
is
handled
automatically
on
output
data
is
written
in
the
platform
s
native
endianness
and
the
bom
is
always
written
on
input
data
is
decoded
per
the
bom
and
the
bom
is
always
stripped
more
specific
using
unicode
files
utf
encoding
names
can
specify
different
endianness
though
you
may
have
to
manually
write
and
skip
the
bom
yourself
in
some
scenarios
if
it
is
required
or
present
sys
byteorder
little
open
temp
txt
w
encoding
utf
write
spam
nspam
n
open
temp
txt
rb
read
b
xff
xfes
x
p
x
a
x
m
x
r
x
n
x
s
x
p
x
a
x
m
x
r
x
n
x
open
temp
txt
r
encoding
utf
read
spam
nspam
n
open
temp
txt
w
encoding
utf
be
write
ufeffspam
nspam
n
open
spam
txt
rb
read
b
xfe
xff
x
s
x
p
x
a
x
m
x
r
x
n
x
s
x
p
x
a
x
m
x
r
x
n
open
temp
txt
r
encoding
utf
read
spam
nspam
n
open
temp
txt
r
encoding
utf
be
read
ufeffspam
nspam
n
the
more
specific
utf
encoding
names
work
fine
with
bom
less
files
though
utf
requires
one
on
input
in
order
to
determine
byte
order
open
temp
txt
w
encoding
utf
le
write
spam
open
temp
txt
rb
read
ok
if
bom
not
present
or
expected
b
s
x
p
x
a
x
m
x
open
temp
txt
r
encoding
utf
le
read
spam
open
temp
txt
r
encoding
utf
read
unicodeerror
utf
stream
does
not
start
with
bom
experiment
with
these
encodings
yourself
or
see
python
s
library
manuals
for
more
details
on
the
bom
unicode
files
in
the
preceding
discussion
applies
to
python
s
string
types
and
files
you
can
achieve
similar
effects
for
unicode
files
in
but
the
interface
is
different
if
you
replace
str
with
unicode
and
open
with
codecs
open
the
result
is
essentially
the
same
in
c
misc
c
python
python
s
u
a
xc
b
xe
c
print
s
a√Ñb√®c
len
s
s
encode
latin
a
xc
b
xe
c
s
encode
utf
a
xc
x
b
xc
xa
c
import
codecs
chapter
unicode
and
byte
strings
codecs
open
latindata
w
encoding
latin
write
s
codecs
open
utfdata
w
encoding
utf
write
s
open
latindata
rb
read
a
xc
b
xe
c
open
utfdata
rb
read
a
xc
x
b
xc
xa
c
codecs
open
latindata
r
encoding
latin
read
u
a
xc
b
xe
c
codecs
open
utfdata
r
encoding
utf
read
u
a
xc
b
xe
c
other
string
tool
changes
in
some
of
the
other
popular
string
processing
tools
in
python
s
standard
library
have
been
revamped
for
the
new
str
bytes
type
dichotomy
too
we
won
t
cover
any
of
these
application
focused
tools
in
much
detail
in
this
core
language
book
but
to
wrap
up
this
chapter
here
s
a
quick
look
at
four
of
the
major
tools
impacted
the
re
patternmatching
module
the
struct
binary
data
module
the
pickle
object
serialization
module
and
the
xml
package
for
parsing
xml
text
the
re
pattern
matching
module
python
s
re
pattern
matching
module
supports
text
processing
that
is
more
general
than
that
afforded
by
simple
string
method
calls
such
as
find
split
and
replace
with
re
strings
that
designate
searching
and
splitting
targets
can
be
described
by
general
patterns
instead
of
absolute
text
this
module
has
been
generalized
to
work
on
objects
of
any
string
type
in
str
bytes
and
bytearray
and
returns
result
substrings
of
the
same
type
as
the
subject
string
here
it
is
at
work
in
extracting
substrings
from
a
line
of
text
within
pattern
strings
means
any
character
zero
or
more
times
saved
away
as
a
matched
substring
parts
of
the
string
matched
by
the
parts
of
a
pattern
enclosed
in
parentheses
are
available
after
a
successful
match
via
the
group
or
groups
method
c
misc
c
python
python
import
re
s
bugger
all
down
here
on
earth
b
b
bugger
all
down
here
on
earth
line
of
text
usually
from
a
file
re
match
down
on
s
groups
bugger
all
here
earth
match
line
to
pattern
matched
substrings
re
match
b
down
on
b
groups
b
bugger
all
b
here
b
earth
bytes
substrings
in
python
results
are
similar
but
the
unicode
type
is
used
for
non
ascii
text
and
str
handles
both
bit
and
binary
text
other
string
tool
changes
in
c
misc
c
python
python
import
re
s
bugger
all
down
here
on
earth
u
u
bugger
all
down
here
on
earth
simple
text
and
binary
unicode
text
re
match
down
on
s
groups
bugger
all
here
earth
re
match
down
on
u
groups
u
bugger
all
u
here
u
earth
since
bytes
and
str
support
essentially
the
same
operation
sets
this
type
distinction
is
largely
transparent
but
note
that
like
in
other
apis
you
can
t
mix
str
and
bytes
types
in
its
calls
arguments
in
although
if
you
don
t
plan
to
do
pattern
matching
on
binary
data
you
probably
don
t
need
to
care
c
misc
c
python
python
import
re
s
bugger
all
down
here
on
earth
b
b
bugger
all
down
here
on
earth
re
match
down
on
b
groups
typeerror
can
t
use
a
string
pattern
on
a
bytes
like
object
re
match
b
down
on
s
groups
typeerror
can
t
use
a
bytes
pattern
on
a
string
like
object
re
match
b
down
on
bytearray
b
groups
bytearray
b
bugger
all
bytearray
b
here
bytearray
b
earth
re
match
down
on
bytearray
b
groups
typeerror
can
t
use
a
string
pattern
on
a
bytes
like
object
the
struct
binary
data
module
the
python
struct
module
used
to
create
and
extract
packed
binary
data
from
strings
also
works
the
same
in
as
it
does
in
x
but
packed
data
is
represented
as
bytes
and
bytearray
objects
only
not
str
objects
which
makes
sense
given
that
it
s
intended
for
processing
binary
data
not
arbitrarily
encoded
text
here
are
both
pythons
in
action
packing
three
objects
into
a
string
according
to
a
binary
type
specification
they
create
a
four
byte
integer
a
four
byte
string
and
a
two
byte
integer
c
misc
c
python
python
from
struct
import
pack
pack
i
sh
spam
b
x
x
x
x
spam
x
x
c
misc
c
python
python
from
struct
import
pack
pack
i
sh
spam
x
x
x
x
spam
x
x
chapter
unicode
and
byte
strings
bytes
in
bit
string
str
in
bit
string
since
bytes
has
an
almost
identical
interface
to
that
of
str
in
and
though
most
programmers
probably
won
t
need
to
care
the
change
is
irrelevant
to
most
existing
code
especially
since
reading
from
a
binary
file
creates
a
bytes
automatically
although
the
last
test
in
the
following
example
fails
on
a
type
mismatch
most
scripts
will
read
binary
data
from
a
file
not
create
it
as
a
string
c
misc
c
python
python
import
struct
b
struct
pack
i
sh
spam
b
b
x
x
x
x
spam
x
x
vals
struct
unpack
i
sh
b
vals
b
spam
vals
struct
unpack
i
sh
b
decode
typeerror
str
does
not
have
the
buffer
interface
apart
from
the
new
syntax
for
bytes
creating
and
reading
binary
files
works
almost
the
same
in
as
it
does
in
x
code
like
this
is
one
of
the
main
places
where
programmers
will
notice
the
bytes
object
type
c
misc
c
python
python
write
values
to
a
packed
binary
file
f
open
data
bin
wb
import
struct
data
struct
pack
i
sh
spam
data
b
x
x
x
x
spam
x
x
f
write
data
f
close
open
binary
output
file
create
packed
binary
data
bytes
in
not
str
write
to
the
file
read
values
from
a
packed
binary
file
f
open
data
bin
rb
data
f
read
data
b
x
x
x
x
spam
x
x
values
struct
unpack
i
sh
data
values
b
spam
open
binary
input
file
read
bytes
extract
packed
binary
data
back
to
python
objects
once
you
ve
extracted
packed
binary
data
into
python
objects
like
this
you
can
dig
even
further
into
the
binary
world
if
you
have
to
strings
can
be
indexed
and
sliced
to
get
individual
bytes
values
individual
bits
can
be
extracted
from
integers
with
bitwise
operators
and
so
on
see
earlier
in
this
book
for
more
on
the
operations
applied
here
values
b
spam
result
of
struct
unpack
other
string
tool
changes
in
accesssing
bits
of
parsed
integers
can
get
to
bits
in
ints
bin
values
b
values
x
values
b
bin
values
b
b
bin
values
b
b
bool
values
b
true
bool
values
b
false
test
first
lowest
bit
in
int
bitwise
or
turn
bits
on
decimal
is
binary
bitwise
xor
off
if
both
true
test
if
bit
is
on
test
if
bit
is
set
since
parsed
bytes
strings
are
sequences
of
small
integers
we
can
do
similar
processing
with
their
individual
bytes
accessing
bytes
of
parsed
strings
and
bits
within
them
values
b
spam
values
values
b
pam
bin
values
b
bin
values
b
b
values
b
bytes
string
sequence
of
ints
prints
as
ascii
characters
can
get
to
bits
of
bytes
in
strings
turn
bits
on
of
course
most
python
programmers
don
t
deal
with
binary
bits
python
has
higherlevel
object
types
like
lists
and
dictionaries
that
are
generally
a
better
choice
for
representing
information
in
python
scripts
however
if
you
must
use
or
produce
lower
level
data
used
by
c
programs
networking
libraries
or
other
interfaces
python
has
tools
to
assist
the
pickle
object
serialization
module
we
met
the
pickle
module
briefly
in
chapters
and
in
chapter
we
also
used
the
shelve
module
which
uses
pickle
internally
for
completeness
here
keep
in
mind
that
the
python
version
of
the
pickle
module
always
creates
a
bytes
object
regardless
of
the
default
or
passed
in
protocol
data
format
level
you
can
see
this
by
using
the
module
s
dumps
call
to
return
an
object
s
pickle
string
c
misc
c
python
python
import
pickle
dumps
returns
pickle
string
pickle
dumps
python
default
protocol
binary
chapter
unicode
and
byte
strings
b
x
x
q
x
k
x
k
x
k
x
e
pickle
dumps
protocol
b
lp
nl
l
nal
l
nal
l
na
ascii
protocol
but
still
bytes
this
implies
that
files
used
to
store
pickled
objects
must
always
be
opened
in
binary
mode
in
python
since
text
files
use
str
strings
to
represent
data
not
bytes
the
dump
call
simply
attempts
to
write
the
pickle
string
to
an
open
output
file
pickle
dump
open
temp
w
typeerror
can
t
write
bytes
to
text
stream
text
files
fail
on
bytes
despite
protocol
value
pickle
dump
open
temp
w
protocol
typeerror
can
t
write
bytes
to
text
stream
pickle
dump
open
temp
wb
always
use
binary
in
open
temp
r
read
unicodeencodeerror
charmap
codec
can
t
encode
character
u
ac
in
because
pickle
data
is
not
decodable
unicode
text
the
same
is
true
on
input
correct
usage
in
requires
always
writing
and
reading
pickle
data
in
binary
modes
pickle
dump
open
temp
wb
pickle
load
open
temp
rb
open
temp
rb
read
b
x
x
q
x
k
x
k
x
k
x
e
in
python
and
earlier
we
can
get
by
with
text
mode
files
for
pickled
data
as
long
as
the
protocol
is
level
the
default
in
and
we
use
text
mode
consistently
to
convert
line
ends
c
misc
c
python
python
import
pickle
pickle
dumps
lp
ni
nai
nai
na
python
default
ascii
pickle
dumps
protocol
q
x
k
x
k
x
k
x
e
pickle
dump
open
temp
w
pickle
load
open
temp
open
temp
read
lp
ni
nai
nai
na
text
mode
works
in
if
you
care
about
version
neutrality
though
or
don
t
want
to
care
about
protocols
or
their
version
specific
defaults
always
use
binary
mode
files
for
pickled
data
the
following
works
the
same
in
python
and
import
pickle
pickle
dump
open
temp
wb
pickle
load
open
temp
rb
version
neutral
and
required
in
other
string
tool
changes
in
because
almost
all
programs
let
python
pickle
and
unpickle
objects
automatically
and
do
not
deal
with
the
content
of
pickled
data
itself
the
requirement
to
always
use
binary
file
modes
is
the
only
significant
incompatibility
in
python
s
new
pickling
model
see
reference
books
or
python
s
manuals
for
more
details
on
object
pickling
xml
parsing
tools
xml
is
a
tag
based
language
for
defining
structured
information
commonly
used
to
define
documents
and
data
shipped
over
the
web
although
some
information
can
be
extracted
from
xml
text
with
basic
string
methods
or
the
re
pattern
module
xml
s
nesting
of
constructs
and
arbitrary
attribute
text
tend
to
make
full
parsing
more
accurate
because
xml
is
such
a
pervasive
format
python
itself
comes
with
an
entire
package
of
xml
parsing
tools
that
support
the
sax
and
dom
parsing
models
as
well
as
a
package
known
as
elementtree
a
python
specific
api
for
parsing
and
constructing
xml
beyond
basic
parsing
the
open
source
domain
provides
support
for
additional
xml
tools
such
as
xpath
xquery
xslt
and
more
xml
by
definition
represents
text
in
unicode
form
to
support
internationalization
although
most
of
python
s
xml
parsing
tools
have
always
returned
unicode
strings
in
python
their
results
have
mutated
from
the
x
unicode
type
to
the
general
str
string
type
which
makes
sense
given
that
s
str
string
is
unicode
whether
the
encoding
is
ascii
or
other
we
can
t
go
into
many
details
here
but
to
sample
the
flavor
of
this
domain
suppose
we
have
a
simple
xml
text
file
mybooks
xml
books
date
date
title
learning
python
title
title
programming
python
title
title
python
pocket
reference
title
publisher
o
reilly
media
publisher
books
and
we
want
to
run
a
script
to
extract
and
display
the
content
of
all
the
nested
title
tags
as
follows
learning
python
programming
python
python
pocket
reference
there
are
at
least
four
basic
ways
to
accomplish
this
not
counting
more
advanced
tools
like
xpath
first
we
could
run
basic
pattern
matching
on
the
file
s
text
though
this
tends
to
be
inaccurate
if
the
text
is
unpredictable
where
applicable
the
re
module
we
met
earlier
does
the
job
its
match
method
looks
for
a
match
at
the
start
of
a
string
search
scans
ahead
for
a
match
and
the
findall
method
used
here
locates
all
places
where
the
pattern
matches
in
the
string
the
result
comes
back
as
a
list
of
matched
chapter
unicode
and
byte
strings
substrings
corresponding
to
parenthesized
pattern
groups
or
tuples
of
such
for
multiple
groups
file
patternparse
py
import
re
text
open
mybooks
xml
read
found
re
findall
title
title
text
for
title
in
found
print
title
second
to
be
more
robust
we
could
perform
complete
xml
parsing
with
the
standard
library
s
dom
parsing
support
dom
parses
xml
text
into
a
tree
of
objects
and
provides
an
interface
for
navigating
the
tree
to
extract
tag
attributes
and
values
the
interface
is
a
formal
specification
independent
of
python
file
domparse
py
from
xml
dom
minidom
import
parse
node
xmltree
parse
mybooks
xml
for
node
in
xmltree
getelementsbytagname
title
for
node
in
node
childnodes
if
node
nodetype
node
text
node
print
node
data
as
a
third
option
python
s
standard
library
supports
sax
parsing
for
xml
under
the
sax
model
a
class
s
methods
receive
callbacks
as
a
parse
progresses
and
use
state
information
to
keep
track
of
where
they
are
in
the
document
and
collect
its
data
file
saxparse
py
import
xml
sax
handler
class
bookhandler
xml
sax
handler
contenthandler
def
init
self
self
intitle
false
def
startelement
self
name
attributes
if
name
title
self
intitle
true
def
characters
self
data
if
self
intitle
print
data
def
endelement
self
name
if
name
title
self
intitle
false
import
xml
sax
parser
xml
sax
make
parser
handler
bookhandler
parser
setcontenthandler
handler
parser
parse
mybooks
xml
finally
the
elementtree
system
available
in
the
etree
package
of
the
standard
library
can
often
achieve
the
same
effects
as
xml
dom
parsers
but
with
less
code
it
s
a
python
specific
way
to
both
parse
and
generate
xml
text
after
a
parse
its
api
gives
access
to
components
of
the
document
other
string
tool
changes
in
file
etreeparse
py
from
xml
etree
elementtree
import
parse
tree
parse
mybooks
xml
for
e
in
tree
findall
title
print
e
text
when
run
in
either
or
all
four
of
these
scripts
display
the
same
printed
result
c
misc
c
python
python
domparse
py
learning
python
programming
python
python
pocket
reference
c
misc
c
python
python
domparse
py
learning
python
programming
python
python
pocket
reference
technically
though
in
some
of
these
scripts
produce
unicode
string
objects
while
in
all
produce
str
strings
since
that
type
includes
unicode
text
whether
ascii
or
other
c
misc
c
python
python
from
xml
dom
minidom
import
parse
node
xmltree
parse
mybooks
xml
for
node
in
xmltree
getelementsbytagname
title
for
node
in
node
childnodes
if
node
nodetype
node
text
node
node
data
learning
python
programming
python
python
pocket
reference
c
misc
c
python
python
same
code
u
learning
python
u
programming
python
u
python
pocket
reference
programs
that
must
deal
with
xml
parsing
results
in
nontrivial
ways
will
need
to
account
for
the
different
object
type
in
again
though
because
all
strings
have
nearly
identical
interfaces
in
both
and
most
scripts
won
t
be
affected
by
the
change
tools
available
on
unicode
in
are
generally
available
on
str
in
regrettably
going
into
further
xml
parsing
details
is
beyond
this
book
s
scope
if
you
are
interested
in
text
or
xml
parsing
it
is
covered
in
more
detail
in
the
applicationsfocused
follow
up
book
programming
python
for
more
details
on
re
struct
pickle
and
xml
tools
in
general
consult
the
web
the
aforementioned
book
and
others
and
python
s
standard
library
manual
chapter
unicode
and
byte
strings
chapter
summary
this
chapter
explored
advanced
string
types
available
in
python
and
for
processing
unicode
text
and
binary
data
as
we
saw
many
programmers
use
ascii
text
and
can
get
by
with
the
basic
string
type
and
its
operations
for
more
advanced
applications
python
s
string
models
fully
support
both
wide
character
unicode
text
via
the
normal
string
type
in
and
a
special
type
in
and
byte
oriented
data
represented
with
a
bytes
type
in
and
normal
strings
in
in
addition
we
learned
how
python
s
file
object
has
mutated
in
to
automatically
encode
and
decode
unicode
text
and
deal
with
byte
strings
for
binary
mode
files
finally
we
briefly
met
some
text
and
binary
data
tools
in
python
s
library
and
sampled
their
behavior
in
in
the
next
chapter
we
ll
shift
our
focus
to
tool
builder
topics
with
a
look
at
ways
to
manage
access
to
object
attributes
by
inserting
automatically
run
code
before
we
move
on
though
here
s
a
set
of
questions
to
review
what
we
ve
learned
here
test
your
knowledge
quiz
what
are
the
names
and
roles
of
string
object
types
in
python
what
are
the
names
and
roles
of
string
object
types
in
python
what
is
the
mapping
between
and
string
types
how
do
python
s
string
types
differ
in
terms
of
operations
how
can
you
code
non
ascii
unicode
characters
in
a
string
in
what
are
the
main
differences
between
text
and
binary
mode
files
in
python
how
would
you
read
a
unicode
text
file
that
contains
text
in
a
different
encoding
than
the
default
for
your
platform
how
can
you
create
a
unicode
text
file
in
a
specific
encoding
format
why
is
ascii
text
considered
to
be
a
kind
of
unicode
text
how
large
an
impact
does
python
s
string
types
change
have
on
your
code
test
your
knowledge
answers
python
has
three
string
types
str
for
unicode
text
including
ascii
bytes
for
binary
data
with
absolute
byte
values
and
bytearray
a
mutable
flavor
of
bytes
the
str
type
usually
represents
content
stored
on
a
text
file
and
the
other
two
types
generally
represent
content
stored
on
binary
files
test
your
knowledge
answers
python
has
two
main
string
types
str
for
bit
text
and
binary
data
and
unicode
for
wide
character
text
the
str
type
is
used
for
both
text
and
binary
file
content
unicode
is
used
for
text
file
content
that
is
generally
more
complex
than
bits
python
but
not
earlier
also
has
s
bytearray
type
but
it
s
mostly
a
back
port
and
doesn
t
exhibit
the
sharp
text
binary
distinction
that
it
does
in
the
mapping
from
to
string
types
is
not
direct
because
s
str
equates
to
both
str
and
bytes
in
and
s
str
equates
to
both
str
and
unicode
in
the
mutability
of
bytearray
in
is
also
unique
python
s
string
types
share
almost
all
the
same
operations
method
calls
sequence
operations
and
even
larger
tools
like
pattern
matching
work
the
same
way
on
the
other
hand
only
str
supports
string
formatting
operations
and
bytearray
has
an
additional
set
of
operations
that
perform
in
place
changes
the
str
and
bytes
types
also
have
methods
for
encoding
and
decoding
text
respectively
non
ascii
unicode
characters
can
be
coded
in
a
string
with
both
hex
xnn
and
unicode
unnnn
unnnnnnnn
escapes
on
some
keyboards
some
non
ascii
characters
certain
latin
characters
for
example
can
also
be
typed
directly
in
text
mode
files
assume
their
file
content
is
unicode
text
even
if
it
s
ascii
and
automatically
decode
when
reading
and
encode
when
writing
with
binarymode
files
bytes
are
transferred
to
and
from
the
file
unchanged
the
contents
of
text
mode
files
are
usually
represented
as
str
objects
in
your
script
and
the
contents
of
binary
files
are
represented
as
bytes
or
bytearray
objects
text
mode
files
also
handle
the
bom
for
certain
encoding
types
and
automatically
translate
endof
line
sequences
to
and
from
the
single
n
character
on
input
and
output
unless
this
is
explicitly
disabled
binary
mode
files
do
not
perform
either
of
these
steps
to
read
files
encoded
in
a
different
encoding
than
the
default
for
your
platform
simply
pass
the
name
of
the
file
s
encoding
to
the
open
built
in
in
codecs
open
in
data
will
be
decoded
per
the
specified
encoding
when
it
is
read
from
the
file
you
can
also
read
in
binary
mode
and
manually
decode
the
bytes
to
a
string
by
giving
an
encoding
name
but
this
involves
extra
work
and
is
somewhat
error
prone
for
multibyte
characters
you
may
accidentally
read
a
partial
character
sequence
to
create
a
unicode
text
file
in
a
specific
encoding
format
pass
the
desired
encoding
name
to
open
in
codecs
open
in
strings
will
be
encoded
per
the
desired
encoding
when
they
are
written
to
the
file
you
can
also
manually
encode
a
string
to
bytes
and
write
it
in
binary
mode
but
this
is
usually
extra
work
ascii
text
is
considered
to
be
a
kind
of
unicode
text
because
its
bit
range
of
values
is
a
subset
of
most
unicode
encodings
for
example
valid
ascii
text
is
also
valid
latin
text
latin
simply
assigns
the
remaining
possible
values
in
an
bit
byte
to
additional
characters
and
valid
utf
text
utf
defines
a
variable
byte
scheme
for
representing
more
characters
but
ascii
characters
are
still
represented
with
the
same
codes
in
a
single
byte
chapter
unicode
and
byte
strings
the
impact
of
python
s
string
types
change
depends
upon
the
types
of
strings
you
use
for
scripts
that
use
simple
ascii
text
there
is
probably
no
impact
at
all
the
str
string
type
works
the
same
in
and
in
this
case
moreover
although
string
related
tools
in
the
standard
library
such
as
re
struct
pickle
and
xml
may
technically
use
different
types
in
than
in
the
changes
are
largely
irrelevant
to
most
programs
because
s
str
and
bytes
and
s
str
support
almost
identical
interfaces
if
you
process
unicode
data
the
toolset
you
need
has
simply
moved
from
s
unicode
and
codecs
open
to
s
str
and
open
if
you
deal
with
binary
data
files
you
ll
need
to
deal
with
content
as
bytes
objects
since
they
have
a
similar
interface
to
strings
though
the
impact
should
again
be
minimal
test
your
knowledge
answers
chapter
managed
attributes
this
chapter
expands
on
the
attribute
interception
techniques
introduced
earlier
introduces
another
and
employs
them
in
a
handful
of
larger
examples
like
everything
in
this
part
of
the
book
this
chapter
is
classified
as
an
advanced
topic
and
optional
reading
because
most
applications
programmers
don
t
need
to
care
about
the
material
discussed
here
they
can
fetch
and
set
attributes
on
objects
without
concern
for
attribute
implementations
especially
for
tools
builders
though
managing
attribute
access
can
be
an
important
part
of
flexible
apis
why
manage
attributes
object
attributes
are
central
to
most
python
programs
they
are
where
we
often
store
information
about
the
entities
our
scripts
process
normally
attributes
are
simply
names
for
objects
a
person
s
name
attribute
for
example
might
be
a
simple
string
fetched
and
set
with
basic
attribute
syntax
person
name
person
name
value
fetch
attribute
value
change
attribute
value
in
most
cases
the
attribute
lives
in
the
object
itself
or
is
inherited
from
a
class
from
which
it
derives
that
basic
model
suffices
for
most
programs
you
will
write
in
your
python
career
sometimes
though
more
flexibility
is
required
suppose
you
ve
written
a
program
to
use
a
name
attribute
directly
but
then
your
requirements
change
for
example
you
decide
that
names
should
be
validated
with
logic
when
set
or
mutated
in
some
way
when
fetched
it
s
straightforward
to
code
methods
to
manage
access
to
the
attribute
s
value
valid
and
transform
are
abstract
here
class
person
def
getname
self
if
not
valid
raise
typeerror
cannot
fetch
name
else
return
self
name
transform
def
setname
self
value
if
not
valid
value
raise
typeerror
cannot
change
name
else
self
name
transform
value
person
person
person
getname
person
setname
value
however
this
also
requires
changing
all
the
places
where
names
are
used
in
the
entire
program
a
possibly
nontrivial
task
moreover
this
approach
requires
the
program
to
be
aware
of
how
values
are
exported
as
simple
names
or
called
methods
if
you
begin
with
a
method
based
interface
to
data
clients
are
immune
to
changes
if
you
do
not
they
can
become
problematic
this
issue
can
crop
up
more
often
than
you
might
expect
the
value
of
a
cell
in
a
spreadsheet
like
program
for
instance
might
begin
its
life
as
a
simple
discrete
value
but
later
mutate
into
an
arbitrary
calculation
since
an
object
s
interface
should
be
flexible
enough
to
support
such
future
changes
without
breaking
existing
code
switching
to
methods
later
is
less
than
ideal
inserting
code
to
run
on
attribute
access
a
better
solution
would
allow
you
to
run
code
automatically
on
attribute
access
if
needed
at
various
points
in
this
book
we
ve
met
python
tools
that
allow
our
scripts
to
dynamically
compute
attribute
values
when
fetching
them
and
validate
or
change
attribute
values
when
storing
them
in
this
chapter
were
going
to
expand
on
the
tools
already
introduced
explore
other
available
tools
and
study
some
larger
use
case
examples
in
this
domain
specifically
this
chapter
presents
the
getattr
and
setattr
methods
for
routing
undefined
attribute
fetches
and
all
attribute
assignments
to
generic
handler
methods
the
getattribute
method
for
routing
all
attribute
fetches
to
a
generic
handler
method
in
new
style
classes
in
and
all
classes
in
the
property
built
in
for
routing
specific
attribute
access
to
get
and
set
handler
functions
known
as
properties
the
descriptor
protocol
for
routing
specific
attribute
accesses
to
instances
of
classes
with
arbitrary
get
and
set
handler
methods
the
first
and
third
of
these
were
briefly
introduced
in
part
vi
the
others
are
new
topics
introduced
and
covered
here
as
we
ll
see
all
four
techniques
share
goals
to
some
degree
and
it
s
usually
possible
to
code
a
given
problem
using
any
one
of
them
they
do
differ
in
some
important
ways
though
for
example
the
last
two
techniques
listed
here
apply
to
specific
attributes
whereas
the
first
two
are
generic
enough
to
be
used
by
delegation
based
classes
that
chapter
managed
attributes
must
route
arbitrary
attributes
to
wrapped
objects
as
we
ll
see
all
four
schemes
also
differ
in
both
complexity
and
aesthetics
in
ways
you
must
see
in
action
to
judge
for
yourself
besides
studying
the
specifics
behind
the
four
attribute
interception
techniques
listed
in
this
section
this
chapter
also
presents
an
opportunity
to
explore
larger
programs
than
we
ve
seen
elsewhere
in
this
book
the
cardholder
case
study
at
the
end
for
example
should
serve
as
a
self
study
example
of
larger
classes
in
action
we
ll
also
be
using
some
of
the
techniques
outlined
here
in
the
next
chapter
to
code
decorators
so
be
sure
you
have
at
least
a
general
understanding
of
these
topics
before
you
move
on
properties
the
property
protocol
allows
us
to
route
a
specific
attribute
s
get
and
set
operations
to
functions
or
methods
we
provide
enabling
us
to
insert
code
to
be
run
automatically
on
attribute
access
intercept
attribute
deletions
and
provide
documentation
for
the
attributes
if
desired
properties
are
created
with
the
property
built
in
and
are
assigned
to
class
attributes
just
like
method
functions
as
such
they
are
inherited
by
subclasses
and
instances
like
any
other
class
attributes
their
access
interception
functions
are
provided
with
the
self
instance
argument
which
grants
access
to
state
information
and
class
attributes
available
on
the
subject
instance
a
property
manages
a
single
specific
attribute
although
it
can
t
catch
all
attribute
accesses
generically
it
allows
us
to
control
both
fetch
and
assignment
accesses
and
enables
us
to
change
an
attribute
from
simple
data
to
a
computation
freely
without
breaking
existing
code
as
we
ll
see
properties
are
strongly
related
to
descriptors
they
are
essentially
a
restricted
form
of
them
the
basics
a
property
is
created
by
assigning
the
result
of
a
built
in
function
to
a
class
attribute
attribute
property
fget
fset
fdel
doc
none
of
this
built
in
s
arguments
are
required
and
all
default
to
none
if
not
passed
such
operations
are
not
supported
and
attempting
them
will
raise
an
exception
when
using
them
we
pass
fget
a
function
for
intercepting
attribute
fetches
fset
a
function
for
assignments
and
fdel
a
function
for
attribute
deletions
the
doc
argument
receives
a
documentation
string
for
the
attribute
if
desired
otherwise
the
property
copies
the
docstring
of
fget
if
provided
which
defaults
to
none
fget
returns
the
computed
attribute
value
and
fset
and
fdel
return
nothing
really
none
this
built
in
call
returns
a
property
object
which
we
assign
to
the
name
of
the
attribute
to
be
managed
in
the
class
scope
where
it
will
be
inherited
by
every
instance
properties
a
first
example
to
demonstrate
how
this
translates
to
working
code
the
following
class
uses
a
property
to
trace
access
to
an
attribute
named
name
the
actual
stored
data
is
named
name
so
it
does
not
clash
with
the
property
class
person
use
object
in
def
init
self
name
self
name
name
def
getname
self
print
fetch
return
self
name
def
setname
self
value
print
change
self
name
value
def
delname
self
print
remove
del
self
name
name
property
getname
setname
delname
name
property
docs
bob
person
bob
smith
print
bob
name
bob
name
robert
smith
print
bob
name
del
bob
name
print
sue
person
sue
jones
print
sue
name
print
person
name
doc
bob
has
a
managed
attribute
runs
getname
runs
setname
runs
delname
sue
inherits
property
too
or
help
person
name
properties
are
available
in
both
and
but
they
require
new
style
object
derivation
in
to
work
correctly
for
assignments
add
object
as
a
superclass
here
to
run
this
in
you
can
the
superclass
in
too
but
it
s
implied
and
not
required
this
particular
property
doesn
t
do
much
it
simply
intercepts
and
traces
an
attribute
but
it
serves
to
demonstrate
the
protocol
when
this
code
is
run
two
instances
inherit
the
property
just
as
they
would
any
other
attribute
attached
to
their
class
however
their
attribute
accesses
are
caught
fetch
bob
smith
change
fetch
robert
smith
remove
fetch
sue
jones
name
property
docs
like
all
class
attributes
properties
are
inherited
by
both
instances
and
lower
subclasses
if
we
change
our
example
as
follows
for
example
chapter
managed
attributes
class
super
the
original
person
class
code
name
property
getname
setname
delname
name
property
docs
class
person
super
pass
properties
are
inherited
bob
person
bob
smith
rest
unchanged
the
output
is
the
same
the
person
subclass
inherits
the
name
property
from
super
and
the
bob
instance
gets
it
from
person
in
terms
of
inheritance
properties
work
the
same
as
normal
methods
because
they
have
access
to
the
self
instance
argument
they
can
access
instance
state
information
like
methods
as
the
next
section
demonstrates
computed
attributes
the
example
in
the
prior
section
simply
traces
attribute
accesses
usually
though
properties
do
much
more
computing
the
value
of
an
attribute
dynamically
when
fetched
for
example
the
following
example
illustrates
class
propsquare
def
init
self
start
self
value
start
def
getx
self
return
self
value
def
setx
self
value
self
value
value
x
property
getx
setx
on
attr
fetch
on
attr
assign
no
delete
or
docs
p
propsquare
q
propsquare
instances
of
class
with
property
each
has
different
state
information
print
p
x
p
x
print
p
x
print
q
x
this
class
defines
an
attribute
x
that
is
accessed
as
though
it
were
static
data
but
really
runs
code
to
compute
its
value
when
fetched
the
effect
is
much
like
an
implicit
method
call
when
the
code
is
run
the
value
is
stored
in
the
instance
as
state
information
but
each
time
we
fetch
it
via
the
managed
attribute
its
value
is
automatically
squared
notice
that
we
ve
made
two
different
instances
because
property
methods
automatically
receive
a
self
argument
they
have
access
to
the
state
information
stored
in
instances
in
our
case
this
mean
the
fetch
computes
the
square
of
the
subject
instance
s
data
properties
coding
properties
with
decorators
although
we
re
saving
additional
details
until
the
next
chapter
we
introduced
function
decorator
basics
earlier
in
chapter
recall
that
the
function
decorator
syntax
decorator
def
func
args
is
automatically
translated
to
this
equivalent
by
python
to
rebind
the
function
name
to
the
result
of
the
decorator
callable
def
func
args
func
decorator
func
because
of
this
mapping
it
turns
out
that
the
property
built
in
can
serve
as
a
decorator
to
define
a
function
that
will
run
automatically
when
an
attribute
is
fetched
class
person
property
def
name
self
rebinds
name
property
name
when
run
the
decorated
method
is
automatically
passed
to
the
first
argument
of
the
property
built
in
this
is
really
just
alternative
syntax
for
creating
a
property
and
rebinding
the
attribute
name
manually
class
person
def
name
self
name
property
name
as
of
python
property
objects
also
have
getter
setter
and
deleter
methods
that
assign
the
corresponding
property
accessor
methods
and
return
a
copy
of
the
property
itself
we
can
use
these
to
specify
components
of
properties
by
decorating
normal
methods
too
though
the
getter
component
is
usually
filled
in
automatically
by
the
act
of
creating
the
property
itself
class
person
def
init
self
name
self
name
name
property
def
name
self
name
property
docs
print
fetch
return
self
name
name
setter
def
name
self
value
print
change
self
name
value
name
deleter
def
name
self
print
remove
del
self
name
chapter
managed
attributes
name
property
name
name
name
setter
name
name
name
deleter
name
bob
person
bob
smith
print
bob
name
bob
name
robert
smith
print
bob
name
del
bob
name
print
sue
person
sue
jones
print
sue
name
print
person
name
doc
bob
has
a
managed
attribute
runs
name
getter
name
runs
name
setter
name
runs
name
deleter
name
sue
inherits
property
too
or
help
person
name
in
fact
this
code
is
equivalent
to
the
first
example
in
this
section
decoration
is
just
an
alternative
way
to
code
properties
in
this
case
when
it
s
run
the
results
are
the
same
fetch
bob
smith
change
fetch
robert
smith
remove
fetch
sue
jones
name
property
docs
compared
to
manual
assignment
of
property
results
in
this
case
using
decorators
to
code
properties
requires
just
three
extra
lines
of
code
a
negligible
difference
as
is
so
often
the
case
with
alternative
tools
the
choice
between
the
two
techniques
is
largely
subjective
descriptors
descriptors
provide
an
alternative
way
to
intercept
attribute
access
they
are
strongly
related
to
the
properties
discussed
in
the
prior
section
in
fact
a
property
is
a
kind
of
descriptor
technically
speaking
the
property
built
in
is
just
a
simplified
way
to
create
a
specific
type
of
descriptor
that
runs
method
functions
on
attribute
accesses
functionally
speaking
the
descriptor
protocol
allows
us
to
route
a
specific
attribute
s
get
and
set
operations
to
methods
of
a
separate
class
object
that
we
provide
they
provide
a
way
to
insert
code
to
be
run
automatically
on
attribute
access
and
they
allow
us
to
intercept
attribute
deletions
and
provide
documentation
for
the
attributes
if
desired
descriptors
are
created
as
independent
classes
and
they
are
assigned
to
class
attributes
just
like
method
functions
like
any
other
class
attribute
they
are
inherited
by
subclasses
and
instances
their
access
interception
methods
are
provided
with
both
a
self
for
the
descriptor
itself
and
the
instance
of
the
client
class
because
of
this
they
can
retain
and
use
state
information
of
their
own
as
well
as
state
information
of
the
subject
instance
for
example
a
descriptor
may
call
methods
available
in
the
client
class
as
well
as
descriptor
specific
methods
it
defines
descriptors
like
a
property
a
descriptor
manages
a
single
specific
attribute
although
it
can
t
catch
all
attribute
accesses
generically
it
provides
control
over
both
fetch
and
assignment
accesses
and
allows
us
to
change
an
attribute
freely
from
simple
data
to
a
computation
without
breaking
existing
code
properties
really
are
just
a
convenient
way
to
create
a
specific
kind
of
descriptor
and
as
we
shall
see
they
can
be
coded
as
descriptors
directly
whereas
properties
are
fairly
narrow
in
scope
descriptors
provide
a
more
general
solution
for
instance
because
they
are
coded
as
normal
classes
descriptors
have
their
own
state
may
participate
in
descriptor
inheritance
hierarchies
can
use
composition
to
aggregate
objects
and
provide
a
natural
structure
for
coding
internal
methods
and
attribute
documentation
strings
the
basics
as
mentioned
previously
descriptors
are
coded
as
separate
classes
and
provide
specially
named
accessor
methods
for
the
attribute
access
operations
they
wish
to
intercept
get
set
and
deletion
methods
in
the
descriptor
class
are
automatically
run
when
the
attribute
assigned
to
the
descriptor
class
instance
is
accessed
in
the
corresponding
way
class
descriptor
docstring
goes
here
def
get
self
instance
owner
def
set
self
instance
value
def
delete
self
instance
return
attr
value
return
nothing
none
return
nothing
none
classes
with
any
of
these
methods
are
considered
descriptors
and
their
methods
are
special
when
one
of
their
instances
is
assigned
to
another
class
s
attribute
when
the
attribute
is
accessed
they
are
automatically
invoked
if
any
of
these
methods
are
absent
it
generally
means
that
the
corresponding
type
of
access
is
not
supported
unlike
with
properties
however
omitting
a
set
allows
the
name
to
be
redefined
in
an
instance
thereby
hiding
the
descriptor
to
make
an
attribute
read
only
you
must
define
set
to
catch
assignments
and
raise
an
exception
descriptor
method
arguments
before
we
code
anything
realistic
let
s
take
a
brief
look
at
some
fundamentals
all
three
descriptor
methods
outlined
in
the
prior
section
are
passed
both
the
descriptor
class
instance
self
and
the
instance
of
the
client
class
to
which
the
descriptor
instance
is
attached
instance
the
get
access
method
additionally
receives
an
owner
argument
specifying
the
class
to
which
the
descriptor
instance
is
attached
its
instance
argument
is
either
the
instance
through
which
the
attribute
was
accessed
for
instance
attr
or
none
when
the
attribute
is
accessed
through
the
owner
class
directly
for
class
attr
the
former
of
these
generally
computes
a
value
for
instance
access
and
the
latter
usually
returns
self
if
descriptor
object
access
is
supported
chapter
managed
attributes
for
example
in
the
following
when
x
attr
is
fetched
python
automatically
runs
the
get
method
of
the
descriptor
class
to
which
the
subject
attr
class
attribute
is
assigned
as
with
properties
in
python
we
must
derive
from
object
to
use
descriptors
here
in
this
is
implied
but
doesn
t
hurt
class
descriptor
object
def
get
self
instance
owner
print
self
instance
owner
sep
n
class
subject
attr
descriptor
descriptor
instance
is
class
attr
x
subject
x
attr
main
descriptor
object
at
x
e
main
subject
object
at
x
b
class
main
subject
subject
attr
main
descriptor
object
at
x
e
none
class
main
subject
notice
the
arguments
automatically
passed
in
to
the
get
method
in
the
first
attribute
fetch
when
x
attr
is
fetched
it
s
as
though
the
following
translation
occurs
though
the
subject
attr
here
doesn
t
invoke
get
again
x
attr
descriptor
get
subject
attr
x
subject
the
descriptor
knows
it
is
being
accessed
directly
when
its
instance
argument
is
none
read
only
descriptors
as
mentioned
earlier
unlike
with
properties
with
descriptors
simply
omitting
the
set
method
isn
t
enough
to
make
an
attribute
read
only
because
the
descriptor
name
can
be
assigned
to
an
instance
in
the
following
the
attribute
assignment
to
x
a
stores
a
in
the
instance
object
x
thereby
hiding
the
descriptor
stored
in
class
c
get
get
class
d
def
get
args
print
get
class
c
a
d
x
c
x
a
runs
inherited
descriptor
get
c
a
x
a
x
a
stored
on
x
hiding
c
a
list
x
dict
keys
descriptors
a
y
c
y
a
get
c
a
get
y
still
inherits
descriptor
this
is
the
way
all
instance
attribute
assignments
work
in
python
and
it
allows
classes
to
selectively
override
class
level
defaults
in
their
instances
to
make
a
descriptor
based
attribute
read
only
catch
the
assignment
in
the
descriptor
class
and
raise
an
exception
to
prevent
attribute
assignment
when
assigning
an
attribute
that
is
a
descriptor
python
effectively
bypasses
the
normal
instance
level
assignment
behavior
and
routes
the
operation
to
the
descriptor
object
class
d
def
get
args
print
get
def
set
args
raise
attributeerror
cannot
set
class
c
a
d
x
c
x
a
routed
to
c
a
get
get
x
a
routed
to
c
a
set
attributeerror
cannot
set
also
be
careful
not
to
confuse
the
descriptor
delete
method
with
the
general
del
method
the
former
is
called
on
attempts
to
delete
the
managed
attribute
name
on
an
instance
of
the
owner
class
the
latter
is
the
general
instance
destructor
method
run
when
an
instance
of
any
kind
of
class
is
about
to
be
garbage
collected
delete
is
more
closely
related
to
the
delattr
generic
attribute
deletion
method
we
ll
meet
later
in
this
chapter
see
chapter
for
more
on
operator
overloading
methods
a
first
example
to
see
how
this
all
comes
together
in
more
realistic
code
let
s
get
started
with
the
same
first
example
we
wrote
for
properties
the
following
defines
a
descriptor
that
intercepts
access
to
an
attribute
named
name
in
its
clients
its
methods
use
their
instance
argument
to
access
state
information
in
the
subject
instance
where
the
name
string
is
actually
stored
like
properties
descriptors
work
properly
only
for
new
style
classes
so
be
sure
to
derive
both
classes
in
the
following
from
object
if
you
re
using
class
name
use
object
in
name
descriptor
docs
def
get
self
instance
owner
print
fetch
return
instance
name
chapter
managed
attributes
def
set
self
instance
value
print
change
instance
name
value
def
delete
self
instance
print
remove
del
instance
name
class
person
def
init
self
name
self
name
name
name
name
use
object
in
bob
person
bob
smith
print
bob
name
bob
name
robert
smith
print
bob
name
del
bob
name
bob
has
a
managed
attribute
runs
name
get
runs
name
set
print
sue
person
sue
jones
print
sue
name
print
name
doc
assign
descriptor
to
attr
runs
name
delete
sue
inherits
descriptor
too
or
help
name
notice
in
this
code
how
we
assign
an
instance
of
our
descriptor
class
to
a
class
attribute
in
the
client
class
because
of
this
it
is
inherited
by
all
instances
of
the
class
just
like
a
class
s
methods
really
we
must
assign
the
descriptor
to
a
class
attribute
like
this
it
won
t
work
if
assigned
to
a
self
instance
attribute
instead
when
the
descriptor
s
get
method
is
run
it
is
passed
three
objects
to
define
its
context
self
is
the
name
class
instance
instance
is
the
person
class
instance
owner
is
the
person
class
when
this
code
is
run
the
descriptor
s
methods
intercept
accesses
to
the
attribute
much
like
the
property
version
in
fact
the
output
is
the
same
again
fetch
bob
smith
change
fetch
robert
smith
remove
fetch
sue
jones
name
descriptor
docs
also
like
in
the
property
example
our
descriptor
class
instance
is
a
class
attribute
and
thus
is
inherited
by
all
instances
of
the
client
class
and
any
subclasses
if
we
change
the
person
class
in
our
example
to
the
following
for
instance
the
output
of
our
script
is
the
same
descriptors
class
super
def
init
self
name
self
name
name
name
name
descriptors
are
inherited
class
person
super
pass
also
note
that
when
a
descriptor
class
is
not
useful
outside
the
client
class
it
s
perfectly
reasonable
to
embed
the
descriptor
s
definition
inside
its
client
syntactically
here
s
what
our
example
looks
like
if
we
use
a
nested
class
class
person
def
init
self
name
self
name
name
class
name
name
descriptor
docs
def
get
self
instance
owner
print
fetch
return
instance
name
def
set
self
instance
value
print
change
instance
name
value
def
delete
self
instance
print
remove
del
instance
name
name
name
using
a
nested
class
when
coded
this
way
name
becomes
a
local
variable
in
the
scope
of
the
person
class
statement
such
that
it
won
t
clash
with
any
names
outside
the
class
this
version
works
the
same
as
the
original
we
ve
simply
moved
the
descriptor
class
definition
into
the
client
class
s
scope
but
the
last
line
of
the
testing
code
must
change
to
fetch
the
docstring
from
its
new
location
print
person
name
doc
differs
not
name
doc
outside
class
computed
attributes
as
was
the
case
when
using
properties
our
first
descriptor
example
of
the
prior
section
didn
t
do
much
it
simply
printed
trace
messages
for
attribute
accesses
in
practice
descriptors
can
also
be
used
to
compute
attribute
values
each
time
they
are
fetched
the
following
illustrates
it
s
a
rehash
of
the
same
example
we
coded
for
properties
which
uses
a
descriptor
to
automatically
square
an
attribute
s
value
each
time
it
is
fetched
class
descsquare
def
init
self
start
self
value
start
def
get
self
instance
owner
chapter
managed
attributes
each
desc
has
own
state
on
attr
fetch
return
self
value
def
set
self
instance
value
self
value
value
class
client
x
descsquare
class
client
x
descsquare
on
attr
assign
no
delete
or
docs
assign
descriptor
instance
to
class
attr
another
instance
in
another
client
class
could
also
code
instances
in
same
class
c
client
c
client
print
c
x
c
x
print
c
x
print
c
x
when
run
the
output
of
this
example
is
the
same
as
that
of
the
original
property
based
version
but
here
a
descriptor
class
object
is
intercepting
the
attribute
accesses
using
state
information
in
descriptors
if
you
study
the
two
descriptor
examples
we
ve
written
so
far
you
might
notice
that
they
get
their
information
from
different
places
the
first
the
name
attribute
example
uses
data
stored
on
the
client
instance
and
the
second
the
attribute
squaring
example
uses
data
attached
to
the
descriptor
object
itself
in
fact
descriptors
can
use
both
instance
state
and
descriptor
state
or
any
combination
thereof
descriptor
state
is
used
to
manage
data
internal
to
the
workings
of
the
descriptor
instance
state
records
information
related
to
and
possibly
created
by
the
client
class
descriptor
methods
may
use
either
but
descriptor
state
often
makes
it
unnecessary
to
use
special
naming
conventions
to
avoid
name
collisions
for
descriptor
data
stored
on
an
instance
for
example
the
following
descriptor
attaches
information
to
its
own
instance
so
it
doesn
t
clash
with
that
on
the
client
class
s
instance
class
descstate
def
init
self
value
self
value
value
def
get
self
instance
owner
print
descstate
get
return
self
value
def
set
self
instance
value
print
descstate
set
self
value
value
use
descriptor
state
on
attr
fetch
on
attr
assign
client
class
descriptors
class
calcattrs
x
descstate
y
def
init
self
self
z
obj
calcattrs
print
obj
x
obj
y
obj
z
obj
x
obj
y
obj
z
print
obj
x
obj
y
obj
z
descriptor
class
attr
class
attr
instance
attr
x
is
computed
others
are
not
x
assignment
is
intercepted
this
code
s
value
information
lives
only
in
the
descriptor
so
there
won
t
be
a
collision
if
the
same
name
is
used
in
the
client
s
instance
notice
that
only
the
descriptor
attribute
is
managed
here
get
and
set
accesses
to
x
are
intercepted
but
accesses
to
y
and
z
are
not
y
is
attached
to
the
client
class
and
z
to
the
instance
when
this
code
is
run
x
is
computed
when
fetched
descstate
get
descstate
set
descstate
get
it
s
also
feasible
for
a
descriptor
to
store
or
use
an
attribute
attached
to
the
client
class
s
instance
instead
of
itself
the
descriptor
in
the
following
example
assumes
the
instance
has
an
attribute
y
attached
by
the
client
class
and
uses
it
to
compute
the
value
of
the
attribute
it
represents
class
inststate
def
get
self
instance
owner
print
inststate
get
return
instance
y
def
set
self
instance
value
print
inststate
set
instance
y
value
using
instance
state
assume
set
by
client
class
client
class
class
calcattrs
x
descstate
y
inststate
def
init
self
self
y
self
z
obj
calcattrs
print
obj
x
obj
y
obj
z
obj
x
obj
y
obj
z
print
obj
x
obj
y
obj
z
chapter
managed
attributes
descriptor
class
attr
descriptor
class
attr
instance
attr
instance
attr
x
and
y
are
computed
z
is
not
x
and
y
assignments
intercepted
this
time
x
and
y
are
both
assigned
to
descriptors
and
computed
when
fetched
x
is
assigned
the
descriptor
of
the
prior
example
the
new
descriptor
here
has
no
information
itself
but
it
uses
an
attribute
assumed
to
exist
in
the
instance
that
attribute
is
named
y
to
avoid
collisions
with
the
name
of
the
descriptor
itself
when
this
version
is
run
the
results
are
similar
but
a
second
attribute
is
managed
using
state
that
lives
in
the
instance
instead
of
the
descriptor
descstate
inststate
descstate
inststate
descstate
inststate
get
get
set
set
get
get
both
descriptor
and
instance
state
have
roles
in
fact
this
is
a
general
advantage
that
descriptors
have
over
properties
because
they
have
state
of
their
own
they
can
easily
retain
data
internally
without
adding
it
to
the
namespace
of
the
client
instance
object
how
properties
and
descriptors
relate
as
mentioned
earlier
properties
and
descriptors
are
strongly
related
the
property
built
in
is
just
a
convenient
way
to
create
a
descriptor
now
that
you
know
how
both
work
you
should
also
be
able
to
see
that
it
s
possible
to
simulate
the
property
built
in
with
a
descriptor
class
like
the
following
class
property
def
init
self
fget
none
fset
none
fdel
none
doc
none
self
fget
fget
self
fset
fset
self
fdel
fdel
save
unbound
methods
self
doc
doc
or
other
callables
def
get
self
instance
instancetype
none
if
instance
is
none
return
self
if
self
fget
is
none
raise
attributeerror
can
t
get
attribute
return
self
fget
instance
pass
instance
to
self
in
property
accessors
def
set
self
instance
value
if
self
fset
is
none
raise
attributeerror
can
t
set
attribute
self
fset
instance
value
def
delete
self
instance
if
self
fdel
is
none
raise
attributeerror
can
t
delete
attribute
self
fdel
instance
class
person
descriptors
def
getname
self
def
setname
self
value
name
property
getname
setname
use
like
property
this
property
class
catches
attribute
accesses
with
the
descriptor
protocol
and
routes
requests
to
functions
or
methods
passed
in
and
saved
in
descriptor
state
when
the
class
is
created
attribute
fetches
for
example
are
routed
from
the
person
class
to
the
property
class
s
get
method
and
back
to
the
person
class
s
getname
with
descriptors
this
just
works
note
that
this
descriptor
class
equivalent
only
handles
basic
property
usage
though
to
use
decorator
syntax
to
also
specify
set
and
delete
operations
our
property
class
would
also
have
to
be
extended
with
setter
and
deleter
methods
which
would
save
the
decorated
accessor
function
and
return
the
property
object
self
should
suffice
since
the
property
built
in
already
does
this
we
ll
omit
a
formal
coding
of
this
extension
here
also
note
that
descriptors
are
used
to
implement
python
s
slots
instance
attribute
dictionaries
are
avoided
by
intercepting
slot
names
with
descriptors
stored
at
the
class
level
see
chapter
for
more
on
slots
in
chapter
we
ll
also
make
use
of
descriptors
to
implement
function
decorators
that
apply
to
both
functions
and
methods
as
you
ll
see
there
because
descriptors
receive
both
descriptor
and
subject
class
instances
they
work
well
in
this
role
though
nested
functions
are
usually
a
simpler
solution
getattr
and
getattribute
so
far
we
ve
studied
properties
and
descriptors
tools
for
managing
specific
attributes
the
getattr
and
getattribute
operator
overloading
methods
provide
still
other
ways
to
intercept
attribute
fetches
for
class
instances
like
properties
and
descriptors
they
allow
us
to
insert
code
to
be
run
automatically
when
attributes
are
accessed
as
we
ll
see
though
these
two
methods
can
be
used
in
more
general
ways
attribute
fetch
interception
comes
in
two
flavors
coded
with
two
different
methods
getattr
is
run
for
undefined
attributes
that
is
attributes
not
stored
on
an
instance
or
inherited
from
one
of
its
classes
getattribute
is
run
for
every
attribute
so
when
using
it
you
must
be
cautious
to
avoid
recursive
loops
by
passing
attribute
accesses
to
a
superclass
we
met
the
former
of
these
in
chapter
it
s
available
for
all
python
versions
the
latter
of
these
is
available
for
new
style
classes
in
and
for
all
implicitly
new
style
classes
in
these
two
methods
are
representatives
of
a
set
of
attribute
interception
methods
that
also
includes
setattr
and
delattr
because
these
methods
have
similar
roles
we
will
generally
treat
them
as
a
single
topic
here
chapter
managed
attributes
unlike
properties
and
descriptors
these
methods
are
part
of
python
s
operator
overloading
protocol
specially
named
methods
of
a
class
inherited
by
subclasses
and
run
automatically
when
instances
are
used
in
the
implied
built
in
operation
like
all
methods
of
a
class
they
each
receive
a
first
self
argument
when
called
giving
access
to
any
required
instance
state
information
or
other
methods
of
the
class
the
getattr
and
getattribute
methods
are
also
more
generic
than
properties
and
descriptors
they
can
be
used
to
intercept
access
to
any
or
even
all
instance
attribute
fetches
not
just
the
specific
name
to
which
they
are
assigned
because
of
this
these
two
methods
are
well
suited
to
general
delegation
based
coding
patterns
they
can
be
used
to
implement
wrapper
objects
that
manage
all
attribute
accesses
for
an
embedded
object
by
contrast
we
must
define
one
property
or
descriptor
for
every
attribute
we
wish
to
intercept
finally
these
two
methods
are
more
narrowly
focused
than
the
alternatives
we
considered
earlier
they
intercept
attribute
fetches
only
not
assignments
to
also
catch
attribute
changes
by
assignment
we
must
code
a
setattr
method
an
operator
overloading
method
run
for
every
attribute
fetch
which
must
take
care
to
avoid
recursive
loops
by
routing
attribute
assignments
through
the
instance
namespace
dictionary
although
much
less
common
we
can
also
code
a
delattr
overloading
method
which
must
avoid
looping
in
the
same
way
to
intercept
attribute
deletions
by
contrast
properties
and
descriptors
catch
get
set
and
delete
operations
by
design
most
of
these
operator
overloading
methods
were
introduced
earlier
in
the
book
here
we
ll
expand
on
their
usage
and
study
their
roles
in
larger
contexts
the
basics
getattr
and
setattr
were
introduced
in
chapters
and
and
getattribute
was
mentioned
briefly
in
chapter
in
short
if
a
class
defines
or
inherits
the
following
methods
they
will
be
run
automatically
when
an
instance
is
used
in
the
context
described
by
the
comments
to
the
right
def
def
def
def
getattr
self
name
getattribute
self
name
setattr
self
name
value
delattr
self
name
on
undefined
attribute
fetch
obj
name
on
all
attribute
fetch
obj
name
on
all
attribute
assignment
obj
name
value
on
all
attribute
deletion
del
obj
name
in
all
of
these
self
is
the
subject
instance
object
as
usual
name
is
the
string
name
of
the
attribute
being
accessed
and
value
is
the
object
being
assigned
to
the
attribute
the
two
get
methods
normally
return
an
attribute
s
value
and
the
other
two
return
nothing
none
for
example
to
catch
every
attribute
fetch
we
can
use
either
of
the
first
two
methods
above
and
to
catch
every
attribute
assignment
we
can
use
the
third
class
catcher
def
getattr
self
name
print
get
name
def
setattr
self
name
value
getattr
and
getattribute
print
set
name
value
x
catcher
x
job
x
pay
x
pay
prints
get
job
prints
get
pay
prints
set
pay
such
a
coding
structure
can
be
used
to
implement
the
delegation
design
pattern
we
met
earlier
in
chapter
because
all
attribute
are
routed
to
our
interception
methods
generically
we
can
validate
and
pass
them
along
to
embedded
managed
objects
the
following
class
borrowed
from
chapter
for
example
traces
every
attribute
fetch
made
to
another
object
passed
to
the
wrapper
class
class
wrapper
def
init
self
object
self
wrapped
object
def
getattr
self
attrname
print
trace
attrname
return
getattr
self
wrapped
attrname
save
object
trace
fetch
delegate
fetch
there
is
no
such
analog
for
properties
and
descriptors
short
of
coding
accessors
for
every
possible
attribute
in
every
possibly
wrapped
object
avoiding
loops
in
attribute
interception
methods
these
methods
are
generally
straightforward
to
use
their
only
complex
part
is
the
potential
for
looping
a
k
a
recursing
because
getattr
is
called
for
undefined
attributes
only
it
can
freely
fetch
other
attributes
within
its
own
code
however
because
getattribute
and
setattr
are
run
for
all
attributes
their
code
needs
to
be
careful
when
accessing
other
attributes
to
avoid
calling
themselves
again
and
triggering
a
recursive
loop
for
example
another
attribute
fetch
run
inside
a
getattribute
method
s
code
will
trigger
getattribute
again
and
the
code
will
loop
until
memory
is
exhausted
def
getattribute
self
name
x
self
other
loops
to
work
around
this
route
the
fetch
through
a
higher
superclass
instead
to
skip
this
level
s
version
the
object
class
is
always
a
superclass
and
it
serves
well
in
this
role
def
getattribute
self
name
x
object
getattribute
self
other
force
higher
to
avoid
me
for
setattr
the
situation
is
similar
assigning
any
attribute
inside
this
method
triggers
setattr
again
and
creates
a
similar
loop
def
setattr
self
name
value
self
other
value
loops
to
work
around
this
problem
assign
the
attribute
as
a
key
in
the
instance
s
dict
namespace
dictionary
instead
this
avoids
direct
attribute
assignment
chapter
managed
attributes
def
setattr
self
name
value
self
dict
other
value
use
atttr
dict
to
avoid
me
although
it
s
a
less
common
approach
setattr
can
also
pass
its
own
attribute
assignments
to
a
higher
superclass
to
avoid
looping
just
like
getattribute
def
setattr
self
name
value
object
setattr
self
other
value
force
higher
to
avoid
me
by
contrast
though
we
cannot
use
the
dict
trick
to
avoid
loops
in
getattribute
def
getattribute
self
name
x
self
dict
other
loops
fetching
the
dict
attribute
itself
triggers
getattribute
again
causing
a
recursive
loop
strange
but
true
the
delattr
method
is
rarely
used
in
practice
but
when
it
is
it
is
called
for
every
attribute
deletion
just
as
setattr
is
called
for
every
attribute
assignment
therefore
you
must
take
care
to
avoid
loops
when
deleting
attributes
by
using
the
same
techniques
namespace
dictionaries
or
superclass
method
calls
a
first
example
all
this
is
not
nearly
as
complicated
as
the
prior
section
may
have
implied
to
see
how
to
put
these
ideas
to
work
here
is
the
same
first
example
we
used
for
properties
and
descriptors
in
action
again
this
time
implemented
with
attribute
operator
overloading
methods
because
these
methods
are
so
generic
we
test
attribute
names
here
to
know
when
a
managed
attribute
is
being
accessed
others
are
allowed
to
pass
normally
class
person
def
init
self
name
self
name
name
on
person
triggers
setattr
def
getattr
self
attr
if
attr
name
print
fetch
return
self
name
else
raise
attributeerror
attr
on
obj
undefined
intercept
name
not
stored
def
setattr
self
attr
value
if
attr
name
print
change
attr
name
self
dict
attr
value
on
obj
any
value
def
delattr
self
attr
if
attr
name
print
remove
attr
name
del
self
dict
attr
on
del
obj
any
does
not
loop
real
attr
others
are
errors
set
internal
name
avoid
looping
here
avoid
looping
here
too
but
much
less
common
getattr
and
getattribute
bob
person
bob
smith
print
bob
name
bob
name
robert
smith
print
bob
name
del
bob
name
print
sue
person
sue
jones
print
sue
name
print
person
name
doc
bob
has
a
managed
attribute
runs
getattr
runs
setattr
runs
delattr
sue
inherits
property
too
no
equivalent
here
notice
that
the
attribute
assignment
in
the
init
constructor
triggers
setattr
too
this
method
catches
every
attribute
assignment
even
those
within
the
class
itself
when
this
code
is
run
the
same
output
is
produced
but
this
time
it
s
the
result
of
python
s
normal
operator
overloading
mechanism
and
our
attribute
interception
methods
fetch
bob
smith
change
fetch
robert
smith
remove
fetch
sue
jones
also
note
that
unlike
with
properties
and
descriptors
there
s
no
direct
notion
of
specifying
documentation
for
our
attribute
here
managed
attributes
exist
within
the
code
of
our
interception
methods
not
as
distinct
objects
to
achieve
exactly
the
same
results
with
getattribute
replace
getattr
in
the
example
with
the
following
because
it
catches
all
attribute
fetches
this
version
must
be
careful
to
avoid
looping
by
passing
new
fetches
to
a
superclass
and
it
can
t
generally
assume
unknown
names
are
errors
replace
getattr
with
this
def
getattribute
self
attr
if
attr
name
print
fetch
attr
name
return
object
getattribute
self
attr
on
obj
any
intercept
all
names
map
to
internal
name
avoid
looping
here
this
example
is
equivalent
to
that
coded
for
properties
and
descriptors
but
it
s
a
bit
artificial
and
it
doesn
t
really
highlight
these
tools
in
practice
because
they
are
generic
getattr
and
getattribute
are
probably
more
commonly
used
in
delegationbase
code
as
sketched
earlier
where
attribute
access
is
validated
and
routed
to
an
embedded
object
where
just
a
single
attribute
must
be
managed
properties
and
descriptors
might
do
as
well
or
better
chapter
managed
attributes
computed
attributes
as
before
our
prior
example
doesn
t
really
do
anything
but
trace
attribute
fetches
it
s
not
much
more
work
to
compute
an
attribute
s
value
when
fetched
as
for
properties
and
descriptors
the
following
creates
a
virtual
attribute
x
that
runs
a
calculation
when
fetched
class
attrsquare
def
init
self
start
self
value
start
triggers
setattr
def
getattr
self
attr
if
attr
x
return
self
value
else
raise
attributeerror
attr
on
undefined
attr
fetch
def
setattr
self
attr
value
if
attr
x
attr
value
self
dict
attr
value
on
all
attr
assignments
value
is
not
undefined
a
attrsquare
b
attrsquare
instances
of
class
with
overloading
each
has
different
state
information
print
a
x
a
x
print
a
x
print
b
x
running
this
code
results
in
the
same
output
that
we
got
earlier
when
using
properties
and
descriptors
but
this
script
s
mechanics
are
based
on
generic
attribute
interception
methods
as
before
we
can
achieve
the
same
effect
with
getattribute
instead
of
getattr
the
following
replaces
the
fetch
method
with
a
getattribute
and
changes
the
setattr
assignment
method
to
avoid
looping
by
using
direct
superclass
method
calls
instead
of
dict
keys
class
attrsquare
def
init
self
start
self
value
start
triggers
setattr
def
getattribute
self
attr
on
all
attr
fetches
if
attr
x
return
self
value
triggers
getattribute
again
else
return
object
getattribute
self
attr
def
setattr
self
attr
value
on
all
attr
assignments
getattr
and
getattribute
if
attr
x
attr
value
object
setattr
self
attr
value
when
this
version
is
run
the
results
are
the
same
again
notice
the
implicit
routing
going
on
in
inside
this
class
s
methods
self
value
start
inside
the
constructor
triggers
setattr
self
value
inside
getattribute
triggers
getattribute
again
in
fact
getattribute
is
run
twice
each
time
we
fetch
attribute
x
this
doesn
t
happen
in
the
getattr
version
because
the
value
attribute
is
not
undefined
if
you
care
about
speed
and
want
to
avoid
this
change
getattribute
to
use
the
superclass
to
fetch
value
as
well
def
getattribute
self
attr
if
attr
x
return
object
getattribute
self
value
of
course
this
still
incurs
a
call
to
the
superclass
method
but
not
an
additional
recursive
call
before
we
get
there
add
print
calls
to
these
methods
to
trace
how
and
when
they
run
getattr
and
getattribute
compared
to
summarize
the
coding
differences
between
getattr
and
getattribute
the
following
example
uses
both
to
implement
three
attributes
attr
is
a
class
attribute
attr
is
an
instance
attribute
and
attr
is
a
virtual
managed
attribute
computed
when
fetched
class
getattr
attr
def
init
self
self
attr
def
getattr
self
attr
print
get
attr
return
on
undefined
attrs
only
not
attr
inherited
from
class
not
attr
stored
on
instance
x
getattr
print
x
attr
print
x
attr
print
x
attr
print
class
getattribute
object
attr
def
init
self
self
attr
def
getattribute
self
attr
print
get
attr
if
attr
attr
return
chapter
managed
attributes
object
needed
in
only
on
all
attr
fetches
use
superclass
to
avoid
looping
here
else
return
object
getattribute
self
attr
x
getattribute
print
x
attr
print
x
attr
print
x
attr
when
run
the
getattr
version
intercepts
only
attr
accesses
because
it
is
undefined
the
getattribute
version
on
the
other
hand
intercepts
all
attribute
fetches
and
must
route
those
it
does
not
manage
to
the
superclass
fetcher
to
avoid
loops
get
attr
get
attr
get
attr
get
attr
although
getattribute
can
catch
more
attribute
fetches
than
getattr
in
practice
they
are
often
just
variations
on
a
theme
if
attributes
are
not
physically
stored
the
two
have
the
same
effect
management
techniques
compared
to
summarize
the
coding
differences
in
all
four
attribute
management
schemes
we
ve
seen
in
this
chapter
let
s
quickly
step
through
a
more
comprehensive
computed
attribute
example
using
each
technique
the
following
version
uses
properties
to
intercept
and
calculate
attributes
named
square
and
cube
notice
how
their
base
values
are
stored
in
names
that
begin
with
an
underscore
so
they
don
t
clash
with
the
names
of
the
properties
themselves
dynamically
computed
attributes
with
properties
class
powers
def
init
self
square
cube
self
square
square
self
cube
cube
square
is
the
base
value
square
is
the
property
name
def
getsquare
self
return
self
square
def
setsquare
self
value
self
square
value
square
property
getsquare
setsquare
def
getcube
self
return
self
cube
cube
property
getcube
getattr
and
getattribute
x
powers
print
x
square
print
x
cube
x
square
print
x
square
to
do
the
same
with
descriptors
we
define
the
attributes
with
complete
classes
note
that
these
descriptors
store
base
values
as
instance
state
so
they
must
use
leading
underscores
again
so
as
not
to
clash
with
the
names
of
descriptors
as
we
ll
see
in
the
final
example
of
this
chapter
we
could
avoid
this
renaming
requirement
by
storing
base
values
as
descriptor
state
instead
same
but
with
descriptors
class
descsquare
def
get
self
instance
owner
return
instance
square
def
set
self
instance
value
instance
square
value
class
desccube
def
get
self
instance
owner
return
instance
cube
class
powers
square
descsquare
cube
desccube
def
init
self
square
cube
self
square
square
self
cube
cube
x
powers
print
x
square
print
x
cube
x
square
print
x
square
use
object
in
self
square
square
works
too
because
it
triggers
desc
set
to
achieve
the
same
result
with
getattr
fetch
interception
we
again
store
base
values
with
underscore
prefixed
names
so
that
accesses
to
managed
names
are
undefined
and
thus
invoke
our
method
we
also
need
to
code
a
setattrr
to
intercept
assignments
and
take
care
to
avoid
its
potential
for
looping
same
but
with
generic
getattr
undefined
attribute
interception
class
powers
def
init
self
square
cube
self
square
square
self
cube
cube
def
getattr
self
name
if
name
square
return
self
square
elif
name
cube
return
self
cube
chapter
managed
attributes
else
raise
typeerror
unknown
attr
name
def
setattr
self
name
value
if
name
square
self
dict
square
value
else
self
dict
name
value
x
powers
print
x
square
print
x
cube
x
square
print
x
square
the
final
option
coding
this
with
getattribute
is
similar
to
the
prior
version
because
we
catch
every
attribute
now
though
we
must
route
base
value
fetches
to
a
superclass
to
avoid
looping
same
but
with
generic
getattribute
all
attribute
interception
class
powers
def
init
self
square
cube
self
square
square
self
cube
cube
def
getattribute
self
name
if
name
square
return
object
getattribute
self
square
elif
name
cube
return
object
getattribute
self
cube
else
return
object
getattribute
self
name
def
setattr
self
name
value
if
name
square
self
dict
square
value
else
self
dict
name
value
x
powers
print
x
square
print
x
cube
x
square
print
x
square
as
you
can
see
each
technique
takes
a
different
form
in
code
but
all
four
produce
the
same
result
when
run
for
more
on
how
these
alternatives
compare
and
other
coding
options
stay
tuned
for
a
more
realistic
application
of
them
in
the
attribute
validation
example
in
the
section
example
attribute
validations
on
page
first
though
we
need
to
study
a
pitfall
associated
with
two
of
these
tools
getattr
and
getattribute
intercepting
built
in
operation
attributes
when
i
introduced
getattr
and
getattribute
i
stated
that
they
intercept
undefined
and
all
attribute
fetches
respectively
which
makes
them
ideal
for
delegationbased
coding
patterns
while
this
is
true
for
normally
named
attributes
their
behavior
needs
some
additional
clarification
for
method
name
attributes
implicitly
fetched
by
built
in
operations
these
methods
may
not
be
run
at
all
this
means
that
operator
overloading
method
calls
cannot
be
delegated
to
wrapped
objects
unless
wrapper
classes
somehow
redefine
these
methods
themselves
for
example
attribute
fetches
for
the
str
add
and
getitem
methods
run
implicitly
by
printing
expressions
and
indexing
respectively
are
not
routed
to
the
generic
attribute
interception
methods
in
specifically
in
python
neither
getattr
nor
getattribute
is
run
for
such
attributes
in
python
getattr
is
run
for
such
attributes
if
they
are
undefined
in
the
class
in
python
getattribute
is
available
for
new
style
classes
only
and
works
as
it
does
in
in
other
words
in
python
classes
and
new
style
classes
there
is
no
direct
way
to
generically
intercept
built
in
operations
like
printing
and
addition
in
python
x
the
methods
such
operations
invoke
are
looked
up
at
runtime
in
instances
like
all
other
attributes
in
python
such
methods
are
looked
up
in
classes
instead
this
change
makes
delegation
based
coding
patterns
more
complex
in
since
they
cannot
generically
intercept
operator
overloading
method
calls
and
route
them
to
an
embedded
object
this
is
not
a
showstopper
wrapper
classes
can
work
around
this
constraint
by
redefining
all
relevant
operator
overloading
methods
in
the
wrapper
itself
in
order
to
delegate
calls
these
extra
methods
can
be
added
either
manually
with
tools
or
by
definition
in
and
inheritance
from
common
superclasses
this
does
however
make
wrappers
more
work
than
they
used
to
be
when
operator
overloading
methods
are
a
part
of
a
wrapped
object
s
interface
keep
in
mind
that
this
issue
applies
only
to
getattr
and
getattribute
because
properties
and
descriptors
are
defined
for
specific
attributes
only
they
don
t
really
apply
to
delegation
based
classes
at
all
a
single
property
or
descriptor
cannot
be
used
to
intercept
arbitrary
attributes
moreover
a
class
that
defines
both
operator
overloading
methods
and
attribute
interception
will
work
correctly
regardless
of
the
type
of
attribute
interception
defined
our
concern
here
is
only
with
classes
that
do
not
have
operator
overloading
methods
defined
but
try
to
intercept
them
generically
consider
the
following
example
the
file
getattr
py
which
tests
various
attribute
types
and
built
in
operations
on
instances
of
classes
containing
getattr
and
getattribute
methods
chapter
managed
attributes
class
getattr
eggs
eggs
stored
on
class
spam
on
instance
def
init
self
self
spam
def
len
self
len
here
else
getattr
called
with
len
print
len
return
def
getattr
self
attr
provide
str
if
asked
else
dummy
func
print
getattr
attr
if
attr
str
return
lambda
args
getattr
str
else
return
lambda
args
none
class
getattribute
object
object
required
in
implied
in
eggs
in
all
are
isinstance
object
auto
def
init
self
but
must
derive
to
get
new
style
tools
self
spam
incl
getattribute
some
x
defaults
def
len
self
print
len
return
def
getattribute
self
attr
print
getattribute
attr
if
attr
str
return
lambda
args
getattribute
str
else
return
lambda
args
none
for
class
in
getattr
getattribute
print
n
class
name
ljust
x
class
x
eggs
x
spam
x
other
len
x
class
attr
instance
attr
missing
attr
len
defined
explicitly
new
styles
must
support
call
directly
redefine
x
getitem
except
print
fail
try
try
x
except
print
fail
add
try
x
call
implicit
via
built
in
except
print
fail
x
call
call
explicit
not
inherited
print
x
str
print
x
str
explicit
inherited
from
type
str
implicit
via
built
in
getattr
and
getattribute
when
run
under
python
getattr
does
receive
a
variety
of
implicit
attribute
fetches
for
built
in
operations
because
python
looks
up
such
attributes
in
instances
normally
conversely
getattribute
is
not
run
for
any
of
the
operator
overloading
names
because
such
names
are
looked
up
in
classes
only
c
misc
c
python
python
getattr
py
getattr
getattr
other
len
getattr
getitem
getattr
coerce
getattr
add
getattr
call
getattr
call
getattr
str
getattr
str
getattr
str
getattr
str
getattribute
getattribute
eggs
getattribute
spam
getattribute
other
len
fail
fail
fail
getattribute
call
getattribute
str
getattribute
str
main
getattribute
object
at
x
ea
d
note
how
getattr
intercepts
both
implicit
and
explicit
fetches
of
call
and
str
in
here
by
contrast
getattribute
fails
to
catch
implicit
fetches
of
either
attribute
name
for
built
in
operations
really
the
getattribute
case
is
the
same
in
as
it
is
in
because
in
classes
must
be
made
new
style
by
deriving
from
object
to
use
this
method
this
code
s
object
derivation
is
optional
in
because
all
classes
are
new
style
when
run
under
python
though
results
for
getattr
differ
none
of
the
implicitly
run
operator
overloading
methods
trigger
either
attribute
interception
method
when
their
attributes
are
fetched
by
built
in
operations
python
skips
the
normal
instance
lookup
mechanism
when
resolving
such
names
c
misc
c
python
python
getattr
py
getattr
getattr
other
len
fail
fail
fail
chapter
managed
attributes
getattr
call
main
getattr
object
at
x
d
f
main
getattr
object
at
x
d
f
getattribute
getattribute
eggs
getattribute
spam
getattribute
other
len
fail
fail
fail
getattribute
call
getattribute
str
getattribute
str
main
getattribute
object
at
x
d
we
can
trace
these
outputs
back
to
prints
in
the
script
to
see
how
this
works
str
access
fails
to
be
caught
twice
by
getattr
in
once
for
the
built
in
print
and
once
for
explicit
fetches
because
a
default
is
inherited
from
the
class
really
from
the
built
in
object
which
is
a
superclass
to
every
class
str
fails
to
be
caught
only
once
by
the
getattribute
catchall
during
the
built
in
print
operation
explicit
fetches
bypass
the
inherited
version
call
fails
to
be
caught
in
both
schemes
in
for
built
in
call
expressions
but
it
is
intercepted
by
both
when
fetched
explicitly
unlike
with
str
there
is
no
inherited
call
default
to
defeat
getattr
len
is
caught
by
both
classes
simply
because
it
is
an
explicitly
defined
method
in
the
classes
themselves
its
name
it
is
not
routed
to
either
getattr
or
get
attribute
in
if
we
delete
the
class
s
len
methods
all
other
built
in
operations
fail
to
be
intercepted
by
both
schemes
in
again
the
net
effect
is
that
operator
overloading
methods
implicitly
run
by
built
in
operations
are
never
routed
through
either
attribute
interception
method
in
python
searches
for
such
attributes
in
classes
and
skips
instance
lookup
entirely
this
makes
delegation
based
wrapper
classes
more
difficult
to
code
in
if
wrapped
classes
may
contain
operator
overloading
methods
those
methods
must
be
redefined
redundantly
in
the
wrapper
class
in
order
to
delegate
to
the
wrapped
object
in
general
delegation
tools
this
can
add
many
extra
methods
of
course
the
addition
of
such
methods
can
be
partly
automated
by
tools
that
augment
classes
with
new
methods
the
class
decorators
and
metaclasses
of
the
next
two
chapters
might
help
here
moreover
a
superclass
might
be
able
to
define
all
these
extra
methods
once
for
inheritance
in
delegation
based
classes
still
delegation
coding
patterns
require
extra
work
in
for
a
more
realistic
illustration
of
this
phenomenon
as
well
as
its
workaround
see
the
private
decorator
example
in
the
following
chapter
there
we
ll
see
that
it
s
also
getattr
and
getattribute
possible
to
insert
a
getattribute
in
the
client
class
to
retain
its
original
type
although
this
method
still
won
t
be
called
for
operator
overloading
methods
printing
still
runs
a
str
defined
in
such
a
class
directly
for
example
instead
of
routing
the
request
through
getattribute
as
another
example
the
next
section
resurrects
our
class
tutorial
example
now
that
you
understand
how
attribute
interception
works
i
ll
be
able
to
explain
one
of
its
stranger
bits
for
an
example
of
this
change
at
work
in
python
itself
see
the
discussion
of
the
os
popen
object
in
chapter
because
it
is
implemented
with
a
wrapper
that
uses
getattr
to
delegate
attribute
fetches
to
an
embedded
object
it
does
not
intercept
the
next
x
builtin
iterator
function
in
python
which
is
defined
to
run
next
it
does
however
intercept
and
delegate
explicit
x
next
calls
because
these
are
not
routed
through
the
built
in
and
are
not
inherited
from
a
superclass
like
str
is
this
is
equivalent
to
call
in
our
example
implicit
calls
for
builtins
do
not
trigger
getattr
but
explicit
calls
to
names
not
inherited
from
the
class
type
do
in
other
words
this
change
impacts
not
only
our
delegators
but
also
those
in
the
python
standard
library
given
the
scope
of
this
change
it
s
possible
that
this
behavior
may
evolve
in
the
future
so
be
sure
to
verify
this
issue
in
later
releases
delegation
based
managers
revisited
the
object
oriented
tutorial
of
chapter
presented
a
manager
class
that
used
object
embedding
and
method
delegation
to
customize
its
superclass
rather
than
inheritance
here
is
the
code
again
for
reference
with
some
irrelevant
testing
removed
class
person
def
init
self
name
job
none
pay
self
name
name
self
job
job
self
pay
pay
def
lastname
self
return
self
name
split
def
giveraise
self
percent
self
pay
int
self
pay
percent
def
str
self
return
person
s
s
self
name
self
pay
class
manager
def
init
self
name
pay
self
person
person
name
mgr
pay
def
giveraise
self
percent
bonus
self
person
giveraise
percent
bonus
def
getattr
self
attr
return
getattr
self
person
attr
chapter
managed
attributes
embed
a
person
object
intercept
and
delegate
delegate
all
other
attrs
def
str
self
return
str
self
person
if
name
main
sue
person
sue
jones
job
dev
print
sue
lastname
sue
giveraise
print
sue
tom
manager
tom
jones
print
tom
lastname
tom
giveraise
print
tom
must
overload
again
in
pay
manager
init
manager
getattr
person
lastname
manager
giveraise
person
giveraise
manager
str
person
str
comments
at
the
end
of
this
file
show
which
methods
are
invoked
for
a
line
s
operation
in
particular
notice
how
lastname
calls
are
undefined
in
manager
and
thus
are
routed
into
the
generic
getattr
and
from
there
on
to
the
embedded
person
object
here
is
the
script
s
output
sue
receives
a
raise
from
person
but
tom
gets
because
giveraise
is
customized
in
manager
c
misc
c
python
python
getattr
py
jones
person
sue
jones
jones
person
tom
jones
by
contrast
though
notice
what
occurs
when
we
print
a
manager
at
the
end
of
the
script
the
wrapper
class
s
str
is
invoked
and
it
delegates
to
the
embedded
person
object
s
str
with
that
in
mind
watch
what
happens
if
we
delete
the
manager
str
method
in
this
code
delete
the
manager
str
method
class
manager
def
init
self
name
pay
self
person
person
name
mgr
pay
def
giveraise
self
percent
bonus
self
person
giveraise
percent
bonus
def
getattr
self
attr
return
getattr
self
person
attr
embed
a
person
object
intercept
and
delegate
delegate
all
other
attrs
now
printing
does
not
route
its
attribute
fetch
through
the
generic
getattr
interceptor
under
python
for
manager
objects
instead
a
default
str
display
method
inherited
from
the
class
s
implicit
object
superclass
is
looked
up
and
run
sue
still
prints
correctly
because
person
has
an
explicit
str
c
misc
c
python
python
person
py
jones
person
sue
jones
jones
main
manager
object
at
x
a
ae
curiously
running
without
a
str
like
this
does
trigger
getattr
in
python
because
operator
overloading
attributes
are
routed
through
this
method
and
classes
do
not
inherit
a
default
for
str
getattr
and
getattribute
c
misc
c
python
python
person
py
jones
person
sue
jones
jones
person
tom
jones
switching
to
getattribute
won
t
help
here
either
like
getattr
it
is
not
run
for
operator
overloading
attributes
implied
by
built
in
operations
in
either
python
or
replace
getattr
with
getattribute
class
manager
def
init
self
name
pay
self
person
person
name
mgr
pay
def
giveraise
self
percent
bonus
self
person
giveraise
percent
bonus
def
getattribute
self
attr
print
attr
if
attr
in
person
giveraise
return
object
getattribute
self
attr
else
return
getattr
self
person
attr
use
object
in
embed
a
person
object
intercept
and
delegate
fetch
my
attrs
delegate
all
others
regardless
of
which
attribute
interception
method
is
used
in
we
still
must
include
a
redefined
str
in
manager
as
shown
above
in
order
to
intercept
printing
operations
and
route
them
to
the
embedded
person
object
c
misc
c
python
python
person
py
jones
person
sue
jones
lastname
person
jones
giveraise
person
main
manager
object
at
x
e
notice
that
getattribute
gets
called
twice
here
for
methods
once
for
the
method
name
and
again
for
the
self
person
embedded
object
fetch
we
could
avoid
that
with
a
different
coding
but
we
would
still
have
to
redefine
str
to
catch
printing
albeit
differently
here
self
person
would
cause
this
getattribute
to
fail
code
getattribute
differently
to
minimize
extra
calls
class
manager
def
init
self
name
pay
self
person
person
name
mgr
pay
def
getattribute
self
attr
print
attr
person
object
getattribute
self
person
if
attr
giveraise
return
lambda
percent
person
giveraise
percent
else
return
getattr
person
attr
chapter
managed
attributes
def
str
self
person
object
getattribute
self
person
return
str
person
when
this
alternative
runs
our
object
prints
properly
but
only
because
we
ve
added
an
explicit
str
in
the
wrapper
this
attribute
is
still
not
routed
to
our
generic
attribute
interception
method
jones
person
sue
jones
lastname
jones
giveraise
person
tom
jones
that
short
story
here
is
that
delegation
based
classes
like
manager
must
redefine
some
operator
overloading
methods
like
str
to
route
them
to
embedded
objects
in
python
but
not
in
python
unless
new
style
classes
are
used
our
only
direct
options
seem
to
be
using
getattr
and
python
or
redefining
operator
overloading
methods
in
wrapper
classes
redundantly
in
again
this
isn
t
an
impossible
task
many
wrappers
can
predict
the
set
of
operator
overloading
methods
required
and
tools
and
superclasses
can
automate
part
of
this
task
moreover
not
all
classes
use
operator
overloading
methods
indeed
most
application
classes
usually
should
not
it
is
however
something
to
keep
in
mind
for
delegation
coding
models
used
in
python
when
operator
overloading
methods
are
part
of
an
object
s
interface
wrappers
must
accommodate
them
portably
by
redefining
them
locally
example
attribute
validations
to
close
out
this
chapter
let
s
turn
to
a
more
realistic
example
coded
in
all
four
of
our
attribute
management
schemes
the
example
we
will
use
defines
a
cardholder
object
with
four
attributes
three
of
which
are
managed
the
managed
attributes
validate
or
transform
values
when
fetched
or
stored
all
four
versions
produce
the
same
results
for
the
same
test
code
but
they
implement
their
attributes
in
very
different
ways
the
examples
are
included
largely
for
self
study
although
i
won
t
go
through
their
code
in
detail
they
all
use
concepts
we
ve
already
explored
in
this
chapter
using
properties
to
validate
our
first
coding
uses
properties
to
manage
three
attributes
as
usual
we
could
use
simple
methods
instead
of
managed
attributes
but
properties
help
if
we
have
been
using
attributes
in
existing
code
already
properties
run
code
automatically
on
attribute
access
but
are
focused
on
a
specific
set
of
attributes
they
cannot
be
used
to
intercept
all
attributes
generically
example
attribute
validations
to
understand
this
code
it
s
crucial
to
notice
that
the
attribute
assignments
inside
the
init
constructor
method
trigger
property
setter
methods
too
when
this
method
assigns
to
self
name
for
example
it
automatically
invokes
the
setname
method
which
transforms
the
value
and
assigns
it
to
an
instance
attribute
called
name
so
it
won
t
clash
with
the
property
s
name
this
renaming
sometimes
called
name
mangling
is
necessary
because
properties
use
common
instance
state
and
have
none
of
their
own
data
is
stored
in
an
attribute
called
name
and
the
attribute
called
name
is
always
a
property
not
data
in
the
end
this
class
manages
attributes
called
name
age
and
acct
allows
the
attribute
addr
to
be
accessed
directly
and
provides
a
read
only
attribute
called
remain
that
is
entirely
virtual
and
computed
on
demand
for
comparison
purposes
this
propertybased
coding
weighs
in
at
lines
of
code
class
cardholder
acctlen
retireage
class
data
def
init
self
acct
name
age
addr
self
acct
acct
instance
data
self
name
name
these
trigger
prop
setters
too
self
age
age
x
mangled
to
have
class
name
self
addr
addr
addr
is
not
managed
remain
has
no
data
def
getname
self
return
self
name
def
setname
self
value
value
value
lower
replace
self
name
value
name
property
getname
setname
def
getage
self
return
self
age
def
setage
self
value
if
value
or
value
raise
valueerror
invalid
age
else
self
age
value
age
property
getage
setage
def
getacct
self
return
self
acct
def
setacct
self
value
value
value
replace
if
len
value
self
acctlen
raise
typeerror
invald
acct
number
else
self
acct
value
acct
property
getacct
setacct
def
remainget
self
chapter
managed
attributes
could
be
a
method
not
attr
return
self
retireage
self
age
remain
property
remainget
unless
already
using
as
attr
self
test
code
the
following
code
tests
our
class
add
this
to
the
bottom
of
your
file
or
place
the
class
in
a
module
and
import
it
first
we
ll
use
this
same
testing
code
for
all
four
versions
of
this
example
when
it
runs
we
make
two
instances
of
our
managed
attribute
class
and
fetch
and
change
its
various
attributes
operations
expected
to
fail
are
wrapped
in
try
statements
bob
cardholder
bob
smith
main
st
print
bob
acct
bob
name
bob
age
bob
remain
bob
addr
sep
bob
name
bob
q
smith
bob
age
bob
acct
print
bob
acct
bob
name
bob
age
bob
remain
bob
addr
sep
sue
cardholder
sue
jones
main
st
print
sue
acct
sue
name
sue
age
sue
remain
sue
addr
sep
try
sue
age
except
print
bad
age
for
sue
try
sue
remain
except
print
can
t
set
sue
remain
try
sue
acct
except
print
bad
acct
for
sue
here
is
the
output
of
our
self
test
code
again
this
is
the
same
for
all
versions
of
this
example
trace
through
this
code
to
see
how
the
class
s
methods
are
invoked
accounts
are
displayed
with
some
digits
hidden
names
are
converted
to
a
standard
format
and
time
remaining
until
retirement
is
computed
when
fetched
using
a
class
attribute
cutoff
bob
smith
main
st
bob
q
smith
main
st
sue
jones
main
st
bad
age
for
sue
can
t
set
sue
remain
bad
acct
for
sue
using
descriptors
to
validate
now
let
s
recode
our
example
using
descriptors
instead
of
properties
as
we
ve
seen
descriptors
are
very
similar
to
properties
in
terms
of
functionality
and
roles
in
fact
properties
are
basically
a
restricted
form
of
descriptor
like
properties
descriptors
are
example
attribute
validations
designed
to
handle
specific
attributes
not
generic
attribute
access
unlike
properties
descriptors
have
their
own
state
and
they
re
a
more
general
scheme
to
understand
this
code
it
s
again
important
to
notice
that
the
attribute
assignments
inside
the
init
constructor
method
trigger
descriptor
set
methods
when
the
constructor
method
assigns
to
self
name
for
example
it
automatically
invokes
the
name
set
method
which
transforms
the
value
and
assigns
it
to
a
descriptor
attribute
called
name
unlike
in
the
prior
property
based
variant
though
in
this
case
the
actual
name
value
is
attached
to
the
descriptor
object
not
the
client
class
instance
although
we
could
store
this
value
in
either
instance
or
descriptor
state
the
latter
avoids
the
need
to
mangle
names
with
underscores
to
avoid
collisions
in
the
cardholder
client
class
the
attribute
called
name
is
always
a
descriptor
object
not
data
in
the
end
this
class
implements
the
same
attributes
as
the
prior
version
it
manages
attributes
called
name
age
and
acct
allows
the
attribute
addr
to
be
accessed
directly
and
provides
a
read
only
attribute
called
remain
that
is
entirely
virtual
and
computed
on
demand
notice
how
we
must
catch
assignments
to
the
remain
name
in
its
descriptor
and
raise
an
exception
as
we
learned
earlier
if
we
did
not
do
this
assigning
to
this
attribute
of
an
instance
would
silently
create
an
instance
attribute
that
hides
the
class
attribute
descriptor
for
comparison
purposes
this
descriptor
based
coding
takes
lines
of
code
class
cardholder
acctlen
retireage
def
init
self
acct
name
age
addr
self
acct
acct
self
name
name
self
age
age
self
addr
addr
class
data
instance
data
these
trigger
set
calls
too
x
not
needed
in
descriptor
addr
is
not
managed
remain
has
no
data
class
name
def
get
self
instance
owner
class
names
cardholder
locals
return
self
name
def
set
self
instance
value
value
value
lower
replace
self
name
value
name
name
class
age
def
get
self
instance
owner
return
self
age
def
set
self
instance
value
if
value
or
value
raise
valueerror
invalid
age
else
self
age
value
age
age
chapter
managed
attributes
use
descriptor
data
class
acct
def
get
self
instance
owner
return
self
acct
def
set
self
instance
value
value
value
replace
if
len
value
instance
acctlen
raise
typeerror
invald
acct
number
else
self
acct
value
acct
acct
class
remain
def
get
self
instance
owner
return
instance
retireage
instance
age
def
set
self
instance
value
raise
typeerror
cannot
set
remain
remain
remain
use
instance
class
data
triggers
age
get
else
set
allowed
here
using
getattr
to
validate
as
we
ve
seen
the
getattr
method
intercepts
all
undefined
attributes
so
it
can
be
more
generic
than
using
properties
or
descriptors
for
our
example
we
simply
test
the
attribute
name
to
know
when
a
managed
attribute
is
being
fetched
others
are
stored
physically
on
the
instance
and
so
never
reach
getattr
although
this
approach
is
more
general
than
using
properties
or
descriptors
extra
work
may
be
required
to
imitate
the
specific
attribute
focus
of
other
tools
we
need
to
check
names
at
runtime
and
we
must
code
a
setattr
in
order
to
intercept
and
validate
attribute
assignments
as
for
the
property
and
descriptor
versions
of
this
example
it
s
critical
to
notice
that
the
attribute
assignments
inside
the
init
constructor
method
trigger
the
class
s
setattr
method
too
when
this
method
assigns
to
self
name
for
example
it
automatically
invokes
the
setattr
method
which
transforms
the
value
and
assigns
it
to
an
instance
attribute
called
name
by
storing
name
on
the
instance
it
ensures
that
future
accesses
will
not
trigger
getattr
in
contrast
acct
is
stored
as
acct
so
that
later
accesses
to
acct
do
invoke
getattr
in
the
end
this
class
like
the
prior
two
manages
attributes
called
name
age
and
acct
allows
the
attribute
addr
to
be
accessed
directly
and
provides
a
read
only
attribute
called
remain
that
is
entirely
virtual
and
is
computed
on
demand
for
comparison
purposes
this
alternative
comes
in
at
lines
of
code
fewer
than
the
property
based
version
and
fewer
than
the
version
using
descriptors
clarity
matters
more
than
code
size
of
course
but
extra
code
can
sometimes
imply
extra
development
and
maintenance
work
probably
more
important
here
are
roles
generic
tools
like
getattr
may
be
better
suited
to
generic
delegation
while
properties
and
descriptors
are
more
directly
designed
to
manage
specific
attributes
also
note
that
the
code
here
incurs
extra
calls
when
setting
unmanaged
attributes
e
g
addr
although
no
extra
calls
are
incurred
for
fetching
unmanaged
attributes
since
they
example
attribute
validations
are
defined
though
this
will
likely
result
in
negligible
overhead
for
most
programs
properties
and
descriptors
incur
an
extra
call
only
when
managed
attributes
are
accessed
here
s
the
getattr
version
of
our
code
class
cardholder
acctlen
retireage
def
init
self
acct
name
age
addr
self
acct
acct
self
name
name
self
age
age
self
addr
addr
def
getattr
self
name
if
name
acct
return
self
acct
elif
name
remain
return
self
retireage
self
age
else
raise
attributeerror
name
class
data
instance
data
these
trigger
setattr
too
acct
not
mangled
name
tested
addr
is
not
managed
remain
has
no
data
on
undefined
attr
fetches
name
age
addr
are
defined
doesn
t
trigger
getattr
def
setattr
self
name
value
if
name
name
on
all
attr
assignments
value
value
lower
replace
addr
stored
directly
elif
name
age
acct
mangled
to
acct
if
value
or
value
raise
valueerror
invalid
age
elif
name
acct
name
acct
value
value
replace
if
len
value
self
acctlen
raise
typeerror
invald
acct
number
elif
name
remain
raise
typeerror
cannot
set
remain
self
dict
name
value
avoid
looping
using
getattribute
to
validate
our
final
variant
uses
the
getattribute
catchall
to
intercept
attribute
fetches
and
manage
them
as
needed
every
attribute
fetch
is
caught
here
so
we
test
the
attribute
names
to
detect
managed
attributes
and
route
all
others
to
the
superclass
for
normal
fetch
processing
this
version
uses
the
same
setattr
to
catch
assignments
as
the
prior
version
the
code
works
very
much
like
the
getattr
version
so
i
won
t
repeat
the
full
description
here
note
though
that
because
every
attribute
fetch
is
routed
to
getattribute
we
don
t
need
to
mangle
names
to
intercept
them
here
acct
is
stored
as
acct
on
the
other
hand
this
code
must
take
care
to
route
nonmanaged
attribute
fetches
to
a
superclass
to
avoid
looping
chapter
managed
attributes
also
notice
that
this
version
incurs
extra
calls
for
both
setting
and
fetching
unmanaged
attributes
e
g
addr
if
speed
is
paramount
this
alternative
may
be
the
slowest
of
the
bunch
for
comparison
purposes
this
version
amounts
to
lines
of
code
just
like
the
prior
version
class
cardholder
acctlen
retireage
def
init
self
acct
name
age
addr
self
acct
acct
self
name
name
self
age
age
self
addr
addr
class
data
instance
data
these
trigger
setattr
too
acct
not
mangled
name
tested
addr
is
not
managed
remain
has
no
data
def
getattribute
self
name
superget
object
getattribute
don
t
loop
one
level
up
if
name
acct
on
all
attr
fetches
return
superget
self
acct
elif
name
remain
return
superget
self
retireage
superget
self
age
else
return
superget
self
name
name
age
addr
stored
def
setattr
self
name
value
if
name
name
on
all
attr
assignments
value
value
lower
replace
addr
stored
directly
elif
name
age
if
value
or
value
raise
valueerror
invalid
age
elif
name
acct
value
value
replace
if
len
value
self
acctlen
raise
typeerror
invald
acct
number
elif
name
remain
raise
typeerror
cannot
set
remain
self
dict
name
value
avoid
loops
orig
names
be
sure
to
study
and
run
this
section
s
code
on
your
own
for
more
pointers
on
managed
attribute
coding
techniques
chapter
summary
this
chapter
covered
the
various
techniques
for
managing
access
to
attributes
in
python
including
the
getattr
and
getattribute
operator
overloading
methods
class
properties
and
attribute
descriptors
along
the
way
it
compared
and
contrasted
these
tools
and
presented
a
handful
of
use
cases
to
demonstrate
their
behavior
chapter
continues
our
tool
building
survey
with
a
look
at
decorators
code
run
automatically
at
function
and
class
creation
time
rather
than
on
attribute
access
before
we
continue
though
let
s
work
through
a
set
of
questions
to
review
what
we
ve
covered
here
chapter
summary
test
your
knowledge
quiz
how
do
getattr
and
getattribute
differ
how
do
properties
and
descriptors
differ
how
are
properties
and
decorators
related
what
are
the
main
functional
differences
between
getattr
and
getattri
bute
and
properties
and
descriptors
isn
t
all
this
feature
comparison
just
a
kind
of
argument
test
your
knowledge
answers
the
getattr
method
is
run
for
fetches
of
undefined
attributes
only
i
e
those
not
present
on
an
instance
and
not
inherited
from
any
of
its
classes
by
contrast
the
getattribute
method
is
called
for
every
attribute
fetch
whether
the
attribute
is
defined
or
not
because
of
this
code
inside
a
getattr
can
freely
fetch
other
attributes
if
they
are
defined
whereas
getattribute
must
use
special
code
for
all
such
attribute
fetches
to
avoid
looping
it
must
route
fetches
to
a
superclass
to
skip
itself
properties
serve
a
specific
role
while
descriptors
are
more
general
properties
define
get
set
and
delete
functions
for
a
specific
attribute
descriptors
provide
a
class
with
methods
for
these
actions
too
but
they
provide
extra
flexibility
to
support
more
arbitrary
actions
in
fact
properties
are
really
a
simple
way
to
create
a
specific
kind
of
descriptor
one
that
runs
functions
on
attribute
accesses
coding
differs
too
a
property
is
created
with
a
built
in
function
and
a
descriptor
is
coded
with
a
class
as
such
descriptors
can
leverage
all
the
usual
oop
features
of
classes
such
as
inheritance
moreover
in
addition
to
the
instance
s
state
information
descriptors
have
local
state
of
their
own
so
they
can
avoid
name
collisions
in
the
instance
properties
can
be
coded
with
decorator
syntax
because
the
property
built
in
accepts
a
single
function
argument
it
can
be
used
directly
as
a
function
decorator
to
define
a
fetch
access
property
due
to
the
name
rebinding
behavior
of
decorators
the
name
of
the
decorated
function
is
assigned
to
a
property
whose
get
accessor
is
set
to
the
original
function
decorated
name
property
name
property
setter
and
deleter
attributes
allow
us
to
further
add
set
and
delete
accessors
with
decoration
syntax
they
set
the
accessor
to
the
decorated
function
and
return
the
augmented
property
chapter
managed
attributes
the
getattr
and
getattribute
methods
are
more
generic
they
can
be
used
to
catch
arbitrarily
many
attributes
in
contrast
each
property
or
descriptor
provides
access
interception
for
only
one
specific
attribute
we
can
t
catch
every
attribute
fetch
with
a
single
property
or
descriptor
on
the
other
hand
properties
and
descriptors
handle
both
attribute
fetch
and
assignment
by
design
getattr
and
getattribute
handle
fetches
only
to
intercept
assignments
as
well
setattr
must
also
be
coded
the
implementation
is
also
different
getattr
and
getattribute
are
operator
overloading
methods
whereas
properties
and
descriptors
are
objects
manually
assigned
to
class
attributes
no
it
isn
t
to
quote
from
python
namesake
monty
python
s
flying
circus
an
argument
is
a
connected
series
of
statements
intended
to
establish
a
proposition
no
it
isn
t
yes
it
is
it
s
not
just
contradiction
look
if
i
argue
with
you
i
must
take
up
a
contrary
position
yes
but
that
s
not
just
saying
no
it
isn
t
yes
it
is
no
it
isn
t
yes
it
is
no
it
isn
t
argument
is
an
intellectual
process
contradiction
is
just
the
automatic
gainsaying
of
any
statement
the
other
person
makes
short
pause
no
it
isn
t
it
is
not
at
all
now
look
test
your
knowledge
quiz
chapter
decorators
in
the
advanced
class
topics
chapter
of
this
book
chapter
we
met
static
and
class
methods
and
took
a
quick
look
at
the
decorator
syntax
python
offers
for
declaring
them
we
also
met
function
decorators
briefly
in
the
prior
chapter
chapter
while
exploring
the
property
built
in
s
ability
to
serve
as
a
decorator
and
in
chapter
while
studying
the
notion
of
abstract
superclasses
this
chapter
picks
up
where
the
previous
decorator
coverage
left
off
here
we
ll
dig
deeper
into
the
inner
workings
of
decorators
and
study
more
advanced
ways
to
code
new
decorators
ourselves
as
we
ll
see
many
of
the
concepts
we
studied
in
earlier
chapters
such
as
state
retention
show
up
regularly
in
decorators
this
is
a
somewhat
advanced
topic
and
decorator
construction
tends
to
be
of
more
interest
to
tool
builders
than
to
application
programmers
still
given
that
decorators
are
becoming
increasingly
common
in
popular
python
frameworks
a
basic
understanding
can
help
demystify
their
role
even
if
you
re
just
a
decorator
user
besides
covering
decorator
construction
details
this
chapter
serves
as
a
more
realistic
case
study
of
python
in
action
because
its
examples
are
somewhat
larger
than
most
of
the
others
we
ve
seen
in
this
book
they
better
illustrate
how
code
comes
together
into
more
complete
systems
and
tools
as
an
extra
perk
much
of
the
code
we
ll
write
here
may
be
used
as
general
purpose
tools
in
your
day
to
day
programs
what
s
a
decorator
decoration
is
a
way
to
specify
management
code
for
functions
and
classes
decorators
themselves
take
the
form
of
callable
objects
e
g
functions
that
process
other
callable
objects
as
we
saw
earlier
in
this
book
python
decorators
come
in
two
related
flavors
function
decorators
do
name
rebinding
at
function
definition
time
providing
a
layer
of
logic
that
can
manage
functions
and
methods
or
later
calls
to
them
class
decorators
do
name
rebinding
at
class
definition
time
providing
a
layer
of
logic
that
can
manage
classes
or
the
instances
created
by
calling
them
later
in
short
decorators
provide
a
way
to
insert
automatically
run
code
at
the
end
of
function
and
class
definition
statements
at
the
end
of
a
def
for
function
decorators
and
at
the
end
of
a
class
for
class
decorators
such
code
can
play
a
variety
of
roles
as
described
in
the
following
sections
managing
calls
and
instances
for
example
in
typical
use
this
automatically
run
code
may
be
used
to
augment
calls
to
functions
and
classes
it
arranges
this
by
installing
wrapper
objects
to
be
invoked
later
function
decorators
install
wrapper
objects
to
intercept
later
function
calls
and
process
them
as
needed
class
decorators
install
wrapper
objects
to
intercept
later
instance
creation
calls
and
process
them
as
required
decorators
achieve
these
effects
by
automatically
rebinding
function
and
class
names
to
other
callables
at
the
end
of
def
and
class
statements
when
later
invoked
these
callables
can
perform
tasks
such
as
tracing
and
timing
function
calls
managing
access
to
class
instance
attributes
and
so
on
managing
functions
and
classes
although
most
examples
in
this
chapter
deal
with
using
wrappers
to
intercept
later
calls
to
functions
and
classes
this
is
not
the
only
way
decorators
can
be
used
function
decorators
can
also
be
used
to
manage
function
objects
instead
of
later
calls
to
them
to
register
a
function
to
an
api
for
instance
our
primary
focus
here
though
will
be
on
their
more
commonly
used
call
wrapper
application
class
decorators
can
also
be
used
to
manage
class
objects
directly
instead
of
instance
creation
calls
to
augment
a
class
with
new
methods
for
example
because
this
role
intersects
strongly
with
that
of
metaclasses
indeed
both
run
at
the
end
of
the
class
creation
process
we
ll
see
additional
use
cases
in
the
next
chapter
in
other
words
function
decorators
can
be
used
to
manage
both
function
calls
and
function
objects
and
class
decorators
can
be
used
to
manage
both
class
instances
and
classes
themselves
by
returning
the
decorated
object
itself
instead
of
a
wrapper
decorators
become
a
simple
post
creation
step
for
functions
and
classes
regardless
of
the
role
they
play
decorators
provide
a
convenient
and
explicit
way
to
code
tools
useful
both
during
program
development
and
in
live
production
systems
using
and
defining
decorators
depending
on
your
job
description
you
might
encounter
decorators
as
a
user
or
a
provider
as
we
ve
seen
python
itself
comes
with
built
in
decorators
that
have
specialized
roles
static
method
declaration
property
creation
and
more
in
addition
chapter
decorators
many
popular
python
toolkits
include
decorators
to
perform
tasks
such
as
managing
database
or
user
interface
logic
in
such
cases
we
can
get
by
without
knowing
how
the
decorators
are
coded
for
more
general
tasks
programmers
can
code
arbitrary
decorators
of
their
own
for
example
function
decorators
may
be
used
to
augment
functions
with
code
that
adds
call
tracing
performs
argument
validity
testing
during
debugging
automatically
acquires
and
releases
thread
locks
times
calls
made
to
function
for
optimization
and
so
on
any
behavior
you
can
imagine
adding
to
a
function
call
is
a
candidate
for
custom
function
decorators
on
the
other
hand
function
decorators
are
designed
to
augment
only
a
specific
function
or
method
call
not
an
entire
object
interface
class
decorators
fill
the
latter
role
better
because
they
can
intercept
instance
creation
calls
they
can
be
used
to
implement
arbitrary
object
interface
augmentation
or
management
tasks
for
example
custom
class
decorators
can
trace
or
validate
every
attribute
reference
made
for
an
object
they
can
also
be
used
to
implement
proxy
objects
singleton
classes
and
other
common
coding
patterns
in
fact
we
ll
find
that
many
class
decorators
bear
a
strong
resemblance
to
the
delegation
coding
pattern
we
met
in
chapter
why
decorators
like
many
advanced
python
tools
decorators
are
never
strictly
required
from
a
purely
technical
perspective
their
functionality
can
often
be
implemented
instead
using
simple
helper
function
calls
or
other
techniques
and
at
a
base
level
we
can
always
manually
code
the
name
rebinding
that
decorators
perform
automatically
that
said
decorators
provide
an
explicit
syntax
for
such
tasks
which
makes
intent
clearer
can
minimize
augmentation
code
redundancy
and
may
help
ensure
correct
api
usage
decorators
have
a
very
explicit
syntax
which
makes
them
easier
to
spot
than
helper
function
calls
that
may
be
arbitrarily
far
removed
from
the
subject
functions
or
classes
decorators
are
applied
once
when
the
subject
function
or
class
is
defined
it
s
not
necessary
to
add
extra
code
which
may
have
to
be
changed
in
the
future
at
every
call
to
the
class
or
function
because
of
both
of
the
prior
points
decorators
make
it
less
likely
that
a
user
of
an
api
will
forget
to
augment
a
function
or
class
according
to
api
requirements
in
other
words
beyond
their
technical
model
decorators
offer
some
advantages
in
terms
of
code
maintenance
and
aesthetics
moreover
as
structuring
tools
decorators
naturally
foster
encapsulation
of
code
which
reduces
redundancy
and
makes
future
changes
easier
what
s
a
decorator
decorators
do
have
some
potential
drawbacks
too
when
they
insert
wrapper
logic
they
can
alter
the
types
of
the
decorated
objects
and
they
may
incur
extra
calls
on
the
other
hand
the
same
considerations
apply
to
any
technique
that
adds
wrapping
logic
to
objects
we
ll
explore
these
tradeoffs
in
the
context
of
real
code
later
in
this
chapter
although
the
choice
to
use
decorators
is
still
somewhat
subjective
their
advantages
are
compelling
enough
that
they
are
quickly
becoming
best
practice
in
the
python
world
to
help
you
decide
for
yourself
let
s
turn
to
the
details
the
basics
let
s
get
started
with
a
first
pass
look
at
decoration
behavior
from
a
symbolic
perspective
we
ll
write
real
code
soon
but
since
most
of
the
magic
of
decorators
boils
down
to
an
automatic
rebinding
operation
it
s
important
to
understand
this
mapping
first
function
decorators
function
decorators
have
been
available
in
python
since
version
as
we
saw
earlier
in
this
book
they
are
largely
just
syntactic
sugar
that
runs
one
function
through
another
at
the
end
of
a
def
statement
and
rebinds
the
original
function
name
to
the
result
usage
a
function
decorator
is
a
kind
of
runtime
declaration
about
the
function
whose
definition
follows
the
decorator
is
coded
on
a
line
just
before
the
def
statement
that
defines
a
function
or
method
and
it
consists
of
the
symbol
followed
by
a
reference
to
a
metafunction
a
function
or
other
callable
object
that
manages
another
function
in
terms
of
code
function
decorators
automatically
map
the
following
syntax
decorator
def
f
arg
decorate
function
f
call
function
into
this
equivalent
form
where
decorator
is
a
one
argument
callable
object
that
returns
a
callable
object
with
the
same
number
of
arguments
as
f
def
f
arg
f
decorator
f
rebind
function
name
to
decorator
result
f
essentially
calls
decorator
f
chapter
decorators
this
automatic
name
rebinding
works
on
any
def
statement
whether
it
s
for
a
simple
function
or
a
method
within
a
class
when
the
function
f
is
later
called
it
s
actually
calling
the
object
returned
by
the
decorator
which
may
be
either
another
object
that
implements
required
wrapping
logic
or
the
original
function
itself
in
other
words
decoration
essentially
maps
the
first
of
the
following
into
the
second
though
the
decorator
is
really
run
only
once
at
decoration
time
func
decorator
func
this
automatic
name
rebinding
accounts
for
the
static
method
and
property
decoration
syntax
we
met
earlier
in
the
book
class
c
staticmethod
def
meth
meth
staticmethod
meth
class
c
property
def
name
self
name
property
name
in
both
cases
the
method
name
is
rebound
to
the
result
of
a
built
in
function
decorator
at
the
end
of
the
def
statement
calling
the
original
name
later
invokes
whatever
object
the
decorator
returns
implementation
a
decorator
itself
is
a
callable
that
returns
a
callable
that
is
it
returns
the
object
to
be
called
later
when
the
decorated
function
is
invoked
through
its
original
name
either
a
wrapper
object
to
intercept
later
calls
or
the
original
function
augmented
in
some
way
in
fact
decorators
can
be
any
type
of
callable
and
return
any
type
of
callable
any
combination
of
functions
and
classes
may
be
used
though
some
are
better
suited
to
certain
contexts
for
example
to
tap
into
the
decoration
protocol
in
order
to
manage
a
function
just
after
it
is
created
we
might
code
a
decorator
of
this
form
def
decorator
f
process
function
f
return
f
decorator
def
func
func
decorator
func
because
the
original
decorated
function
is
assigned
back
to
its
name
this
simply
adds
a
post
creation
step
to
function
definition
such
a
structure
might
be
used
to
register
a
function
to
an
api
assign
function
attributes
and
so
on
the
basics
in
more
typical
use
to
insert
logic
that
intercepts
later
calls
to
a
function
we
might
code
a
decorator
to
return
a
different
object
than
the
original
function
def
decorator
f
save
or
use
function
f
return
a
different
callable
nested
def
class
with
call
etc
decorator
def
func
func
decorator
func
this
decorator
is
invoked
at
decoration
time
and
the
callable
it
returns
is
invoked
when
the
original
function
name
is
later
called
the
decorator
itself
receives
the
decorated
function
the
callable
returned
receives
whatever
arguments
are
later
passed
to
the
decorated
function
s
name
this
works
the
same
for
class
methods
the
implied
instance
object
simply
shows
up
in
the
first
argument
of
the
returned
callable
in
skeleton
terms
here
s
one
common
coding
pattern
that
captures
this
idea
the
decorator
returns
a
wrapper
that
retains
the
original
function
in
an
enclosing
scope
def
decorator
f
def
wrapper
args
use
f
and
args
f
args
calls
original
function
return
wrapper
on
decoration
on
wrapped
function
call
decorator
def
func
x
y
func
decorator
func
func
is
passed
to
decorator
s
f
func
are
passed
to
wrapper
s
args
when
the
name
func
is
later
called
it
really
invokes
the
wrapper
function
returned
by
decorator
the
wrapper
function
can
then
run
the
original
func
because
it
is
still
available
in
an
enclosing
scope
when
coded
this
way
each
decorated
function
produces
a
new
scope
to
retain
state
to
do
the
same
with
classes
we
can
overload
the
call
operation
and
use
instance
attributes
instead
of
enclosing
scopes
class
decorator
def
init
self
func
on
decoration
self
func
func
def
call
self
args
on
wrapped
function
call
use
self
func
and
args
self
func
args
calls
original
function
decorator
def
func
x
y
func
decorator
func
func
is
passed
to
init
func
are
passed
to
call
s
args
when
the
name
func
is
later
called
now
it
really
invokes
the
call
operator
overloading
method
of
the
instance
created
by
decorator
the
call
method
can
then
chapter
decorators
run
the
original
func
because
it
is
still
available
in
an
instance
attribute
when
coded
this
way
each
decorated
function
produces
a
new
instance
to
retain
state
supporting
method
decoration
one
subtle
point
about
the
prior
class
based
coding
is
that
while
it
works
to
intercept
simple
function
calls
it
does
not
quite
work
when
applied
to
class
method
functions
class
decorator
def
init
self
func
func
is
method
without
instance
self
func
func
def
call
self
args
self
is
decorator
instance
self
func
args
fails
c
instance
not
in
args
class
c
decorator
def
method
self
x
y
method
decorator
method
rebound
to
decorator
instance
when
coded
this
way
the
decorated
method
is
rebound
to
an
instance
of
the
decorator
class
instead
of
a
simple
function
the
problem
with
this
is
that
the
self
in
the
decorator
s
call
receives
the
decorator
class
instance
when
the
method
is
later
run
and
the
instance
of
class
c
is
never
included
in
args
this
makes
it
impossible
to
dispatch
the
call
to
the
original
method
the
decorator
object
retains
the
original
method
function
but
it
has
no
instance
to
pass
to
it
to
support
both
functions
and
methods
the
nested
function
alternative
works
better
def
decorator
f
def
wrapper
args
f
args
runs
func
or
method
return
wrapper
decorator
def
func
x
y
func
f
is
func
or
method
without
instance
class
instance
in
args
for
method
func
decorator
func
really
calls
wrapper
class
c
decorator
def
method
self
x
y
method
decorator
method
rebound
to
simple
function
x
c
x
method
really
calls
wrapper
x
when
coded
this
way
wrapper
receives
the
c
class
instance
in
its
first
argument
so
it
can
dispatch
to
the
original
method
and
access
state
information
technically
this
nested
function
version
works
because
python
creates
a
bound
method
object
and
thus
passes
the
subject
class
instance
to
the
self
argument
only
when
a
method
attribute
references
a
simple
function
when
it
references
an
instance
the
basics
of
a
callable
class
instead
the
callable
class
s
instance
is
passed
to
self
to
give
the
callable
class
access
to
its
own
state
information
we
ll
see
how
this
subtle
difference
can
matter
in
more
realistic
examples
later
in
this
chapter
also
note
that
nested
functions
are
perhaps
the
most
straightforward
way
to
support
decoration
of
both
functions
and
methods
but
not
necessarily
the
only
way
the
prior
chapter
s
descriptors
for
example
receive
both
the
descriptor
and
subject
class
instance
when
called
though
more
complex
later
in
this
chapter
we
ll
see
how
this
tool
can
be
leveraged
in
this
context
as
well
class
decorators
function
decorators
proved
so
useful
that
the
model
was
extended
to
allow
class
decoration
in
python
and
class
decorators
are
strongly
related
to
function
decorators
in
fact
they
use
the
same
syntax
and
very
similar
coding
patterns
rather
than
wrapping
individual
functions
or
methods
though
class
decorators
are
a
way
to
manage
classes
or
wrap
up
instance
construction
calls
with
extra
logic
that
manages
or
augments
instances
created
from
a
class
usage
syntactically
class
decorators
appear
just
before
class
statements
just
as
function
decorators
appear
just
before
function
definitions
in
symbolic
terms
assuming
that
decorator
is
a
one
argument
function
that
returns
a
callable
the
class
decorator
syntax
decorator
class
c
decorate
class
x
c
make
an
instance
is
equivalent
to
the
following
the
class
is
automatically
passed
to
the
decorator
function
and
the
decorator
s
result
is
assigned
back
to
the
class
name
class
c
c
decorator
c
rebind
class
name
to
decorator
result
x
c
essentially
calls
decorator
c
the
net
effect
is
that
calling
the
class
name
later
to
create
an
instance
winds
up
triggering
the
callable
returned
by
the
decorator
instead
of
calling
the
original
class
itself
implementation
new
class
decorators
are
coded
using
many
of
the
same
techniques
used
for
function
decorators
because
a
class
decorator
is
also
a
callable
that
returns
a
callable
most
combinations
of
functions
and
classes
suffice
chapter
decorators
however
it
s
coded
the
decorator
s
result
is
what
runs
when
an
instance
is
later
created
for
example
to
simply
manage
a
class
just
after
it
is
created
return
the
original
class
itself
def
decorator
c
process
class
c
return
c
decorator
class
c
c
decorator
c
to
instead
insert
a
wrapper
layer
that
intercepts
later
instance
creation
calls
return
a
different
callable
object
def
decorator
c
save
or
use
class
c
return
a
different
callable
nested
def
class
with
call
etc
decorator
class
c
c
decorator
c
the
callable
returned
by
such
a
class
decorator
typically
creates
and
returns
a
new
instance
of
the
original
class
augmented
in
some
way
to
manage
its
interface
for
example
the
following
inserts
an
object
that
intercepts
undefined
attributes
of
a
class
instance
def
decorator
cls
on
decoration
class
wrapper
def
init
self
args
on
instance
creation
self
wrapped
cls
args
def
getattr
self
name
on
attribute
fetch
return
getattr
self
wrapped
name
return
wrapper
decorator
class
c
def
init
self
x
y
self
attr
spam
c
decorator
c
run
by
wrapper
init
x
c
print
x
attr
really
calls
wrapper
runs
wrapper
getattr
prints
spam
in
this
example
the
decorator
rebinds
the
class
name
to
another
class
which
retains
the
original
class
in
an
enclosing
scope
and
creates
and
embeds
an
instance
of
the
original
class
when
it
s
called
when
an
attribute
is
later
fetched
from
the
instance
it
is
intercepted
by
the
wrapper
s
getattr
and
delegated
to
the
embedded
instance
of
the
original
class
moreover
each
decorated
class
creates
a
new
scope
which
remembers
the
original
class
we
ll
flesh
out
this
example
into
some
more
useful
code
later
in
this
chapter
the
basics
like
function
decorators
class
decorators
are
commonly
coded
as
either
factory
functions
that
create
and
return
callables
classes
that
use
init
or
call
methods
to
intercept
call
operations
or
some
combination
thereof
factory
functions
typically
retain
state
in
enclosing
scope
references
and
classes
in
attributes
supporting
multiple
instances
as
with
function
decorators
with
class
decorators
some
callable
type
combinations
work
better
than
others
consider
the
following
invalid
alternative
to
the
class
decorator
of
the
prior
example
class
decorator
def
init
self
c
on
decoration
self
c
c
def
call
self
args
on
instance
creation
self
wrapped
self
c
args
return
self
def
getattr
self
attrname
on
atrribute
fetch
return
getattr
self
wrapped
attrname
decorator
class
c
c
decorator
c
x
c
y
c
overwrites
x
this
code
handles
multiple
decorated
classes
each
makes
a
new
decorator
instance
and
will
intercept
instance
creation
calls
each
runs
call
unlike
the
prior
version
however
this
version
fails
to
handle
multiple
instances
of
a
given
class
each
instance
creation
call
overwrites
the
prior
saved
instance
the
original
version
does
support
multiple
instances
because
each
instance
creation
call
makes
a
new
independent
wrapper
object
more
generally
either
of
the
following
patterns
supports
multiple
wrapped
instances
def
decorator
c
class
wrapper
def
init
self
args
self
wrapped
c
args
return
wrapper
class
wrapper
def
decorator
c
def
oncall
args
return
wrapper
c
args
return
oncall
on
decoration
on
instance
creation
on
decoration
on
instance
creation
embed
instance
in
instance
we
ll
study
this
phenomenon
in
a
more
realistic
context
later
in
the
chapter
in
practice
though
we
must
be
careful
to
combine
callable
types
properly
to
support
our
intent
chapter
decorators
decorator
nesting
sometimes
one
decorator
isn
t
enough
to
support
multiple
steps
of
augmentation
decorator
syntax
allows
you
to
add
multiple
layers
of
wrapper
logic
to
a
decorated
function
or
method
when
this
feature
is
used
each
decorator
must
appear
on
a
line
of
its
own
decorator
syntax
of
this
form
a
b
c
def
f
runs
the
same
as
the
following
def
f
f
a
b
c
f
here
the
original
function
is
passed
through
three
different
decorators
and
the
resulting
callable
object
is
assigned
back
to
the
original
name
each
decorator
processes
the
result
of
the
prior
which
may
be
the
original
function
or
an
inserted
wrapper
if
all
the
decorators
insert
wrappers
the
net
effect
is
that
when
the
original
function
name
is
called
three
different
layers
of
wrapping
object
logic
will
be
invoked
to
augment
the
original
function
in
three
different
ways
the
last
decorator
listed
is
the
first
applied
and
the
most
deeply
nested
insert
joke
about
interior
decorators
here
just
as
for
functions
multiple
class
decorators
result
in
multiple
nested
function
calls
and
possibly
multiple
levels
of
wrapper
logic
around
instance
creation
calls
for
example
the
following
code
spam
eggs
class
c
x
c
is
equivalent
to
the
following
class
c
c
spam
eggs
c
x
c
again
each
decorator
is
free
to
return
either
the
original
class
or
an
inserted
wrapper
object
with
wrappers
when
an
instance
of
the
original
c
class
is
finally
requested
the
call
is
redirected
to
the
wrapping
layer
objects
provided
by
both
the
spam
and
eggs
decorators
which
may
have
arbitrarily
different
roles
the
basics
for
example
the
following
do
nothing
decorators
simply
return
the
decorated
function
def
d
f
return
f
def
d
f
return
f
def
d
f
return
f
d
d
d
def
func
print
spam
func
func
d
d
d
func
prints
spam
the
same
syntax
works
on
classes
as
do
these
same
do
nothing
decorators
when
decorators
insert
wrapper
function
objects
though
they
may
augment
the
original
function
when
called
the
following
concatenates
to
its
result
in
the
decorator
layers
as
it
runs
the
layers
from
inner
to
outer
def
d
f
return
lambda
x
f
def
d
f
return
lambda
y
f
def
d
f
return
lambda
z
f
d
d
d
def
func
return
spam
print
func
func
d
d
d
func
prints
xyzspam
we
use
lambda
functions
to
implement
wrapper
layers
here
each
retains
the
wrapped
function
in
an
enclosing
scope
in
practice
wrappers
can
take
the
form
of
functions
callable
classes
and
more
when
designed
well
decorator
nesting
allows
us
to
combine
augmentation
steps
in
a
wide
variety
of
ways
decorator
arguments
both
function
and
class
decorators
can
also
seem
to
take
arguments
although
really
these
arguments
are
passed
to
a
callable
that
in
effect
returns
the
decorator
which
in
turn
returns
a
callable
the
following
for
instance
decorator
a
b
def
f
arg
f
is
automatically
mapped
into
this
equivalent
form
where
decorator
is
a
callable
that
returns
the
actual
decorator
the
returned
decorator
in
turn
returns
the
callable
run
later
for
calls
to
the
original
function
name
chapter
decorators
def
f
arg
f
decorator
a
b
f
rebind
f
to
result
of
decorator
s
return
value
f
essentially
calls
decorator
a
b
f
decorator
arguments
are
resolved
before
decoration
ever
occurs
and
they
are
usually
used
to
retain
state
information
for
use
in
later
calls
the
decorator
function
in
this
example
for
instance
might
take
a
form
like
the
following
def
decorator
a
b
save
or
use
a
b
def
actualdecorator
f
save
or
use
function
f
return
a
callable
nested
def
class
with
call
etc
return
callable
return
actualdecorator
the
outer
function
in
this
structure
generally
saves
the
decorator
arguments
away
as
state
information
for
use
in
the
actual
decorator
the
callable
it
returns
or
both
this
code
snippet
retains
the
state
information
argument
in
enclosing
function
scope
references
but
class
attributes
are
commonly
used
as
well
in
other
words
decorator
arguments
often
imply
three
levels
of
callables
a
callable
to
accept
decorator
arguments
which
returns
a
callable
to
serve
as
decorator
which
returns
a
callable
to
handle
calls
to
the
original
function
or
class
each
of
the
three
levels
may
be
a
function
or
class
and
may
retain
state
in
the
form
of
scopes
or
class
attributes
we
ll
see
concrete
examples
of
decorator
arguments
employed
later
in
this
chapter
decorators
manage
functions
and
classes
too
although
much
of
the
rest
of
this
chapter
focuses
on
wrapping
later
calls
to
functions
and
classes
i
should
underscore
that
the
decorator
mechanism
is
more
general
than
this
it
is
a
protocol
for
passing
functions
and
classes
through
a
callable
immediately
after
they
are
created
as
such
it
can
also
be
used
to
invoke
arbitrary
post
creation
processing
def
decorate
o
save
or
augment
function
or
class
o
return
o
decorator
def
f
f
decorator
f
decorator
class
c
c
decorator
c
as
long
as
we
return
the
original
decorated
object
this
way
instead
of
a
wrapper
we
can
manage
functions
and
classes
themselves
not
just
later
calls
to
them
we
ll
see
more
realistic
examples
later
in
this
chapter
that
use
this
idea
to
register
callable
objects
to
an
api
with
decoration
and
assign
attributes
to
functions
when
they
are
created
the
basics
coding
function
decorators
on
to
the
code
in
the
rest
of
this
chapter
we
are
going
to
study
working
examples
that
demonstrate
the
decorator
concepts
we
just
explored
this
section
presents
a
handful
of
function
decorators
at
work
and
the
next
shows
class
decorators
in
action
following
that
we
ll
close
out
with
some
larger
case
studies
of
class
and
function
decorator
usage
tracing
calls
to
get
started
let
s
revive
the
call
tracer
example
we
met
in
chapter
the
following
defines
and
applies
a
function
decorator
that
counts
the
number
of
calls
made
to
the
decorated
function
and
prints
a
trace
message
for
each
call
class
tracer
def
init
self
func
on
decoration
save
original
func
self
calls
self
func
func
def
call
self
args
on
later
calls
run
original
func
self
calls
print
call
s
to
s
self
calls
self
func
name
self
func
args
tracer
def
spam
a
b
c
print
a
b
c
spam
tracer
spam
wraps
spam
in
a
decorator
object
notice
how
each
function
decorated
with
this
class
will
create
a
new
instance
with
its
own
saved
function
object
and
calls
counter
also
observe
how
the
args
argument
syntax
is
used
to
pack
and
unpack
arbitrarily
many
passed
in
arguments
this
generality
enables
this
decorator
to
be
used
to
wrap
any
function
with
any
number
of
arguments
this
version
doesn
t
yet
work
on
class
methods
but
we
ll
fix
that
later
in
this
section
now
if
we
import
this
module
s
function
and
test
it
interactively
we
get
the
following
sort
of
behavior
each
call
generates
a
trace
message
initially
because
the
decorator
class
intercepts
it
this
code
runs
under
both
python
and
as
does
all
code
in
this
chapter
unless
otherwise
noted
from
decorator
import
spam
spam
call
to
spam
really
calls
the
tracer
wrapper
object
spam
a
b
c
call
to
spam
abc
invokes
call
in
class
spam
calls
number
calls
in
wrapper
state
information
chapter
decorators
spam
decorator
tracer
object
at
x
d
a
when
run
the
tracer
class
saves
away
the
decorated
function
and
intercepts
later
calls
to
it
in
order
to
add
a
layer
of
logic
that
counts
and
prints
each
call
notice
how
the
total
number
of
calls
shows
up
as
an
attribute
of
the
decorated
function
spam
is
really
an
instance
of
the
tracer
class
when
decorated
a
finding
that
may
have
ramifications
for
programs
that
do
type
checking
but
is
generally
benign
for
function
calls
the
decoration
syntax
can
be
more
convenient
than
modifying
each
call
to
account
for
the
extra
logic
level
and
it
avoids
accidentally
calling
the
original
function
directly
consider
a
nondecorator
equivalent
such
as
the
following
calls
def
tracer
func
args
global
calls
calls
print
call
s
to
s
calls
func
name
func
args
def
spam
a
b
c
print
a
b
c
spam
normal
non
traced
call
accidental
tracer
spam
call
to
spam
special
traced
call
without
decorators
this
alternative
can
be
used
on
any
function
without
the
special
syntax
but
unlike
the
decorator
version
it
requires
extra
syntax
at
every
place
where
the
function
is
called
in
your
code
furthermore
its
intent
may
not
be
as
obvious
and
it
does
not
ensure
that
the
extra
layer
will
be
invoked
for
normal
calls
although
decorators
are
never
required
we
can
always
rebind
names
manually
they
are
often
the
most
convenient
option
state
information
retention
options
the
last
example
of
the
prior
section
raises
an
important
issue
function
decorators
have
a
variety
of
options
for
retaining
state
information
provided
at
decoration
time
for
use
during
the
actual
function
call
they
generally
need
to
support
multiple
decorated
objects
and
multiple
calls
but
there
are
a
number
of
ways
to
implement
these
goals
instance
attributes
global
variables
nonlocal
variables
and
function
attributes
can
all
be
used
for
retaining
state
coding
function
decorators
class
instance
attributes
for
example
here
is
an
augmented
version
of
the
prior
example
which
adds
support
for
keyword
arguments
and
returns
the
wrapped
function
s
result
to
support
more
use
cases
class
tracer
def
init
self
func
self
calls
self
func
func
def
call
self
args
kwargs
self
calls
print
call
s
to
s
self
calls
return
self
func
args
kwargs
state
via
instance
attributes
on
decorator
save
func
for
later
call
on
call
to
original
function
self
func
name
tracer
def
spam
a
b
c
print
a
b
c
same
as
spam
tracer
spam
triggers
tracer
init
tracer
def
eggs
x
y
print
x
y
same
as
eggs
tracer
eggs
wraps
eggs
in
a
tracer
object
spam
spam
a
b
c
really
calls
tracer
instance
runs
tracer
call
spam
is
an
instance
attribute
eggs
eggs
y
really
calls
tracer
instance
self
func
is
eggs
self
calls
is
per
function
here
need
nonlocal
like
the
original
this
uses
class
instance
attributes
to
save
state
explicitly
both
the
wrapped
function
and
the
calls
counter
are
per
instance
information
each
decoration
gets
its
own
copy
when
run
as
a
script
under
either
or
the
output
of
this
version
is
as
follows
notice
how
the
spam
and
eggs
functions
each
have
their
own
calls
counter
because
each
decoration
creates
a
new
class
instance
call
call
call
call
to
spam
to
spam
to
eggs
to
eggs
while
useful
for
decorating
functions
this
coding
scheme
has
issues
when
applied
to
methods
more
on
this
later
enclosing
scopes
and
globals
enclosing
def
scope
references
and
nested
defs
can
often
achieve
the
same
effect
especially
for
static
data
like
the
decorated
original
function
in
this
example
though
we
would
also
need
a
counter
in
the
enclosing
scope
that
changes
on
each
call
and
that
s
chapter
decorators
not
possible
in
python
in
we
can
either
use
classes
and
attributes
as
we
did
earlier
or
move
the
state
variable
out
to
the
global
scope
with
global
declarations
calls
def
tracer
func
state
via
enclosing
scope
and
global
def
wrapper
args
kwargs
instead
of
class
attributes
global
calls
calls
is
global
not
per
function
calls
print
call
s
to
s
calls
func
name
return
func
args
kwargs
return
wrapper
tracer
def
spam
a
b
c
print
a
b
c
same
as
spam
tracer
spam
tracer
def
eggs
x
y
print
x
y
same
as
eggs
tracer
eggs
spam
spam
a
b
c
really
calls
wrapper
bound
to
func
wrapper
calls
spam
eggs
eggs
y
really
calls
wrapper
bound
to
eggs
global
calls
is
not
per
function
here
unfortunately
moving
the
counter
out
to
the
common
global
scope
to
allow
it
to
be
changed
like
this
also
means
that
it
will
be
shared
by
every
wrapped
function
unlike
class
instance
attributes
global
counters
are
cross
program
not
per
function
the
counter
is
incremented
for
any
traced
function
call
you
can
tell
the
difference
if
you
compare
this
version
s
output
with
the
prior
version
s
the
single
shared
global
call
counter
is
incorrectly
updated
by
calls
to
every
decorated
function
call
call
call
call
to
spam
to
spam
to
eggs
to
eggs
enclosing
scopes
and
nonlocals
shared
global
state
may
be
what
we
want
in
some
cases
if
we
really
want
a
per
function
counter
though
we
can
either
use
classes
as
before
or
make
use
of
the
new
nonlocal
statement
in
python
described
in
chapter
because
this
new
statement
allows
enclosing
function
scope
variables
to
be
changed
they
can
serve
as
per
decoration
and
changeable
data
def
tracer
func
calls
def
wrapper
args
kwargs
state
via
enclosing
scope
and
nonlocal
instead
of
class
attrs
or
global
calls
is
per
function
not
global
coding
function
decorators
nonlocal
calls
calls
print
call
s
to
s
calls
func
name
return
func
args
kwargs
return
wrapper
tracer
def
spam
a
b
c
print
a
b
c
same
as
spam
tracer
spam
tracer
def
eggs
x
y
print
x
y
same
as
eggs
tracer
eggs
spam
spam
a
b
c
really
calls
wrapper
bound
to
func
wrapper
calls
spam
eggs
eggs
y
really
calls
wrapper
bound
to
eggs
nonlocal
calls
is
not
per
function
here
now
because
enclosing
scope
variables
are
not
cross
program
globals
each
wrapped
function
gets
its
own
counter
again
just
as
for
classes
and
attributes
here
s
the
new
output
when
run
under
call
call
call
call
to
spam
to
spam
to
eggs
to
eggs
function
attributes
finally
if
you
are
not
using
python
x
and
don
t
have
a
nonlocal
statement
you
may
still
be
able
to
avoid
globals
and
classes
by
making
use
of
function
attributes
for
some
changeable
state
instead
in
recent
pythons
we
can
assign
arbitrary
attributes
to
functions
to
attach
them
with
func
attr
value
in
our
example
we
can
simply
use
wrapper
calls
for
state
the
following
works
the
same
as
the
preceding
nonlocal
version
because
the
counter
is
again
per
decorated
function
but
it
also
runs
in
python
def
tracer
func
state
via
enclosing
scope
and
func
attr
def
wrapper
args
kwargs
calls
is
per
function
not
global
wrapper
calls
print
call
s
to
s
wrapper
calls
func
name
return
func
args
kwargs
wrapper
calls
return
wrapper
notice
that
this
only
works
because
the
name
wrapper
is
retained
in
the
enclosing
tracer
function
s
scope
when
we
later
increment
wrapper
calls
we
are
not
changing
the
name
wrapper
itself
so
no
nonlocal
declaration
is
required
chapter
decorators
this
scheme
was
almost
relegated
to
a
footnote
because
it
is
more
obscure
than
nonlocal
in
and
is
probably
better
saved
for
cases
where
other
schemes
don
t
help
however
we
will
employ
it
in
an
answer
to
one
of
the
end
of
chapter
questions
where
we
ll
need
to
access
the
saved
state
from
outside
the
decorator
s
code
nonlocals
can
only
be
seen
inside
the
nested
function
itself
but
function
attributes
have
wider
visibility
because
decorators
often
imply
multiple
levels
of
callables
you
can
combine
functions
with
enclosing
scopes
and
classes
with
attributes
to
achieve
a
variety
of
coding
structures
as
we
ll
see
later
though
this
sometimes
may
be
subtler
than
you
expect
each
decorated
function
should
have
its
own
state
and
each
decorated
class
may
require
state
both
for
itself
and
for
each
generated
instance
in
fact
as
the
next
section
will
explain
if
we
want
to
apply
function
decorators
to
class
methods
too
we
also
have
to
be
careful
about
the
distinction
python
makes
between
decorators
coded
as
callable
class
instance
objects
and
decorators
coded
as
functions
class
blunders
i
decorating
class
methods
when
i
wrote
the
first
tracer
function
decorator
above
i
naively
assumed
that
it
could
also
be
applied
to
any
method
decorated
methods
should
work
the
same
but
the
automatic
self
instance
argument
would
simply
be
included
at
the
front
of
args
unfortunately
i
was
wrong
when
applied
to
a
class
s
method
the
first
version
of
the
tracer
fails
because
self
is
the
instance
of
the
decorator
class
and
the
instance
of
the
decorated
subject
class
in
not
included
in
args
this
is
true
in
both
python
and
i
introduced
this
phenomenon
earlier
in
this
chapter
but
now
we
can
see
it
in
the
context
of
realistic
working
code
given
the
class
based
tracing
decorator
class
tracer
def
init
self
func
self
calls
self
func
func
def
call
self
args
kwargs
self
calls
print
call
s
to
s
self
calls
return
self
func
args
kwargs
on
decorator
save
func
for
later
call
on
call
to
original
function
self
func
name
decoration
of
simple
functions
works
as
advertised
earlier
tracer
def
spam
a
b
c
print
a
b
c
spam
tracer
spam
triggers
tracer
init
spam
spam
a
b
c
runs
tracer
call
spam
is
an
instance
attribute
coding
function
decorators
however
decoration
of
class
methods
fails
more
lucid
readers
might
recognize
this
as
our
person
class
resurrected
from
the
object
oriented
tutorial
in
chapter
class
person
def
init
self
name
pay
self
name
name
self
pay
pay
tracer
def
giveraise
self
percent
self
pay
percent
giveraise
tracer
giverraise
tracer
def
lastname
self
return
self
name
split
lastname
tracer
lastname
bob
person
bob
smith
bob
giveraise
print
bob
lastname
tracer
remembers
method
funcs
runs
tracer
call
runs
tracer
call
the
root
of
the
problem
here
is
in
the
self
argument
of
the
tracer
class
s
call
method
is
it
a
tracer
instance
or
a
person
instance
we
really
need
both
as
it
s
coded
the
tracer
for
decorator
state
and
the
person
for
routing
on
to
the
original
method
really
self
must
be
the
tracer
object
to
provide
access
to
tracer
s
state
information
this
is
true
whether
decorating
a
simple
function
or
a
method
unfortunately
when
our
decorated
method
name
is
rebound
to
a
class
instance
object
with
a
call
python
passes
only
the
tracer
instance
to
self
it
doesn
t
pass
along
the
person
subject
in
the
arguments
list
at
all
moreover
because
the
tracer
knows
nothing
about
the
person
instance
we
are
trying
to
process
with
method
calls
there
s
no
way
to
create
a
bound
method
with
an
instance
and
thus
no
way
to
correctly
dispatch
the
call
in
fact
the
prior
listing
winds
up
passing
too
few
arguments
to
the
decorated
method
and
results
in
an
error
add
a
line
to
the
decorator
s
call
to
print
all
its
arguments
to
verify
this
as
you
can
see
self
is
the
tracer
and
the
person
instance
is
entirely
absent
main
tracer
object
at
x
d
ad
call
to
giveraise
traceback
most
recent
call
last
file
c
misc
tracer
py
line
in
module
bob
giveraise
file
c
misc
tracer
py
line
in
call
return
self
func
args
kwargs
typeerror
giveraise
takes
exactly
positional
arguments
given
as
mentioned
earlier
this
happens
because
python
passes
the
implied
subject
instance
to
self
when
a
method
name
is
bound
to
a
simple
function
only
when
it
is
an
instance
of
a
callable
class
that
class
s
instance
is
passed
instead
technically
python
only
makes
a
bound
method
object
containing
the
subject
instance
when
the
method
is
a
simple
function
chapter
decorators
using
nested
functions
to
decorate
methods
if
you
want
your
function
decorators
to
work
on
both
simple
functions
and
class
methods
the
most
straightforward
solution
lies
in
using
one
of
the
other
state
retention
solutions
described
earlier
code
your
function
decorator
as
nested
defs
so
that
you
don
t
depend
on
a
single
self
instance
argument
to
be
both
the
wrapper
class
instance
and
the
subject
class
instance
the
following
alternative
applies
this
fix
using
python
nonlocals
because
decorated
methods
are
rebound
to
simple
functions
instead
of
instance
objects
python
correctly
passes
the
person
object
as
the
first
argument
and
the
decorator
propagates
it
on
in
the
first
item
of
args
to
the
self
argument
of
the
real
decorated
methods
a
decorator
for
both
functions
and
methods
def
tracer
func
use
function
not
class
with
call
calls
else
self
is
decorator
instance
only
def
oncall
args
kwargs
nonlocal
calls
calls
print
call
s
to
s
calls
func
name
return
func
args
kwargs
return
oncall
applies
to
simple
functions
tracer
def
spam
a
b
c
print
a
b
c
spam
spam
a
b
c
spam
tracer
spam
oncall
remembers
spam
runs
oncall
applies
to
class
method
functions
too
class
person
def
init
self
name
pay
self
name
name
self
pay
pay
tracer
def
giveraise
self
percent
self
pay
percent
tracer
def
lastname
self
return
self
name
split
giveraise
tracer
giverraise
oncall
remembers
giveraise
lastname
tracer
lastname
print
methods
bob
person
bob
smith
sue
person
sue
jones
print
bob
name
sue
name
coding
function
decorators
sue
giveraise
print
sue
pay
print
bob
lastname
sue
lastname
runs
oncall
sue
runs
oncall
bob
lastname
in
scopes
this
version
works
the
same
on
both
functions
and
methods
call
to
spam
call
to
spam
methods
bob
smith
sue
jones
call
to
giveraise
call
to
lastname
call
to
lastname
smith
jones
using
descriptors
to
decorate
methods
although
the
nested
function
solution
illustrated
in
the
prior
section
is
the
most
straightforward
way
to
support
decorators
that
apply
to
both
functions
and
class
methods
other
schemes
are
possible
the
descriptor
feature
we
explored
in
the
prior
chapter
for
example
can
help
here
as
well
recall
from
our
discussion
in
that
chapter
that
a
descriptor
may
be
a
class
attribute
assigned
to
objects
with
a
get
method
run
automatically
when
that
attribute
is
referenced
and
fetched
object
derivation
is
required
in
python
but
not
class
descriptor
object
def
get
self
instance
owner
class
subject
attr
descriptor
x
subject
x
attr
roughly
runs
descriptor
get
subject
attr
x
subject
descriptors
may
also
have
set
and
del
access
methods
but
we
don
t
need
them
here
now
because
the
descriptor
s
get
method
receives
both
the
descriptor
class
and
subject
class
instances
when
invoked
it
s
well
suited
to
decorating
methods
when
we
need
both
the
decorator
s
state
and
the
original
class
instance
for
dispatching
calls
consider
the
following
alternative
tracing
decorator
which
is
also
a
descriptor
class
tracer
object
def
init
self
func
self
calls
self
func
func
def
call
self
args
kwargs
self
calls
print
call
s
to
s
self
calls
return
self
func
args
kwargs
def
get
self
instance
owner
return
wrapper
self
instance
chapter
decorators
on
decorator
save
func
for
later
call
on
call
to
original
func
self
func
name
on
method
attribute
fetch
class
wrapper
def
init
self
desc
subj
save
both
instances
self
desc
desc
route
calls
back
to
decr
self
subj
subj
def
call
self
args
kwargs
return
self
desc
self
subj
args
kwargs
runs
tracer
call
tracer
def
spam
a
b
c
same
as
prior
spam
tracer
spam
uses
call
only
class
person
tracer
def
giveraise
self
percent
same
as
prior
giveraise
tracer
giverraise
makes
giveraise
a
descriptor
this
works
the
same
as
the
preceding
nested
function
coding
decorated
functions
invoke
only
its
call
while
decorated
methods
invoke
its
get
first
to
resolve
the
method
name
fetch
on
instance
method
the
object
returned
by
get
retains
the
subject
class
instance
and
is
then
invoked
to
complete
the
call
expression
thereby
triggering
call
on
args
for
example
the
test
code
s
call
to
sue
giveraise
runs
get
then
call
run
s
tracer
get
first
because
the
giveraise
attribute
in
the
person
class
has
been
rebound
to
a
descriptor
by
the
function
decorator
the
call
expression
then
triggers
the
call
method
of
the
returned
wrapper
object
which
in
turn
invokes
tracer
call
the
wrapper
object
retains
both
descriptor
and
subject
instances
so
it
can
route
control
back
to
the
original
decorator
descriptor
class
instance
in
effect
the
wrapper
object
saves
the
subject
class
instance
available
during
method
attribute
fetch
and
adds
it
to
the
later
call
s
arguments
list
which
is
passed
to
call
routing
the
call
back
to
the
descriptor
class
instance
this
way
is
required
in
this
application
so
that
all
calls
to
a
wrapped
method
use
the
same
calls
counter
state
information
in
the
descriptor
instance
object
alternatively
we
could
use
a
nested
function
and
enclosing
scope
references
to
achieve
the
same
effect
the
following
version
works
the
same
as
the
preceding
one
by
swapping
a
class
and
object
attributes
for
a
nested
function
and
scope
references
but
it
requires
noticeably
less
code
class
tracer
object
def
init
self
func
self
calls
self
func
func
def
call
self
args
kwargs
self
calls
print
call
s
to
s
self
calls
return
self
func
args
kwargs
def
get
self
instance
owner
def
wrapper
args
kwargs
on
decorator
save
func
for
later
call
on
call
to
original
func
self
func
name
on
method
fetch
retain
both
inst
coding
function
decorators
return
self
instance
args
kwargs
return
wrapper
runs
call
add
print
statements
to
these
alternatives
methods
to
trace
the
two
step
get
call
process
on
your
own
and
run
them
with
the
same
test
code
as
in
the
nested
function
alternative
shown
earlier
in
either
coding
this
descriptor
based
scheme
is
also
substantially
subtler
than
the
nested
function
option
and
so
is
probably
a
second
choice
here
it
may
be
a
useful
coding
pattern
in
other
contexts
though
in
the
rest
of
this
chapter
we
re
going
to
be
fairly
casual
about
using
classes
or
functions
to
code
our
function
decorators
as
long
as
they
are
applied
only
to
functions
some
decorators
may
not
require
the
instance
of
the
original
class
and
will
still
work
on
both
functions
and
methods
if
coded
as
a
class
something
like
python
s
own
staticmethod
decorator
for
example
wouldn
t
require
an
instance
of
the
subject
class
indeed
its
whole
point
is
to
remove
the
instance
from
the
call
the
moral
of
this
story
though
is
that
if
you
want
your
decorators
to
work
on
both
simple
functions
and
class
methods
you
re
better
off
using
the
nested
function
based
coding
pattern
outlined
here
instead
of
a
class
with
call
interception
timing
calls
to
sample
the
fuller
flavor
of
what
function
decorators
are
capable
of
let
s
turn
to
a
different
use
case
our
next
decorator
times
calls
made
to
a
decorated
function
both
the
time
for
one
call
and
the
total
time
among
all
calls
the
decorator
is
applied
to
two
functions
in
order
to
compare
the
time
requirements
of
list
comprehensions
and
the
map
built
in
call
for
comparison
also
see
chapter
for
another
nondecorator
example
that
times
iteration
alternatives
like
these
import
time
class
timer
def
init
self
func
self
func
func
self
alltime
def
call
self
args
kargs
start
time
clock
result
self
func
args
kargs
elapsed
time
clock
start
self
alltime
elapsed
print
s
f
f
self
func
name
elapsed
self
alltime
return
result
timer
def
listcomp
n
return
x
for
x
in
range
n
timer
def
mapcall
n
return
map
lambda
x
x
range
n
chapter
decorators
result
listcomp
time
for
this
call
all
calls
return
value
listcomp
listcomp
listcomp
print
result
print
alltime
s
listcomp
alltime
total
time
for
all
listcomp
calls
print
result
mapcall
mapcall
mapcall
mapcall
print
result
print
alltime
s
mapcall
alltime
total
time
for
all
mapcall
calls
print
map
comp
s
round
mapcall
alltime
listcomp
alltime
in
this
case
a
nondecorator
approach
would
allow
the
subject
functions
to
be
used
with
or
without
timing
but
it
would
also
complicate
the
call
signature
when
timing
is
desired
we
d
need
to
add
code
at
every
call
instead
of
once
at
the
def
and
there
would
be
no
direct
way
to
guarantee
that
all
list
builder
calls
in
a
program
are
routed
through
timer
logic
short
of
finding
and
potentially
changing
them
all
when
run
in
python
the
output
of
this
file
s
self
test
code
is
as
follows
listcomp
listcomp
listcomp
listcomp
alltime
mapcall
mapcall
mapcall
mapcall
alltime
map
comp
testing
subtlety
i
didn
t
run
this
under
python
because
as
described
in
chapter
the
map
built
in
returns
an
iterator
in
instead
of
an
actual
list
as
in
hence
s
map
doesn
t
quite
compare
directly
to
a
list
comprehension
s
work
as
is
the
map
test
takes
virtually
no
time
at
all
in
if
you
wish
to
run
this
under
too
use
list
map
to
force
it
to
build
a
list
like
the
list
comprehension
does
or
else
you
re
not
really
comparing
apples
to
apples
don
t
do
so
in
though
if
you
do
the
map
test
will
be
charged
for
building
two
lists
not
one
the
following
sort
of
code
would
pick
fairly
for
and
note
though
that
while
this
makes
the
comparison
between
list
comprehensions
and
map
more
fair
in
either
coding
function
decorators
or
because
range
is
also
an
iterator
in
the
results
for
and
won
t
compare
directly
import
sys
timer
def
listcomp
n
return
x
for
x
in
range
n
if
sys
version
info
timer
def
mapcall
n
return
map
lambda
x
x
range
n
else
timer
def
mapcall
n
return
list
map
lambda
x
x
range
n
finally
as
we
learned
in
the
modules
part
of
this
book
if
you
want
to
be
able
to
reuse
this
decorator
in
other
modules
you
should
indent
the
self
test
code
at
the
bottom
of
the
file
under
a
name
main
test
so
it
runs
only
when
the
file
is
run
not
when
it
s
imported
we
won
t
do
this
though
because
we
re
about
to
add
another
feature
to
our
code
adding
decorator
arguments
the
timer
decorator
of
the
prior
section
works
but
it
would
be
nice
if
it
was
more
configurable
providing
an
output
label
and
turning
trace
messages
on
and
off
for
instance
might
be
useful
in
a
general
purpose
tool
like
this
decorator
arguments
come
in
handy
here
when
they
re
coded
properly
we
can
use
them
to
specify
configuration
options
that
can
vary
for
each
decorated
function
a
label
for
instance
might
be
added
as
follows
def
timer
label
def
decorator
func
def
oncall
args
print
label
return
oncall
return
decorator
args
passed
to
function
func
retained
in
enclosing
scope
label
retained
in
enclosing
scope
timer
def
listcomp
n
like
listcomp
timer
listcomp
listcomp
is
rebound
to
decorator
listcomp
really
calls
decorator
returns
that
actual
decorator
this
code
adds
an
enclosing
scope
to
retain
a
decorator
argument
for
use
on
a
later
actual
call
when
the
listcomp
function
is
defined
it
really
invokes
decorator
the
result
of
timer
run
before
decoration
actually
occurs
with
the
label
value
available
in
its
enclosing
scope
that
is
timer
returns
the
decorator
which
remembers
both
the
chapter
decorators
decorator
argument
and
the
original
function
and
returns
a
callable
which
invokes
the
original
function
on
later
calls
we
can
put
this
structure
to
use
in
our
timer
to
allow
a
label
and
a
trace
control
flag
to
be
passed
in
at
decoration
time
here
s
an
example
that
does
just
that
coded
in
a
module
file
named
mytools
py
so
it
can
be
imported
as
a
general
tool
import
time
def
timer
label
trace
true
on
decorator
args
retain
args
class
timer
def
init
self
func
on
retain
decorated
func
self
func
func
self
alltime
def
call
self
args
kargs
on
calls
call
original
start
time
clock
result
self
func
args
kargs
elapsed
time
clock
start
self
alltime
elapsed
if
trace
format
s
s
f
f
values
label
self
func
name
elapsed
self
alltime
print
format
values
return
result
return
timer
mostly
all
we
ve
done
here
is
embed
the
original
timer
class
in
an
enclosing
function
in
order
to
create
a
scope
that
retains
the
decorator
arguments
the
outer
timer
function
is
called
before
decoration
occurs
and
it
simply
returns
the
timer
class
to
serve
as
the
actual
decorator
on
decoration
an
instance
of
timer
is
made
that
remembers
the
decorated
function
itself
but
also
has
access
to
the
decorator
arguments
in
the
enclosing
function
scope
this
time
rather
than
embedding
self
test
code
in
this
file
we
ll
run
the
decorator
in
a
different
file
here
s
a
client
of
our
timer
decorator
the
module
file
testseqs
py
applying
it
to
sequence
iteration
alternatives
again
from
mytools
import
timer
timer
label
ccc
def
listcomp
n
return
x
for
x
in
range
n
like
listcomp
timer
listcomp
listcomp
triggers
timer
call
timer
trace
true
label
mmm
def
mapcall
n
return
map
lambda
x
x
range
n
for
func
in
listcomp
mapcall
print
result
func
time
for
this
call
all
calls
return
value
func
func
func
print
result
coding
function
decorators
print
alltime
s
func
alltime
total
time
for
all
calls
print
map
comp
s
round
mapcall
alltime
listcomp
alltime
again
if
you
wish
to
run
this
fairly
in
wrap
the
map
function
in
a
list
call
when
run
as
is
in
this
file
prints
the
following
output
each
decorated
function
now
has
a
label
of
its
own
defined
by
decorator
arguments
ccc
listcomp
ccc
listcomp
ccc
listcomp
ccc
listcomp
alltime
mmm
mapcall
mmm
mapcall
mmm
mapcall
mmm
mapcall
alltime
map
comp
as
usual
we
can
also
test
this
interactively
to
see
how
the
configuration
arguments
come
into
play
from
mytools
import
timer
timer
trace
false
def
listcomp
n
return
x
for
x
in
range
n
x
listcomp
x
listcomp
x
listcomp
listcomp
mytools
timer
instance
at
x
c
b
listcomp
alltime
timer
trace
true
label
t
def
listcomp
n
return
x
for
x
in
range
n
x
listcomp
listcomp
x
listcomp
listcomp
x
listcomp
listcomp
listcomp
alltime
no
tracing
collect
total
time
turn
on
tracing
this
timing
function
decorator
can
be
used
for
any
function
both
in
modules
and
interactively
in
other
words
it
automatically
qualifies
as
a
general
purpose
tool
for
timing
code
in
our
scripts
watch
for
another
example
of
decorator
arguments
in
the
chapter
decorators
section
implementing
private
attributes
on
page
and
again
in
a
basic
rangetesting
decorator
for
positional
arguments
on
page
timing
methods
this
section
s
timer
decorator
works
on
any
function
but
a
minor
rewrite
is
required
to
be
able
to
apply
it
to
class
methods
too
in
short
as
our
earlier
section
class
blunders
i
decorating
class
methods
on
page
illustrated
it
must
avoid
using
a
nested
class
because
this
mutation
will
be
a
subject
of
one
of
our
end
of
chapter
quiz
questions
though
i
ll
avoid
giving
away
the
answer
completely
here
coding
class
decorators
so
far
we
ve
been
coding
function
decorators
to
manage
function
calls
but
as
we
ve
seen
python
and
extend
decorators
to
work
on
classes
too
as
described
earlier
while
similar
in
concept
to
function
decorators
class
decorators
are
applied
to
classes
instead
they
may
be
used
either
to
manage
classes
themselves
or
to
intercept
instance
creation
calls
in
order
to
manage
instances
also
like
function
decorators
class
decorators
are
really
just
optional
syntactic
sugar
though
many
believe
that
they
make
a
programmer
s
intent
more
obvious
and
minimize
erroneous
calls
singleton
classes
because
class
decorators
may
intercept
instance
creation
calls
they
can
be
used
to
either
manage
all
the
instances
of
a
class
or
augment
the
interfaces
of
those
instances
to
demonstrate
here
s
a
first
class
decorator
example
that
does
the
former
managing
all
instances
of
a
class
this
code
implements
the
classic
singleton
coding
pattern
where
at
most
one
instance
of
a
class
ever
exists
its
singleton
function
defines
and
returns
a
function
for
managing
instances
and
the
syntax
automatically
wraps
up
a
subject
class
in
this
function
instances
def
getinstance
aclass
args
if
aclass
not
in
instances
instances
aclass
aclass
args
return
instances
aclass
def
singleton
aclass
def
oncall
args
return
getinstance
aclass
args
return
oncall
manage
global
table
add
kargs
for
keywords
one
dict
entry
per
class
on
decoration
on
instance
creation
to
use
this
decorate
the
classes
for
which
you
want
to
enforce
a
single
instance
model
singleton
class
person
def
init
self
name
hours
rate
self
name
name
self
hours
hours
person
singleton
person
rebinds
person
to
oncall
oncall
remembers
person
coding
class
decorators
self
rate
rate
def
pay
self
return
self
hours
self
rate
singleton
class
spam
def
init
self
val
self
attr
val
spam
singleton
spam
rebinds
spam
to
oncall
oncall
remembers
spam
bob
person
bob
print
bob
name
bob
pay
really
calls
oncall
sue
person
sue
print
sue
name
sue
pay
same
single
object
x
spam
y
spam
print
x
attr
y
attr
one
person
one
spam
now
when
the
person
or
spam
class
is
later
used
to
create
an
instance
the
wrapping
logic
layer
provided
by
the
decorator
routes
instance
construction
calls
to
oncall
which
in
turn
calls
getinstance
to
manage
and
share
a
single
instance
per
class
regardless
of
how
many
construction
calls
are
made
here
s
this
code
s
output
bob
bob
interestingly
you
can
code
a
more
self
contained
solution
here
if
you
re
able
to
use
the
nonlocal
statement
available
in
python
and
later
to
change
enclosing
scope
names
as
described
earlier
the
following
alternative
achieves
an
identical
effect
by
using
one
enclosing
scope
per
class
instead
of
one
global
table
entry
per
class
def
singleton
aclass
instance
none
def
oncall
args
nonlocal
instance
if
instance
none
instance
aclass
args
return
instance
return
oncall
on
decoration
on
instance
creation
and
later
nonlocal
one
scope
per
class
this
version
works
the
same
but
it
does
not
depend
on
names
in
the
global
scope
outside
the
decorator
in
either
python
or
you
can
also
code
a
self
contained
solution
with
a
class
instead
the
following
uses
one
instance
per
class
rather
than
an
enclosing
scope
or
global
table
and
works
the
same
as
the
other
two
versions
in
fact
it
relies
on
the
same
coding
pattern
that
we
will
later
see
is
a
common
decorator
class
blunder
here
we
want
just
one
instance
but
that
s
not
always
the
case
class
singleton
def
init
self
aclass
self
aclass
aclass
self
instance
none
def
call
self
args
chapter
decorators
on
decoration
on
instance
creation
if
self
instance
none
self
instance
self
aclass
args
one
instance
per
class
return
self
instance
to
make
this
decorator
a
fully
general
purpose
tool
store
it
in
an
importable
module
file
indent
the
self
test
code
under
a
name
check
and
add
support
for
keyword
arguments
in
construction
calls
with
kargs
syntax
i
ll
leave
this
as
a
suggested
exercise
tracing
object
interfaces
the
singleton
example
of
the
prior
section
illustrated
using
class
decorators
to
manage
all
the
instances
of
a
class
another
common
use
case
for
class
decorators
augments
the
interface
of
each
generated
instance
class
decorators
can
essentially
install
on
instances
a
wrapper
logic
layer
that
manages
access
to
their
interfaces
in
some
way
for
example
in
chapter
the
getattr
operator
overloading
method
is
shown
as
a
way
to
wrap
up
entire
object
interfaces
of
embedded
instances
in
order
to
implement
the
delegation
coding
pattern
we
saw
similar
examples
in
the
managed
attribute
coverage
of
the
prior
chapter
recall
that
getattr
is
run
when
an
undefined
attribute
name
is
fetched
we
can
use
this
hook
to
intercept
method
calls
in
a
controller
class
and
propagate
them
to
an
embedded
object
for
reference
here
s
the
original
nondecorator
delegation
example
working
on
two
built
in
type
objects
class
wrapper
def
init
self
object
self
wrapped
object
def
getattr
self
attrname
print
trace
attrname
return
getattr
self
wrapped
attrname
save
object
trace
fetch
delegate
fetch
x
wrapper
x
append
trace
append
x
wrapped
wrap
a
list
delegate
to
list
method
x
wrapper
a
b
list
x
keys
trace
keys
a
b
wrap
a
dictionary
delegate
to
dictionary
method
use
list
in
print
my
member
in
this
code
the
wrapper
class
intercepts
access
to
any
of
the
wrapped
object
s
attributes
prints
a
trace
message
and
uses
the
getattr
built
in
to
pass
off
the
request
to
the
wrapped
object
specifically
it
traces
attribute
accesses
made
outside
the
wrapped
object
s
class
accesses
inside
the
wrapped
object
s
methods
are
not
caught
and
run
normally
by
design
this
whole
interface
model
differs
from
the
behavior
of
function
decorators
which
wrap
up
just
one
specific
method
coding
class
decorators
class
decorators
provide
an
alternative
and
convenient
way
to
code
this
getattr
technique
to
wrap
an
entire
interface
in
and
for
example
the
prior
class
example
can
be
coded
as
a
class
decorator
that
triggers
wrapped
instance
creation
instead
of
passing
a
pre
made
instance
into
the
wrapper
s
constructor
also
augmented
here
to
support
keyword
arguments
with
kargs
and
to
count
the
number
of
accesses
made
def
tracer
aclass
class
wrapper
def
init
self
args
kargs
self
fetches
self
wrapped
aclass
args
kargs
def
getattr
self
attrname
print
trace
attrname
self
fetches
return
getattr
self
wrapped
attrname
return
wrapper
tracer
class
spam
def
display
self
print
spam
tracer
class
person
def
init
self
name
hours
rate
self
name
name
self
hours
hours
self
rate
rate
def
pay
self
return
self
hours
self
rate
on
decorator
on
instance
creation
use
enclosing
scope
name
catches
all
but
own
attrs
delegate
to
wrapped
obj
spam
tracer
spam
spam
is
rebound
to
wrapper
person
tracer
person
wrapper
remembers
person
accesses
outside
class
traced
in
method
accesses
not
traced
food
spam
food
display
print
food
fetches
triggers
wrapper
triggers
getattr
bob
person
bob
print
bob
name
print
bob
pay
bob
is
really
a
wrapper
wrapper
embeds
a
person
print
sue
person
sue
rate
hours
print
sue
name
print
sue
pay
print
bob
name
print
bob
pay
print
bob
fetches
sue
fetches
sue
is
a
different
wrapper
with
a
different
person
bob
has
different
state
wrapper
attrs
not
traced
it
s
important
to
note
that
this
is
very
different
from
the
tracer
decorator
we
met
earlier
in
coding
function
decorators
on
page
we
looked
at
decorators
that
enabled
us
to
trace
and
time
calls
to
a
given
function
or
method
in
contrast
by
intercepting
instance
creation
calls
the
class
decorator
here
allows
us
to
trace
an
entire
object
interface
i
e
accesses
to
any
of
its
attributes
chapter
decorators
the
following
is
the
output
produced
by
this
code
under
both
and
attribute
fetches
on
instances
of
both
the
spam
and
person
classes
invoke
the
getattr
logic
in
the
wrapper
class
because
food
and
bob
are
really
instances
of
wrapper
thanks
to
the
decorator
s
redirection
of
instance
creation
calls
trace
display
spam
spam
spam
spam
spam
spam
spam
spam
trace
name
bob
trace
pay
trace
sue
trace
trace
bob
trace
name
pay
name
pay
notice
that
the
preceding
code
decorates
a
user
defined
class
just
like
in
the
original
example
in
chapter
we
can
also
use
the
decorator
to
wrap
up
a
built
in
type
such
as
a
list
as
long
as
we
either
subclass
to
allow
decoration
syntax
or
perform
the
decoration
manually
decorator
syntax
requires
a
class
statement
for
the
line
in
the
following
x
is
really
a
wrapper
again
due
to
the
indirection
of
decoration
i
moved
the
decorator
class
to
module
file
tracer
py
in
order
to
reuse
it
this
way
from
tracer
import
tracer
decorator
moved
to
a
module
file
tracer
class
mylist
list
pass
mylist
tracer
mylist
x
mylist
x
append
trace
append
x
wrapped
triggers
wrapper
triggers
getattr
append
wraplist
tracer
list
x
wraplist
x
append
trace
append
x
wrapped
or
perform
decoration
manually
else
subclass
statement
required
the
decorator
approach
allows
us
to
move
instance
creation
into
the
decorator
itself
instead
of
requiring
a
premade
object
to
be
passed
in
although
this
seems
like
a
minor
difference
it
lets
us
retain
normal
instance
creation
syntax
and
realize
all
the
benefits
coding
class
decorators
of
decorators
in
general
rather
than
requiring
all
instance
creation
calls
to
route
objects
through
a
wrapper
manually
we
need
only
augment
classes
with
decorator
syntax
tracer
class
person
bob
person
bob
sue
person
sue
rate
hours
decorator
approach
class
person
non
decorator
approach
bob
wrapper
person
bob
sue
wrapper
person
sue
rate
hours
assuming
you
will
make
more
than
one
instance
of
a
class
decorators
will
generally
be
a
net
win
in
terms
of
both
code
size
and
code
maintenance
attribute
version
skew
note
as
we
learned
in
chapter
getattr
will
intercept
accesses
to
operator
overloading
methods
like
str
and
repr
in
python
but
not
in
in
python
class
instances
inherit
defaults
for
some
but
not
all
of
these
names
from
the
class
really
from
the
automatic
object
superclass
because
all
classes
are
new
style
moreover
in
implicitly
invoked
attributes
for
built
in
operations
like
printing
and
are
not
routed
through
getattr
or
its
cousin
getattribute
newstyle
classes
look
up
such
methods
in
classes
and
skip
the
normal
instance
lookup
entirely
here
this
means
that
the
getattr
based
tracing
wrapper
will
automatically
trace
and
propagate
operator
overloading
calls
in
but
not
in
to
see
this
display
x
directly
at
the
end
of
the
preceding
interactive
session
in
the
attribute
repr
is
traced
and
the
list
prints
as
expected
but
in
no
trace
occurs
and
the
list
prints
using
a
default
display
for
the
wrapper
class
x
trace
repr
x
tracer
wrapper
object
at
x
c
d
to
work
the
same
in
operator
overloading
methods
generally
need
to
be
redefined
redundantly
in
the
wrapper
class
either
by
hand
by
tools
or
by
definition
in
superclasses
only
simple
named
attributes
will
work
the
same
in
both
versions
we
ll
see
this
version
skew
at
work
again
in
a
private
decorator
later
in
this
chapter
class
blunders
ii
retaining
multiple
instances
curiously
the
decorator
function
in
this
example
can
almost
be
coded
as
a
class
instead
of
a
function
with
the
proper
operator
overloading
protocol
the
following
slightly
simplified
alternative
works
similarly
because
its
init
is
triggered
when
the
decorator
is
applied
to
the
class
and
its
call
is
triggered
when
a
subject
class
instance
chapter
decorators
is
created
our
objects
are
really
instances
of
tracer
this
time
and
we
essentially
just
trade
an
enclosing
scope
reference
for
an
instance
attribute
here
class
tracer
def
init
self
aclass
on
decorator
self
aclass
aclass
use
instance
attribute
def
call
self
args
on
instance
creation
self
wrapped
self
aclass
args
one
last
instance
per
class
return
self
def
getattr
self
attrname
print
trace
attrname
return
getattr
self
wrapped
attrname
tracer
class
spam
def
display
self
print
spam
food
spam
food
display
triggers
init
like
spam
tracer
spam
triggers
call
triggers
getattr
as
we
saw
in
the
abstract
earlier
though
this
class
only
alternative
handles
multiple
classes
as
before
but
it
won
t
quite
work
for
multiple
instances
of
a
given
class
each
instance
construction
call
triggers
call
which
overwrites
the
prior
instance
the
net
effect
is
that
tracer
saves
just
one
instance
the
last
one
created
experiment
with
this
yourself
to
see
how
but
here
s
an
example
of
the
problem
tracer
class
person
def
init
self
name
self
name
name
bob
person
bob
print
bob
name
sue
person
sue
print
sue
name
print
bob
name
person
tracer
person
wrapper
bound
to
person
bob
is
really
a
wrapper
wrapper
embeds
a
person
sue
overwrites
bob
oops
now
bob
s
name
is
sue
this
code
s
output
follows
because
this
tracer
only
has
a
single
shared
instance
the
second
overwrites
the
first
trace
name
bob
trace
name
sue
trace
name
sue
the
problem
here
is
bad
state
retention
we
make
one
decorator
instance
per
class
but
not
per
class
instance
such
that
only
the
last
instance
is
retained
the
solution
as
in
our
prior
class
blunder
for
decorating
methods
lies
in
abandoning
class
based
decorators
coding
class
decorators
the
earlier
function
based
tracer
version
does
work
for
multiple
instances
because
each
instance
construction
call
makes
a
new
wrapper
instance
instead
of
overwriting
the
state
of
a
single
shared
tracer
instance
the
original
nondecorator
version
handles
multiple
instances
correctly
for
the
same
reason
decorators
are
not
only
arguably
magical
they
can
also
be
incredibly
subtle
decorators
versus
manager
functions
regardless
of
such
subtleties
the
tracer
class
decorator
example
ultimately
still
relies
on
getattr
to
intercept
fetches
on
a
wrapped
and
embedded
instance
object
as
we
saw
earlier
all
we
ve
really
accomplished
is
moving
the
instance
creation
call
inside
a
class
instead
of
passing
the
instance
into
a
manager
function
with
the
original
nondecorator
tracing
example
we
would
simply
code
instance
creation
differently
class
spam
food
wrapper
spam
non
decorator
version
any
class
will
do
special
creation
syntax
tracer
class
spam
food
spam
decorator
version
requires
syntax
at
class
normal
creation
syntax
essentially
class
decorators
shift
special
syntax
requirements
from
the
instance
creation
call
to
the
class
statement
itself
this
is
also
true
for
the
singleton
example
earlier
in
this
section
rather
than
decorating
a
class
and
using
normal
instance
creation
calls
we
could
simply
pass
the
class
and
its
construction
arguments
into
a
manager
function
instances
def
getinstance
aclass
args
if
aclass
not
in
instances
instances
aclass
aclass
args
return
instances
aclass
bob
getinstance
person
bob
versus
bob
person
bob
alternatively
we
could
use
python
s
introspection
facilities
to
fetch
the
class
from
an
already
created
instance
assuming
creating
an
initial
instance
is
acceptable
instances
def
getinstance
object
aclass
object
class
if
aclass
not
in
instances
instances
aclass
object
return
instances
aclass
bob
getinstance
person
bob
versus
bob
person
bob
the
same
holds
true
for
function
decorators
like
the
tracer
we
wrote
earlier
rather
than
decorating
a
function
with
logic
that
intercepts
later
calls
we
could
simply
pass
the
function
and
its
arguments
into
a
manager
that
dispatches
the
call
chapter
decorators
def
func
x
y
result
tracer
func
nondecorator
version
def
tracer
func
args
func
args
special
call
syntax
tracer
def
func
x
y
result
func
decorator
version
rebinds
name
func
tracer
func
normal
call
syntax
manager
function
approaches
like
this
place
the
burden
of
using
special
syntax
on
calls
instead
of
expecting
decoration
syntax
at
function
and
class
definitions
why
decorators
revisited
so
why
did
i
just
show
you
ways
to
not
use
decorators
to
implement
singletons
as
i
mentioned
at
the
start
of
this
chapter
decorators
present
us
with
tradeoffs
although
syntax
matters
we
all
too
often
forget
to
ask
the
why
questions
when
confronted
with
new
tools
now
that
we
ve
seen
how
decorators
actually
work
let
s
step
back
for
a
minute
to
glimpse
the
big
picture
here
like
most
language
features
decorators
have
both
pros
and
cons
for
example
in
the
negatives
column
class
decorators
suffer
from
two
potential
drawbacks
type
changes
as
we
ve
seen
when
wrappers
are
inserted
a
decorated
function
or
class
does
not
retain
its
original
type
its
name
is
rebound
to
a
wrapper
object
which
might
matter
in
programs
that
use
object
names
or
test
object
types
in
the
singleton
example
both
the
decorator
and
manager
function
approaches
retain
the
original
class
type
for
instances
in
the
tracer
code
neither
approach
does
because
wrappers
are
required
extra
calls
a
wrapping
layer
added
by
decoration
incurs
the
additional
performance
cost
of
an
extra
call
each
time
the
decorated
object
is
invoked
calls
are
relatively
timeexpensive
operations
so
decoration
wrappers
can
make
a
program
slower
in
the
tracer
code
both
approaches
require
each
attribute
to
be
routed
through
a
wrapper
layer
the
singleton
example
avoids
extra
calls
by
retaining
the
original
class
type
similar
concerns
apply
with
function
decorators
both
decoration
and
manager
functions
incur
extra
calls
and
type
changes
generally
occur
when
decorating
but
not
otherwise
that
said
neither
of
these
is
a
very
serious
issue
for
most
programs
the
type
difference
issue
is
unlikely
to
matter
and
the
speed
hit
of
the
extra
calls
will
be
insignificant
furthermore
the
latter
occurs
only
when
wrappers
are
used
can
often
be
negated
by
simply
removing
the
decorator
when
optimal
performance
is
required
and
is
also
incurred
by
nondecorator
solutions
that
add
wrapping
logic
including
metaclasses
as
we
ll
see
in
chapter
coding
class
decorators
conversely
as
we
saw
at
the
start
of
this
chapter
decorators
have
three
main
advantages
compared
to
the
manager
a
k
a
helper
function
solutions
of
the
prior
section
decorators
offer
explicit
syntax
decorators
make
augmentation
explicit
and
obvious
their
syntax
is
easier
to
recognize
than
special
code
in
calls
that
may
appear
anywhere
in
a
source
file
in
our
singleton
and
tracer
examples
for
instance
the
decorator
lines
seem
more
likely
to
be
noticed
than
extra
code
at
calls
would
be
moreover
decorators
allow
function
and
instance
creation
calls
to
use
normal
syntax
familiar
to
all
python
programmers
code
maintenance
decorators
avoid
repeated
augmentation
code
at
each
function
or
class
call
because
they
appear
just
once
at
the
definition
of
the
class
or
function
itself
they
obviate
redundancy
and
simplify
future
code
maintenance
for
our
singleton
and
tracer
cases
we
need
to
use
special
code
at
each
call
to
use
a
manager
function
approach
extra
work
is
required
both
initially
and
for
any
modifications
that
must
be
made
in
the
future
consistency
decorators
make
it
less
likely
that
a
programmer
will
forget
to
use
required
wrapping
logic
this
derives
mostly
from
the
two
prior
advantages
because
decoration
is
explicit
and
appears
only
once
at
the
decorated
objects
themselves
decorators
promote
more
consistent
and
uniform
api
usage
than
special
code
that
must
be
included
at
each
call
in
the
singleton
example
for
instance
it
would
be
easy
to
forget
to
route
all
class
creation
calls
through
special
code
which
would
subvert
the
singleton
management
altogether
decorators
also
promote
code
encapsulation
to
reduce
redundancy
and
minimize
future
maintenance
effort
although
other
code
structuring
tools
do
too
decorators
make
this
natural
for
augmentation
tasks
none
of
these
benefits
completely
requires
decorator
syntax
to
be
achieved
though
and
decorator
usage
is
ultimately
a
stylistic
choice
that
said
most
programmers
find
them
to
be
a
net
win
especially
as
a
tool
for
using
libraries
and
apis
correctly
i
can
recall
similar
arguments
being
made
both
for
and
against
constructor
functions
in
classes
prior
to
the
introduction
of
init
methods
the
same
effect
was
often
achieved
by
running
an
instance
through
a
method
manually
when
creating
it
e
g
x
class
init
over
time
though
despite
being
fundamentally
a
stylistic
choice
the
init
syntax
came
to
be
universally
preferred
because
it
was
more
explicit
consistent
and
maintainable
although
you
should
be
the
judge
decorators
seem
to
bring
many
of
the
same
assets
to
the
table
chapter
decorators
managing
functions
and
classes
directly
most
of
our
examples
in
this
chapter
have
been
designed
to
intercept
function
and
instance
creation
calls
although
this
is
typical
for
decorators
they
are
not
limited
to
this
role
because
decorators
work
by
running
new
functions
and
classes
through
decorator
code
they
can
also
be
used
to
manage
function
and
class
objects
themselves
not
just
later
calls
made
to
them
imagine
for
example
that
you
require
methods
or
classes
used
by
an
application
to
be
registered
to
an
api
for
later
processing
perhaps
that
api
will
call
the
objects
later
in
response
to
events
although
you
could
provide
a
registration
function
to
be
called
manually
after
the
objects
are
defined
decorators
make
your
intent
more
explicit
the
following
simple
implementation
of
this
idea
defines
a
decorator
that
can
be
applied
to
both
functions
and
classes
to
add
the
object
to
a
dictionary
based
registry
because
it
returns
the
object
itself
instead
of
a
wrapper
it
does
not
intercept
later
calls
registering
decorated
objects
to
an
api
registry
def
register
obj
registry
obj
name
obj
return
obj
both
class
and
func
decorator
add
to
registry
return
obj
itself
not
a
wrapper
register
def
spam
x
return
x
spam
register
spam
register
def
ham
x
return
x
register
class
eggs
def
init
self
x
self
data
x
def
str
self
return
str
self
data
eggs
register
eggs
print
registry
for
name
in
registry
print
name
registry
name
type
registry
name
print
nmanual
calls
print
spam
print
ham
x
eggs
print
x
print
nregistry
calls
for
name
in
registry
print
name
registry
name
invoke
objects
manually
later
calls
not
intercepted
invoke
from
registry
managing
functions
and
classes
directly
when
this
code
is
run
the
decorated
objects
are
added
to
the
registry
by
name
but
they
still
work
as
originally
coded
when
they
re
called
later
without
being
routed
through
a
wrapper
layer
in
fact
our
objects
can
be
run
both
manually
and
from
inside
the
registry
table
registry
eggs
class
main
eggs
class
type
ham
function
ham
at
x
cfb
class
function
spam
function
spam
at
x
cfb
f
class
function
manual
calls
registry
calls
eggs
ham
spam
a
user
interface
might
use
this
technique
for
example
to
register
callback
handlers
for
user
actions
handlers
might
be
registered
by
function
or
class
name
as
done
here
or
decorator
arguments
could
be
used
to
specify
the
subject
event
an
extra
def
statement
enclosing
our
decorator
could
be
used
to
retain
such
arguments
for
use
on
decoration
this
example
is
artificial
but
its
technique
is
very
general
for
example
function
decorators
might
also
be
used
to
process
function
attributes
and
class
decorators
might
insert
new
class
attributes
or
even
new
methods
dynamically
consider
the
following
function
decorators
they
assign
function
attributes
to
record
information
for
later
use
by
an
api
but
they
do
not
insert
a
wrapper
layer
to
intercept
later
calls
augmenting
decorated
objects
directly
def
decorate
func
func
marked
true
return
func
decorate
def
spam
a
b
return
a
b
spam
marked
true
def
annotate
text
def
decorate
func
func
label
text
return
func
return
decorate
annotate
spam
data
def
spam
a
b
return
a
b
chapter
decorators
assign
function
attribute
for
later
use
same
but
value
is
decorator
argument
spam
annotate
spam
spam
spam
label
spam
data
such
decorators
augment
functions
and
classes
directly
without
catching
later
calls
to
them
we
ll
see
more
examples
of
class
decorations
managing
classes
directly
in
the
next
chapter
because
this
turns
out
to
encroach
on
the
domain
of
metaclasses
for
the
remainder
of
this
chapter
let
s
turn
to
two
larger
case
studies
of
decorators
at
work
example
private
and
public
attributes
the
final
two
sections
of
this
chapter
present
larger
examples
of
decorator
use
both
are
presented
with
minimal
description
partly
because
this
chapter
has
exceeded
its
size
limits
but
mostly
because
you
should
already
understand
decorator
basics
well
enough
to
study
these
on
your
own
being
general
purpose
tools
these
examples
give
us
a
chance
to
see
how
decorator
concepts
come
together
in
more
useful
code
implementing
private
attributes
the
following
class
decorator
implements
a
private
declaration
for
class
instance
attributes
that
is
attributes
stored
on
an
instance
or
inherited
from
one
of
its
classes
it
disallows
fetch
and
change
access
to
such
attributes
from
outside
the
decorated
class
but
still
allows
the
class
itself
to
access
those
names
freely
within
its
methods
it
s
not
exactly
c
or
java
but
it
provides
similar
access
control
as
an
option
in
python
we
saw
an
incomplete
first
cut
implementation
of
instance
attribute
privacy
for
changes
only
in
chapter
the
version
here
extends
this
concept
to
validate
attribute
fetches
too
and
it
uses
delegation
instead
of
inheritance
to
implement
the
model
in
fact
in
a
sense
this
is
just
an
extension
to
the
attribute
tracer
class
decorator
we
met
earlier
although
this
example
utilizes
the
new
syntactic
sugar
of
class
decorators
to
code
attribute
privacy
its
attribute
interception
is
ultimately
still
based
upon
the
getattr
and
setattr
operator
overloading
methods
we
met
in
prior
chapters
when
a
private
attribute
access
is
detected
this
version
uses
the
raise
statement
to
raise
an
exception
along
with
an
error
message
the
exception
may
be
caught
in
a
try
or
allowed
to
terminate
the
script
here
is
the
code
along
with
a
self
test
at
the
bottom
of
the
file
it
will
work
under
both
python
and
because
it
employs
print
and
raise
syntax
though
it
catches
operator
overloading
method
attributes
in
only
more
on
this
in
a
moment
privacy
for
attributes
fetched
from
class
instances
see
self
test
code
at
end
of
file
for
a
usage
example
decorator
same
as
doubler
private
data
size
doubler
private
returns
ondecorator
ondecorator
returns
oninstance
and
each
oninstance
instance
embeds
a
doubler
instance
example
private
and
public
attributes
traceme
false
def
trace
args
if
traceme
print
join
map
str
args
def
private
privates
privates
in
enclosing
scope
def
ondecorator
aclass
aclass
in
enclosing
scope
class
oninstance
wrapped
in
instance
attribute
def
init
self
args
kargs
self
wrapped
aclass
args
kargs
def
getattr
self
attr
my
attrs
don
t
call
getattr
trace
get
attr
others
assumed
in
wrapped
if
attr
in
privates
raise
typeerror
private
attribute
fetch
attr
else
return
getattr
self
wrapped
attr
def
setattr
self
attr
value
outside
accesses
trace
set
attr
value
others
run
normally
if
attr
wrapped
allow
my
attrs
self
dict
attr
value
avoid
looping
elif
attr
in
privates
raise
typeerror
private
attribute
change
attr
else
setattr
self
wrapped
attr
value
wrapped
obj
attrs
return
oninstance
or
use
dict
return
ondecorator
if
name
main
traceme
true
private
data
size
doubler
private
doubler
class
doubler
def
init
self
label
start
self
label
label
accesses
inside
the
subject
class
self
data
start
not
intercepted
run
normally
def
size
self
return
len
self
data
methods
run
with
no
checking
def
double
self
because
privacy
not
inherited
for
i
in
range
self
size
self
data
i
self
data
i
def
display
self
print
s
s
self
label
self
data
x
doubler
x
is
y
doubler
y
is
the
followng
all
succeed
print
x
label
x
display
x
double
x
display
print
y
label
y
display
y
double
y
label
spam
y
display
chapter
decorators
accesses
outside
subject
class
intercepted
validated
delegated
the
following
all
fail
properly
print
x
size
prints
typeerror
private
attribute
fetch
size
print
x
data
x
data
x
size
lambda
s
print
y
data
print
y
size
when
traceme
is
true
the
module
file
s
self
test
code
produces
the
following
output
notice
how
the
decorator
catches
and
validates
both
attribute
fetches
and
assignments
run
outside
of
the
wrapped
class
but
does
not
catch
attribute
accesses
inside
the
class
itself
set
wrapped
main
doubler
object
at
x
b
aaf
set
wrapped
main
doubler
object
at
x
b
ae
get
label
x
is
get
display
x
is
get
double
get
display
x
is
get
label
y
is
get
display
y
is
get
double
set
label
spam
get
display
spam
implementation
details
i
this
code
is
a
bit
complex
and
you
re
probably
best
off
tracing
through
it
on
your
own
to
see
how
it
works
to
help
you
study
though
here
are
a
few
highlights
worth
mentioning
inheritance
versus
delegation
the
first
cut
privacy
example
shown
in
chapter
used
inheritance
to
mix
in
a
setattr
to
catch
accesses
inheritance
makes
this
difficult
however
because
dif
ferentiating
between
accesses
from
inside
or
outside
the
class
is
not
straightforward
inside
access
should
be
allowed
to
run
normally
and
outside
access
should
be
restricted
to
work
around
this
the
chapter
example
requires
inheriting
classes
to
use
dict
assignments
to
set
attributes
an
incomplete
solution
at
best
the
version
here
uses
delegation
embedding
one
object
inside
another
instead
of
inheritance
this
pattern
is
better
suited
to
our
task
as
it
makes
it
much
easier
to
distinguish
between
accesses
inside
and
outside
of
the
subject
class
attribute
accesses
from
example
private
and
public
attributes
outside
the
subject
class
are
intercepted
by
the
wrapper
layer
s
overloading
methods
and
delegated
to
the
class
if
valid
accesses
inside
the
class
itself
i
e
through
self
inside
its
methods
code
are
not
intercepted
and
are
allowed
to
run
normally
without
checks
because
privacy
is
not
inherited
here
decorator
arguments
the
class
decorator
used
here
accepts
any
number
of
arguments
to
name
private
attributes
what
really
happens
though
is
that
the
arguments
are
passed
to
the
private
function
and
private
returns
the
decorator
function
to
be
applied
to
the
subject
class
that
is
the
arguments
are
used
before
decoration
ever
occurs
private
returns
the
decorator
which
in
turn
remembers
the
privates
list
as
an
enclosing
scope
reference
state
retention
and
enclosing
scopes
speaking
of
enclosing
scopes
there
are
actually
three
levels
of
state
retention
at
work
in
this
code
the
arguments
to
private
are
used
before
decoration
occurs
and
are
retained
as
an
enclosing
scope
reference
for
use
in
both
ondecorator
and
oninstance
the
class
argument
to
ondecorator
is
used
at
decoration
time
and
is
retained
as
an
enclosing
scope
reference
for
use
at
instance
construction
time
the
wrapped
instance
object
is
retained
as
an
instance
attribute
in
oninstance
for
use
when
attributes
are
later
accessed
from
outside
the
class
this
all
works
fairly
naturally
given
python
s
scope
and
namespace
rules
using
dict
and
slots
the
setattr
in
this
code
relies
on
an
instance
object
s
dict
attribute
namespace
dictionary
in
order
to
set
oninstance
s
own
wrapped
attribute
as
we
learned
in
the
prior
chapter
it
cannot
assign
an
attribute
directly
without
looping
however
it
uses
the
setattr
built
in
instead
of
dict
to
set
attributes
in
the
wrapped
object
itself
moreover
getattr
is
used
to
fetch
attributes
in
the
wrapped
object
since
they
may
be
stored
in
the
object
itself
or
inherited
by
it
because
of
that
this
code
will
work
for
most
classes
you
may
recall
from
chapter
that
new
style
classes
with
slots
may
not
store
attributes
in
a
dict
however
because
we
only
rely
on
a
dict
at
the
oninstance
level
here
not
in
the
wrapped
instance
and
because
setattr
and
getattr
apply
to
attributes
based
on
both
dict
and
slots
our
decorator
applies
to
classes
using
either
storage
scheme
generalizing
for
public
declarations
too
now
that
we
have
a
private
implementation
it
s
straightforward
to
generalize
the
code
to
allow
for
public
declarations
too
they
are
essentially
the
inverse
of
private
declarations
so
we
need
only
negate
the
inner
test
the
example
listed
in
this
section
allows
chapter
decorators
a
class
to
use
decorators
to
define
a
set
of
either
private
or
public
instance
attributes
attributes
stored
on
an
instance
or
inherited
from
its
classes
with
the
following
semantics
private
declares
attributes
of
a
class
s
instances
that
cannot
be
fetched
or
assigned
except
from
within
the
code
of
the
class
s
methods
that
is
any
name
declared
private
cannot
be
accessed
from
outside
the
class
while
any
name
not
declared
private
can
be
freely
fetched
or
assigned
from
outside
the
class
public
declares
attributes
of
a
class
s
instances
that
can
be
fetched
or
assigned
from
both
outside
the
class
and
within
the
class
s
methods
that
is
any
name
declared
public
can
be
freely
accessed
anywhere
while
any
name
not
declared
public
cannot
be
accessed
from
outside
the
class
private
and
public
declarations
are
intended
to
be
mutually
exclusive
when
using
private
all
undeclared
names
are
considered
public
and
when
using
public
all
undeclared
names
are
considered
private
they
are
essentially
inverses
though
unde
clared
names
not
created
by
class
methods
behave
slightly
differently
they
can
be
assigned
and
thus
created
outside
the
class
under
private
all
undeclared
names
are
accessible
but
not
under
public
all
undeclared
names
are
inaccessible
again
study
this
code
on
your
own
to
get
a
feel
for
how
this
works
notice
that
this
scheme
adds
an
additional
fourth
level
of
state
retention
at
the
top
beyond
that
described
in
the
preceding
section
the
test
functions
used
by
the
lambdas
are
saved
in
an
extra
enclosing
scope
this
example
is
coded
to
run
under
either
python
or
though
it
comes
with
a
caveat
when
run
under
explained
briefly
in
the
file
s
docstring
and
expanded
on
after
the
code
class
decorator
with
private
and
public
attribute
declarations
controls
access
to
attributes
stored
on
an
instance
or
inherited
by
it
from
its
classes
private
declares
attribute
names
that
cannot
be
fetched
or
assigned
outside
the
decorated
class
and
public
declares
all
the
names
that
can
caveat
this
works
in
for
normally
named
attributes
only
x
operator
overloading
methods
implicitly
run
for
built
in
operations
do
not
trigger
either
getattr
or
getattribute
in
new
style
classes
add
x
methods
here
to
intercept
and
delegate
built
ins
traceme
false
def
trace
args
if
traceme
print
join
map
str
args
def
accesscontrol
failif
def
ondecorator
aclass
class
oninstance
def
init
self
args
kargs
self
wrapped
aclass
args
kargs
def
getattr
self
attr
trace
get
attr
example
private
and
public
attributes
if
failif
attr
raise
typeerror
private
attribute
fetch
attr
else
return
getattr
self
wrapped
attr
def
setattr
self
attr
value
trace
set
attr
value
if
attr
oninstance
wrapped
self
dict
attr
value
elif
failif
attr
raise
typeerror
private
attribute
change
attr
else
setattr
self
wrapped
attr
value
return
oninstance
return
ondecorator
def
private
attributes
return
accesscontrol
failif
lambda
attr
attr
in
attributes
def
public
attributes
return
accesscontrol
failif
lambda
attr
attr
not
in
attributes
see
the
prior
example
s
self
test
code
for
a
usage
example
here
s
a
quick
look
at
these
class
decorators
in
action
at
the
interactive
prompt
they
work
the
same
in
and
as
advertised
non
private
or
public
names
can
be
fetched
and
changed
from
outside
the
subject
class
but
private
or
non
public
names
cannot
from
access
import
private
public
private
age
class
person
def
init
self
name
age
self
name
name
self
age
age
x
person
bob
x
name
bob
x
name
sue
x
name
sue
x
age
typeerror
private
attribute
fetch
age
x
age
tom
typeerror
private
attribute
change
age
public
name
class
person
def
init
self
name
age
self
name
name
self
age
age
x
person
bob
x
name
bob
x
name
sue
chapter
decorators
person
private
age
person
person
oninstance
with
state
inside
accesses
run
normally
outside
accesses
validated
x
is
an
oninstance
oninstance
embeds
person
x
name
sue
x
age
typeerror
private
attribute
fetch
age
x
age
tom
typeerror
private
attribute
change
age
implementation
details
ii
to
help
you
analyze
the
code
here
are
a
few
final
notes
on
this
version
since
this
is
just
a
generalization
of
the
preceding
section
s
example
most
of
the
notes
there
apply
here
as
well
using
x
pseudoprivate
names
besides
generalizing
this
version
also
makes
use
of
python
s
x
pseudoprivate
name
mangling
feature
which
we
met
in
chapter
to
localize
the
wrapped
attribute
to
the
control
class
by
automatically
prefixing
it
with
the
class
name
this
avoids
the
prior
version
s
risk
for
collisions
with
a
wrapped
attribute
that
may
be
used
by
the
real
wrapped
class
and
it
s
useful
in
a
general
tool
like
this
it
s
not
quite
privacy
though
because
the
mangled
name
can
be
used
freely
outside
the
class
notice
that
we
also
have
to
use
the
fully
expanded
name
string
oninstance
wrapped
in
setattr
because
that
s
what
python
changes
it
to
breaking
privacy
although
this
example
does
implement
access
controls
for
attributes
of
an
instance
and
its
classes
it
is
possible
to
subvert
these
controls
in
various
ways
for
instance
by
going
through
the
expanded
version
of
the
wrapped
attribute
explicitly
bob
pay
might
not
work
but
the
fully
mangled
bob
oninstance
wrapped
pay
could
if
you
have
to
explicitly
try
to
do
so
though
these
controls
are
probably
sufficient
for
normal
intended
use
of
course
privacy
controls
can
generally
be
subverted
in
any
language
if
you
try
hard
enough
define
private
public
may
work
in
some
c
implementations
too
although
access
controls
can
reduce
accidental
changes
much
of
this
is
up
to
programmers
in
any
language
whenever
source
code
may
be
changed
access
control
will
always
be
a
bit
of
a
pipe
dream
decorator
tradeoffs
we
could
again
achieve
the
same
results
without
decorators
by
using
manager
functions
or
coding
the
name
rebinding
of
decorators
manually
the
decorator
syntax
however
makes
this
consistent
and
a
bit
more
obvious
in
the
code
the
chief
potential
downsides
of
this
and
any
other
wrapper
based
approach
are
that
attribute
access
incurs
an
extra
call
and
instances
of
decorated
classes
are
not
really
instances
of
the
original
decorated
class
if
you
test
their
type
with
x
class
or
isinstance
x
c
example
private
and
public
attributes
for
example
you
ll
find
that
they
are
instances
of
the
wrapper
class
unless
you
plan
to
do
introspection
on
objects
types
though
the
type
issue
is
probably
irrelevant
open
issues
as
is
this
example
works
as
planned
under
python
and
provided
operator
overloading
methods
to
be
delegated
are
redefined
in
the
wrapper
as
with
most
software
though
there
is
always
room
for
improvement
caveat
operator
overloading
methods
fail
to
delegate
under
like
all
delegation
based
classes
that
use
getattr
this
decorator
works
crossversion
for
normally
named
attributes
only
operator
overloading
methods
like
str
and
add
work
differently
for
new
style
classes
and
so
fail
to
reach
the
embedded
object
if
defined
there
when
this
runs
under
as
we
learned
in
the
prior
chapter
classic
classes
look
up
operator
overloading
names
in
instances
at
runtime
normally
but
new
style
classes
do
not
they
skip
the
instance
entirely
and
look
up
such
methods
in
classes
hence
the
x
operator
overloading
methods
implicitly
run
for
built
in
operations
do
not
trigger
either
getattr
or
getattribute
in
new
style
classes
in
and
all
classes
in
such
attribute
fetches
skip
our
oninstance
getattr
altogether
so
they
cannot
be
validated
or
delegated
our
decorator
s
class
is
not
coded
as
new
style
by
deriving
from
object
so
it
will
catch
operator
overloading
methods
if
run
under
since
all
classes
are
new
style
automatically
in
though
such
methods
will
fail
if
they
are
coded
on
the
embedded
object
the
simplest
workaround
in
is
to
redefine
redundantly
in
oninstance
all
the
operator
overloading
methods
that
can
possibly
be
used
in
wrapped
objects
such
extra
methods
can
be
added
by
hand
by
tools
that
partly
automate
the
task
e
g
with
class
decorators
or
the
metaclasses
discussed
in
the
next
chapter
or
by
definition
in
superclasses
to
see
the
difference
yourself
try
applying
the
decorator
to
a
class
that
uses
operator
overloading
methods
under
validations
work
as
before
and
both
the
str
method
used
by
printing
and
the
add
method
run
for
invoke
the
decorator
s
getattr
and
hence
wind
up
being
validated
and
delegated
to
the
subject
person
object
correctly
c
misc
c
python
python
from
access
import
private
private
age
class
person
def
init
self
self
age
def
str
self
return
person
str
self
age
def
add
self
yrs
self
age
yrs
chapter
decorators
x
person
x
age
typeerror
private
attribute
fetch
age
print
x
person
x
print
x
person
name
validations
fail
correctly
getattr
runs
person
str
getattr
runs
person
add
getattr
runs
person
str
when
the
same
code
is
run
under
python
though
the
implicitly
invoked
str
and
add
skip
the
decorator
s
getattr
and
look
for
definitions
in
or
above
the
decorator
class
itself
print
winds
up
finding
the
default
display
inherited
from
the
class
type
technically
from
the
implied
object
superclass
in
and
generates
an
error
because
no
default
is
inherited
c
misc
c
python
python
from
access
import
private
private
age
class
person
def
init
self
self
age
def
str
self
return
person
str
self
age
def
add
self
yrs
self
age
yrs
x
person
name
validations
still
work
x
age
but
fails
to
delegate
built
ins
typeerror
private
attribute
fetch
age
print
x
access
oninstance
object
at
x
e
x
typeerror
unsupported
operand
type
s
for
oninstance
and
int
print
x
access
oninstance
object
at
x
e
using
the
alternative
getattribute
method
won
t
help
here
although
it
is
defined
to
catch
every
attribute
reference
not
just
undefined
names
it
is
also
not
run
by
builtin
operations
python
s
property
feature
which
we
met
in
chapter
won
t
help
here
either
recall
that
properties
are
automatically
run
code
associated
with
specific
attributes
defined
when
a
class
is
written
and
are
not
designed
to
handle
arbitrary
attributes
in
wrapped
objects
as
mentioned
earlier
the
most
straightforward
solution
under
is
to
redundantly
redefine
operator
overloading
names
that
may
appear
in
embedded
objects
in
delegation
based
classes
like
our
decorator
this
isn
t
ideal
because
it
creates
some
code
redundancy
especially
compared
to
solutions
however
it
isn
t
too
major
a
coding
effort
can
be
automated
to
some
extent
with
tools
or
superclasses
suffices
to
make
our
decorator
work
in
and
allows
operator
overloading
names
to
be
declared
private
or
public
too
assuming
each
overloading
method
runs
the
failif
test
internally
example
private
and
public
attributes
def
accesscontrol
failif
def
ondecorator
aclass
class
oninstance
def
init
self
args
kargs
self
wrapped
aclass
args
kargs
intercept
and
delegate
operator
overloading
methods
def
str
self
return
str
self
wrapped
def
add
self
other
return
self
wrapped
other
def
getitem
self
index
return
self
wrapped
index
if
needed
def
call
self
args
kargs
return
self
wrapped
arg
kargs
if
needed
plus
any
others
needed
intercept
and
delegate
named
attributes
def
getattr
self
attr
def
setattr
self
attr
value
return
oninstance
return
ondecorator
with
such
operator
overloading
methods
added
the
prior
example
with
str
and
add
works
the
same
under
and
although
a
substantial
amount
of
extra
code
may
be
required
to
accommodate
in
principle
every
operator
overloading
method
that
is
not
run
automatically
will
need
to
be
defined
redundantly
for
in
a
general
tool
class
like
this
which
is
why
this
extension
is
omitted
in
our
code
since
every
class
is
new
style
in
delegation
based
code
is
more
difficult
though
not
impossible
in
this
release
on
the
other
hand
delegation
wrappers
could
simply
inherit
from
a
common
superclass
that
redefines
operator
overloading
methods
once
with
standard
delegation
code
moreover
tools
such
as
additional
class
decorators
or
metaclasses
might
automate
some
of
the
work
of
adding
such
methods
to
delegation
classes
see
the
class
augmentation
examples
in
chapter
for
details
though
still
not
as
simple
as
the
solution
such
techniques
might
help
make
delegation
classes
more
general
implementation
alternatives
getattribute
inserts
call
stack
inspection
although
redundantly
defining
operator
overloading
methods
in
wrappers
is
probably
the
most
straightforward
workaround
to
python
dilemma
outlined
in
the
prior
section
it
s
not
necessarily
the
only
one
we
don
t
have
space
to
explore
this
issue
much
further
here
so
investigating
other
potential
solutions
is
relegated
to
a
suggested
exercise
because
one
dead
end
alternative
underscores
class
concepts
well
though
it
merits
a
brief
mention
one
downside
of
this
example
is
that
instance
objects
are
not
truly
instances
of
the
original
class
they
are
instances
of
the
wrapper
instead
in
some
programs
that
rely
chapter
decorators
on
type
testing
this
might
matter
to
support
such
cases
we
might
try
to
achieve
similar
effects
by
inserting
a
getattribute
method
into
the
original
class
to
catch
every
attribute
reference
made
on
its
instances
this
inserted
method
would
pass
valid
requests
up
to
its
superclass
to
avoid
loops
using
the
techniques
we
studied
in
the
prior
chapter
here
is
the
potential
change
to
our
class
decorator
s
code
trace
support
as
before
def
accesscontrol
failif
def
ondecorator
aclass
def
getattributes
self
attr
trace
get
attr
if
failif
attr
raise
typeerror
private
attribute
fetch
attr
else
return
object
getattribute
self
attr
aclass
getattribute
getattributes
return
aclass
return
ondecorator
def
private
attributes
return
accesscontrol
failif
lambda
attr
attr
in
attributes
def
public
attributes
return
accesscontrol
failif
lambda
attr
attr
not
in
attributes
this
alternative
addresses
the
type
testing
issue
but
suffers
from
others
for
example
it
handles
only
attribute
fetches
as
is
this
version
allows
private
names
to
be
assigned
freely
intercepting
assignments
would
still
have
to
use
setattr
and
either
an
instance
wrapper
object
or
another
class
method
insertion
adding
an
instance
wrapper
to
catch
assignments
would
change
the
type
again
and
inserting
methods
fails
if
the
original
class
is
using
a
setattr
of
its
own
or
a
getattribute
for
that
matter
an
inserted
setattr
would
also
have
to
allow
for
a
slots
in
the
client
class
in
addition
this
scheme
does
not
address
the
built
in
operation
attributes
issue
described
in
the
prior
section
since
getattribute
is
not
run
in
these
contexts
either
in
our
case
if
person
had
a
str
it
would
be
run
by
print
operations
but
only
because
it
was
actually
present
in
that
class
as
before
the
str
attribute
would
not
be
routed
to
the
inserted
getattribute
method
generically
printing
would
bypass
this
method
altogether
and
call
the
class
s
str
directly
although
this
is
probably
better
than
not
supporting
operator
overloading
methods
in
a
wrapped
object
at
all
barring
redefinition
at
least
this
scheme
still
cannot
intercept
and
validate
x
methods
making
it
impossible
for
any
of
them
to
be
private
although
most
operator
overloading
methods
are
meant
to
be
public
some
might
not
be
much
worse
because
this
nonwrapper
approach
works
by
adding
a
getattribute
to
the
decorated
class
it
also
intercepts
attribute
accesses
made
by
example
private
and
public
attributes
the
class
itself
and
validates
them
the
same
as
accesses
made
from
outside
this
means
the
class
s
method
won
t
be
able
to
use
private
names
either
in
fact
inserting
methods
this
way
is
functionally
equivalent
to
inheriting
them
and
implies
the
same
constraints
as
our
original
chapter
privacy
code
to
know
whether
an
attribute
access
originated
inside
or
outside
the
class
our
method
might
need
to
inspect
frame
objects
on
the
python
call
stack
this
might
ultimately
yield
a
solution
replace
private
attributes
with
properties
or
descriptors
that
check
the
stack
for
example
but
it
would
slow
access
further
and
is
far
too
dark
a
magic
for
us
to
explore
here
while
interesting
and
possibly
relevant
for
some
other
use
cases
this
method
insertion
technique
doesn
t
meet
our
goals
we
won
t
explore
this
option
s
coding
pattern
further
here
because
we
will
study
class
augmentation
techniques
in
the
next
chapter
in
conjunction
with
metaclasses
as
we
ll
see
there
metaclasses
are
not
strictly
required
for
changing
classes
this
way
because
class
decorators
can
often
serve
the
same
role
python
isn
t
about
control
now
that
i
ve
gone
to
such
great
lengths
to
add
private
and
public
attribute
declarations
for
python
code
i
must
again
remind
you
that
it
is
not
entirely
pythonic
to
add
access
controls
to
your
classes
like
this
in
fact
most
python
programmers
will
probably
find
this
example
to
be
largely
or
totally
irrelevant
apart
from
serving
as
a
demonstration
of
decorators
in
action
most
large
python
programs
get
by
successfully
without
any
such
controls
at
all
if
you
do
wish
to
regulate
attribute
access
in
order
to
eliminate
coding
mistakes
though
or
happen
to
be
a
soon
to
be
ex
c
or
java
programmer
most
things
are
possible
with
python
s
operator
overloading
and
introspection
tools
example
validating
function
arguments
as
a
final
example
of
the
utility
of
decorators
this
section
develops
a
function
decorator
that
automatically
tests
whether
arguments
passed
to
a
function
or
method
are
within
a
valid
numeric
range
it
s
designed
to
be
used
during
either
development
or
production
and
it
can
be
used
as
a
template
for
similar
tasks
e
g
argument
type
testing
if
you
must
because
this
chapter
s
size
limits
has
been
broached
this
example
s
code
is
largely
self
study
material
with
limited
narrative
as
usual
browse
the
code
for
more
details
the
goal
in
the
object
oriented
tutorial
of
chapter
we
wrote
a
class
that
gave
a
raise
to
objects
representing
people
based
upon
a
passed
in
percentage
class
person
chapter
decorators
def
giveraise
self
percent
self
pay
int
self
pay
percent
there
we
noted
that
if
we
wanted
the
code
to
be
robust
it
would
be
a
good
idea
to
check
the
percentage
to
make
sure
it
s
not
too
large
or
too
small
we
could
implement
such
a
check
with
either
if
or
assert
statements
in
the
method
itself
using
inline
tests
class
person
def
giveraise
self
percent
validate
with
inline
code
if
percent
or
percent
raise
typeerror
percent
invalid
self
pay
int
self
pay
percent
class
person
validate
with
asserts
def
giveraise
self
percent
assert
percent
and
percent
percent
invalid
self
pay
int
self
pay
percent
however
this
approach
clutters
up
the
method
with
inline
tests
that
will
probably
be
useful
only
during
development
for
more
complex
cases
this
can
become
tedious
imagine
trying
to
inline
the
code
needed
to
implement
the
attribute
privacy
provided
by
the
last
section
s
decorator
perhaps
worse
if
the
validation
logic
ever
needs
to
change
there
may
be
arbitrarily
many
inline
copies
to
find
and
update
a
more
useful
and
interesting
alternative
would
be
to
develop
a
general
tool
that
can
perform
range
tests
for
us
automatically
for
the
arguments
of
any
function
or
method
we
might
code
now
or
in
the
future
a
decorator
approach
makes
this
explicit
and
convenient
class
person
rangetest
percent
use
decorator
to
validate
def
giveraise
self
percent
self
pay
int
self
pay
percent
isolating
validation
logic
in
a
decorator
simplifies
both
clients
and
future
maintenance
notice
that
our
goal
here
is
different
than
the
attribute
validations
coded
in
the
prior
chapter
s
final
example
here
we
mean
to
validate
the
values
of
function
arguments
when
passed
rather
than
attribute
values
when
set
python
s
decorator
and
introspection
tools
allow
us
to
code
this
new
task
just
as
easily
a
basic
range
testing
decorator
for
positional
arguments
let
s
start
with
a
basic
range
test
implementation
to
keep
things
simple
we
ll
begin
by
coding
a
decorator
that
works
only
for
positional
arguments
and
assumes
they
always
appear
at
the
same
position
in
every
call
they
cannot
be
passed
by
keyword
name
and
we
don
t
support
additional
args
keywords
in
calls
because
this
can
invalidate
the
positions
declared
in
the
decorator
code
the
following
in
a
file
called
devtools
py
def
rangetest
argchecks
def
ondecorator
func
if
not
debug
validate
positional
arg
ranges
true
if
python
o
main
py
args
example
validating
function
arguments
return
func
no
op
call
original
directly
else
else
wrapper
while
debugging
def
oncall
args
for
ix
low
high
in
argchecks
if
args
ix
low
or
args
ix
high
errmsg
argument
s
not
in
s
s
ix
low
high
raise
typeerror
errmsg
return
func
args
return
oncall
return
ondecorator
as
is
this
code
is
mostly
a
rehash
of
the
coding
patterns
we
explored
earlier
we
use
decorator
arguments
nested
scopes
for
state
retention
and
so
on
we
also
use
nested
def
statements
to
ensure
that
this
works
for
both
simple
functions
and
methods
as
we
learned
earlier
when
used
for
a
class
method
oncall
receives
the
subject
class
s
instance
in
the
first
item
in
args
and
passes
this
along
to
self
in
the
original
method
function
argument
numbers
in
range
tests
start
at
in
this
case
not
also
notice
this
code
s
use
of
the
debug
built
in
variable
though
python
sets
this
to
true
unless
it
s
being
run
with
the
o
optimize
command
line
flag
e
g
python
o
main
py
when
debug
is
false
the
decorator
returns
the
origin
function
unchanged
to
avoid
extra
calls
and
their
associated
performance
penalty
this
first
iteration
solution
is
used
as
follows
file
devtools
test
py
from
devtools
import
rangetest
print
debug
false
if
python
o
main
py
rangetest
persinfo
rangetest
persinfo
def
persinfo
name
age
age
must
be
in
print
s
is
s
years
old
name
age
rangetest
def
birthday
m
d
y
print
birthday
format
m
d
y
class
person
def
init
self
name
job
pay
self
job
job
self
pay
pay
rangetest
giveraise
rangetest
giveraise
def
giveraise
self
percent
arg
is
the
self
instance
here
self
pay
int
self
pay
percent
comment
lines
raise
typeerror
unless
python
o
used
on
shell
command
line
persinfo
bob
smith
persinfo
bob
smith
birthday
birthday
chapter
decorators
really
runs
oncall
with
state
or
person
if
o
cmd
line
argument
sue
person
sue
jones
dev
sue
giveraise
print
sue
pay
sue
giveraise
print
sue
pay
really
runs
oncall
self
or
giveraise
self
if
o
when
run
valid
calls
in
this
code
produce
the
following
output
all
the
code
in
this
section
works
the
same
under
python
and
because
function
decorators
are
supported
in
both
we
re
not
using
attribute
delegation
and
we
use
style
print
calls
and
exception
construction
syntax
c
misc
c
python
python
devtools
test
py
true
bob
smith
is
years
old
birthday
uncommenting
any
of
the
invalid
calls
causes
a
typeerror
to
be
raised
by
the
decorator
here
s
the
result
when
the
last
two
lines
are
allowed
to
run
as
usual
i
ve
omitted
some
of
the
error
message
text
here
to
save
space
c
misc
c
python
python
devtools
test
py
true
bob
smith
is
years
old
birthday
typeerror
argument
not
in
running
python
with
its
o
flag
at
a
system
command
line
will
disable
range
testing
but
also
avoid
the
performance
overhead
of
the
wrapping
layer
we
wind
up
calling
the
original
undecorated
function
directly
assuming
this
is
a
debugging
tool
only
you
can
use
this
flag
to
optimize
your
program
for
production
use
c
misc
c
python
python
o
devtools
test
py
false
bob
smith
is
years
old
birthday
generalizing
for
keywords
and
defaults
too
the
prior
version
illustrates
the
basics
we
need
to
employ
but
it
s
fairly
limited
it
supports
validating
arguments
passed
by
position
only
and
it
does
not
validate
keyword
arguments
in
fact
it
assumes
that
no
keywords
are
passed
in
a
way
that
makes
argument
position
numbers
incorrect
additionally
it
does
nothing
about
arguments
with
defaults
that
may
be
omitted
in
a
given
call
that
s
fine
if
all
your
arguments
are
passed
by
position
and
never
defaulted
but
less
than
ideal
in
a
general
tool
python
supports
much
more
flexible
argument
passing
modes
which
we
re
not
yet
addressing
example
validating
function
arguments
the
mutation
of
our
example
shown
next
does
better
by
matching
the
wrapped
function
s
expected
arguments
against
the
actual
arguments
passed
in
a
call
it
supports
range
validations
for
arguments
passed
by
either
position
or
keyword
name
and
it
skips
testing
for
default
arguments
omitted
in
the
call
in
short
arguments
to
be
validated
are
specified
by
keyword
arguments
to
the
decorator
which
later
steps
through
both
the
pargs
positionals
tuple
and
the
kargs
keywords
dictionary
to
validate
file
devtools
py
function
decorator
that
performs
range
test
validation
for
passed
arguments
arguments
are
specified
by
keyword
to
the
decorator
in
the
actual
call
arguments
may
be
passed
by
position
or
keyword
and
defaults
may
be
omitted
see
devtools
test
py
for
example
use
cases
trace
true
def
rangetest
argchecks
validate
ranges
for
both
defaults
def
ondecorator
func
oncall
remembers
func
and
argchecks
if
not
debug
true
if
python
o
main
py
args
return
func
wrap
if
debugging
else
use
original
else
import
sys
code
func
code
allargs
code
co
varnames
code
co
argcount
funcname
func
name
def
oncall
pargs
kargs
all
pargs
match
first
n
expected
args
by
position
the
rest
must
be
in
kargs
or
be
omitted
defaults
positionals
list
allargs
positionals
positionals
len
pargs
for
argname
low
high
in
argchecks
items
for
all
args
to
be
checked
if
argname
in
kargs
was
passed
by
name
if
kargs
argname
low
or
kargs
argname
high
errmsg
argument
not
in
errmsg
errmsg
format
funcname
argname
low
high
raise
typeerror
errmsg
elif
argname
in
positionals
was
passed
by
position
position
positionals
index
argname
if
pargs
position
low
or
pargs
position
high
errmsg
argument
not
in
errmsg
errmsg
format
funcname
argname
low
high
raise
typeerror
errmsg
else
assume
not
passed
default
if
trace
print
argument
defaulted
format
argname
chapter
decorators
return
func
pargs
kargs
return
oncall
return
ondecorator
ok
run
original
call
the
following
test
script
shows
how
the
decorator
is
used
arguments
to
be
validated
are
given
by
keyword
decorator
arguments
and
at
actual
calls
we
can
pass
by
name
or
position
and
omit
arguments
with
defaults
even
if
they
are
to
be
validated
otherwise
file
devtools
test
py
comment
lines
raise
typeerror
unless
python
o
used
on
shell
command
line
from
devtools
import
rangetest
test
functions
positional
and
keyword
rangetest
age
persinfo
rangetest
persinfo
def
persinfo
name
age
print
s
is
s
years
old
name
age
rangetest
m
d
y
def
birthday
m
d
y
print
birthday
format
m
d
y
persinfo
bob
persinfo
age
name
bob
birthday
d
y
persinfo
bob
persinfo
age
name
bob
birthday
d
y
test
methods
positional
and
keyword
class
person
def
init
self
name
job
pay
self
job
job
self
pay
pay
giveraise
rangetest
giveraise
rangetest
percent
percent
passed
by
name
or
position
def
giveraise
self
percent
self
pay
int
self
pay
percent
bob
person
bob
smith
dev
sue
person
sue
jones
dev
bob
giveraise
sue
giveraise
percent
print
bob
pay
sue
pay
bob
giveraise
bob
giveraise
percent
test
omitted
defaults
skipped
rangetest
a
b
c
d
def
omitargs
a
b
c
d
example
validating
function
arguments
print
a
b
c
d
omitargs
omitargs
omitargs
d
omitargs
d
omitargs
d
a
omitargs
b
d
omitargs
d
c
a
omitargs
omitargs
omitargs
d
omitargs
d
omitargs
d
a
omitargs
b
d
omitargs
d
c
a
bad
d
bad
c
bad
d
bad
a
bad
a
bad
b
bad
a
when
this
script
is
run
out
of
range
arguments
raise
an
exception
as
before
but
arguments
may
be
passed
by
either
name
or
position
and
omitted
defaults
are
not
validated
this
code
runs
on
both
and
but
extra
tuple
parentheses
print
in
trace
its
output
and
test
this
further
on
your
own
to
experiment
it
works
as
before
but
its
scope
has
been
broadened
c
misc
c
python
python
devtools
test
py
bob
is
years
old
bob
is
years
old
birthday
argument
d
defaulted
argument
c
defaulted
argument
b
defaulted
argument
c
defaulted
argument
b
defaulted
argument
c
defaulted
argument
b
defaulted
on
validation
errors
we
get
an
exception
as
before
unless
the
o
command
line
argument
is
passed
to
python
when
one
of
the
method
test
lines
is
uncommented
typeerror
giveraise
argument
percent
not
in
implementation
details
this
decorator
s
code
relies
on
both
introspection
apis
and
subtle
constraints
of
argument
passing
to
be
fully
general
we
could
in
principle
try
to
mimic
python
s
argument
matching
logic
in
its
entirety
to
see
which
names
have
been
passed
in
which
chapter
decorators
modes
but
that
s
far
too
much
complexity
for
our
tool
it
would
be
better
if
we
could
somehow
match
arguments
passed
by
name
against
the
set
of
all
expected
arguments
names
in
order
to
determine
which
position
arguments
actually
appear
in
during
a
given
call
function
introspection
it
turns
out
that
the
introspection
api
available
on
function
objects
and
their
associated
code
objects
has
exactly
the
tool
we
need
this
api
was
briefly
introduced
in
chapter
but
we
ll
actually
put
it
to
use
here
the
set
of
expected
argument
names
is
simply
the
first
n
variable
names
attached
to
a
function
s
code
object
in
python
and
for
compatibility
def
func
a
b
c
d
x
y
code
func
code
code
co
nlocals
code
co
varnames
a
b
c
d
x
y
code
co
varnames
code
co
argcount
a
b
c
d
code
object
of
function
object
all
local
var
names
first
n
locals
are
expected
args
import
sys
for
backward
compatibility
sys
version
info
is
major
release
number
final
code
func
code
if
sys
version
info
else
func
func
code
the
same
api
is
available
in
older
pythons
but
the
func
code
attribute
is
spelled
as
func
func
code
in
and
earlier
the
newer
code
attribute
is
also
redundantly
available
in
for
portability
run
a
dir
call
on
function
and
code
objects
for
more
details
argument
assumptions
given
this
set
of
expected
argument
names
the
solution
relies
on
two
constraints
on
argument
passing
order
imposed
by
python
these
still
hold
true
in
both
and
at
the
call
all
positional
arguments
appear
before
all
keyword
arguments
in
the
def
all
nondefault
arguments
appear
before
all
default
arguments
that
is
a
nonkeyword
argument
cannot
generally
follow
a
keyword
argument
at
a
call
and
a
nondefault
argument
cannot
follow
a
default
argument
at
a
definition
all
name
value
syntax
must
appear
after
any
simple
name
in
both
places
to
simplify
our
work
we
can
also
make
the
assumption
that
a
call
is
valid
in
general
i
e
that
all
arguments
either
will
receive
values
by
name
or
position
or
will
be
omitted
intentionally
to
pick
up
defaults
this
assumption
won
t
necessarily
hold
because
the
function
has
not
yet
actually
been
called
when
the
wrapper
logic
tests
validity
the
call
example
validating
function
arguments
may
still
fail
later
when
invoked
by
the
wrapper
layer
due
to
incorrect
argument
passing
as
long
as
that
doesn
t
cause
the
wrapper
to
fail
any
more
badly
though
we
can
finesse
the
validity
of
the
call
this
helps
because
validating
calls
before
they
are
actually
made
would
require
us
to
emulate
python
s
argument
matching
algorithm
in
full
again
too
complex
a
procedure
for
our
tool
matching
algorithm
now
given
these
constraints
and
assumptions
we
can
allow
for
both
keywords
and
omitted
default
arguments
in
the
call
with
this
algorithm
when
a
call
is
intercepted
we
can
make
the
following
assumptions
all
n
passed
positional
arguments
in
pargs
must
match
the
first
n
expected
arguments
obtained
from
the
function
s
code
object
this
is
true
per
python
s
call
ordering
rules
outlined
earlier
since
all
positionals
precede
all
keywords
to
obtain
the
names
of
arguments
actually
passed
by
position
we
can
slice
the
list
of
all
expected
arguments
up
to
the
length
n
of
the
pargs
positionals
tuple
any
arguments
after
the
first
n
expected
arguments
either
were
passed
by
keyword
or
were
defaulted
by
omission
at
the
call
for
each
argument
name
to
be
validated
if
it
is
in
kargs
it
was
passed
by
name
and
if
it
is
in
the
first
n
expected
arguments
it
was
passed
by
position
in
which
case
its
relative
position
in
the
expected
list
gives
its
relative
position
in
pargs
otherwise
we
can
assume
it
was
omitted
in
the
call
and
defaulted
and
need
not
be
checked
in
other
words
we
can
skip
tests
for
arguments
that
were
omitted
in
a
call
by
assuming
that
the
first
n
actually
passed
positional
arguments
in
pargs
must
match
the
first
n
argument
names
in
the
list
of
all
expected
arguments
and
that
any
others
must
either
have
been
passed
by
keyword
and
thus
be
in
kargs
or
have
been
defaulted
under
this
scheme
the
decorator
will
simply
skip
any
argument
to
be
checked
that
was
omitted
between
the
rightmost
positional
argument
and
the
leftmost
keyword
argument
between
keyword
arguments
or
after
the
rightmost
positional
in
general
trace
through
the
decorator
and
its
test
script
to
see
how
this
is
realized
in
code
open
issues
although
our
range
testing
tool
works
as
planned
two
caveats
remain
first
as
mentioned
earlier
calls
to
the
original
function
that
are
not
valid
still
fail
in
our
final
decorator
the
following
both
trigger
exceptions
for
example
omitargs
omitargs
d
c
b
these
only
fail
though
where
we
try
to
invoke
the
original
function
at
the
end
of
the
wrapper
while
we
could
try
to
imitate
python
s
argument
matching
to
avoid
this
chapter
decorators
there
s
not
much
reason
to
do
so
since
the
call
would
fail
at
this
point
anyhow
we
might
as
well
let
python
s
own
argument
matching
logic
detect
the
problem
for
us
lastly
although
our
final
version
handles
positional
arguments
keyword
arguments
and
omitted
defaults
it
still
doesn
t
do
anything
explicit
about
args
and
args
that
may
be
used
in
a
decorated
function
that
accepts
arbitrarily
many
arguments
we
probably
don
t
need
to
care
for
our
purposes
though
if
an
extra
keyword
argument
is
passed
its
name
will
show
up
in
kargs
and
can
be
tested
normally
if
mentioned
to
the
decorator
if
an
extra
keyword
argument
is
not
passed
its
name
won
t
be
in
either
kargs
or
the
sliced
expected
positionals
list
and
it
will
thus
not
be
checked
it
is
treated
as
though
it
were
defaulted
even
though
it
is
really
an
optional
extra
argument
if
an
extra
positional
argument
is
passed
there
s
no
way
to
reference
it
in
the
decorator
anyhow
its
name
won
t
be
in
either
kargs
or
the
sliced
expected
arguments
list
so
it
will
simply
be
skipped
because
such
arguments
are
not
listed
in
the
function
s
definition
there
s
no
way
to
map
a
name
given
to
the
decorator
back
to
an
expected
relative
position
in
other
words
as
it
is
the
code
supports
testing
arbitrary
keyword
arguments
by
name
but
not
arbitrary
positionals
that
are
unnamed
and
hence
have
no
set
position
in
the
function
s
argument
signature
in
principle
we
could
extend
the
decorator
s
interface
to
support
args
in
the
decorated
function
too
for
the
rare
cases
where
this
might
be
useful
e
g
a
special
argument
name
with
a
test
to
apply
to
all
arguments
in
the
wrapper
s
pargs
beyond
the
length
of
the
expected
arguments
list
since
we
ve
already
exhausted
the
space
allocation
for
this
example
though
if
you
care
about
such
improvements
you
ve
officially
crossed
over
into
the
realm
of
suggested
exercises
decorator
arguments
versus
function
annotations
interestingly
the
function
annotation
feature
introduced
in
python
could
provide
an
alternative
to
the
decorator
arguments
used
by
our
example
to
specify
range
tests
as
we
learned
in
chapter
annotations
allow
us
to
associate
expressions
with
arguments
and
return
values
by
coding
them
in
the
def
header
line
itself
python
collects
annotations
in
a
dictionary
and
attaches
it
to
the
annotated
function
we
could
use
this
in
our
example
to
code
range
limits
in
the
header
line
instead
of
in
decorator
arguments
we
would
still
need
a
function
decorator
to
wrap
the
function
in
order
to
intercept
later
calls
but
we
would
essentially
trade
decorator
argument
syntax
rangetest
a
c
def
func
a
b
c
print
a
b
c
func
rangetest
func
example
validating
function
arguments
for
annotation
syntax
like
this
rangetest
def
func
a
b
c
print
a
b
c
that
is
the
range
constraints
would
be
moved
into
the
function
itself
instead
of
being
coded
externally
the
following
script
illustrates
the
structure
of
the
resulting
decorators
under
both
schemes
in
incomplete
skeleton
code
the
decorator
arguments
code
pattern
is
that
of
our
complete
solution
shown
earlier
the
annotation
alternative
requires
one
less
level
of
nesting
because
it
doesn
t
need
to
retain
decorator
arguments
using
decorator
arguments
def
rangetest
argchecks
def
ondecorator
func
def
oncall
pargs
kargs
print
argchecks
for
check
in
argchecks
pass
return
func
pargs
kargs
return
oncall
return
ondecorator
add
validation
code
here
rangetest
a
c
def
func
a
b
c
print
a
b
c
func
rangetest
func
func
c
runs
oncall
argchecks
in
scope
using
function
annotations
def
rangetest
func
def
oncall
pargs
kargs
argchecks
func
annotations
print
argchecks
for
check
in
argchecks
pass
return
func
pargs
kargs
return
oncall
add
validation
code
here
rangetest
def
func
a
b
c
print
a
b
c
func
rangetest
func
func
c
runs
oncall
annotations
on
func
when
run
both
schemes
have
access
to
the
same
validation
test
information
but
in
different
forms
the
decorator
argument
version
s
information
is
retained
in
an
argument
in
an
enclosing
scope
and
the
annotation
version
s
information
is
retained
in
an
attribute
of
the
function
itself
a
c
a
c
chapter
decorators
i
ll
leave
fleshing
out
the
rest
of
the
annotation
based
version
as
a
suggested
exercise
its
code
would
be
identical
to
that
of
our
complete
solution
shown
earlier
because
range
test
information
is
simply
on
the
function
instead
of
in
an
enclosing
scope
really
all
this
buys
us
is
a
different
user
interface
for
our
tool
it
will
still
need
to
match
argument
names
against
expected
argument
names
to
obtain
relative
positions
as
before
in
fact
using
annotation
instead
of
decorator
arguments
in
this
example
actually
limits
its
utility
for
one
thing
annotation
only
works
under
python
so
is
no
longer
supported
function
decorators
with
arguments
on
the
other
hand
work
in
both
versions
more
importantly
by
moving
the
validation
specifications
into
the
def
header
we
essentially
commit
the
function
to
a
single
role
since
annotation
allows
us
to
code
only
one
expression
per
argument
it
can
have
only
one
purpose
for
instance
we
cannot
use
range
test
annotations
for
any
other
role
by
contrast
because
decorator
arguments
are
coded
outside
the
function
itself
they
are
both
easier
to
remove
and
more
general
the
code
of
the
function
itself
does
not
imply
a
single
decoration
purpose
in
fact
by
nesting
decorators
with
arguments
we
can
apply
multiple
augmentation
steps
to
the
same
function
annotation
directly
supports
only
one
with
decorator
arguments
the
function
itself
also
retains
a
simpler
normal
appearance
still
if
you
have
a
single
purpose
in
mind
and
you
can
commit
to
supporting
x
only
the
choice
between
annotation
and
decorator
arguments
is
largely
stylistic
and
subjective
as
is
so
often
true
in
life
one
person
s
annotation
may
well
be
another
s
syntactic
clutter
other
applications
type
testing
if
you
insist
the
coding
pattern
we
ve
arrived
at
for
processing
arguments
in
decorators
could
be
applied
in
other
contexts
checking
argument
data
types
at
development
time
for
example
is
a
straightforward
extension
def
typetest
argchecks
def
ondecorator
func
def
oncall
pargs
kargs
positionals
list
allargs
len
pargs
for
argname
type
in
argchecks
items
if
argname
in
kargs
if
not
isinstance
kargs
argname
type
raise
typeerror
errmsg
elif
argname
in
positionals
position
positionals
index
argname
if
not
isinstance
pargs
position
type
raise
typeerror
errmsg
example
validating
function
arguments
else
assume
not
passed
default
return
func
pargs
kargs
return
oncall
return
ondecorator
typetest
a
int
c
float
def
func
a
b
c
d
func
typetest
func
func
func
spam
okay
triggers
exception
correctly
in
fact
we
might
even
generalize
further
by
passing
in
a
test
function
much
as
we
did
to
add
public
decorations
earlier
a
single
copy
of
this
sort
of
code
would
suffice
for
both
range
and
type
testing
using
function
annotations
instead
of
decorator
arguments
for
such
a
decorator
as
described
in
the
prior
section
would
make
this
look
even
more
like
type
declarations
in
other
languages
typetest
def
func
a
int
b
c
float
d
func
typetest
func
gasp
as
you
should
have
learned
in
this
book
though
this
particular
role
is
generally
a
bad
idea
in
working
code
and
not
at
all
pythonic
in
fact
it
s
often
a
symptom
of
an
ex
c
programmer
s
first
attempts
to
use
python
type
testing
restricts
your
function
to
work
on
specific
types
only
instead
of
allowing
it
to
operate
on
any
types
with
compatible
interfaces
in
effect
it
limits
your
code
and
breaks
its
flexibility
on
the
other
hand
every
rule
has
exceptions
type
checking
may
come
in
handy
in
isolated
cases
while
debugging
and
when
interfacing
with
code
written
in
more
restrictive
languages
such
as
c
this
general
pattern
of
argument
processing
might
also
be
applicable
in
a
variety
of
less
controversial
roles
chapter
summary
in
this
chapter
we
explored
decorators
both
the
function
and
class
varieties
as
we
learned
decorators
are
a
way
to
insert
code
to
be
run
automatically
when
a
function
or
class
is
defined
when
a
decorator
is
used
python
rebinds
a
function
or
class
name
to
the
callable
object
it
returns
this
hook
allows
us
to
add
a
layer
of
wrapper
logic
to
function
calls
and
class
instance
creation
calls
in
order
to
manage
functions
and
instances
as
we
also
saw
manager
functions
and
manual
name
rebinding
can
achieve
the
same
effect
but
decorators
provide
a
more
explicit
and
uniform
solution
as
we
ll
see
in
the
next
chapter
class
decorators
can
also
be
used
to
manage
classes
themselves
rather
than
just
their
instances
because
this
functionality
overlaps
with
metaclasses
the
topic
of
the
next
chapter
you
ll
have
to
read
ahead
for
the
rest
of
this
story
first
though
work
through
the
following
quiz
because
this
chapter
was
mostly
chapter
decorators
focused
on
its
larger
examples
its
quiz
will
ask
you
to
modify
some
of
its
code
in
order
to
review
test
your
knowledge
quiz
as
mentioned
in
one
of
this
chapter
s
notes
the
timer
function
decorator
with
decorator
arguments
that
we
wrote
in
the
section
adding
decorator
arguments
on
page
can
be
applied
only
to
simple
functions
because
it
uses
a
nested
class
with
a
call
operator
overloading
method
to
catch
calls
this
structure
does
not
work
for
class
methods
because
the
decorator
instance
is
passed
to
self
not
the
subject
class
instance
rewrite
this
decorator
so
that
it
can
be
applied
to
both
simple
functions
and
class
methods
and
test
it
on
both
functions
and
methods
hint
see
the
section
class
blunders
i
decorating
class
methods
on
page
for
pointers
note
that
you
may
make
use
of
assigning
function
object
attributes
to
keep
track
of
total
time
since
you
won
t
have
a
nested
class
for
state
retention
and
can
t
access
nonlocals
from
outside
the
decorator
code
the
public
private
class
decorators
we
wrote
in
this
chapter
will
add
overhead
to
every
attribute
fetch
in
a
decorated
class
although
we
could
simply
delete
the
decoration
line
to
gain
speed
we
could
also
augment
the
decorator
itself
to
check
the
debug
switch
and
perform
no
wrapping
at
all
when
the
o
python
flag
is
passed
on
the
command
line
just
as
we
did
for
the
argument
range
test
decorators
that
way
we
can
speed
our
program
without
changing
its
source
via
commandline
arguments
python
o
main
py
code
and
test
this
extension
test
your
knowledge
answers
here
s
one
way
to
code
the
first
question
s
solution
and
its
output
albeit
with
class
methods
that
run
too
fast
to
time
the
trick
lies
in
replacing
nested
classes
with
nested
functions
so
the
self
argument
is
not
the
decorator
s
instance
and
assigning
the
total
time
to
the
decorator
function
itself
so
it
can
be
fetched
later
through
the
original
rebound
name
see
the
section
state
information
retention
options
on
page
of
this
chapter
for
details
functions
support
arbitrary
attribute
attachment
and
the
function
name
is
an
enclosing
scope
reference
in
this
context
import
time
def
timer
label
trace
true
def
ondecorator
func
def
oncall
args
kargs
start
time
clock
result
func
args
kargs
elapsed
time
clock
start
on
decorator
args
retain
args
on
retain
decorated
func
on
calls
call
original
state
is
scopes
func
attr
test
your
knowledge
answers
oncall
alltime
elapsed
if
trace
format
s
s
f
f
values
label
func
name
elapsed
oncall
alltime
print
format
values
return
result
oncall
alltime
return
oncall
return
ondecorator
test
on
functions
timer
trace
true
label
ccc
def
listcomp
n
return
x
for
x
in
range
n
like
listcomp
timer
listcomp
listcomp
triggers
oncall
timer
trace
true
label
mmm
def
mapcall
n
return
list
map
lambda
x
x
range
n
list
for
views
for
func
in
listcomp
mapcall
result
func
time
for
this
call
all
calls
return
value
func
print
result
print
alltime
s
n
func
alltime
total
time
for
all
calls
test
on
methods
class
person
def
init
self
name
pay
self
name
name
self
pay
pay
timer
def
giveraise
self
percent
self
pay
percent
giveraise
timer
giveraise
tracer
remembers
giveraise
timer
label
def
lastname
self
return
self
name
split
lastname
timer
lastname
alltime
per
class
not
instance
bob
person
bob
smith
sue
person
sue
jones
bob
giveraise
sue
giveraise
runs
oncall
sue
print
bob
pay
sue
pay
print
bob
lastname
sue
lastname
runs
oncall
bob
remembers
lastname
print
f
f
person
giveraise
alltime
person
lastname
alltime
expected
output
ccc
listcomp
ccc
listcomp
alltime
chapter
decorators
mmm
mapcall
mmm
mapcall
alltime
giveraise
giveraise
lastname
lastname
smith
jones
the
following
satisfies
the
second
question
it
s
been
augmented
to
return
the
original
class
in
optimized
mode
o
so
attribute
accesses
don
t
incur
a
speed
hit
really
all
i
did
was
add
the
debug
mode
test
statements
and
indent
the
class
further
to
the
right
add
operator
overloading
method
redefinitions
to
the
wrapper
class
if
you
want
to
support
delegation
of
these
to
the
subject
class
in
too
routes
these
through
getattr
but
and
new
style
classes
in
do
not
traceme
false
def
trace
args
if
traceme
print
join
map
str
args
def
accesscontrol
failif
def
ondecorator
aclass
if
not
debug
return
aclass
else
class
oninstance
def
init
self
args
kargs
self
wrapped
aclass
args
kargs
def
getattr
self
attr
trace
get
attr
if
failif
attr
raise
typeerror
private
attribute
fetch
attr
else
return
getattr
self
wrapped
attr
def
setattr
self
attr
value
trace
set
attr
value
if
attr
oninstance
wrapped
self
dict
attr
value
elif
failif
attr
raise
typeerror
private
attribute
change
attr
else
setattr
self
wrapped
attr
value
return
oninstance
return
ondecorator
def
private
attributes
return
accesscontrol
failif
lambda
attr
attr
in
attributes
def
public
attributes
return
accesscontrol
failif
lambda
attr
attr
not
in
attributes
test
your
knowledge
answers
test
code
split
me
off
to
another
file
to
reuse
decorator
private
age
class
person
def
init
self
name
age
self
name
name
self
age
age
x
person
bob
print
x
name
x
name
sue
print
x
name
print
x
age
fails
unles
python
o
x
age
ditto
print
x
age
ditto
person
private
age
person
person
oninstance
with
state
inside
accesses
run
normally
outside
accesses
validated
public
name
class
person
def
init
self
name
age
self
name
name
self
age
age
x
person
bob
x
is
an
oninstance
print
x
name
oninstance
embeds
person
x
name
sue
print
x
name
print
x
age
fails
unless
python
o
main
py
x
age
ditto
print
x
age
ditto
chapter
decorators
chapter
metaclasses
in
the
prior
chapter
we
explored
decorators
and
studied
various
examples
of
their
use
in
this
final
chapter
of
the
book
we
re
going
continue
our
tool
builders
focus
and
investigate
another
advanced
topic
metaclasses
in
a
sense
metaclasses
simply
extend
the
code
insertion
model
of
decorators
as
we
learned
in
the
prior
chapter
function
and
class
decorators
allow
us
to
intercept
and
augment
function
calls
and
class
instance
creation
calls
in
a
similar
sprit
metaclasses
allow
us
to
intercept
and
augment
class
creation
they
provide
an
api
for
inserting
extra
logic
to
be
run
at
the
conclusion
of
a
class
statement
albeit
in
different
ways
than
decorators
as
such
they
provide
a
general
protocol
for
managing
class
objects
in
a
program
like
all
the
subjects
dealt
with
in
this
part
of
the
book
this
is
an
advanced
topic
that
can
be
investigated
on
an
as
needed
basis
in
practice
metaclasses
allow
us
to
gain
a
high
level
of
control
over
how
a
set
of
classes
work
this
is
a
powerful
concept
and
metaclasses
are
not
intended
for
most
application
programmers
nor
frankly
the
faint
of
heart
on
the
other
hand
metaclasses
open
the
door
to
a
variety
of
coding
patterns
that
may
be
difficult
or
impossible
to
achieve
otherwise
and
they
are
especially
of
interest
to
programmers
seeking
to
write
flexible
apis
or
programming
tools
for
others
to
use
even
if
you
don
t
fall
into
that
category
metaclasses
can
teach
you
much
about
python
s
class
model
in
general
as
in
the
prior
chapter
part
of
our
goal
here
is
also
to
show
more
realistic
code
examples
than
we
did
earlier
in
this
book
although
metaclasses
are
a
core
language
topic
and
not
themselves
an
application
domain
part
of
this
chapter
s
goal
is
to
spark
your
interest
in
exploring
larger
application
programming
examples
after
you
finish
this
book
to
metaclass
or
not
to
metaclass
metaclasses
are
perhaps
the
most
advanced
topic
in
this
book
if
not
the
python
language
as
a
whole
to
borrow
a
quote
from
the
comp
lang
python
newsgroup
by
veteran
python
core
developer
tim
peters
who
is
also
the
author
of
the
famous
import
this
python
motto
metaclasses
are
deeper
magic
than
of
users
should
ever
worry
about
if
you
wonder
whether
you
need
them
you
don
t
the
people
who
actually
need
them
know
with
certainty
that
they
need
them
and
don
t
need
an
explanation
about
why
in
other
words
metaclasses
are
primarily
intended
for
programmers
building
apis
and
tools
for
others
to
use
in
many
if
not
most
cases
they
are
probably
not
the
best
choice
in
applications
work
this
is
especially
true
if
you
re
developing
code
that
other
people
will
use
in
the
future
coding
something
because
it
seems
cool
is
not
generally
a
reasonable
justification
unless
you
are
experimenting
or
learning
still
metaclasses
have
a
wide
variety
of
potential
roles
and
it
s
important
to
know
when
they
can
be
useful
for
example
they
can
be
used
to
enhance
classes
with
features
like
tracing
object
persistence
exception
logging
and
more
they
can
also
be
used
to
construct
portions
of
a
class
at
runtime
based
upon
configuration
files
apply
function
decorators
to
every
method
of
a
class
generically
verify
conformance
to
expected
interfaces
and
so
on
in
their
more
grandiose
incarnations
metaclasses
can
even
be
used
to
implement
alternative
coding
patterns
such
as
aspect
oriented
programming
object
relational
mappers
orms
for
databases
and
more
although
there
are
often
alternative
ways
to
achieve
such
results
as
we
ll
see
the
roles
of
class
decorators
and
metaclasses
often
intersect
metaclasses
provide
a
formal
model
tailored
to
those
tasks
we
don
t
have
space
to
explore
all
such
applications
first
hand
in
this
chapter
but
you
should
feel
free
to
search
the
web
for
additional
use
cases
after
studying
the
basics
here
probably
the
reason
for
studying
metaclasses
most
relevant
to
this
book
is
that
this
topic
can
help
demystify
python
s
class
mechanics
in
general
although
you
may
or
may
not
code
or
reuse
them
in
your
work
a
cursory
understanding
of
metaclasses
can
impart
a
deeper
understanding
of
python
at
large
increasing
levels
of
magic
most
of
this
book
has
focused
on
straightforward
application
coding
techniques
as
most
programmers
spend
their
time
writing
modules
functions
and
classes
to
achieve
real
world
goals
they
may
use
classes
and
make
instances
and
might
even
do
a
bit
of
operator
overloading
but
they
probably
won
t
get
too
deep
into
the
details
of
how
their
classes
actually
work
chapter
metaclasses
however
in
this
book
we
ve
also
seen
a
variety
of
tools
that
allow
us
to
control
python
s
behavior
in
generic
ways
and
that
often
have
more
to
do
with
python
internals
or
tool
building
than
with
application
programming
domains
introspection
attributes
special
attributes
like
class
and
dict
allow
us
to
inspect
internal
implementation
aspects
of
python
objects
in
order
to
process
them
generically
to
list
all
attributes
of
an
object
display
a
class
s
name
and
so
on
operator
overloading
methods
specially
named
methods
such
as
str
and
add
coded
in
classes
intercept
and
provide
behavior
for
built
in
operations
applied
to
class
instances
such
as
printing
expression
operators
and
so
on
they
are
run
automatically
in
response
to
built
in
operations
and
allow
classes
to
conform
to
expected
interfaces
attribute
interception
methods
a
special
category
of
operator
overloading
methods
provide
a
way
to
intercept
attribute
accesses
on
instances
generically
getattr
setattr
and
getattribute
allow
wrapper
classes
to
insert
automatically
run
code
that
may
validate
attribute
requests
and
delegate
them
to
embedded
objects
they
allow
any
number
of
attributes
of
an
object
either
selected
attributes
or
all
of
them
to
be
computed
when
accessed
class
properties
the
property
built
in
allows
us
to
associate
code
with
a
specific
class
attribute
that
is
automatically
run
when
the
attribute
is
fetched
assigned
or
deleted
though
not
as
generic
as
the
prior
paragraph
s
tools
properties
allow
for
automatic
code
invocation
on
access
to
specific
attributes
class
attribute
descriptors
really
property
is
a
succinct
way
to
define
an
attribute
descriptor
that
runs
functions
on
access
automatically
descriptors
allow
us
to
code
in
a
separate
class
get
set
and
delete
handler
methods
that
are
run
automatically
when
an
attribute
assigned
to
an
instance
of
that
class
is
accessed
they
provide
a
general
way
to
insert
automatically
run
code
when
a
specific
attribute
is
accessed
and
they
are
triggered
after
an
attribute
is
looked
up
normally
function
and
class
decorators
as
we
saw
in
chapter
the
special
callable
syntax
for
decorators
allows
us
to
add
logic
to
be
automatically
run
when
a
function
is
called
or
a
class
instance
is
created
this
wrapper
logic
can
trace
or
time
calls
validate
arguments
manage
all
instances
of
a
class
augment
instances
with
extra
behavior
such
as
attribute
fetch
validation
and
more
decorator
syntax
inserts
name
rebinding
logic
to
be
run
at
the
end
of
function
and
class
definition
statements
decorated
function
and
class
names
are
rebound
to
callable
objects
that
intercept
later
calls
to
metaclass
or
not
to
metaclass
as
mentioned
in
this
chapter
s
introduction
metaclasses
are
a
continuation
of
this
story
they
allow
us
to
insert
logic
to
be
run
automatically
when
a
class
object
is
created
at
the
end
of
a
class
statement
this
logic
doesn
t
rebind
the
class
name
to
a
decorator
callable
but
rather
routes
creation
of
the
class
itself
to
specialized
logic
in
other
words
metaclasses
are
ultimately
just
another
way
to
define
automatically
run
code
via
metaclasses
and
the
other
tools
just
listed
python
provides
ways
for
us
to
interject
logic
in
a
variety
of
contexts
at
operator
evaluation
attribute
access
function
calls
class
instance
creation
and
now
class
object
creation
unlike
class
decorators
which
usually
add
logic
to
be
run
at
instance
creation
time
metaclasses
run
at
class
creation
time
as
such
they
are
hooks
generally
used
for
managing
or
augmenting
classes
instead
of
their
instances
for
example
metaclasses
can
be
used
to
add
decoration
to
all
methods
of
classes
automatically
register
all
classes
in
use
to
an
api
add
user
interface
logic
to
classes
automatically
create
or
extend
classes
from
simplified
specifications
in
text
files
and
so
on
because
we
can
control
how
classes
are
made
and
by
proxy
the
behavior
their
instances
acquire
their
applicability
is
potentially
very
wide
as
we
ve
also
seen
many
of
these
advanced
python
tools
have
intersecting
roles
for
example
attributes
can
often
be
managed
with
properties
descriptors
or
attribute
interception
methods
as
we
ll
see
in
this
chapter
class
decorators
and
metaclasses
can
often
be
used
interchangeably
as
well
although
class
decorators
are
often
used
to
manage
instances
they
can
be
used
to
manage
classes
instead
similarly
while
metaclasses
are
designed
to
augment
class
construction
they
can
often
insert
code
to
manage
instances
too
since
the
choice
of
which
technique
to
use
is
sometimes
purely
subjective
knowledge
of
the
alternatives
can
help
you
pick
the
right
tool
for
a
given
task
the
downside
of
helper
functions
also
like
the
decorators
of
the
prior
chapter
metaclasses
are
often
optional
from
a
theoretical
perspective
we
can
usually
achieve
the
same
effect
by
passing
class
objects
through
manager
functions
sometimes
known
as
helper
functions
much
as
we
can
achieve
the
goals
of
decorators
by
passing
functions
and
instances
through
manager
code
just
like
decorators
though
metaclasses
provide
a
more
formal
and
explicit
structure
help
ensure
that
application
programmers
won
t
forget
to
augment
their
classes
according
to
an
api
s
requirements
avoid
code
redundancy
and
its
associated
maintenance
costs
by
factoring
class
customization
logic
into
a
single
location
the
metaclass
to
illustrate
suppose
we
want
to
automatically
insert
a
method
into
a
set
of
classes
of
course
we
could
do
this
with
simple
inheritance
if
the
subject
method
is
known
chapter
metaclasses
when
we
code
the
classes
in
that
case
we
can
simply
code
the
method
in
a
superclass
and
have
all
the
classes
in
question
inherit
from
it
class
extras
def
extra
self
args
normal
inheritance
too
static
class
client
extras
class
client
extras
class
client
extras
clients
inherit
extra
methods
x
client
x
extra
make
an
instance
run
the
extra
methods
sometimes
though
it
s
impossible
to
predict
such
augmentation
when
classes
are
coded
consider
the
case
where
classes
are
augmented
in
response
to
choices
made
in
a
user
interface
at
runtime
or
to
specifications
typed
in
a
configuration
file
although
we
could
code
every
class
in
our
imaginary
set
to
manually
check
these
too
it
s
a
lot
to
ask
of
clients
required
is
abstract
here
it
s
something
to
be
filled
in
def
extra
self
arg
class
client
if
required
client
extra
extra
client
augments
too
distributed
class
client
if
required
client
extra
extra
class
client
if
required
client
extra
extra
x
client
x
extra
we
can
add
methods
to
a
class
after
the
class
statement
like
this
because
a
class
method
is
just
a
function
that
is
associated
with
a
class
and
has
a
first
argument
to
receive
the
self
instance
although
this
works
it
puts
all
the
burden
of
augmentation
on
client
classes
and
assumes
they
ll
remember
to
do
this
at
all
it
would
be
better
from
a
maintenance
perspective
to
isolate
the
choice
logic
in
a
single
place
we
might
encapsulate
some
of
this
extra
work
by
routing
classes
though
a
manager
function
such
a
manager
function
would
extend
the
class
as
required
and
handle
all
the
work
of
runtime
testing
and
configuration
def
extra
self
arg
def
extras
class
if
required
class
extra
extra
manager
function
too
manual
class
client
to
metaclass
or
not
to
metaclass
extras
client
class
client
extras
client
class
client
extras
client
x
client
x
extra
this
code
runs
the
class
through
a
manager
function
immediately
after
it
is
created
although
manager
functions
like
this
one
can
achieve
our
goal
here
they
still
put
a
fairly
heavy
burden
on
class
coders
who
must
understand
the
requirements
and
adhere
to
them
in
their
code
it
would
be
better
if
there
were
a
simple
way
to
enforce
the
augmentation
in
the
subject
classes
so
that
they
don
t
need
to
deal
with
and
can
t
forget
to
use
the
augmentation
in
other
words
we
d
like
to
be
able
to
insert
some
code
to
run
automatically
at
the
end
of
a
class
statement
to
augment
the
class
this
is
exactly
what
metaclasses
do
by
declaring
a
metaclass
we
tell
python
to
route
the
creation
of
the
class
object
to
another
class
we
provide
def
extra
self
arg
class
extras
type
def
init
class
classname
superclasses
attributedict
if
required
class
extra
extra
class
client
metaclass
extras
class
client
metaclass
extras
class
client
metaclass
extras
metaclass
declaration
only
client
class
is
instance
of
meta
x
client
x
extra
x
is
instance
of
client
because
python
invokes
the
metaclass
automatically
at
the
end
of
the
class
statement
when
the
new
class
is
created
it
can
augment
register
or
otherwise
manage
the
class
as
needed
moreover
the
only
requirement
for
the
client
classes
is
that
they
declare
the
metaclass
every
class
that
does
so
will
automatically
acquire
whatever
augmentation
the
metaclass
provides
both
now
and
in
the
future
if
the
metaclass
changes
although
it
may
be
difficult
to
see
in
this
small
example
metaclasses
generally
handle
such
tasks
better
than
other
approaches
metaclasses
versus
class
decorators
round
having
said
that
it
s
also
interesting
to
note
that
the
class
decorators
described
in
the
preceding
chapter
sometimes
overlap
with
metaclasses
in
terms
of
functionality
although
they
are
typically
used
for
managing
or
augmenting
instances
class
decorators
can
also
augment
classes
independent
of
any
created
instances
chapter
metaclasses
for
example
suppose
we
coded
our
manager
function
to
return
the
augmented
class
instead
of
simply
modifying
it
in
place
this
would
allow
a
greater
degree
of
flexibility
because
the
manager
would
be
free
to
return
any
type
of
object
that
implements
the
class
s
expected
interface
def
extra
self
arg
def
extras
class
if
required
class
extra
extra
return
class
class
client
client
extras
client
class
client
client
extras
client
class
client
client
extras
client
x
client
x
extra
if
you
think
this
is
starting
to
look
reminiscent
of
class
decorators
you
re
right
in
the
prior
chapter
we
presented
class
decorators
as
a
tool
for
augmenting
instance
creation
calls
because
they
work
by
automatically
rebinding
a
class
name
to
the
result
of
a
function
though
there
s
no
reason
that
we
can
t
use
them
to
augment
the
class
before
any
instances
are
ever
created
that
is
class
decorators
can
apply
extra
logic
to
classes
not
just
instances
at
creation
time
def
extra
self
arg
def
extras
class
if
required
class
extra
extra
return
class
extras
class
client
client
extras
client
extras
class
client
rebinds
class
independent
of
instances
extras
class
client
x
client
x
extra
makes
instance
of
augmented
class
x
is
instance
of
original
client
decorators
essentially
automate
the
prior
example
s
manual
name
rebinding
here
just
like
with
metaclasses
because
the
decorator
returns
the
original
class
instances
are
to
metaclass
or
not
to
metaclass
made
from
it
not
from
a
wrapper
object
in
fact
instance
creation
is
not
intercepted
at
all
in
this
specific
case
adding
methods
to
a
class
when
it
s
created
the
choice
between
metaclasses
and
decorators
is
somewhat
arbitrary
decorators
can
be
used
to
manage
both
instances
and
classes
and
they
intersect
with
metaclasses
in
the
second
of
these
roles
however
this
really
addresses
only
one
operational
mode
of
metaclasses
as
we
ll
see
decorators
correspond
to
metaclass
init
methods
in
this
role
but
metaclasses
have
additional
customization
hooks
as
we
ll
also
see
in
addition
to
class
initialization
metaclasses
can
perform
arbitrary
construction
tasks
that
might
be
more
difficult
with
decorators
moreover
although
decorators
can
manage
both
instances
and
classes
the
converse
is
not
as
direct
metaclasses
are
designed
to
manage
classes
and
applying
them
to
managing
instances
is
less
straightforward
we
ll
explore
this
difference
in
code
later
in
this
chapter
much
of
this
section
s
code
has
been
abstract
but
we
ll
flesh
it
out
into
a
real
working
example
later
in
this
chapter
to
fully
understand
how
metaclasses
work
though
we
first
need
to
get
a
clearer
picture
of
their
underlying
model
the
metaclass
model
to
really
understand
how
metaclasses
do
their
work
you
need
to
understand
a
bit
more
about
python
s
type
model
and
what
happens
at
the
end
of
a
class
statement
classes
are
instances
of
type
so
far
in
this
book
we
ve
done
most
of
our
work
by
making
instances
of
built
in
types
like
lists
and
strings
as
well
as
instances
of
classes
we
code
ourselves
as
we
ve
seen
instances
of
classes
have
some
state
information
attributes
of
their
own
but
they
also
inherit
behavioral
attributes
from
the
classes
from
which
they
are
made
the
same
holds
true
for
built
in
types
list
instances
for
example
have
values
of
their
own
but
they
inherit
methods
from
the
list
type
while
we
can
get
a
lot
done
with
such
instance
objects
python
s
type
model
turns
out
to
be
a
bit
richer
than
i
ve
formally
described
really
there
s
a
hole
in
the
model
we
ve
seen
thus
far
if
instances
are
created
from
classes
what
is
it
that
creates
our
classes
it
turns
out
that
classes
are
instances
of
something
too
in
python
user
defined
class
objects
are
instances
of
the
object
named
type
which
is
itself
a
class
in
python
new
style
classes
inherit
from
object
which
is
a
subclass
of
type
classic
classes
are
instances
of
type
and
are
not
created
from
a
class
chapter
metaclasses
we
explored
the
notion
of
types
in
chapter
and
the
relationship
of
classes
to
types
in
chapter
but
let
s
review
the
basics
here
so
we
can
see
how
they
apply
to
metaclasses
recall
that
the
type
built
in
returns
the
type
of
any
object
which
is
itself
an
object
for
built
in
types
like
lists
the
type
of
the
instance
is
the
built
in
list
type
but
the
type
of
the
list
type
is
the
type
type
itself
the
type
object
at
the
top
of
the
hierarchy
creates
specific
types
and
specific
types
create
instances
you
can
see
this
for
yourself
at
the
interactive
prompt
in
python
for
example
c
misc
c
python
python
type
class
list
type
type
class
type
type
list
class
type
type
type
class
type
in
list
is
instance
of
list
type
type
of
list
is
type
class
same
but
with
type
names
type
of
type
is
type
top
of
hierarchy
as
we
learned
when
studying
new
style
class
changes
in
chapter
the
same
is
generally
true
in
python
and
older
but
types
are
not
quite
the
same
as
classes
type
is
a
unique
kind
of
built
in
object
that
caps
the
type
hierarchy
and
is
used
to
construct
types
c
misc
c
python
python
type
type
list
type
type
type
type
in
type
is
a
bit
different
type
list
type
type
type
type
type
type
it
turns
out
that
the
type
instance
relationship
holds
true
for
classes
as
well
instances
are
created
from
classes
and
classes
are
created
from
type
in
python
though
the
notion
of
a
type
is
merged
with
the
notion
of
a
class
in
fact
the
two
are
essentially
synonyms
classes
are
types
and
types
are
classes
that
is
types
are
defined
by
classes
that
derive
from
type
user
defined
classes
are
instances
of
type
classes
user
defined
classes
are
types
that
generate
instances
of
their
own
as
we
saw
earlier
this
equivalence
effects
code
that
tests
the
type
of
instances
the
type
of
an
instance
is
the
class
from
which
it
was
generated
it
also
has
implications
for
the
way
that
classes
are
created
that
turn
out
to
be
the
key
to
this
chapter
s
subject
because
classes
are
normally
created
from
a
root
type
class
by
default
most
programmers
don
t
the
metaclass
model
need
to
think
about
this
type
class
equivalence
however
it
opens
up
new
possibilities
for
customizing
both
classes
and
their
instances
for
example
classes
in
and
new
style
classes
in
are
instances
of
the
type
class
and
instance
objects
are
instances
of
their
classes
in
fact
classes
now
have
a
class
that
links
to
type
just
as
an
instance
has
a
class
that
links
to
the
class
from
which
it
was
made
c
misc
c
python
python
class
c
pass
x
c
class
object
new
style
class
instance
object
type
x
class
main
c
x
class
class
main
c
instance
is
instance
of
class
type
c
class
type
c
class
class
type
class
is
instance
of
type
instance
s
class
class
s
class
is
type
notice
especially
the
last
two
lines
here
classes
are
instances
of
the
type
class
just
as
normal
instances
are
instances
of
a
class
this
works
the
same
for
both
built
ins
and
user
defined
class
types
in
in
fact
classes
are
not
really
a
separate
concept
at
all
they
are
simply
user
defined
types
and
type
itself
is
defined
by
a
class
in
python
things
work
similarly
for
new
style
classes
derived
from
object
because
this
enables
class
behavior
c
misc
c
python
python
class
c
object
pass
x
c
in
new
style
classes
classes
have
a
class
too
type
x
class
main
c
type
c
type
type
x
class
class
main
c
c
class
type
type
classic
classes
in
are
a
bit
different
though
because
they
reflect
the
class
model
in
older
python
releases
they
do
not
have
a
class
link
and
like
built
in
types
in
they
are
instances
of
type
not
a
type
class
c
misc
c
python
python
class
c
pass
x
c
chapter
metaclasses
in
classic
classes
classes
have
no
class
themselves
type
x
type
instance
type
c
type
classobj
x
class
class
main
c
at
x
f
a
c
class
attributeerror
class
c
has
no
attribute
class
metaclasses
are
subclasses
of
type
so
why
do
we
care
that
classes
are
instances
of
a
type
class
in
it
turns
out
that
this
is
the
hook
that
allows
us
to
code
metaclasses
because
the
notion
of
type
is
the
same
as
class
today
we
can
subclass
type
with
normal
object
oriented
techniques
and
class
syntax
to
customize
it
and
because
classes
are
really
instances
of
the
type
class
creating
classes
from
customized
subclasses
of
type
allows
us
to
implement
custom
kinds
of
classes
in
full
detail
this
all
works
out
quite
naturally
in
and
in
newstyle
classes
type
is
a
class
that
generates
user
defined
classes
metaclasses
are
subclasses
of
the
type
class
class
objects
are
instances
of
the
type
class
or
a
subclass
thereof
instance
objects
are
generated
from
a
class
in
other
words
to
control
the
way
classes
are
created
and
augment
their
behavior
all
we
need
to
do
is
specify
that
a
user
defined
class
be
created
from
a
user
defined
metaclass
instead
of
the
normal
type
class
notice
that
this
type
instance
relationship
is
not
quite
the
same
as
inheritance
userdefined
classes
may
also
have
superclasses
from
which
they
and
their
instances
inherit
attributes
inheritance
superclasses
are
listed
in
parentheses
in
the
class
statement
and
show
up
in
a
class
s
bases
tuple
the
type
from
which
a
class
is
created
and
of
which
it
is
an
instance
is
a
different
relationship
the
next
section
describes
the
procedure
python
follows
to
implement
this
instance
of
type
relationship
class
statement
protocol
subclassing
the
type
class
to
customize
it
is
really
only
half
of
the
magic
behind
metaclasses
we
still
need
to
somehow
route
a
class
s
creation
to
the
metaclass
instead
of
the
default
type
to
fully
understand
how
this
is
arranged
we
also
need
to
know
how
class
statements
do
their
business
we
ve
already
learned
that
when
python
reaches
a
class
statement
it
runs
its
nested
block
of
code
to
create
its
attributes
all
the
names
assigned
at
the
top
level
of
the
nested
code
block
generate
attributes
in
the
resulting
class
object
these
names
are
the
metaclass
model
usually
method
functions
created
by
nested
defs
but
they
can
also
be
arbitrary
attributes
assigned
to
create
class
data
shared
by
all
instances
technically
speaking
python
follows
a
standard
protocol
to
make
this
happen
at
the
end
of
a
class
statement
and
after
running
all
its
nested
code
in
a
namespace
dictionary
it
calls
the
type
object
to
create
the
class
object
class
type
classname
superclasses
attributedict
the
type
object
in
turn
defines
a
call
operator
overloading
method
that
runs
two
other
methods
when
the
type
object
is
called
type
new
typeclass
classname
superclasses
attributedict
type
init
class
classname
superclasses
attributedict
the
new
method
creates
and
returns
the
new
class
object
and
then
the
init
method
initializes
the
newly
created
object
as
we
ll
see
in
a
moment
these
are
the
hooks
that
metaclass
subclasses
of
type
generally
use
to
customize
classes
for
example
given
a
class
definition
like
the
following
class
spam
eggs
data
def
meth
self
arg
pass
inherits
from
eggs
class
data
attribute
class
method
attribute
python
will
internally
run
the
nested
code
block
to
create
two
attributes
of
the
class
data
and
meth
and
then
call
the
type
object
to
generate
the
class
object
at
the
end
of
the
class
statement
spam
type
spam
eggs
data
meth
meth
module
main
because
this
call
is
made
at
the
end
of
the
class
statement
it
s
an
ideal
hook
for
augmenting
or
otherwise
processing
a
class
the
trick
lies
in
replacing
type
with
a
custom
subclass
that
will
intercept
this
call
the
next
section
shows
how
declaring
metaclasses
as
we
ve
just
seen
classes
are
created
by
the
type
class
by
default
to
tell
python
to
create
a
class
with
a
custom
metaclass
instead
you
simply
need
to
declare
a
metaclass
to
intercept
the
normal
class
creation
call
how
you
do
so
depends
on
which
python
version
you
are
using
in
python
list
the
desired
metaclass
as
a
keyword
argument
in
the
class
header
class
spam
metaclass
meta
and
later
inheritance
superclasses
can
be
listed
in
the
header
as
well
before
the
metaclass
in
the
following
for
example
the
new
class
spam
inherits
from
eggs
but
is
also
an
instance
of
and
is
created
by
meta
class
spam
eggs
metaclass
meta
chapter
metaclasses
other
supers
okay
we
can
get
the
same
effect
in
python
but
we
must
specify
the
metaclass
differently
using
a
class
attribute
instead
of
a
keyword
argument
the
object
derivation
is
required
to
make
this
a
new
style
class
and
this
form
no
longer
works
in
as
the
attribute
is
simply
ignored
class
spam
object
metaclass
meta
version
only
in
a
module
global
metaclass
variable
is
also
available
to
link
all
classes
in
the
module
to
a
metaclass
this
is
no
longer
supported
in
as
it
was
intended
as
a
temporary
measure
to
make
it
easier
to
default
to
new
style
classes
without
deriving
every
class
from
object
when
declared
in
these
ways
the
call
to
create
the
class
object
run
at
the
end
of
the
class
statement
is
modified
to
invoke
the
metaclass
instead
of
the
type
default
class
meta
classname
superclasses
attributedict
and
because
the
metaclass
is
a
subclass
of
type
the
type
class
s
call
delegates
the
calls
to
create
and
initialize
the
new
class
object
to
the
metaclass
if
it
defines
custom
versions
of
these
methods
meta
new
meta
classname
superclasses
attributedict
meta
init
class
classname
superclasses
attributedict
to
demonstrate
here
s
the
prior
section
s
example
again
augmented
with
a
metaclass
specification
class
spam
eggs
metaclass
meta
data
def
meth
self
arg
pass
inherits
from
eggs
instance
of
meta
class
data
attribute
class
method
attribute
at
the
end
of
this
class
statement
python
internally
runs
the
following
to
create
the
class
object
spam
meta
spam
eggs
data
meth
meth
module
main
if
the
metaclass
defines
its
own
versions
of
new
or
init
they
will
be
invoked
in
turn
during
this
call
by
the
inherited
type
class
s
call
method
to
create
and
initialize
the
new
class
the
next
section
shows
how
we
might
go
about
coding
this
final
piece
of
the
metaclass
puzzle
coding
metaclasses
so
far
we
ve
seen
how
python
routes
class
creation
calls
to
a
metaclass
if
one
is
provided
how
though
do
we
actually
code
a
metaclass
that
customizes
type
it
turns
out
that
you
already
know
most
of
the
story
metaclasses
are
coded
with
normal
python
class
statements
and
semantics
their
only
substantial
distinctions
are
that
python
calls
them
automatically
at
the
end
of
a
class
statement
and
that
they
must
adhere
to
the
interface
expected
by
the
type
superclass
coding
metaclasses
a
basic
metaclass
perhaps
the
simplest
metaclass
you
can
code
is
simply
a
subclass
of
type
with
a
new
method
that
creates
the
class
object
by
running
the
default
version
in
type
a
metaclass
new
like
this
is
run
by
the
call
method
inherited
from
type
it
typically
performs
whatever
customization
is
required
and
calls
the
type
superclass
s
new
method
to
create
and
return
the
new
class
object
class
meta
type
def
new
meta
classname
supers
classdict
run
by
inherited
type
call
return
type
new
meta
classname
supers
classdict
this
metaclass
doesn
t
really
do
anything
we
might
as
well
let
the
default
type
class
create
the
class
but
it
demonstrates
the
way
a
metaclass
taps
into
the
metaclass
hook
to
customize
because
the
metaclass
is
called
at
the
end
of
a
class
statement
and
because
the
type
object
s
call
dispatches
to
the
new
and
init
methods
code
we
provide
in
these
methods
can
manage
all
the
classes
created
from
the
metaclass
here
s
our
example
in
action
again
with
prints
added
to
the
metaclass
and
the
file
at
large
to
trace
class
metaone
type
def
new
meta
classname
supers
classdict
print
in
metaone
new
classname
supers
classdict
sep
n
return
type
new
meta
classname
supers
classdict
class
eggs
pass
print
making
class
class
spam
eggs
metaclass
metaone
data
def
meth
self
arg
pass
inherits
from
eggs
instance
of
meta
class
data
attribute
class
method
attribute
print
making
instance
x
spam
print
data
x
data
here
spam
inherits
from
eggs
and
is
an
instance
of
metaone
but
x
is
an
instance
of
and
inherits
from
spam
when
this
code
is
run
with
python
notice
how
the
metaclass
is
invoked
at
the
end
of
the
class
statement
before
we
ever
make
an
instance
metaclasses
are
for
processing
classes
and
classes
are
for
processing
instances
making
class
in
metaone
new
spam
class
main
eggs
module
main
data
meth
function
meth
at
x
aeba
making
instance
data
chapter
metaclasses
customizing
construction
and
initialization
metaclasses
can
also
tap
into
the
init
protocol
invoked
by
the
type
object
s
call
in
general
new
creates
and
returns
the
class
object
and
init
initializes
the
already
created
class
metaclasses
can
use
both
hooks
to
manage
the
class
at
creation
time
class
metaone
type
def
new
meta
classname
supers
classdict
print
in
metaone
new
classname
supers
classdict
sep
n
return
type
new
meta
classname
supers
classdict
def
init
class
classname
supers
classdict
print
in
metaone
init
classname
supers
classdict
sep
n
print
init
class
object
list
class
dict
keys
class
eggs
pass
print
making
class
class
spam
eggs
metaclass
metaone
data
def
meth
self
arg
pass
inherits
from
eggs
instance
of
meta
class
data
attribute
class
method
attribute
print
making
instance
x
spam
print
data
x
data
in
this
case
the
class
initialization
method
is
run
after
the
class
construction
method
but
both
run
at
the
end
of
the
class
statement
before
any
instances
are
made
making
class
in
metaone
new
spam
class
main
eggs
module
main
data
meth
function
meth
at
x
aab
in
metaone
init
spam
class
main
eggs
module
main
data
meth
function
meth
at
x
aab
init
class
object
module
data
meth
doc
making
instance
data
other
metaclass
coding
techniques
although
redefining
the
type
superclass
s
new
and
init
methods
is
the
most
common
way
metaclasses
insert
logic
into
the
class
object
creation
process
other
schemes
are
possible
too
coding
metaclasses
using
simple
factory
functions
for
example
metaclasses
need
not
really
be
classes
at
all
as
we
ve
learned
the
class
statement
issues
a
simple
call
to
create
a
class
at
the
conclusion
of
its
processing
because
of
this
any
callable
object
can
in
principle
be
used
as
a
metaclass
provided
it
accepts
the
arguments
passed
and
returns
an
object
compatible
with
the
intended
class
in
fact
a
simple
object
factory
function
will
serve
just
as
well
as
a
class
a
simple
function
can
serve
as
a
metaclass
too
def
metafunc
classname
supers
classdict
print
in
metafunc
classname
supers
classdict
sep
n
return
type
classname
supers
classdict
class
eggs
pass
print
making
class
class
spam
eggs
metaclass
metafunc
data
def
meth
self
args
pass
run
simple
function
at
end
function
returns
class
print
making
instance
x
spam
print
data
x
data
when
run
the
function
is
called
at
the
end
of
the
declaring
class
statement
and
it
returns
the
expected
new
class
object
the
function
is
simply
catching
the
call
that
the
type
object
s
call
normally
intercepts
by
default
making
class
in
metafunc
spam
class
main
eggs
module
main
data
meth
function
meth
at
x
b
b
a
making
instance
data
overloading
class
creation
calls
with
metaclasses
since
they
participate
in
normal
oop
mechanics
it
s
also
possible
for
metaclasses
to
catch
the
creation
call
at
the
end
of
a
class
statement
directly
by
redefining
the
type
object
s
call
the
required
protocol
is
a
bit
involved
though
call
can
be
redefined
metas
can
have
metas
class
supermeta
type
def
call
meta
classname
supers
classdict
print
in
supermeta
call
classname
supers
classdict
sep
n
return
type
call
meta
classname
supers
classdict
class
submeta
type
metaclass
supermeta
def
new
meta
classname
supers
classdict
chapter
metaclasses
print
in
submeta
new
classname
supers
classdict
sep
n
return
type
new
meta
classname
supers
classdict
def
init
class
classname
supers
classdict
print
in
submeta
init
classname
supers
classdict
sep
n
print
init
class
object
list
class
dict
keys
class
eggs
pass
print
making
class
class
spam
eggs
metaclass
submeta
data
def
meth
self
arg
pass
print
making
instance
x
spam
print
data
x
data
when
this
code
is
run
all
three
redefined
methods
run
in
turn
this
is
essentially
what
the
type
object
does
by
default
making
class
in
supermeta
call
spam
class
main
eggs
module
main
data
meth
function
meth
at
x
b
ba
in
submeta
new
spam
class
main
eggs
module
main
data
meth
function
meth
at
x
b
ba
in
submeta
init
spam
class
main
eggs
module
main
data
meth
function
meth
at
x
b
ba
init
class
object
module
data
meth
doc
making
instance
data
overloading
class
creation
calls
with
normal
classes
the
preceding
example
is
complicated
by
the
fact
that
metaclasses
are
used
to
create
class
objects
but
don
t
generate
instances
of
themselves
because
of
this
with
metaclasses
name
lookup
rules
are
somewhat
different
than
what
we
are
accustomed
to
the
call
method
for
example
is
looked
up
in
the
class
of
an
object
for
metaclasses
this
means
the
metaclass
of
a
metaclass
to
use
normal
inheritance
based
name
lookup
we
can
achieve
the
same
effect
with
normal
classes
and
instances
the
output
of
the
following
is
the
same
as
the
preceding
version
but
note
that
new
and
init
must
have
different
names
here
or
else
they
will
run
when
the
submeta
instance
is
created
not
when
it
is
later
called
as
a
metaclass
coding
metaclasses
class
supermeta
def
call
self
classname
supers
classdict
print
in
supermeta
call
classname
supers
classdict
sep
n
class
self
new
classname
supers
classdict
self
init
class
classname
supers
classdict
return
class
class
submeta
supermeta
def
new
self
classname
supers
classdict
print
in
submeta
new
classname
supers
classdict
sep
n
return
type
classname
supers
classdict
def
init
self
class
classname
supers
classdict
print
in
submeta
init
classname
supers
classdict
sep
n
print
init
class
object
list
class
dict
keys
class
eggs
pass
print
making
class
class
spam
eggs
metaclass
submeta
data
def
meth
self
arg
pass
meta
is
normal
class
instance
called
at
end
of
statement
print
making
instance
x
spam
print
data
x
data
although
these
alternative
forms
work
most
metaclasses
get
their
work
done
by
redefining
the
type
superclass
s
new
and
init
in
practice
this
is
usually
as
much
control
as
is
required
and
it
s
often
simpler
than
other
schemes
however
we
ll
see
later
that
a
simple
function
based
metaclass
can
often
work
much
like
a
class
decorator
which
allows
the
metaclasses
to
manage
instances
as
well
as
classes
instances
versus
inheritance
because
metaclasses
are
specified
in
similar
ways
to
inheritance
superclasses
they
can
be
a
bit
confusing
at
first
glance
a
few
key
points
should
help
summarize
and
clarify
the
model
metaclasses
inherit
from
the
type
class
although
they
have
a
special
role
metaclasses
are
coded
with
class
statements
and
follow
the
usual
oop
model
in
python
for
example
as
subclasses
of
type
they
can
redefine
the
type
object
s
methods
overriding
and
customizing
them
as
needed
metaclasses
typically
redefine
the
type
class
s
new
and
init
to
customize
class
creation
and
initialization
but
they
can
also
redefine
call
if
they
wish
to
catch
the
end
of
class
creation
call
directly
although
it
s
unusual
they
can
even
be
simple
functions
that
return
arbitrary
objects
instead
of
type
subclasses
chapter
metaclasses
metaclass
declarations
are
inherited
by
subclasses
the
metaclass
m
declaration
in
a
user
defined
class
is
inherited
by
the
class
s
subclasses
too
so
the
metaclass
will
run
for
the
construction
of
each
class
that
inherits
this
specification
in
a
superclass
chain
metaclass
attributes
are
not
inherited
by
class
instances
metaclass
declarations
specify
an
instance
relationship
which
is
not
the
same
as
inheritance
because
classes
are
instances
of
metaclasses
the
behavior
defined
in
a
metaclass
applies
to
the
class
but
not
the
class
s
later
instances
instances
obtain
behavior
from
their
classes
and
superclasses
but
not
from
any
metaclasses
technically
instance
attribute
lookups
usually
search
only
the
dict
dictionaries
of
the
instance
and
all
its
classes
the
metaclass
is
not
included
in
inheritance
lookup
to
illustrate
the
last
two
points
consider
the
following
example
class
metaone
type
def
new
meta
classname
supers
classdict
redefine
type
method
print
in
metaone
new
classname
return
type
new
meta
classname
supers
classdict
def
toast
self
print
toast
class
super
metaclass
metaone
def
spam
self
print
spam
metaclass
inherited
by
subs
too
metaone
run
twice
for
two
classes
class
c
super
def
eggs
self
print
eggs
superclass
inheritance
versus
instance
classes
inherit
from
superclasses
but
not
from
metclasses
x
c
x
eggs
x
spam
x
toast
inherited
from
c
inherited
from
super
not
inherited
from
metaclass
when
this
code
is
run
the
metaclass
handles
construction
of
both
client
classes
and
instances
inherit
class
attributes
but
not
metaclass
attributes
in
metaone
new
super
in
metaone
new
c
eggs
spam
attributeerror
c
object
has
no
attribute
toast
although
detail
matters
it
s
important
to
keep
the
big
picture
in
mind
when
dealing
with
metaclasses
metaclasses
like
those
we
ve
seen
here
will
be
run
automatically
for
every
class
that
declares
them
unlike
the
helper
function
approaches
we
saw
earlier
such
classes
will
automatically
acquire
whatever
augmentation
the
metaclass
provides
moreover
changes
in
such
augmentation
only
need
to
be
coded
in
one
place
the
metaclass
which
simplifies
making
modifications
as
our
needs
evolve
like
so
many
tools
in
python
metaclasses
ease
maintenance
work
by
eliminating
redundancy
to
fully
sample
their
power
though
we
need
to
move
on
to
some
larger
use
case
examples
coding
metaclasses
example
adding
methods
to
classes
in
this
and
the
following
section
we
re
going
to
study
examples
of
two
common
use
cases
for
metaclasses
adding
methods
to
a
class
and
decorating
all
methods
automatically
these
are
just
two
of
the
many
metaclass
roles
which
unfortunately
consume
the
space
we
have
left
for
this
chapter
again
you
should
consult
the
web
for
more
advanced
applications
these
examples
are
representative
of
metaclasses
in
action
though
and
they
suffice
to
illustrate
the
basics
moreover
both
give
us
an
opportunity
to
contrast
class
decorators
and
metaclasses
our
first
example
compares
metaclass
and
decorator
based
implementations
of
class
augmentation
and
instance
wrapping
and
the
second
applies
a
decorator
with
a
metaclass
first
and
then
with
another
decorator
as
you
ll
see
the
two
tools
are
often
interchangeable
and
even
complementary
manual
augmentation
earlier
in
this
chapter
we
looked
at
skeleton
code
that
augmented
classes
by
adding
methods
to
them
in
various
ways
as
we
saw
simple
class
based
inheritance
suffices
if
the
extra
methods
are
statically
known
when
the
class
is
coded
composition
via
object
embedding
can
often
achieve
the
same
effect
too
for
more
dynamic
scenarios
though
other
techniques
are
sometimes
required
helper
functions
can
usually
suffice
but
metaclasses
provide
an
explicit
structure
and
minimize
the
maintenance
costs
of
changes
in
the
future
let
s
put
these
ideas
in
action
here
with
working
code
consider
the
following
example
of
manual
class
augmentation
it
adds
two
methods
to
two
classes
after
they
have
been
created
extend
manually
adding
new
methods
to
classes
class
client
def
init
self
value
self
value
value
def
spam
self
return
self
value
class
client
value
ni
def
eggsfunc
obj
return
obj
value
def
hamfunc
obj
value
return
value
ham
client
eggs
eggsfunc
client
ham
hamfunc
client
eggs
eggsfunc
chapter
metaclasses
client
ham
hamfunc
x
client
ni
print
x
spam
print
x
eggs
print
x
ham
bacon
y
client
print
y
eggs
print
y
ham
bacon
this
works
because
methods
can
always
be
assigned
to
a
class
after
it
s
been
created
as
long
as
the
methods
assigned
are
functions
with
an
extra
first
argument
to
receive
the
subject
self
instance
this
argument
can
be
used
to
access
state
information
accessible
from
the
class
instance
even
though
the
function
is
defined
independently
of
the
class
when
this
code
runs
we
receive
the
output
of
a
method
coded
inside
the
first
class
as
well
as
the
two
methods
added
to
the
classes
after
the
fact
ni
ni
ni
ni
ni
ni
baconham
ni
ni
ni
ni
baconham
this
scheme
works
well
in
isolated
cases
and
can
be
used
to
fill
out
a
class
arbitrarily
at
runtime
it
suffers
from
a
potentially
major
downside
though
we
have
to
repeat
the
augmentation
code
for
every
class
that
needs
these
methods
in
our
case
it
wasn
t
too
onerous
to
add
the
two
methods
to
both
classes
but
in
more
complex
scenarios
this
approach
can
be
time
consuming
and
error
prone
if
we
ever
forget
to
do
this
consistently
or
we
ever
need
to
change
the
augmentation
we
can
run
into
problems
metaclass
based
augmentation
although
manual
augmentation
works
in
larger
programs
it
would
be
better
if
we
could
apply
such
changes
to
an
entire
set
of
classes
automatically
that
way
we
d
avoid
the
chance
of
the
augmentation
being
botched
for
any
given
class
moreover
coding
the
augmentation
in
a
single
location
better
supports
future
changes
all
classes
in
the
set
will
pick
up
changes
automatically
one
way
to
meet
this
goal
is
to
use
metaclasses
if
we
code
the
augmentation
in
a
metaclass
every
class
that
declares
that
metaclass
will
be
augmented
uniformly
and
correctly
and
will
automatically
pick
up
any
changes
made
in
the
future
the
following
code
demonstrates
extend
with
a
metaclass
supports
future
changes
better
def
eggsfunc
obj
return
obj
value
example
adding
methods
to
classes
def
hamfunc
obj
value
return
value
ham
class
extender
type
def
new
meta
classname
supers
classdict
classdict
eggs
eggsfunc
classdict
ham
hamfunc
return
type
new
meta
classname
supers
classdict
class
client
metaclass
extender
def
init
self
value
self
value
value
def
spam
self
return
self
value
class
client
metaclass
extender
value
ni
x
client
ni
print
x
spam
print
x
eggs
print
x
ham
bacon
y
client
print
y
eggs
print
y
ham
bacon
this
time
both
of
the
client
classes
are
extended
with
the
new
methods
because
they
are
instances
of
a
metaclass
that
performs
the
augmentation
when
run
this
version
s
output
is
the
same
as
before
we
haven
t
changed
what
the
code
does
we
ve
just
refactored
it
to
encapsulate
the
augmentation
more
cleanly
ni
ni
ni
ni
ni
ni
baconham
ni
ni
ni
ni
baconham
notice
that
the
metaclass
in
this
example
still
performs
a
fairly
static
task
adding
two
known
methods
to
every
class
that
declares
it
in
fact
if
all
we
need
to
do
is
always
add
the
same
two
methods
to
a
set
of
classes
we
might
as
well
code
them
in
a
normal
superclass
and
inherit
in
subclasses
in
practice
though
the
metaclass
structure
supports
much
more
dynamic
behavior
for
instance
the
subject
class
might
also
be
configured
based
upon
arbitrary
logic
at
runtime
can
also
configure
class
based
on
runtime
tests
class
metaextend
type
def
new
meta
classname
supers
classdict
if
sometest
classdict
eggs
eggsfunc
else
classdict
eggs
eggsfunc
if
someothertest
chapter
metaclasses
classdict
ham
hamfunc
else
classdict
ham
lambda
args
not
supported
return
type
new
meta
classname
supers
classdict
metaclasses
versus
class
decorators
round
just
in
case
this
chapter
has
not
yet
managed
to
make
your
head
explode
keep
in
mind
again
that
the
prior
chapter
s
class
decorators
often
overlap
with
this
chapter
s
metaclasses
in
terms
of
functionality
this
derives
from
the
fact
that
class
decorators
rebind
class
names
to
the
result
of
a
function
at
the
end
of
a
class
statement
metaclasses
work
by
routing
class
object
creation
through
an
object
at
the
end
of
a
class
statement
although
these
are
slightly
different
models
in
practice
they
can
usually
achieve
the
same
goals
albeit
in
different
ways
in
fact
class
decorators
can
be
used
to
manage
both
instances
of
a
class
and
the
class
itself
while
decorators
can
manage
classes
naturally
though
it
s
somewhat
less
straightforward
for
metaclasses
to
manage
instances
metaclasses
are
probably
best
used
for
class
object
management
decorator
based
augmentation
for
example
the
prior
section
s
metaclass
example
which
adds
methods
to
a
class
on
creation
can
also
be
coded
as
a
class
decorator
in
this
mode
decorators
roughly
correspond
to
the
init
method
of
metaclasses
since
the
class
object
has
already
been
created
by
the
time
the
decorator
is
invoked
also
like
with
metaclasses
the
original
class
type
is
retained
since
no
wrapper
object
layer
is
inserted
the
output
of
the
following
is
the
same
as
that
of
the
prior
metaclass
code
extend
with
a
decorator
same
as
providing
init
in
a
metaclass
def
eggsfunc
obj
return
obj
value
def
hamfunc
obj
value
return
value
ham
def
extender
aclass
aclass
eggs
eggsfunc
aclass
ham
hamfunc
return
aclass
extender
class
client
def
init
self
value
self
value
value
def
spam
self
return
self
value
manages
class
not
instance
equiv
to
metaclass
init
client
extender
client
rebound
at
end
of
class
stmt
example
adding
methods
to
classes
extender
class
client
value
ni
x
client
ni
print
x
spam
print
x
eggs
print
x
ham
bacon
x
is
a
client
instance
y
client
print
y
eggs
print
y
ham
bacon
in
other
words
at
least
in
certain
cases
decorators
can
manage
classes
as
easily
as
metaclasses
the
converse
isn
t
quite
so
straightforward
though
metaclasses
can
be
used
to
manage
instances
but
only
with
a
certain
amount
of
magic
the
next
section
demonstrates
managing
instances
instead
of
classes
as
we
ve
just
seen
class
decorators
can
often
serve
the
same
class
management
role
as
metaclasses
metaclasses
can
often
serve
the
same
instance
management
role
as
decorators
too
but
this
is
a
bit
more
complex
that
is
class
decorators
can
manage
both
classes
and
instances
metaclasses
can
manage
both
classes
and
instances
but
instances
take
extra
work
that
said
certain
applications
may
be
better
coded
in
one
or
the
other
for
example
consider
the
following
class
decorator
example
from
the
prior
chapter
it
s
used
to
print
a
trace
message
whenever
any
normally
named
attribute
of
a
class
instance
is
fetched
class
decorator
to
trace
external
instance
attribute
fetches
def
tracer
aclass
class
wrapper
def
init
self
args
kargs
self
wrapped
aclass
args
kargs
def
getattr
self
attrname
print
trace
attrname
return
getattr
self
wrapped
attrname
return
wrapper
tracer
class
person
def
init
self
name
hours
rate
self
name
name
self
hours
hours
self
rate
rate
def
pay
self
return
self
hours
self
rate
bob
person
bob
chapter
metaclasses
on
decorator
on
instance
creation
use
enclosing
scope
name
catches
all
but
wrapped
delegate
to
wrapped
object
person
tracer
person
wrapper
remembers
person
in
method
fetch
not
traced
bob
is
really
a
wrapper
wrapper
embeds
a
person
triggers
getattr
print
bob
name
print
bob
pay
when
this
code
is
run
the
decorator
uses
class
name
rebinding
to
wrap
instance
objects
in
an
object
that
produces
the
trace
lines
in
the
following
output
trace
name
bob
trace
pay
although
it
s
possible
for
a
metaclass
to
achieve
the
same
effect
it
seems
less
straightforward
conceptually
metaclasses
are
designed
explicitly
to
manage
class
object
creation
and
they
have
an
interface
tailored
for
this
purpose
to
use
a
metaclass
to
manage
instances
we
have
to
rely
on
a
bit
more
magic
the
following
metaclass
has
the
same
effect
and
output
as
the
prior
decorator
manage
instances
like
the
prior
example
but
with
a
metaclass
def
tracer
classname
supers
classdict
aclass
type
classname
supers
classdict
class
wrapper
def
init
self
args
kargs
self
wrapped
aclass
args
kargs
def
getattr
self
attrname
print
trace
attrname
return
getattr
self
wrapped
attrname
return
wrapper
on
class
creation
call
make
client
class
class
person
metaclass
tracer
def
init
self
name
hours
rate
self
name
name
self
hours
hours
self
rate
rate
def
pay
self
return
self
hours
self
rate
make
person
with
tracer
wrapper
remembers
person
bob
person
bob
print
bob
name
print
bob
pay
bob
is
really
a
wrapper
wrapper
embeds
a
person
triggers
getattr
on
instance
creation
catches
all
but
wrapped
delegate
to
wrapped
object
in
method
fetch
not
traced
this
works
but
it
relies
on
two
tricks
first
it
must
use
a
simple
function
instead
of
a
class
because
type
subclasses
must
adhere
to
object
creation
protocols
second
it
must
manually
create
the
subject
class
by
calling
type
manually
it
needs
to
return
an
instance
wrapper
but
metaclasses
are
also
responsible
for
creating
and
returning
the
subject
class
really
we
re
using
the
metaclass
protocol
to
imitate
decorators
in
this
example
rather
than
vice
versa
because
both
run
at
the
conclusion
of
a
class
statement
in
many
roles
they
are
just
variations
on
a
theme
this
metaclass
version
produces
the
same
output
as
the
decorator
when
run
live
trace
name
bob
trace
pay
example
adding
methods
to
classes
you
should
study
both
versions
of
these
examples
for
yourself
to
weigh
their
tradeoffs
in
general
though
metaclasses
are
probably
best
suited
to
class
management
due
to
their
design
class
decorators
can
manage
either
instances
or
classes
though
they
may
not
be
the
best
option
for
more
advanced
metaclass
roles
that
we
don
t
have
space
to
cover
in
this
book
if
you
want
to
learn
more
about
decorators
and
metaclasses
after
reading
this
chapter
search
the
web
or
python
s
standard
manuals
the
next
section
concludes
this
chapter
with
one
more
common
use
case
applying
operations
to
a
class
s
methods
automatically
example
applying
decorators
to
methods
as
we
saw
in
the
prior
section
because
they
are
both
run
at
the
end
of
a
class
statement
metaclasses
and
decorators
can
often
be
used
interchangeably
albeit
with
different
syntax
the
choice
between
the
two
is
arbitrary
in
many
contexts
it
s
also
possible
to
use
them
in
combination
as
complementary
tools
in
this
section
we
ll
explore
an
example
of
just
such
a
combination
applying
a
function
decorator
to
all
the
methods
of
a
class
tracing
with
decoration
manually
in
the
prior
chapter
we
coded
two
function
decorators
one
that
traced
and
counted
all
calls
made
to
a
decorated
function
and
another
that
timed
such
calls
they
took
various
forms
there
some
of
which
were
applicable
to
both
functions
and
methods
and
some
of
which
were
not
the
following
collects
both
decorators
final
forms
into
a
module
file
for
reuse
and
reference
here
file
mytools
py
assorted
decorator
tools
def
tracer
func
use
function
not
class
with
call
calls
else
self
is
decorator
instance
only
def
oncall
args
kwargs
nonlocal
calls
calls
print
call
s
to
s
calls
func
name
return
func
args
kwargs
return
oncall
import
time
def
timer
label
trace
true
def
ondecorator
func
def
oncall
args
kargs
start
time
clock
result
func
args
kargs
elapsed
time
clock
start
oncall
alltime
elapsed
if
trace
format
s
s
f
f
values
label
func
name
print
format
values
chapter
metaclasses
on
decorator
args
retain
args
on
retain
decorated
func
on
calls
call
original
state
is
scopes
func
attr
elapsed
oncall
alltime
return
result
oncall
alltime
return
oncall
return
ondecorator
as
we
learned
in
the
prior
chapter
to
use
these
decorators
manually
we
simply
import
them
from
the
module
and
code
the
decoration
syntax
before
each
method
we
wish
to
trace
or
time
from
mytools
import
tracer
class
person
tracer
def
init
self
name
pay
self
name
name
self
pay
pay
tracer
def
giveraise
self
percent
self
pay
percent
tracer
def
lastname
self
return
self
name
split
bob
person
bob
smith
sue
person
sue
jones
print
bob
name
sue
name
sue
giveraise
print
sue
pay
print
bob
lastname
sue
lastname
giveraise
tracer
giverraise
oncall
remembers
giveraise
lastname
tracer
lastname
runs
oncall
sue
runs
oncall
bob
remembers
lastname
when
this
code
is
run
we
get
the
following
output
calls
to
decorated
methods
are
routed
to
logic
that
intercepts
and
then
delegates
the
call
because
the
original
method
names
have
been
bound
to
the
decorator
call
to
init
call
to
init
bob
smith
sue
jones
call
to
giveraise
call
to
lastname
call
to
lastname
smith
jones
tracing
with
metaclasses
and
decorators
the
manual
decoration
scheme
of
the
prior
section
works
but
it
requires
us
to
add
decoration
syntax
before
each
method
we
wish
to
trace
and
to
later
remove
that
syntax
when
we
no
longer
desire
tracing
if
we
want
to
trace
every
method
of
a
class
this
can
become
tedious
in
larger
programs
it
would
be
better
if
we
could
somehow
apply
the
tracer
decorator
to
all
of
a
class
s
methods
automatically
example
applying
decorators
to
methods
with
metaclasses
we
can
do
exactly
that
because
they
are
run
when
a
class
is
constructed
they
are
a
natural
place
to
add
decoration
wrappers
to
a
class
s
methods
by
scanning
the
class
s
attribute
dictionary
and
testing
for
function
objects
there
we
can
automatically
run
methods
through
the
decorator
and
rebind
the
original
names
to
the
results
the
effect
is
the
same
as
the
automatic
method
name
rebinding
of
decorators
but
we
can
apply
it
more
globally
metaclass
that
adds
tracing
decorator
to
every
method
of
a
client
class
from
types
import
functiontype
from
mytools
import
tracer
class
metatrace
type
def
new
meta
classname
supers
classdict
for
attr
attrval
in
classdict
items
if
type
attrval
is
functiontype
classdict
attr
tracer
attrval
return
type
new
meta
classname
supers
classdict
method
decorate
it
make
class
class
person
metaclass
metatrace
def
init
self
name
pay
self
name
name
self
pay
pay
def
giveraise
self
percent
self
pay
percent
def
lastname
self
return
self
name
split
bob
person
bob
smith
sue
person
sue
jones
print
bob
name
sue
name
sue
giveraise
print
sue
pay
print
bob
lastname
sue
lastname
when
this
code
is
run
the
results
are
the
same
as
before
calls
to
methods
are
routed
to
the
tracing
decorator
first
for
tracing
and
then
propagated
on
to
the
original
method
call
to
init
call
to
init
bob
smith
sue
jones
call
to
giveraise
call
to
lastname
call
to
lastname
smith
jones
the
result
you
see
here
is
a
combination
of
decorator
and
metaclass
work
the
metaclass
automatically
applies
the
function
decorator
to
every
method
at
class
creation
time
and
the
function
decorator
automatically
intercepts
method
calls
in
order
to
print
the
trace
messages
in
this
output
the
combination
just
works
thanks
to
the
generality
of
both
tools
chapter
metaclasses
applying
any
decorator
to
methods
the
prior
metaclass
example
works
for
just
one
specific
function
decorator
tracing
however
it
s
trivial
to
generalize
this
to
apply
any
decorator
to
all
the
methods
of
a
class
all
we
have
to
do
is
add
an
outer
scope
layer
to
retain
the
desired
decorator
much
like
we
did
for
decorators
in
the
prior
chapter
the
following
for
example
codes
such
a
generalization
and
then
uses
it
to
apply
the
tracer
decorator
again
metaclass
factory
apply
any
decorator
to
all
methods
of
a
class
from
types
import
functiontype
from
mytools
import
tracer
timer
def
decorateall
decorator
class
metadecorate
type
def
new
meta
classname
supers
classdict
for
attr
attrval
in
classdict
items
if
type
attrval
is
functiontype
classdict
attr
decorator
attrval
return
type
new
meta
classname
supers
classdict
return
metadecorate
class
person
metaclass
decorateall
tracer
def
init
self
name
pay
self
name
name
self
pay
pay
def
giveraise
self
percent
self
pay
percent
def
lastname
self
return
self
name
split
apply
a
decorator
to
all
bob
person
bob
smith
sue
person
sue
jones
print
bob
name
sue
name
sue
giveraise
print
sue
pay
print
bob
lastname
sue
lastname
when
this
code
is
run
as
it
is
the
output
is
again
the
same
as
that
of
the
previous
examples
we
re
still
ultimately
decorating
every
method
in
a
client
class
with
the
tracer
function
decorator
but
we
re
doing
so
in
a
more
generic
fashion
call
to
init
call
to
init
bob
smith
sue
jones
call
to
giveraise
call
to
lastname
call
to
lastname
smith
jones
now
to
apply
a
different
decorator
to
the
methods
we
can
simply
replace
the
decorator
name
in
the
class
header
line
to
use
the
timer
function
decorator
shown
earlier
for
example
we
could
use
either
of
the
last
two
header
lines
in
the
following
when
defining
example
applying
decorators
to
methods
our
class
the
first
accepts
the
timer
s
default
arguments
and
the
second
specifies
label
text
class
person
metaclass
decorateall
tracer
apply
tracer
class
person
metaclass
decorateall
timer
apply
timer
defaults
class
person
metaclass
decorateall
timer
label
decorator
arguments
notice
that
this
scheme
cannot
support
nondefault
decorator
arguments
differing
per
method
but
it
can
pass
in
decorator
arguments
that
apply
to
all
methods
as
done
here
to
test
use
the
last
of
these
metaclass
declarations
to
apply
the
timer
and
add
the
following
lines
at
the
end
of
the
script
if
using
timer
total
time
per
method
print
print
f
person
init
alltime
print
f
person
giveraise
alltime
print
f
person
lastname
alltime
the
new
output
is
as
follows
the
metaclass
wraps
methods
in
timer
decorators
now
so
we
can
tell
how
long
each
and
every
call
takes
for
every
method
of
the
class
init
init
bob
smith
sue
jones
giveraise
lastname
lastname
smith
jones
metaclasses
versus
class
decorators
round
class
decorators
intersect
with
metaclasses
here
too
the
following
version
replaces
the
preceding
example
s
metaclass
with
a
class
decorator
it
defines
and
uses
a
class
decorator
that
applies
a
function
decorator
to
all
methods
of
a
class
although
the
prior
sentence
may
sound
more
like
a
zen
statement
than
a
technical
description
this
all
works
quite
naturally
python
s
decorators
support
arbitrary
nesting
and
combinations
class
decorator
factory
apply
any
decorator
to
all
methods
of
a
class
from
types
import
functiontype
from
mytools
import
tracer
timer
def
decorateall
decorator
def
decodecorate
aclass
chapter
metaclasses
for
attr
attrval
in
aclass
dict
items
if
type
attrval
is
functiontype
setattr
aclass
attr
decorator
attrval
return
aclass
return
decodecorate
decorateall
tracer
class
person
def
init
self
name
pay
self
name
name
self
pay
pay
def
giveraise
self
percent
self
pay
percent
def
lastname
self
return
self
name
split
not
dict
use
a
class
decorator
applies
func
decorator
to
methods
person
decorateall
person
person
decodecorate
person
bob
person
bob
smith
sue
person
sue
jones
print
bob
name
sue
name
sue
giveraise
print
sue
pay
print
bob
lastname
sue
lastname
when
this
code
is
run
as
it
is
the
class
decorator
applies
the
tracer
function
decorator
to
every
method
and
produces
a
trace
message
on
calls
the
output
is
the
same
as
that
of
the
preceding
metaclass
version
of
this
example
call
to
init
call
to
init
bob
smith
sue
jones
call
to
giveraise
call
to
lastname
call
to
lastname
smith
jones
notice
that
the
class
decorator
returns
the
original
augmented
class
not
a
wrapper
layer
for
it
as
is
common
when
wrapping
instance
objects
instead
as
for
the
metaclass
version
we
retain
the
type
of
the
original
class
an
instance
of
person
is
an
instance
of
person
not
of
some
wrapper
class
in
fact
this
class
decorator
deals
with
class
creation
only
instance
creation
calls
are
not
intercepted
at
all
this
distinction
can
matter
in
programs
that
require
type
testing
for
instances
to
yield
the
original
class
not
a
wrapper
when
augmenting
a
class
instead
of
an
instance
class
decorators
can
retain
the
original
class
type
the
class
s
methods
are
not
their
original
functions
because
they
are
rebound
to
decorators
but
this
is
less
important
in
practice
and
it
s
true
in
the
metaclass
alternative
as
well
also
note
that
like
the
metaclass
version
this
structure
cannot
support
function
decorator
arguments
that
differ
per
method
but
it
can
handle
such
arguments
if
they
apply
to
all
methods
to
use
this
scheme
to
apply
the
timer
decorator
for
example
either
of
the
last
two
decoration
lines
in
the
following
will
suffice
if
coded
just
before
our
class
example
applying
decorators
to
methods
definition
the
first
uses
decorator
argument
defaults
and
the
second
provides
one
explicitly
decorateall
tracer
decorate
all
with
tracer
decorateall
timer
decorate
all
with
timer
defaults
decorateall
timer
label
same
but
pass
a
decorator
argument
as
before
let
s
use
the
last
of
these
decorator
lines
and
add
the
following
at
the
end
of
the
script
to
test
our
example
with
a
different
decorator
if
using
timer
total
time
per
method
print
print
f
person
init
alltime
print
f
person
giveraise
alltime
print
f
person
lastname
alltime
the
same
sort
of
output
appears
for
every
method
we
get
timing
data
for
each
and
all
calls
but
we
ve
passed
a
different
label
argument
to
the
timer
decorator
init
init
bob
smith
sue
jones
giveraise
lastname
lastname
smith
jones
as
you
can
see
metaclasses
and
class
decorators
are
not
only
often
interchangeable
but
also
commonly
complementary
both
provide
advanced
but
powerful
ways
to
customize
and
manage
both
class
and
instance
objects
because
both
ultimately
allow
you
to
insert
code
into
the
class
creation
process
although
some
more
advanced
applications
may
be
better
coded
with
one
or
the
other
the
way
you
choose
or
combine
these
two
tools
in
many
cases
is
largely
up
to
you
optional
language
features
i
included
a
quote
near
the
start
of
this
chapter
about
metaclasses
not
being
of
interest
to
of
python
programmers
to
underscore
their
relative
obscurity
that
statement
is
not
quite
accurate
though
and
not
just
numerically
so
the
quote
s
author
is
a
friend
of
mine
from
the
early
days
of
python
and
i
don
t
mean
to
pick
on
anyone
unfairly
moreover
i
ve
often
made
such
statements
about
language
feature
obscurity
myself
in
this
very
book
in
fact
the
problem
though
is
that
such
statements
really
only
apply
to
people
who
work
alone
and
only
ever
use
code
that
they
ve
written
themselves
as
soon
as
an
optional
chapter
metaclasses
advanced
language
feature
is
used
by
anyone
in
an
organization
it
is
no
longer
optional
it
is
effectively
imposed
on
everyone
in
the
organization
the
same
holds
true
for
externally
developed
software
you
use
in
your
systems
if
the
software
s
author
uses
an
advanced
language
feature
it
s
no
longer
entirely
optional
for
you
because
you
have
to
understand
the
feature
to
use
or
change
the
code
this
observation
applies
to
all
the
advanced
tools
listed
near
the
beginning
of
this
chapter
decorators
properties
descriptors
metaclasses
and
so
on
if
any
person
or
program
you
need
to
work
with
uses
them
they
automatically
become
part
of
your
required
knowledge
base
too
that
is
nothing
is
truly
optional
if
nothing
is
truly
optional
most
of
us
don
t
get
to
pick
and
choose
this
is
why
some
python
old
timers
myself
included
sometimes
lament
that
python
seems
to
have
grown
larger
and
more
complex
over
time
new
features
added
by
veterans
seem
to
have
raised
the
intellectual
bar
for
newcomers
although
python
s
core
ideas
like
dynamic
typing
and
built
in
types
have
remained
essentially
the
same
its
advanced
additions
can
become
required
reading
for
any
python
programmer
i
chose
to
cover
these
topics
here
for
this
reason
despite
the
omission
of
most
in
prior
editions
it
s
not
possible
to
skip
the
advanced
stuff
if
it
s
in
code
you
have
to
understand
on
the
other
hand
many
new
learners
can
pick
up
advanced
topics
as
needed
and
frankly
application
programmers
tend
to
spend
most
of
their
time
dealing
with
libraries
and
extensions
not
advanced
and
sometimes
arcane
language
features
for
instance
the
book
programming
python
a
follow
up
to
this
one
deals
mostly
with
the
marriage
of
python
to
application
libraries
for
tasks
such
as
guis
databases
and
the
web
not
with
esoteric
language
tools
the
flipside
of
this
growth
is
that
python
has
become
more
powerful
when
used
well
tools
like
decorators
and
metaclasses
are
not
only
arguably
cool
but
allow
creative
programmers
to
build
more
flexible
and
useful
apis
for
other
programmers
to
use
as
we
ve
seen
they
can
also
provide
good
solutions
to
problems
of
encapsulation
and
maintenance
whether
this
justifies
the
potential
expansion
of
required
python
knowledge
is
up
to
you
to
decide
unfortunately
a
person
s
skill
level
often
decides
this
issue
by
default
more
advanced
programmers
like
more
advanced
tools
and
tend
to
forget
about
their
impact
on
other
camps
fortunately
though
this
isn
t
an
absolute
good
programmers
also
understand
that
simplicity
is
good
engineering
and
advanced
tools
should
be
used
only
when
warranted
this
is
true
in
any
programming
language
but
especially
in
a
language
like
python
that
is
frequently
exposed
to
new
or
novice
programmers
as
an
extension
tool
if
you
re
still
not
buying
this
keep
in
mind
that
there
are
very
many
python
users
who
are
not
comfortable
with
even
basic
oop
and
classes
trust
me
on
this
i
ve
met
thousands
of
them
python
based
systems
that
require
their
users
to
master
the
nuances
of
metaclasses
decorators
and
the
like
should
probably
scale
their
market
expectations
accordingly
example
applying
decorators
to
methods
chapter
summary
in
this
chapter
we
studied
metaclasses
and
explored
examples
of
them
in
action
metaclasses
allow
us
to
tap
into
the
class
creation
protocol
of
python
in
order
to
manage
or
augment
user
defined
classes
because
they
automate
this
process
they
can
provide
better
solutions
for
api
writers
then
manual
code
or
helper
functions
because
they
encapsulate
such
code
they
can
minimize
maintenance
costs
better
than
some
other
approaches
along
the
way
we
also
saw
how
the
roles
of
class
decorators
and
metaclasses
often
intersect
because
both
run
at
the
conclusion
of
a
class
statement
they
can
sometimes
be
used
interchangeably
class
decorators
can
be
used
to
manage
both
class
and
instance
objects
metaclasses
can
too
although
they
are
more
directly
targeted
toward
classes
since
this
chapter
covered
an
advanced
topic
we
ll
work
through
just
a
few
quiz
questions
to
review
the
basics
if
you
ve
made
it
this
far
in
a
chapter
on
metaclasses
you
probably
already
deserve
extra
credit
because
this
is
the
last
part
of
the
book
we
ll
forego
the
end
of
part
exercises
be
sure
to
see
the
appendixes
that
follow
for
pointers
on
installation
steps
and
the
solutions
to
the
prior
parts
exercises
once
you
finish
the
quiz
you
ve
officially
reached
the
end
of
this
book
now
that
you
know
python
inside
and
out
your
next
step
should
you
choose
to
take
it
is
to
explore
the
libraries
techniques
and
tools
available
in
the
application
domains
in
which
you
work
because
python
is
so
widely
used
you
ll
find
ample
resources
for
using
it
in
almost
any
application
you
can
think
of
from
guis
the
web
and
databases
to
numeric
programming
robotics
and
system
administration
this
is
where
python
starts
to
become
truly
fun
but
this
is
also
where
this
book
s
story
ends
and
others
begin
for
pointers
on
where
to
turn
after
this
book
see
the
list
of
recommended
follow
up
texts
in
the
preface
good
luck
with
your
journey
and
of
course
always
look
on
the
bright
side
of
life
test
your
knowledge
quiz
what
is
a
metaclass
how
do
you
declare
the
metaclass
of
a
class
how
do
class
decorators
overlap
with
metaclasses
for
managing
classes
how
do
class
decorators
overlap
with
metaclasses
for
managing
instances
would
you
rather
count
decorators
or
metaclasses
amongst
your
weaponry
and
please
phrase
your
answer
in
terms
of
a
popular
monty
python
skit
chapter
metaclasses
test
your
knowledge
answers
a
metaclass
is
a
class
used
to
create
a
class
normal
classes
are
instances
of
the
type
class
by
default
metaclasses
are
usually
subclasses
of
the
type
class
which
redefines
class
creation
protocol
methods
in
order
to
customize
the
class
creation
call
issued
at
the
end
of
a
class
statement
they
typically
redefine
the
methods
new
and
init
to
tap
into
the
class
creation
protocol
metaclasses
can
also
be
coded
other
ways
as
simple
functions
for
example
but
they
are
responsible
for
making
and
returning
an
object
for
the
new
class
in
python
and
later
use
a
keyword
argument
in
the
class
header
line
class
c
metaclass
m
in
python
x
use
a
class
attribute
instead
metaclass
m
in
the
class
header
line
can
also
name
normal
superclasses
a
k
a
base
classes
before
the
metaclass
keyword
argument
because
both
are
automatically
triggered
at
the
end
of
a
class
statement
class
decorators
and
metaclasses
can
both
be
used
to
manage
classes
decorators
rebind
a
class
name
to
a
callable
s
result
and
metaclasses
route
class
creation
through
a
callable
but
both
hooks
can
be
used
for
similar
purposes
to
manage
classes
decorators
simply
augment
and
return
the
original
class
objects
metaclasses
augment
a
class
after
they
create
it
because
both
are
automatically
triggered
at
the
end
of
a
class
statement
class
decorators
and
metaclasses
can
both
be
used
to
manage
class
instances
by
inserting
a
wrapper
object
to
catch
instance
creation
calls
decorators
may
rebind
the
class
name
to
a
callable
run
on
instance
creation
that
retains
the
original
class
object
metaclasses
can
do
the
same
but
they
must
also
create
the
class
object
so
their
usage
is
somewhat
more
complex
in
this
role
our
chief
weapon
is
decorators
decorators
and
metaclasses
metaclasses
and
decorators
our
two
weapons
are
metaclasses
and
decorators
and
ruthless
efficiency
our
three
weapons
are
metaclasses
decorators
and
ruthless
efficiency
and
an
almost
fanatical
devotion
to
guido
our
four
no
amongst
our
weapons
amongst
our
weaponry
are
such
elements
as
metaclasses
decorators
i
ll
come
in
again
test
your
knowledge
answers
part
ix
appendixes
appendix
a
installation
and
configuration
this
appendix
provides
additional
installation
and
configuration
details
as
a
resource
for
people
new
to
such
topics
installing
the
python
interpreter
because
you
need
the
python
interpreter
to
run
python
scripts
the
first
step
in
using
python
is
usually
installing
python
unless
one
is
already
available
on
your
machine
you
ll
need
to
fetch
install
and
possibly
configure
a
recent
version
of
python
on
your
computer
you
ll
only
need
to
do
this
once
per
machine
and
if
you
will
be
running
a
frozen
binary
described
in
chapter
or
self
installing
system
you
may
not
need
to
do
much
more
is
python
already
present
before
you
do
anything
else
check
whether
you
already
have
a
recent
python
on
your
machine
if
you
are
working
on
linux
mac
os
x
or
some
unix
systems
python
is
probably
already
installed
on
your
computer
though
it
may
be
one
or
two
releases
behind
the
cutting
edge
here
s
how
to
check
on
windows
check
whether
there
is
a
python
entry
in
the
start
button
s
all
programs
menu
at
the
bottom
left
of
the
screen
on
mac
os
x
open
a
terminal
window
applications
utilities
terminal
and
type
python
at
the
prompt
on
linux
and
unix
type
python
at
a
shell
prompt
a
k
a
terminal
window
and
see
what
happens
alternatively
try
searching
for
python
in
the
usual
places
usr
bin
usr
local
bin
etc
if
you
find
a
python
make
sure
it
s
a
recent
version
although
any
recent
python
will
do
for
most
of
this
text
this
edition
focuses
on
python
and
specifically
so
you
may
want
to
install
one
of
these
to
run
some
of
the
examples
in
this
book
speaking
of
versions
i
recommend
starting
out
with
python
or
later
if
you
re
learning
python
anew
and
don
t
need
to
deal
with
existing
x
code
otherwise
you
should
generally
use
python
some
popular
python
based
systems
still
use
older
releases
though
is
still
widespread
so
if
you
re
working
with
existing
systems
be
sure
to
use
a
version
relevant
to
your
needs
the
next
section
describes
locations
where
you
can
fetch
a
variety
of
python
versions
where
to
get
python
if
there
is
no
python
on
your
machine
you
will
need
to
install
one
yourself
the
good
news
is
that
python
is
an
open
source
system
that
is
freely
available
on
the
web
and
very
easy
to
install
on
most
platforms
you
can
always
fetch
the
latest
and
greatest
standard
python
release
from
http
www
python
org
python
s
official
website
look
for
the
downloads
link
on
that
page
and
choose
a
release
for
the
platform
on
which
you
will
be
working
you
ll
find
prebuilt
self
installer
files
for
windows
run
to
install
installer
disk
images
for
mac
os
x
installed
per
mac
conventions
the
full
source
code
distribution
typically
compiled
on
linux
unix
or
os
x
machines
to
generate
an
interpreter
and
more
although
python
is
standard
on
linux
these
days
you
can
also
find
rpms
for
linux
on
the
web
unpack
them
with
rpm
python
s
website
also
has
links
to
pages
where
versions
for
other
platforms
are
maintained
either
at
python
org
itself
or
offsite
a
google
web
search
is
another
great
way
to
find
python
packages
among
other
platforms
you
can
find
python
pre
built
for
ipods
palm
handhelds
nokia
cell
phones
playstation
and
psp
solaris
as
and
windows
mobile
if
you
find
yourself
pining
for
a
unix
environment
on
a
windows
machine
you
might
also
be
interested
in
installing
cygwin
and
its
version
of
python
see
http
www
cygwin
com
cygwin
is
a
gpl
licensed
library
and
toolset
that
provides
full
unix
functionality
on
windows
machines
and
it
includes
a
prebuilt
python
that
makes
use
of
the
all
the
unix
tools
provided
you
can
also
find
python
on
cd
roms
supplied
with
linux
distributions
included
with
some
products
and
computer
systems
and
enclosed
with
some
other
python
books
these
tend
to
lag
behind
the
current
release
somewhat
but
usually
not
seriously
so
in
addition
you
can
find
python
in
some
free
and
commercial
development
bundles
for
example
activestate
distributes
python
as
part
of
its
activepython
a
package
that
combines
standard
python
with
extensions
for
windows
development
such
as
pywin
an
ide
called
pythonwin
described
in
chapter
and
other
commonly
used
extensions
python
can
also
be
had
today
in
the
enthought
python
distribution
a
package
aimed
at
scientific
computing
needs
as
well
as
in
portable
python
preconfigured
to
run
directly
from
a
portable
device
search
the
web
for
details
appendix
a
installation
and
configuration
finally
if
you
are
interested
in
alternative
python
implementations
run
a
web
search
to
check
out
jython
the
python
port
to
the
java
environment
and
ironpython
python
for
the
c
net
world
both
of
which
are
described
in
chapter
installation
of
these
systems
is
beyond
the
scope
of
this
book
installation
steps
once
you
ve
downloaded
python
you
need
to
install
it
installation
steps
are
very
platform
specific
but
here
are
a
few
pointers
for
the
major
python
platforms
windows
on
windows
python
comes
as
a
self
installer
msi
program
file
simply
doubleclick
on
its
file
icon
and
answer
yes
or
next
at
every
prompt
to
perform
a
default
install
the
default
install
includes
python
s
documentation
set
and
support
for
tkinter
tkinter
in
python
guis
shelve
databases
and
the
idle
development
gui
python
and
are
normally
installed
in
the
directories
c
python
and
c
python
though
this
can
be
changed
at
install
time
for
convenience
after
the
install
python
shows
up
in
the
start
button
s
all
programs
menu
python
s
menu
there
has
five
entries
that
give
quick
access
to
common
tasks
starting
the
idle
user
interface
reading
module
documentation
starting
an
interactive
session
reading
python
s
standard
manuals
in
a
web
browser
and
uninstalling
most
of
these
options
involve
concepts
explored
in
detail
elsewhere
in
this
text
when
installed
on
windows
python
also
by
default
automatically
registers
itself
to
be
the
program
that
opens
python
files
when
their
icons
are
clicked
a
program
launch
technique
described
in
chapter
it
is
also
possible
to
build
python
from
its
source
code
on
windows
but
this
is
not
commonly
done
one
note
for
windows
vista
users
security
features
of
the
some
versions
of
vista
change
some
of
the
rules
for
using
msi
installer
files
although
this
may
be
a
nonissue
by
the
time
you
read
these
words
see
the
sidebar
the
python
msi
installer
on
windows
vista
on
page
in
this
appendix
for
assistance
if
the
current
python
installer
does
not
work
or
does
not
place
python
in
the
correct
place
on
your
machine
linux
on
linux
python
is
available
as
one
or
more
rpm
files
which
you
unpack
in
the
usual
way
consult
the
rpm
manpage
for
details
depending
on
which
rpms
you
download
there
may
be
one
for
python
itself
and
another
that
adds
support
for
tkinter
guis
and
the
idle
environment
because
linux
is
a
unix
like
system
the
next
paragraph
applies
as
well
unix
on
unix
systems
python
is
usually
compiled
from
its
full
c
source
code
distribution
this
usually
only
requires
you
to
unpack
the
file
and
run
simple
config
and
make
commands
python
configures
its
own
build
procedure
automatically
installing
the
python
interpreter
according
to
the
system
on
which
it
is
being
compiled
however
be
sure
to
see
the
package
s
readme
file
for
more
details
on
this
process
because
python
is
open
source
its
source
code
may
be
used
and
distributed
free
of
charge
on
other
platforms
the
installation
details
can
differ
widely
but
they
generally
follow
the
platform
s
normal
conventions
installing
the
pippy
port
of
python
for
palmos
for
example
requires
a
hotsync
operation
with
your
pda
and
python
for
the
sharp
zaurus
linux
based
pda
comes
as
one
or
more
ipk
files
which
you
simply
run
to
install
it
because
additional
install
procedures
for
both
executable
and
source
forms
are
well
documented
though
we
ll
skip
further
details
here
the
python
msi
installer
on
windows
vista
as
i
write
this
the
python
self
installer
for
windows
is
an
msi
installation
file
this
format
works
fine
on
windows
xp
simply
double
click
on
the
file
and
it
runs
but
it
can
have
issues
on
some
versions
of
windows
vista
in
particular
running
the
msi
installer
by
clicking
on
it
may
cause
python
to
be
installed
at
the
root
of
the
c
drive
instead
of
in
the
correct
c
pythonxx
directory
python
still
works
in
the
root
directory
but
this
is
not
the
correct
place
to
install
it
this
is
a
vista
security
related
issue
in
short
msi
files
are
not
true
executables
so
they
do
not
correctly
inherit
administrator
permissions
even
if
run
by
the
administrator
user
instead
msi
files
are
run
via
the
windows
registry
their
filenames
are
associated
with
the
msi
installer
program
this
problem
seems
to
be
either
python
or
vista
version
specific
on
a
recent
laptop
for
example
python
and
installed
without
issue
to
install
python
on
my
vista
based
oqo
handheld
though
i
had
to
use
a
command
line
approach
to
force
the
required
administrator
permissions
if
python
doesn
t
install
in
the
right
place
for
you
here
s
the
workaround
go
to
your
start
button
select
the
all
programs
entry
choose
accessories
right
click
on
the
command
prompt
entry
there
choose
run
as
administrator
and
select
continue
in
the
access
control
dialog
now
within
the
command
prompt
window
issue
a
cd
command
to
change
to
the
directory
where
your
python
msi
installer
file
resides
e
g
cd
c
user
downloads
and
then
run
the
msi
installer
manually
by
typing
a
command
line
of
the
form
msiexec
i
python
msi
finally
follow
the
usual
gui
interactions
to
complete
the
install
naturally
this
behavior
may
change
over
time
this
procedure
may
not
be
required
in
every
version
of
vista
and
additional
workarounds
may
be
possible
such
as
disabling
vista
security
if
you
dare
it
s
also
possible
that
the
python
self
installer
may
eventually
be
provided
in
a
different
format
that
obviates
this
problem
as
a
true
executable
for
instance
be
sure
to
try
your
installer
by
simply
clicking
its
icon
to
see
if
it
works
properly
before
attempting
any
workarounds
appendix
a
installation
and
configuration
configuring
python
after
you
ve
installed
python
you
may
want
to
configure
some
system
settings
that
impact
the
way
python
runs
your
code
if
you
are
just
getting
started
with
the
language
you
can
probably
skip
this
section
completely
there
is
usually
no
need
to
specify
any
system
settings
for
basic
programs
generally
speaking
parts
of
the
python
interpreter
s
behavior
can
be
configured
with
environment
variable
settings
and
command
line
options
in
this
section
we
ll
take
a
brief
look
at
both
but
be
sure
to
see
other
documentation
sources
for
more
details
on
the
topics
we
introduce
here
python
environment
variables
environment
variables
known
to
some
as
shell
variables
or
dos
variables
are
system
wide
settings
that
live
outside
python
and
thus
can
be
used
to
customize
the
interpreter
s
behavior
each
time
it
is
run
on
a
given
computer
python
recognizes
a
handful
of
environment
variable
settings
but
only
a
few
are
used
often
enough
to
warrant
explanation
here
table
a
summarizes
the
main
python
related
environment
variable
settings
table
a
important
environment
variables
variable
role
path
or
path
system
shell
search
path
for
finding
python
pythonpath
python
module
search
path
for
imports
pythonstartup
path
to
python
interactive
startup
file
tcl
library
tk
library
gui
extension
variables
tkinter
these
variables
are
straightforward
to
use
but
here
are
a
few
pointers
path
the
path
setting
lists
a
set
of
directories
that
the
operating
system
searches
for
executable
programs
it
should
normally
include
the
directory
where
your
python
interpreter
lives
the
python
program
on
unix
or
the
python
exe
file
on
windows
you
don
t
need
to
set
this
variable
at
all
if
you
are
willing
to
work
in
the
directory
where
python
resides
or
type
the
full
path
to
python
in
command
lines
on
windows
for
instance
the
path
is
irrelevant
if
you
run
a
cd
c
python
before
running
any
code
to
change
to
the
directory
where
python
lives
or
always
type
c
python
python
instead
of
just
python
giving
a
full
path
also
note
that
path
settings
are
mostly
for
launching
programs
from
command
lines
they
are
usually
irrelevant
when
launching
via
icon
clicks
and
ides
configuring
python
pythonpath
the
pythonpath
setting
serves
a
role
similar
to
path
the
python
interpreter
consults
the
pythonpath
variable
to
locate
module
files
when
you
import
them
in
a
program
if
used
this
variable
is
set
to
a
platform
dependent
list
of
directory
names
separated
by
colons
on
unix
and
semicolons
on
windows
this
list
normally
includes
just
your
own
source
code
directories
its
content
is
merged
into
the
sys
path
module
import
search
path
along
with
the
script
s
directory
any
path
file
settings
and
standard
library
directories
you
don
t
need
to
set
this
variable
unless
you
will
be
performing
cross
directory
imports
because
python
always
searches
the
home
directory
of
the
program
s
top
level
file
automatically
this
setting
is
required
only
if
a
module
needs
to
import
another
module
that
lives
in
a
different
directory
see
also
the
discussion
of
pth
path
files
later
in
this
appendix
for
an
alternative
to
pythonpath
for
more
on
the
module
search
path
refer
to
chapter
pythonstartup
if
pythonstartup
is
set
to
the
pathname
of
a
file
of
python
code
python
executes
the
file
s
code
automatically
whenever
you
start
the
interactive
interpreter
as
though
you
had
typed
it
at
the
interactive
command
line
this
is
a
rarely
used
but
handy
way
to
make
sure
you
always
load
certain
utilities
when
working
interactively
it
saves
an
import
tkinter
settings
if
you
wish
to
use
the
tkinter
gui
toolkit
named
tkinter
in
you
might
have
to
set
the
two
gui
variables
in
the
last
line
of
table
a
to
the
names
of
the
source
library
directories
of
the
tcl
and
tk
systems
much
like
pythonpath
however
these
settings
are
not
required
on
windows
systems
where
tkinter
support
is
installed
alongside
python
and
they
re
usually
not
required
elsewhere
if
tcl
and
tk
reside
in
standard
directories
note
that
because
these
environment
settings
are
external
to
python
itself
when
you
set
them
is
usually
irrelevant
this
can
be
done
before
or
after
python
is
installed
as
long
as
they
are
set
the
way
you
require
before
python
is
actually
run
getting
tkinter
and
idle
gui
support
on
linux
the
idle
interface
described
in
chapter
is
a
python
tkinter
gui
program
the
tkinter
module
named
tkinter
in
is
a
gui
toolkit
and
it
s
a
complete
standard
component
of
python
on
windows
and
some
other
platforms
on
some
linux
systems
though
the
underlying
gui
library
may
not
be
a
standard
installed
component
to
add
gui
support
to
your
python
on
linux
if
needed
try
running
a
command
line
of
the
form
yum
tkinter
to
automatically
install
tkinter
s
underlying
libraries
this
should
work
on
linux
distributions
and
some
other
systems
on
which
the
yum
installation
program
is
available
appendix
a
installation
and
configuration
how
to
set
configuration
options
the
way
to
set
python
related
environment
variables
and
what
to
set
them
to
depends
on
the
type
of
computer
you
re
working
on
and
again
remember
that
you
won
t
necessarily
have
to
set
these
at
all
right
away
especially
if
you
re
working
in
idle
described
in
chapter
configuration
is
not
required
up
front
but
suppose
for
illustration
that
you
have
generally
useful
module
files
in
directories
called
utilities
and
package
somewhere
on
your
machine
and
you
want
to
be
able
to
import
these
modules
from
files
located
in
other
directories
that
is
to
load
a
file
called
spam
py
from
the
utilities
directory
you
want
to
be
able
to
say
import
spam
from
another
file
located
anywhere
on
your
computer
to
make
this
work
you
ll
have
to
configure
your
module
search
path
one
way
or
another
to
include
the
directory
containing
spam
py
here
are
a
few
tips
on
this
process
unix
linux
shell
variables
on
unix
systems
the
way
to
set
environment
variables
depends
on
the
shell
you
use
under
the
csh
shell
you
might
add
a
line
like
the
following
in
your
cshrc
or
login
file
to
set
the
python
module
search
path
setenv
pythonpath
usr
home
pycode
utilities
usr
lib
pycode
package
this
tells
python
to
look
for
imported
modules
in
two
user
defined
directories
alternatively
if
you
re
using
the
ksh
shell
the
setting
might
instead
appear
in
your
kshrc
file
and
look
like
this
export
pythonpath
usr
home
pycode
utilities
usr
lib
pycode
package
other
shells
may
use
different
but
analogous
syntax
dos
variables
windows
if
you
are
using
ms
dos
or
some
older
flavors
of
windows
you
may
need
to
add
an
environment
variable
configuration
command
to
your
c
autoexec
bat
file
and
reboot
your
machine
for
the
changes
to
take
effect
the
configuration
command
on
such
machines
has
a
syntax
unique
to
dos
set
pythonpath
c
pycode
utilities
d
pycode
package
you
can
type
such
a
command
in
a
dos
console
window
too
but
the
setting
will
then
be
active
only
for
that
one
console
window
changing
your
bat
file
makes
the
change
permanent
and
global
to
all
programs
windows
environment
variable
gui
on
more
recent
versions
of
windows
including
xp
and
vista
you
can
instead
set
pythonpath
and
other
variables
via
the
system
environment
variable
gui
without
having
configuring
python
to
edit
files
or
reboot
on
xp
select
the
control
panel
choose
the
system
icon
pick
the
advanced
tab
and
click
the
environment
variables
button
to
edit
or
add
new
variables
pythonpath
is
usually
a
user
variable
use
the
same
variable
name
and
values
syntax
shown
in
the
dos
set
command
earlier
the
procedure
is
similar
on
vista
but
you
may
have
to
verify
operations
along
the
way
you
do
not
need
to
reboot
your
machine
but
be
sure
to
restart
python
if
it
s
open
so
that
it
picks
up
your
changes
it
configures
its
path
at
startup
time
only
if
you
re
working
in
a
windows
command
prompt
window
you
ll
probably
need
to
restart
that
to
pick
up
your
changes
as
well
windows
registry
if
you
are
an
experienced
windows
user
you
may
also
be
able
to
configure
the
module
search
path
by
using
the
windows
registry
editor
go
to
start
run
and
type
regedit
assuming
the
typical
registry
tool
is
on
your
machine
you
can
then
navigate
to
python
s
entries
and
make
your
changes
this
is
a
delicate
and
error
prone
procedure
though
so
unless
you
re
familiar
with
the
registry
i
suggest
using
other
options
indeed
this
is
akin
to
performing
brain
surgery
on
your
computer
so
be
careful
path
files
finally
if
you
choose
to
extend
the
module
search
path
with
a
pth
file
instead
of
the
pythonpath
variable
you
might
instead
code
a
text
file
that
looks
like
the
following
on
windows
e
g
file
c
python
mypath
pth
c
pycode
utilities
d
pycode
package
its
contents
will
differ
per
platform
and
its
container
directory
may
differ
per
both
platform
and
python
release
python
locates
this
file
automatically
when
it
starts
up
directory
names
in
path
files
may
be
absolute
or
relative
to
the
directory
containing
the
path
file
multiple
pth
files
can
be
used
all
their
directories
are
added
and
pth
files
may
appear
in
various
automatically
checked
directories
that
are
platform
and
version
specific
in
general
a
python
release
numbered
python
n
m
typically
looks
for
path
files
in
c
pythonnm
and
c
pythonnm
lib
site
packages
on
windows
and
in
usr
local
lib
pythonn
m
site
packages
and
usr
local
lib
site
python
on
unix
and
linux
see
chapter
for
more
on
using
path
files
to
configure
the
sys
path
import
search
path
because
environment
settings
are
often
optional
and
because
this
isn
t
a
book
on
operating
system
shells
i
ll
defer
to
other
sources
for
further
details
consult
your
system
shell
s
manpages
or
other
documentation
for
more
information
and
if
you
have
trouble
figuring
out
what
your
settings
should
be
ask
your
system
administrator
or
another
local
expert
for
help
appendix
a
installation
and
configuration
python
command
line
options
when
you
start
python
from
a
system
command
line
a
k
a
a
shell
prompt
you
can
pass
in
a
variety
of
option
flags
to
control
how
python
runs
unlike
system
wide
environment
variables
command
line
options
can
be
different
each
time
you
run
a
script
the
complete
form
of
a
python
command
line
invocation
in
looks
like
this
is
roughly
the
same
with
a
few
option
differences
python
bbdehiossuvvwx
c
command
m
module
name
script
args
most
command
lines
only
make
use
of
the
script
and
args
parts
of
this
format
to
run
a
program
s
source
file
with
arguments
to
be
used
by
the
program
itself
to
illustrate
consider
the
following
script
file
main
py
which
prints
the
command
line
arguments
list
made
available
to
the
script
as
sys
argv
file
main
py
import
sys
print
sys
argv
in
the
following
command
line
both
python
and
main
py
can
also
be
complete
directory
paths
and
the
three
arguments
a
b
c
meant
for
the
script
show
up
in
the
sys
argv
list
the
first
item
in
sys
argv
is
always
the
script
file
s
name
when
it
is
known
c
python
python
main
py
a
b
c
main
py
a
b
c
most
common
run
a
script
file
other
code
format
specification
options
allow
you
to
specify
python
code
to
be
run
on
the
command
line
itself
c
to
accept
code
to
run
from
the
standard
input
stream
a
means
read
from
a
pipe
or
redirected
input
stream
file
and
so
on
c
python
python
c
print
read
code
from
command
argument
c
python
python
c
import
main
c
import
a
file
to
run
its
code
c
python
python
main
py
a
b
c
a
b
c
read
code
from
standard
input
c
python
python
a
b
c
main
py
a
b
c
same
effect
as
prior
line
the
m
code
specification
locates
a
module
on
python
s
module
search
path
sys
path
and
runs
it
as
a
top
level
script
as
module
main
leave
off
the
py
suffix
here
since
the
filename
is
a
module
c
python
python
m
main
a
b
c
c
python
main
py
a
b
c
locate
run
module
as
script
the
m
option
also
supports
running
modules
in
packages
with
relative
import
syntax
as
well
as
modules
located
in
zip
archives
this
switch
is
commonly
used
to
run
the
pdb
debugger
and
profile
profiler
modules
from
a
command
line
for
a
script
invocation
rather
than
interactively
though
this
usage
mode
seems
to
have
changed
somewhat
in
configuring
python
profile
appears
to
have
been
affected
by
the
removal
of
execfile
in
and
pdb
steps
into
superfluous
input
output
code
in
the
new
io
module
c
python
python
m
pdb
main
py
a
b
c
return
c
python
lib
io
py
closed
false
return
self
raw
closed
pdb
c
debug
a
script
c
python
c
python
python
m
pdb
main
py
a
b
c
better
in
c
python
main
py
module
import
sys
pdb
c
c
python
python
m
profile
main
py
a
b
c
profile
a
script
c
python
python
m
cprofile
main
py
a
b
c
low
overhead
profiler
immediately
after
the
python
and
before
the
designation
of
code
to
be
run
python
accepts
additional
arguments
that
control
its
own
behavior
these
arguments
are
consumed
by
python
itself
and
are
not
meant
for
the
script
being
run
for
example
o
runs
python
in
optimized
mode
u
forces
standard
streams
to
be
unbuffered
and
i
enters
interactive
mode
after
running
a
script
c
python
python
u
main
py
a
b
c
unbuffered
output
streams
python
supports
additional
options
that
promote
compatibility
q
and
detecting
inconsistent
tab
indentation
usage
which
is
always
detected
and
reported
in
t
see
chapter
see
the
python
manuals
or
reference
texts
for
more
details
on
available
command
line
options
or
better
yet
ask
python
itself
run
a
command
line
form
like
this
c
python
python
to
request
python
s
help
display
which
documents
available
command
line
options
if
you
deal
with
complex
command
lines
be
sure
to
also
check
out
the
standard
library
modules
getopt
and
optparse
which
support
more
sophisticated
command
line
processing
for
more
help
python
s
standard
manual
set
today
includes
valuable
pointers
for
usage
on
various
platforms
the
standard
manual
set
is
available
in
your
start
button
on
windows
after
python
is
installed
option
python
manuals
and
online
at
http
www
python
org
look
for
the
manual
set
s
top
level
section
titled
using
python
for
more
platformspecific
pointers
and
hints
as
well
as
up
to
date
cross
platform
environment
and
command
line
details
appendix
a
installation
and
configuration
as
always
the
web
is
your
friend
too
especially
in
a
field
that
often
evolves
faster
than
books
like
this
can
be
updated
given
python
s
widespread
adoption
chances
are
good
that
answers
to
any
usage
questions
you
may
have
can
be
found
with
a
web
search
for
more
help
appendix
b
solutions
to
end
of
part
exercises
part
i
getting
started
see
test
your
knowledge
part
i
exercises
on
page
in
chapter
for
the
exercises
interaction
assuming
python
is
configured
properly
the
interaction
should
look
something
like
the
following
you
can
run
this
any
way
you
like
in
idle
from
a
shell
prompt
and
so
on
python
copyright
information
lines
hello
world
hello
world
use
ctrl
d
or
ctrl
z
to
exit
or
close
window
programs
your
code
i
e
module
file
module
py
and
the
operating
system
shell
interactions
should
look
like
this
print
hello
module
world
python
module
py
hello
module
world
again
feel
free
to
run
this
other
ways
by
clicking
the
file
s
icon
by
using
idle
s
run
run
module
menu
option
and
so
on
modules
the
following
interaction
listing
illustrates
running
a
module
file
by
importing
it
python
import
module
hello
module
world
remember
that
you
will
need
to
reload
the
module
to
run
it
again
without
stopping
and
restarting
the
interpreter
the
question
about
moving
the
file
to
a
different
directory
and
importing
it
again
is
a
trick
question
if
python
generates
a
module
pyc
file
in
the
original
directory
it
uses
that
when
you
import
the
module
even
if
the
source
code
py
file
has
been
moved
to
a
directory
not
in
python
s
search
path
the
pyc
file
is
written
automatically
if
python
has
access
to
the
source
file
s
directory
it
contains
the
compiled
byte
code
version
of
a
module
see
chapter
for
more
on
modules
scripts
assuming
your
platform
supports
the
trick
your
solution
will
look
like
the
following
although
your
line
may
need
to
list
another
path
on
your
machine
usr
local
bin
python
print
hello
module
world
chmod
x
module
py
or
usr
bin
env
python
module
py
hello
module
world
errors
the
following
interaction
run
in
python
demonstrates
the
sorts
of
error
messages
you
ll
get
when
you
complete
this
exercise
really
you
re
triggering
python
exceptions
the
default
exception
handling
behavior
terminates
the
running
python
program
and
prints
an
error
message
and
stack
trace
on
the
screen
the
stack
trace
shows
where
you
were
in
a
program
when
the
exception
occurred
if
function
calls
are
active
when
the
error
happens
the
traceback
section
displays
all
active
call
levels
in
part
vii
you
will
learn
that
you
can
catch
exceptions
using
try
statements
and
process
them
arbitrarily
you
ll
also
see
there
that
python
includes
a
full
blown
source
code
debugger
for
special
error
detection
requirements
for
now
notice
that
python
gives
meaningful
messages
when
programming
errors
occur
instead
of
crashing
silently
python
traceback
most
recent
call
last
file
stdin
line
in
module
zerodivisionerror
int
division
or
modulo
by
zero
spam
traceback
most
recent
call
last
file
stdin
line
in
module
nameerror
name
spam
is
not
defined
breaks
and
cycles
when
you
type
this
code
l
l
append
l
you
create
a
cyclic
data
structure
in
python
in
python
releases
before
the
python
printer
wasn
t
smart
enough
to
detect
cycles
in
objects
and
it
would
print
an
unending
stream
of
and
so
on
until
you
hit
the
break
key
combination
on
your
machine
which
technically
raises
a
keyboardinterrupt
exception
that
prints
a
default
message
beginning
with
python
appendix
b
solutions
to
end
of
part
exercises
the
printer
is
clever
enough
to
detect
cycles
and
prints
instead
to
let
you
know
that
it
has
detected
a
loop
in
the
object
s
structure
and
avoided
getting
stuck
printing
forever
the
reason
for
the
cycle
is
subtle
and
requires
information
you
will
glean
in
part
ii
so
this
is
something
of
a
preview
but
in
short
assignments
in
python
always
generate
references
to
objects
not
copies
of
them
you
can
think
of
objects
as
chunks
of
memory
and
of
references
as
implicitly
followed
pointers
when
you
run
the
first
assignment
above
the
name
l
becomes
a
named
reference
to
a
two
item
list
object
a
pointer
to
a
piece
of
memory
python
lists
are
really
arrays
of
object
references
with
an
append
method
that
changes
the
array
in
place
by
tacking
on
another
object
reference
at
the
end
here
the
append
call
adds
a
reference
to
the
front
of
l
at
the
end
of
l
which
leads
to
the
cycle
illustrated
in
figure
b
a
pointer
at
the
end
of
the
list
that
points
back
to
the
front
of
the
list
besides
being
printed
specially
as
you
ll
learn
in
chapter
cyclic
objects
must
also
be
handled
specially
by
python
s
garbage
collector
or
their
space
will
remain
unreclaimed
even
when
they
are
no
longer
in
use
though
rare
in
practice
in
some
programs
that
traverse
arbitrary
objects
or
structures
you
might
have
to
detect
such
cycles
yourself
by
keeping
track
of
where
you
ve
been
to
avoid
looping
believe
it
or
not
cyclic
data
structures
can
sometimes
be
useful
despite
their
special
case
printing
figure
b
a
cyclic
object
created
by
appending
a
list
to
itself
by
default
python
appends
a
reference
to
the
original
list
not
a
copy
of
the
list
part
ii
types
and
operations
see
test
your
knowledge
part
ii
exercises
on
page
in
chapter
for
the
exercises
the
basics
here
are
the
sorts
of
results
you
should
get
along
with
a
few
comments
about
their
meaning
again
note
that
is
used
in
a
few
of
these
to
squeeze
more
than
one
statement
onto
a
single
line
the
is
a
statement
separator
and
commas
part
ii
types
and
operations
build
up
tuples
displayed
in
parentheses
also
keep
in
mind
that
the
division
result
near
the
top
differs
in
python
and
see
chapter
for
details
and
the
list
wrapper
around
dictionary
method
calls
is
needed
to
display
results
in
but
not
see
chapter
numbers
raised
to
the
power
integer
truncates
in
but
not
strings
spam
eggs
spameggs
s
ham
eggs
s
eggs
ham
s
hamhamhamhamham
s
concatenation
repetition
an
empty
slice
at
the
front
empty
of
same
type
as
object
sliced
green
s
and
s
eggs
s
formatting
green
eggs
and
ham
green
and
format
eggs
s
green
eggs
and
ham
tuples
x
x
x
y
y
indexing
a
single
item
tuple
indexing
a
item
tuple
lists
l
list
operations
l
l
l
l
l
l
l
fetch
from
offsets
store
in
a
list
l
reverse
l
method
reverse
list
in
place
l
sort
l
method
sort
list
in
place
l
index
method
offset
of
first
search
dictionaries
a
b
b
appendix
b
solutions
to
end
of
part
exercises
index
a
dictionary
by
key
d
x
y
z
d
w
d
x
d
w
create
a
new
entry
d
a
tuple
used
as
a
key
immutable
d
w
z
y
x
list
d
keys
list
d
values
in
d
w
z
y
x
true
methods
key
test
empties
none
none
lots
of
nothings
empty
objects
indexing
and
slicing
indexing
out
of
bounds
e
g
l
raises
an
error
python
always
checks
to
make
sure
that
all
offsets
are
within
the
bounds
of
a
sequence
on
the
other
hand
slicing
out
of
bounds
e
g
l
works
because
python
scales
out
of
bounds
slices
so
that
they
always
fit
the
limits
are
set
to
zero
and
the
sequence
length
if
required
extracting
a
sequence
in
reverse
with
the
lower
bound
greater
than
the
higher
bound
e
g
l
doesn
t
really
work
you
get
back
an
empty
slice
because
python
scales
the
slice
limits
to
make
sure
that
the
lower
bound
is
always
less
than
or
equal
to
the
upper
bound
e
g
l
is
scaled
to
l
the
empty
insertion
point
at
offset
python
slices
are
always
extracted
from
left
to
right
even
if
you
use
negative
indexes
they
are
first
converted
to
positive
indexes
by
adding
the
sequence
length
note
that
python
s
three
limit
slices
modify
this
behavior
somewhat
for
instance
l
does
extract
from
right
to
left
l
l
traceback
innermost
last
file
stdin
line
in
indexerror
list
index
out
of
range
l
l
l
l
l
indexing
slicing
and
del
your
interaction
with
the
interpreter
should
look
something
like
the
following
code
note
that
assigning
an
empty
list
to
an
offset
stores
an
empty
list
object
there
but
assigning
an
empty
list
to
a
slice
deletes
the
slice
slice
assignment
expects
another
sequence
or
you
ll
get
a
type
error
it
inserts
items
inside
the
sequence
assigned
not
the
sequence
itself
part
ii
types
and
operations
l
l
l
l
l
del
l
l
del
l
l
l
traceback
innermost
last
file
stdin
line
in
typeerror
illegal
argument
type
for
built
in
operation
tuple
assignment
the
values
of
x
and
y
are
swapped
when
tuples
appear
on
the
left
and
right
of
an
assignment
symbol
python
assigns
objects
on
the
right
to
targets
on
the
left
according
to
their
positions
this
is
probably
easiest
to
understand
by
noting
that
the
targets
on
the
left
aren
t
a
real
tuple
even
though
they
look
like
one
they
are
simply
a
set
of
independent
assignment
targets
the
items
on
the
right
are
a
tuple
which
gets
unpacked
during
the
assignment
the
tuple
provides
the
temporary
assignment
needed
to
achieve
the
swap
effect
x
spam
y
eggs
x
y
y
x
x
eggs
y
spam
dictionary
keys
any
immutable
object
can
be
used
as
a
dictionary
key
including
integers
tuples
strings
and
so
on
this
really
is
a
dictionary
even
though
some
of
its
keys
look
like
integer
offsets
mixed
type
keys
work
fine
too
d
d
a
d
b
d
c
d
a
b
c
dictionary
indexing
indexing
a
nonexistent
key
d
d
raises
an
error
assigning
to
a
nonexistent
key
d
d
spam
creates
a
new
dictionary
entry
on
the
other
hand
out
of
bounds
indexing
for
lists
raises
an
error
too
but
so
do
out
of
bounds
assignments
variable
names
work
like
dictionary
keys
they
must
have
already
been
assigned
when
referenced
but
they
are
created
when
first
assigned
in
fact
variable
names
can
be
processed
as
dictionary
keys
if
you
wish
they
re
made
visible
in
module
namespace
or
stack
frame
dictionaries
appendix
b
solutions
to
end
of
part
exercises
d
a
b
c
d
a
d
d
traceback
innermost
last
file
stdin
line
in
keyerror
d
d
d
d
b
d
a
c
l
l
traceback
innermost
last
file
stdin
line
in
indexerror
list
index
out
of
range
l
traceback
innermost
last
file
stdin
line
in
indexerror
list
assignment
index
out
of
range
generic
operations
question
answers
the
operator
doesn
t
work
on
different
mixed
types
e
g
string
list
list
tuple
doesn
t
work
for
dictionaries
as
they
aren
t
sequences
the
append
method
works
only
for
lists
not
strings
and
keys
works
only
on
dictionaries
append
assumes
its
target
is
mutable
since
it
s
an
in
place
extension
strings
are
immutable
slicing
and
concatenation
always
return
a
new
object
of
the
same
type
as
the
objects
processed
x
traceback
innermost
last
file
stdin
line
in
typeerror
illegal
argument
type
for
built
in
operation
traceback
innermost
last
file
stdin
line
in
typeerror
bad
operand
type
s
for
append
append
s
traceback
innermost
last
file
stdin
line
in
attributeerror
attribute
less
object
list
keys
list
needed
in
not
keys
traceback
innermost
last
file
stdin
line
in
attributeerror
keys
part
ii
types
and
operations
string
indexing
this
is
a
bit
of
a
trick
question
because
strings
are
collections
of
one
character
strings
every
time
you
index
a
string
you
get
back
a
string
that
can
be
indexed
again
s
just
keeps
indexing
the
first
character
over
and
over
this
generally
doesn
t
work
for
lists
lists
can
hold
arbitrary
objects
unless
the
list
contains
strings
s
s
s
spam
s
l
s
p
l
immutable
types
either
of
the
following
solutions
works
index
assignment
doesn
t
because
strings
are
immutable
s
spam
s
s
l
s
s
slam
s
s
l
s
s
s
slam
see
also
the
python
bytearray
string
type
in
chapter
it
s
a
mutable
sequence
of
small
integers
that
is
essentially
processed
the
same
as
a
string
nesting
here
is
a
sample
me
name
john
q
doe
age
job
engineer
me
job
engineer
me
name
doe
files
here
s
one
way
to
create
and
read
back
a
text
file
in
python
ls
is
a
unix
command
use
dir
on
windows
file
maker
py
file
open
myfile
txt
w
file
write
hello
file
world
n
file
close
or
open
write
close
not
always
needed
file
reader
py
file
open
myfile
txt
print
file
read
r
is
default
open
mode
or
print
open
read
python
maker
py
python
reader
py
hello
file
world
appendix
b
solutions
to
end
of
part
exercises
ls
l
myfile
txt
rwxrwxrwa
apr
myfile
txt
part
iii
statements
and
syntax
see
test
your
knowledge
part
iii
exercises
on
page
in
chapter
for
the
exercises
coding
basic
loops
as
you
work
through
this
exercise
you
ll
wind
up
with
code
that
looks
like
the
following
s
spam
for
c
in
s
print
ord
c
x
for
c
in
s
x
ord
c
x
or
x
x
ord
c
x
for
c
in
s
x
append
ord
c
x
list
map
ord
s
list
required
in
not
backslash
characters
the
example
prints
the
bell
character
a
times
assuming
your
machine
can
handle
it
and
when
it
s
run
outside
of
idle
you
may
get
a
series
of
beeps
or
one
sustained
tone
if
your
machine
is
fast
enough
hey
i
warned
you
sorting
dictionaries
here
s
one
way
to
work
through
this
exercise
see
chapter
or
chapter
if
this
doesn
t
make
sense
remember
you
really
do
have
to
split
up
the
keys
and
sort
calls
like
this
because
sort
returns
none
in
python
and
later
you
can
iterate
through
dictionary
keys
directly
without
calling
keys
e
g
for
key
in
d
but
the
keys
list
will
not
be
sorted
like
it
is
by
this
code
in
more
recent
pythons
you
can
achieve
the
same
effect
with
the
sorted
built
in
too
d
a
b
c
d
e
f
g
d
f
c
a
g
e
d
b
keys
list
d
keys
list
required
in
not
in
part
iii
statements
and
syntax
keys
sort
for
key
in
keys
print
key
d
key
a
b
c
d
e
f
g
for
key
in
sorted
d
print
key
d
key
better
in
more
recent
pythons
program
logic
alternatives
here
s
some
sample
code
for
the
solutions
for
step
e
assign
the
result
of
x
to
a
variable
outside
the
loops
of
steps
a
and
b
and
use
it
inside
the
loop
your
results
may
vary
a
bit
this
exercise
is
mostly
designed
to
get
you
playing
with
code
alternatives
so
anything
reasonable
gets
full
credit
a
l
x
i
while
i
len
l
if
x
l
i
print
at
index
i
break
i
else
print
x
not
found
b
l
x
for
p
in
l
if
x
p
print
x
was
found
at
l
index
p
break
else
print
x
not
found
c
l
x
if
x
in
l
print
x
was
found
at
l
index
x
appendix
b
solutions
to
end
of
part
exercises
else
print
x
not
found
d
x
l
for
i
in
range
l
append
i
print
l
if
x
in
l
print
x
was
found
at
l
index
x
else
print
x
not
found
f
x
l
list
map
lambda
x
x
range
print
l
or
x
for
x
in
range
list
to
print
all
in
not
if
x
in
l
print
x
was
found
at
l
index
x
else
print
x
not
found
part
iv
functions
see
test
your
knowledge
part
iv
exercises
on
page
in
chapter
for
the
exercises
the
basics
there
s
not
much
to
this
one
but
notice
that
using
print
and
hence
your
function
is
technically
a
polymorphic
operation
which
does
the
right
thing
for
each
type
of
object
python
def
func
x
print
x
func
spam
spam
func
func
func
food
spam
food
spam
arguments
here
s
a
sample
solution
remember
that
you
have
to
use
print
to
see
results
in
the
test
calls
because
a
file
isn
t
the
same
as
code
typed
interactively
python
doesn
t
normally
echo
the
results
of
expression
statements
in
files
part
iv
functions
def
adder
x
y
return
x
y
print
adder
print
adder
spam
eggs
print
adder
a
b
c
d
python
mod
py
spameggs
a
b
c
d
varargs
two
alternative
adder
functions
are
shown
in
the
following
file
adders
py
the
hard
part
here
is
figuring
out
how
to
initialize
an
accumulator
to
an
empty
value
of
whatever
type
is
passed
in
the
first
solution
uses
manual
type
testing
to
look
for
an
integer
and
an
empty
slice
of
the
first
argument
assumed
to
be
a
sequence
if
the
argument
is
determined
not
to
be
an
integer
the
second
solution
uses
the
first
argument
to
initialize
and
scan
items
and
beyond
much
like
one
of
the
min
function
variants
shown
in
chapter
the
second
solution
is
better
both
of
these
assume
all
arguments
are
of
the
same
type
and
neither
works
on
dictionaries
as
we
saw
in
part
ii
doesn
t
work
on
mixed
types
or
dictionaries
you
could
add
a
type
test
and
special
code
to
allow
dictionaries
too
but
that
s
extra
credit
def
adder
args
print
adder
end
if
type
args
type
sum
else
sum
args
for
arg
in
args
sum
sum
arg
return
sum
def
adder
args
print
adder
end
sum
args
for
next
in
args
sum
next
return
sum
integer
init
to
zero
else
sequence
use
empty
slice
of
arg
init
to
arg
add
items
n
for
func
in
adder
adder
print
func
print
func
spam
eggs
toast
print
func
a
b
c
d
e
f
python
adders
py
adder
adder
spameggstoast
adder
a
b
c
d
e
f
adder
adder
spameggstoast
adder
a
b
c
d
e
f
appendix
b
solutions
to
end
of
part
exercises
keywords
here
is
my
solution
to
the
first
and
second
parts
of
this
exercise
coded
in
the
file
mod
py
to
iterate
over
keyword
arguments
use
the
args
form
in
the
function
header
and
use
a
loop
e
g
for
x
in
args
keys
use
args
x
or
use
args
values
to
make
this
the
same
as
summing
args
positionals
def
adder
good
bad
ugly
return
good
bad
ugly
print
adder
print
adder
print
adder
print
adder
print
adder
ugly
good
bad
python
mod
py
second
part
solutions
def
adder
args
tot
args
for
arg
in
args
tot
arg
return
tot
sum
any
number
of
positional
args
def
adder
args
argskeys
list
args
keys
tot
args
argskeys
for
key
in
argskeys
tot
args
key
return
tot
sum
any
number
of
keyword
args
list
needed
in
def
adder
args
args
list
args
values
tot
args
for
arg
in
args
tot
arg
return
tot
same
but
convert
to
list
of
values
list
needed
to
index
in
def
adder
args
return
adder
args
values
same
but
reuse
positional
version
print
adder
adder
aa
bb
cc
print
adder
a
b
c
adder
a
aa
b
bb
c
cc
print
adder
a
b
c
adder
a
aa
b
bb
c
cc
print
adder
a
b
c
adder
a
aa
b
bb
c
cc
part
iv
functions
and
here
are
my
solutions
to
exercises
and
file
dicts
py
these
are
just
coding
exercises
though
because
python
added
the
dictionary
methods
d
copy
and
d
update
d
to
handle
things
like
copying
and
adding
merging
dictionaries
see
python
s
library
manual
or
o
reilly
s
python
pocket
reference
for
more
details
x
doesn
t
work
for
dictionaries
as
they
re
not
sequences
see
chapter
for
details
also
remember
that
if
you
assign
e
d
rather
than
copying
you
generate
a
reference
to
a
shared
dictionary
object
changing
d
changes
e
too
def
copydict
old
new
for
key
in
old
keys
new
key
old
key
return
new
def
adddict
d
d
new
for
key
in
d
keys
new
key
d
key
for
key
in
d
keys
new
key
d
key
return
new
python
from
dicts
import
d
e
copydict
d
d
d
e
x
y
z
adddict
x
y
z
see
more
argument
matching
examples
here
is
the
sort
of
interaction
you
should
get
along
with
comments
that
explain
the
matching
that
goes
on
def
f
a
b
print
a
b
normal
args
def
f
a
b
print
a
b
positional
varargs
def
f
a
b
print
a
b
keyword
varargs
def
f
a
b
c
print
a
b
c
mixed
modes
def
f
a
b
c
print
a
b
c
defaults
appendix
b
solutions
to
end
of
part
exercises
def
f
a
b
c
print
a
b
c
python
f
f
b
a
defaults
and
positional
varargs
matched
by
position
order
matters
matched
by
name
order
doesn
t
matter
f
extra
positionals
collected
in
a
tuple
f
x
y
x
y
extra
keywords
collected
in
a
dictionary
f
x
y
x
y
extra
of
both
kinds
f
f
both
defaults
kick
in
f
f
one
argument
matches
a
only
one
default
used
extra
positional
collected
primes
revisited
here
is
the
primes
example
wrapped
up
in
a
function
and
a
module
file
primes
py
so
it
can
be
run
multiple
times
i
added
an
if
test
to
trap
negatives
and
i
also
changed
to
in
this
edition
to
make
this
solution
immune
to
the
python
true
division
changes
we
studied
in
chapter
and
to
enable
it
to
support
floating
point
numbers
uncomment
the
from
statement
and
change
to
to
see
the
differences
in
from
future
import
division
def
prime
y
if
y
print
y
not
prime
else
x
y
while
x
if
y
x
print
y
has
factor
x
break
x
else
print
y
is
prime
prime
prime
prime
prime
for
some
y
fails
no
remainder
skip
else
prime
prime
prime
prime
part
iv
functions
here
is
the
module
in
action
the
operator
allows
it
to
work
for
floating
point
numbers
too
even
though
it
perhaps
should
not
python
primes
py
is
prime
is
prime
has
factor
has
factor
is
prime
is
prime
not
prime
not
prime
this
function
still
isn
t
very
reusable
it
could
return
values
instead
of
printing
but
it
s
enough
to
run
experiments
it
s
also
not
a
strict
mathematical
prime
floating
points
work
and
it
s
still
inefficient
improvements
are
left
as
exercises
for
more
mathematically
minded
readers
hint
a
for
loop
over
range
y
may
be
a
bit
quicker
than
the
while
but
the
algorithm
is
the
real
bottleneck
here
to
time
alternatives
use
the
built
in
time
module
and
coding
patterns
like
those
used
in
this
general
function
call
timer
see
the
library
manual
for
details
def
timer
reps
func
args
import
time
start
time
clock
for
i
in
range
reps
func
args
return
time
clock
start
list
comprehensions
here
is
the
sort
of
code
you
should
write
i
may
have
a
preference
but
i
m
not
telling
values
import
math
res
for
x
in
values
res
append
math
sqrt
x
res
list
map
math
sqrt
values
math
sqrt
x
for
x
in
values
timing
tools
here
is
some
code
i
wrote
to
time
the
three
square
root
options
along
with
the
results
in
and
the
last
result
of
each
function
is
printed
to
verify
that
all
three
do
the
same
work
file
mytimer
py
and
same
as
listed
in
chapter
file
timesqrt
py
appendix
b
solutions
to
end
of
part
exercises
import
sys
mytimer
reps
repslist
range
reps
from
math
import
sqrt
def
mathmod
for
i
in
repslist
res
sqrt
i
return
res
pull
out
range
list
time
for
not
math
sqrt
adds
attr
fetch
time
def
powcall
for
i
in
repslist
res
pow
i
return
res
def
powexpr
for
i
in
repslist
res
i
return
res
print
sys
version
for
tester
in
mytimer
timer
mytimer
best
print
s
tester
name
for
test
in
mathmod
powcall
powexpr
elapsed
result
tester
test
print
print
s
f
s
test
name
elapsed
result
following
are
the
test
results
for
python
and
for
both
it
looks
like
the
math
module
is
quicker
than
the
expression
which
is
quicker
than
the
pow
call
however
you
should
try
this
with
your
code
and
on
your
own
machine
and
version
of
python
also
note
that
python
is
nearly
twice
as
slow
as
on
this
test
or
later
might
perform
better
time
this
in
the
future
to
see
for
yourself
c
misc
c
python
python
timesqrt
py
r
feb
msc
v
bit
intel
timer
mathmod
powcall
powexpr
best
mathmod
powcall
powexpr
c
misc
c
python
python
timesqrt
py
part
iv
functions
r
dec
msc
v
bit
intel
timer
mathmod
powcall
powexpr
best
mathmod
powcall
powexpr
to
time
the
relative
speeds
of
python
dictionary
comprehensions
and
equivalent
for
loops
interactively
run
a
session
like
the
following
it
appears
that
the
two
are
roughly
the
same
in
this
regard
under
python
unlike
list
comprehensions
though
manual
loops
are
slightly
faster
than
dictionary
comprehensions
today
though
the
difference
isn
t
exactly
earth
shattering
at
the
end
we
save
half
a
second
when
making
dictionaries
of
items
each
again
rather
than
taking
these
results
as
gospel
you
should
investigate
further
on
your
own
on
your
computer
and
with
your
python
c
misc
c
python
python
def
dictcomp
i
return
i
i
for
i
in
range
i
def
dictloop
i
new
for
i
in
range
i
new
i
i
return
new
dictcomp
dictloop
from
mytimer
import
best
timer
best
dictcomp
best
dictloop
best
dictcomp
best
dictloop
best
dictcomp
best
dictloop
appendix
b
solutions
to
end
of
part
exercises
item
dict
items
times
slower
items
x
time
time
for
making
one
dict
timer
dictcomp
reps
timer
dictloop
reps
item
dict
time
for
making
part
v
modules
see
test
your
knowledge
part
v
exercises
on
page
in
chapter
for
the
exercises
import
basics
this
one
is
simpler
than
you
may
think
when
you
re
done
your
file
mymod
py
and
interaction
should
look
similar
to
the
following
remember
that
python
can
read
a
whole
file
into
a
list
of
line
strings
and
the
len
built
in
returns
the
lengths
of
strings
and
lists
def
countlines
name
file
open
name
return
len
file
readlines
def
countchars
name
return
len
open
name
read
def
test
name
return
countlines
name
countchars
name
or
pass
file
object
or
return
a
dictionary
python
import
mymod
mymod
test
mymod
py
note
that
these
functions
load
the
entire
file
in
memory
all
at
once
so
they
won
t
work
for
pathologically
large
files
too
big
for
your
machine
s
memory
to
be
more
robust
you
could
read
line
by
line
with
iterators
instead
and
count
as
you
go
def
countlines
name
tot
for
line
in
open
name
tot
return
tot
def
countchars
name
tot
for
line
in
open
name
tot
len
line
return
tot
on
unix
you
can
verify
your
output
with
a
wc
command
on
windows
right
click
on
your
file
to
view
its
properties
but
note
that
your
script
may
report
fewer
characters
than
windows
does
for
portability
python
converts
windows
r
n
lineend
markers
to
n
thereby
dropping
one
byte
character
per
line
to
match
byte
counts
with
windows
exactly
you
have
to
open
in
binary
mode
rb
or
add
the
number
of
bytes
corresponding
to
the
number
of
lines
part
v
modules
incidentally
to
do
the
ambitious
part
of
this
exercise
passing
in
a
file
object
so
you
only
open
the
file
once
you
ll
probably
need
to
use
the
seek
method
of
the
built
in
file
object
we
didn
t
cover
it
in
the
text
but
it
works
just
like
c
s
fseek
call
and
calls
it
behind
the
scenes
seek
resets
the
current
position
in
the
file
to
a
passed
in
offset
after
a
seek
future
input
output
operations
are
relative
to
the
new
position
to
rewind
to
the
start
of
a
file
without
closing
and
reopening
it
call
file
seek
the
file
read
methods
all
pick
up
at
the
current
position
in
the
file
so
you
need
to
rewind
to
reread
here
s
what
this
tweak
would
look
like
def
countlines
file
file
seek
return
len
file
readlines
rewind
to
start
of
file
def
countchars
file
file
seek
return
len
file
read
ditto
rewind
if
needed
def
test
name
file
open
name
return
countlines
file
countchars
file
pass
file
object
open
file
only
once
import
mymod
mymod
test
mymod
py
from
from
here
s
the
from
part
replace
with
countchars
to
do
the
rest
python
from
mymod
import
countchars
mymod
py
main
if
you
code
it
properly
it
works
in
either
mode
program
run
or
module
import
def
countlines
name
file
open
name
return
len
file
readlines
def
countchars
name
return
len
open
name
read
def
test
name
return
countlines
name
countchars
name
or
pass
file
object
or
return
a
dictionary
if
name
main
print
test
mymod
py
python
mymod
py
this
is
where
i
would
probably
begin
to
consider
using
command
line
arguments
or
user
input
to
provide
the
filename
to
be
counted
instead
of
hardcoding
it
in
the
script
see
chapter
for
more
on
sys
argv
and
chapter
for
more
on
input
appendix
b
solutions
to
end
of
part
exercises
if
name
main
print
test
input
enter
file
name
if
name
main
import
sys
print
test
sys
argv
nested
imports
here
is
my
solution
file
myclient
py
from
mymod
import
countlines
countchars
print
countlines
mymod
py
countchars
mymod
py
python
myclient
py
as
for
the
rest
of
this
one
mymod
s
functions
are
accessible
that
is
importable
from
the
top
level
of
myclient
since
from
simply
assigns
to
names
in
the
importer
it
works
almost
as
though
mymod
s
defs
appeared
in
myclient
for
example
another
file
can
say
this
import
myclient
myclient
countlines
from
myclient
import
countchars
countchars
if
myclient
used
import
instead
of
from
you
d
need
to
use
a
path
to
get
to
the
functions
in
mymod
through
myclient
import
myclient
myclient
mymod
countlines
from
myclient
import
mymod
mymod
countchars
in
general
you
can
define
collector
modules
that
import
all
the
names
from
other
modules
so
they
re
available
in
a
single
convenience
module
using
the
following
code
you
wind
up
with
three
different
copies
of
the
name
somename
mod
somename
collector
somename
and
main
somename
all
three
share
the
same
integer
object
initially
and
only
the
name
somename
exists
at
the
interactive
prompt
as
is
file
mod
py
somename
file
collector
py
from
mod
import
from
mod
import
from
mod
import
collect
lots
of
names
here
from
assigns
to
my
names
from
collector
import
somename
package
imports
for
this
i
put
the
mymod
py
solution
file
listed
for
exercise
into
a
directory
package
the
following
is
what
i
did
to
set
up
the
directory
and
its
required
init
py
file
in
a
windows
console
interface
you
ll
need
to
interpolate
for
other
platforms
e
g
use
mv
and
vi
instead
of
move
and
edit
this
works
in
any
part
v
modules
directory
i
just
happened
to
run
my
commands
in
python
s
install
directory
and
you
can
do
some
of
this
from
a
file
explorer
gui
too
when
i
was
done
i
had
a
mypkg
subdirectory
that
contained
the
files
init
py
and
mymod
py
you
need
an
init
py
in
the
mypkg
directory
but
not
in
its
parent
mypkg
is
located
in
the
home
directory
component
of
the
module
search
path
notice
how
a
print
statement
coded
in
the
directory
s
initialization
file
fires
only
the
first
time
it
is
imported
not
the
second
c
python
mkdir
mypkg
c
python
move
mymod
py
mypkg
mymod
py
c
python
edit
mypkg
init
py
coded
a
print
statement
c
python
python
import
mypkg
mymod
initializing
mypkg
mypkg
mymod
countlines
mypkg
mymod
py
from
mypkg
mymod
import
countchars
countchars
mypkg
mymod
py
reloads
this
exercise
just
asks
you
to
experiment
with
changing
the
changer
py
example
in
the
book
so
there
s
nothing
to
show
here
circular
imports
the
short
story
is
that
importing
recur
first
works
because
the
recursive
import
then
happens
at
the
import
in
recur
not
at
a
from
in
recur
the
long
story
goes
like
this
importing
recur
first
works
because
the
recursive
import
from
recur
to
recur
fetches
recur
as
a
whole
instead
of
getting
specific
names
recur
is
incomplete
when
it
s
imported
from
recur
but
because
it
uses
import
instead
of
from
you
re
safe
python
finds
and
returns
the
already
created
recur
module
object
and
continues
to
run
the
rest
of
recur
without
a
glitch
when
the
recur
import
resumes
the
second
from
finds
the
name
y
in
recur
it
s
been
run
completely
so
no
error
is
reported
running
a
file
as
a
script
is
not
the
same
as
importing
it
as
a
module
these
cases
are
the
same
as
running
the
first
import
or
from
in
the
script
interactively
for
instance
running
recur
as
a
script
is
the
same
as
importing
recur
interactively
as
recur
is
the
first
module
imported
in
recur
part
vi
classes
and
oop
see
test
your
knowledge
part
vi
exercises
on
page
in
chapter
for
the
exercises
inheritance
here
s
the
solution
code
for
this
exercise
file
adder
py
along
with
some
interactive
tests
the
add
overload
has
to
appear
only
once
in
the
superclass
as
it
invokes
type
specific
add
methods
in
subclasses
class
adder
def
add
self
x
y
appendix
b
solutions
to
end
of
part
exercises
print
not
implemented
def
init
self
start
self
data
start
def
add
self
other
return
self
add
self
data
other
or
in
subclasses
or
return
type
class
listadder
adder
def
add
self
x
y
return
x
y
class
dictadder
adder
def
add
self
x
y
new
for
k
in
x
keys
new
k
x
k
for
k
in
y
keys
new
k
y
k
return
new
python
from
adder
import
x
adder
x
add
not
implemented
x
listadder
x
add
x
dictadder
x
add
x
adder
x
not
implemented
x
listadder
x
x
traceback
innermost
last
file
stdin
line
in
typeerror
add
nor
radd
defined
for
these
operands
notice
in
the
last
test
that
you
get
an
error
for
expressions
where
a
class
instance
appears
on
the
right
of
a
if
you
want
to
fix
this
use
radd
methods
as
described
in
operator
overloading
in
chapter
if
you
are
saving
a
value
in
the
instance
anyhow
you
might
as
well
rewrite
the
add
method
to
take
just
one
argument
in
the
spirit
of
other
examples
in
this
part
of
the
book
class
adder
def
init
self
start
self
data
start
def
add
self
other
return
self
add
other
def
add
self
y
pass
a
single
argument
the
left
side
is
in
self
part
vi
classes
and
oop
print
not
implemented
class
listadder
adder
def
add
self
y
return
self
data
y
class
dictadder
adder
def
add
self
y
pass
change
to
use
self
data
instead
of
x
x
listadder
y
x
print
y
prints
because
values
are
attached
to
objects
rather
than
passed
around
this
version
is
arguably
more
object
oriented
and
once
you
ve
gotten
to
this
point
you
ll
probably
find
that
you
can
get
rid
of
add
altogether
and
simply
define
type
specific
add
methods
in
the
two
subclasses
operator
overloading
the
solution
code
file
mylist
py
uses
a
few
operator
overloading
methods
that
the
text
didn
t
say
much
about
but
they
should
be
straightforward
to
understand
copying
the
initial
value
in
the
constructor
is
important
because
it
may
be
mutable
you
don
t
want
to
change
or
have
a
reference
to
an
object
that
s
possibly
shared
somewhere
outside
the
class
the
getattr
method
routes
calls
to
the
wrapped
list
for
hints
on
an
easier
way
to
code
this
in
python
and
later
see
extending
types
by
subclassing
on
page
in
chapter
class
mylist
def
init
self
start
self
wrapped
start
copy
start
no
side
effects
self
wrapped
make
sure
it
s
a
list
here
for
x
in
start
self
wrapped
append
x
def
add
self
other
return
mylist
self
wrapped
other
def
mul
self
time
return
mylist
self
wrapped
time
def
getitem
self
offset
return
self
wrapped
offset
def
len
self
return
len
self
wrapped
def
getslice
self
low
high
return
mylist
self
wrapped
low
high
def
append
self
node
self
wrapped
append
node
def
getattr
self
name
other
methods
sort
reverse
etc
return
getattr
self
wrapped
name
def
repr
self
return
repr
self
wrapped
if
name
main
x
mylist
spam
print
x
print
x
print
x
appendix
b
solutions
to
end
of
part
exercises
print
x
eggs
print
x
x
append
a
x
sort
for
c
in
x
print
c
end
python
mylist
py
s
p
a
m
a
p
a
m
s
p
a
m
eggs
s
p
a
m
s
p
a
m
s
p
a
m
a
a
m
p
s
note
that
it
s
important
to
copy
the
start
value
by
appending
instead
of
slicing
here
because
otherwise
the
result
may
not
be
a
true
list
and
so
will
not
respond
to
expected
list
methods
such
as
append
e
g
slicing
a
string
returns
another
string
not
a
list
you
would
be
able
to
copy
a
mylist
start
value
by
slicing
because
its
class
overloads
the
slicing
operation
and
provides
the
expected
list
interface
however
you
need
to
avoid
slice
based
copying
for
objects
such
as
strings
also
note
that
sets
are
a
built
in
type
in
python
today
so
this
is
largely
just
a
coding
exercise
see
chapter
for
more
on
sets
subclassing
my
solution
mysub
py
appears
below
your
solution
should
be
similar
from
mylist
import
mylist
class
mylistsub
mylist
calls
shared
by
instances
def
init
self
start
self
adds
mylist
init
self
start
varies
in
each
instance
def
add
self
other
mylistsub
calls
self
adds
return
mylist
add
self
other
class
wide
counter
per
instance
counts
def
stats
self
return
self
calls
self
adds
all
adds
my
adds
if
name
main
x
mylistsub
spam
y
mylistsub
foo
print
x
print
x
print
x
eggs
print
x
toast
print
y
bar
print
x
stats
python
mysub
py
part
vi
classes
and
oop
a
p
a
s
p
s
p
f
o
m
a
m
eggs
a
m
toast
o
bar
metaclass
methods
i
worked
through
this
exercise
as
follows
notice
that
in
python
operators
try
to
fetch
attributes
through
getattr
too
you
need
to
return
a
value
to
make
them
work
caveat
as
noted
in
chapter
getattr
is
not
called
for
built
in
operations
in
python
so
the
following
expression
won
t
work
as
shown
in
a
class
like
this
must
redefine
x
operator
overloading
methods
explicitly
more
on
this
in
chapters
and
class
meta
def
getattr
self
name
print
get
name
def
setattr
self
name
value
print
set
name
value
x
meta
x
append
get
append
x
spam
pork
set
spam
pork
x
get
coerce
traceback
innermost
last
file
stdin
line
in
typeerror
call
of
non
function
x
get
getitem
traceback
innermost
last
file
stdin
line
in
typeerror
call
of
non
function
x
get
len
traceback
innermost
last
file
stdin
line
in
typeerror
call
of
non
function
set
objects
here
s
the
sort
of
interaction
you
should
get
comments
explain
which
methods
are
called
python
from
setwrapper
import
set
x
set
y
set
x
y
set
x
y
appendix
b
solutions
to
end
of
part
exercises
runs
init
and
intersect
then
repr
or
union
then
repr
set
z
set
hello
z
z
h
o
init
removes
duplicates
getitem
h
e
for
c
in
z
print
c
end
getitem
l
o
len
z
z
set
h
e
l
o
len
repr
z
mello
z
mello
set
e
l
o
set
h
e
l
o
m
my
solution
to
the
multiple
operand
extension
subclass
looks
like
the
following
class
file
multiset
py
it
only
needs
to
replace
two
methods
in
the
original
set
the
class
s
documentation
string
explains
how
it
works
from
setwrapper
import
set
class
multiset
set
inherits
all
set
names
but
extends
intersect
and
union
to
support
multiple
operands
note
that
self
is
still
the
first
argument
stored
in
the
args
argument
now
also
note
that
the
inherited
and
operators
call
the
new
methods
here
with
arguments
but
processing
more
than
requires
a
method
call
not
an
expression
def
intersect
self
others
res
for
x
in
self
for
other
in
others
if
x
not
in
other
break
else
res
append
x
return
set
res
def
union
args
res
for
seq
in
args
for
x
in
seq
if
not
x
in
res
res
append
x
return
set
res
scan
first
sequence
for
all
other
args
item
in
each
one
no
break
out
of
loop
yes
add
item
to
end
self
is
args
for
all
args
for
all
nodes
add
new
items
to
result
your
interaction
with
the
extension
will
look
something
like
the
following
note
that
you
can
intersect
by
using
or
calling
intersect
but
you
must
call
intersect
for
three
or
more
operands
is
a
binary
two
sided
operator
also
note
that
we
could
have
called
multiset
simply
set
to
make
this
change
more
transparent
if
we
used
setwrapper
set
to
refer
to
the
original
within
multiset
part
vi
classes
and
oop
from
multiset
import
x
multiset
y
multiset
z
multiset
x
y
x
y
set
set
two
operands
x
intersect
y
z
set
x
union
y
z
set
x
intersect
set
x
union
range
set
three
operands
four
operands
non
multisets
work
too
class
tree
links
here
is
the
way
i
changed
the
lister
classes
and
a
rerun
of
the
test
to
show
its
format
do
the
same
for
the
dir
based
version
and
also
do
this
when
formatting
class
objects
in
the
tree
climber
variant
class
listinstance
def
str
self
return
instance
of
s
s
address
s
n
s
self
class
name
my
class
s
name
self
supers
my
class
s
own
supers
id
self
my
address
self
attrnames
name
value
list
def
attrnames
self
unchanged
def
supers
self
names
for
super
in
self
class
bases
one
level
up
from
class
names
append
super
name
name
not
str
super
return
join
names
c
misc
python
testmixin
py
instance
of
sub
super
listinstance
address
name
data
spam
name
data
eggs
name
data
composition
my
solution
is
below
file
lunch
py
with
comments
from
the
description
mixed
in
with
the
code
this
is
one
case
where
it
s
probably
easier
to
express
a
problem
in
python
than
it
is
in
english
class
lunch
def
init
self
make
embed
customer
employee
self
cust
customer
self
empl
employee
def
order
self
foodname
start
customer
order
simulation
self
cust
placeorder
foodname
self
empl
def
result
self
ask
the
customer
about
its
food
self
cust
printfood
appendix
b
solutions
to
end
of
part
exercises
class
customer
def
init
self
initialize
my
food
to
none
self
food
none
def
placeorder
self
foodname
employee
place
order
with
employee
self
food
employee
takeorder
foodname
def
printfood
self
print
the
name
of
my
food
print
self
food
name
class
employee
def
takeorder
self
foodname
return
food
foodname
return
food
with
desired
name
class
food
def
init
self
name
self
name
name
store
food
name
if
name
main
x
lunch
x
order
burritos
x
result
x
order
pizza
x
result
self
test
code
if
run
not
imported
python
lunch
py
burritos
pizza
zoo
animal
hierarchy
here
is
the
way
i
coded
the
taxonomy
in
python
file
zoo
py
it
s
artificial
but
the
general
coding
pattern
applies
to
many
real
structures
from
guis
to
employee
databases
notice
that
the
self
speak
reference
in
animal
triggers
an
independent
inheritance
search
which
finds
speak
in
a
subclass
test
this
interactively
per
the
exercise
description
try
extending
this
hierarchy
with
new
classes
and
making
instances
of
various
classes
in
the
tree
class
animal
def
reply
self
def
speak
self
self
speak
print
spam
class
mammal
animal
def
speak
self
print
huh
class
cat
mammal
def
speak
self
print
meow
class
dog
mammal
def
speak
self
print
bark
back
to
subclass
custom
message
class
primate
mammal
def
speak
self
print
hello
world
class
hacker
primate
pass
inherit
from
primate
part
vi
classes
and
oop
the
dead
parrot
sketch
here
s
how
i
implemented
this
one
file
parrot
py
notice
how
the
line
method
in
the
actor
superclass
works
by
accessing
self
attributes
twice
it
sends
python
back
to
the
instance
twice
and
hence
invokes
two
inheritance
searches
self
name
and
self
says
find
information
in
the
specific
subclasses
class
actor
def
line
self
print
self
name
repr
self
says
class
customer
actor
name
customer
def
says
self
return
that
s
one
ex
bird
class
clerk
actor
name
clerk
def
says
self
return
no
it
isn
t
class
parrot
actor
name
parrot
def
says
self
return
none
class
scene
def
init
self
self
clerk
clerk
self
customer
customer
self
subject
parrot
def
action
self
self
customer
line
self
clerk
line
self
subject
line
embed
some
instances
scene
is
a
composite
delegate
to
embedded
part
vii
exceptions
and
tools
see
test
your
knowledge
part
vii
exercises
on
page
in
chapter
for
the
exercises
try
except
my
version
of
the
oops
function
file
oops
py
follows
as
for
the
noncoding
questions
changing
oops
to
raise
a
keyerror
instead
of
an
indexerror
means
that
the
try
handler
won
t
catch
the
exception
it
percolates
to
the
top
level
and
triggers
python
s
default
error
message
the
names
keyerror
and
index
error
come
from
the
outermost
built
in
names
scope
import
builtins
builtin
in
python
and
pass
it
as
an
argument
to
the
dir
function
to
see
for
yourself
def
oops
raise
indexerror
def
doomed
try
oops
except
indexerror
appendix
b
solutions
to
end
of
part
exercises
print
caught
an
index
error
else
print
no
error
caught
if
name
main
doomed
python
oops
py
caught
an
index
error
exception
objects
and
lists
here
s
the
way
i
extended
this
module
for
an
exception
of
my
own
class
myerror
exception
pass
def
oops
raise
myerror
spam
def
doomed
try
oops
except
indexerror
print
caught
an
index
error
except
myerror
as
data
print
caught
error
myerror
data
else
print
no
error
caught
if
name
main
doomed
python
oops
py
caught
error
class
main
myerror
spam
like
all
class
exceptions
the
instance
comes
back
as
the
extra
data
the
error
message
shows
both
the
class
and
its
instance
spam
the
instance
must
be
inheriting
both
an
init
and
a
repr
or
str
from
python
s
exception
class
or
it
would
print
like
the
class
does
see
chapter
for
details
on
how
this
works
in
built
in
exception
classes
error
handling
here
s
one
way
to
solve
this
one
file
safe
py
i
did
my
tests
in
a
file
rather
than
interactively
but
the
results
are
about
the
same
import
sys
traceback
def
safe
entry
args
try
entry
args
catch
everything
else
except
traceback
print
exc
print
got
sys
exc
info
sys
exc
info
import
oops
safe
oops
oops
python
safe
py
part
vii
exceptions
and
tools
traceback
innermost
last
file
safe
py
line
in
safe
entry
args
file
oops
py
line
in
oops
raise
myerror
world
hello
world
got
hello
world
catch
everything
else
here
are
a
few
examples
for
you
to
study
as
time
allows
for
more
see
follow
up
books
and
the
web
find
the
largest
python
source
file
in
a
single
directory
import
os
glob
dirname
r
c
python
lib
allsizes
allpy
glob
glob
dirname
os
sep
py
for
filename
in
allpy
filesize
os
path
getsize
filename
allsizes
append
filesize
filename
allsizes
sort
print
allsizes
print
allsizes
find
the
largest
python
source
file
in
an
entire
directory
tree
import
sys
os
pprint
if
sys
platform
win
dirname
r
c
python
lib
else
dirname
usr
lib
python
allsizes
for
thisdir
subshere
fileshere
in
os
walk
dirname
for
filename
in
fileshere
if
filename
endswith
py
fullname
os
path
join
thisdir
filename
fullsize
os
path
getsize
fullname
allsizes
append
fullsize
fullname
allsizes
sort
pprint
pprint
allsizes
pprint
pprint
allsizes
find
the
largest
python
source
file
on
the
module
import
search
path
import
sys
os
pprint
visited
allsizes
for
srcdir
in
sys
path
for
thisdir
subshere
fileshere
in
os
walk
srcdir
thisdir
os
path
normpath
thisdir
appendix
b
solutions
to
end
of
part
exercises
if
thisdir
upper
in
visited
continue
else
visited
thisdir
upper
true
for
filename
in
fileshere
if
filename
endswith
py
pypath
os
path
join
thisdir
filename
try
pysize
os
path
getsize
pypath
except
print
skipping
pypath
allsizes
append
pysize
pypath
allsizes
sort
pprint
pprint
allsizes
pprint
pprint
allsizes
sum
columns
in
a
text
file
separated
by
commas
filename
data
txt
sums
for
line
in
open
filename
cols
line
split
nums
int
col
for
col
in
cols
for
ix
num
in
enumerate
nums
sums
ix
sums
get
ix
num
for
key
in
sorted
sums
print
key
sums
key
similar
to
prior
but
using
lists
instead
of
dictionaries
for
sums
import
sys
filename
sys
argv
numcols
int
sys
argv
totals
numcols
for
line
in
open
filename
cols
line
split
nums
int
x
for
x
in
cols
totals
x
y
for
x
y
in
zip
totals
nums
print
totals
test
for
regressions
in
the
output
of
a
set
of
scripts
import
os
testscripts
dict
script
test
py
args
dict
script
test
py
args
spam
or
glob
script
args
dir
for
testcase
in
testscripts
part
vii
exceptions
and
tools
commandline
script
s
args
s
testcase
output
os
popen
commandline
read
result
testcase
script
result
if
not
os
path
exists
result
open
result
w
write
output
print
created
result
else
priorresult
open
result
read
if
output
priorresult
print
failed
testcase
script
print
output
else
print
passed
testcase
script
build
gui
with
tkinter
tkinter
in
with
buttons
that
change
color
and
grow
from
tkinter
import
use
tkinter
in
import
random
fontsize
colors
red
green
blue
yellow
orange
white
cyan
purple
def
reply
text
print
text
popup
toplevel
color
random
choice
colors
label
popup
text
popup
bg
black
fg
color
pack
l
config
fg
color
def
timer
l
config
fg
random
choice
colors
win
after
timer
def
grow
global
fontsize
fontsize
l
config
font
arial
fontsize
italic
win
after
grow
win
tk
l
label
win
text
spam
font
arial
fontsize
italic
fg
yellow
bg
navy
relief
raised
l
pack
side
top
expand
yes
fill
both
button
win
text
press
command
lambda
reply
red
pack
side
bottom
fill
x
button
win
text
timer
command
timer
pack
side
bottom
fill
x
button
win
text
grow
command
grow
pack
side
bottom
fill
x
win
mainloop
similar
to
prior
but
use
classes
so
each
window
has
own
state
information
from
tkinter
import
import
random
appendix
b
solutions
to
end
of
part
exercises
class
mygui
a
gui
with
buttons
that
change
color
and
make
the
label
grow
colors
blue
green
orange
red
brown
yellow
def
init
self
parent
title
popup
parent
title
title
self
growing
false
self
fontsize
self
lab
label
parent
text
gui
fg
white
bg
navy
self
lab
pack
expand
yes
fill
both
button
parent
text
spam
command
self
reply
pack
side
left
button
parent
text
grow
command
self
grow
pack
side
left
button
parent
text
stop
command
self
stop
pack
side
left
def
reply
self
change
the
button
s
color
at
random
on
spam
presses
self
fontsize
color
random
choice
self
colors
self
lab
config
bg
color
font
courier
self
fontsize
bold
italic
def
grow
self
start
making
the
label
grow
on
grow
presses
self
growing
true
self
grower
def
grower
self
if
self
growing
self
fontsize
self
lab
config
font
courier
self
fontsize
bold
self
lab
after
self
grower
def
stop
self
stop
the
button
growing
on
stop
presses
self
growing
false
class
mysubgui
mygui
colors
black
purple
customize
to
change
color
choices
mygui
tk
main
mygui
toplevel
mysubgui
toplevel
mainloop
email
inbox
scanning
and
maintenance
utility
scan
pop
email
box
fetching
just
headers
allowing
deletions
without
downloading
the
complete
message
import
poplib
getpass
sys
part
vii
exceptions
and
tools
mailserver
your
pop
email
server
name
here
pop
rmi
net
mailuser
your
pop
email
user
name
here
brian
mailpasswd
getpass
getpass
password
for
s
mailserver
print
connecting
server
poplib
pop
mailserver
server
user
mailuser
server
pass
mailpasswd
try
print
server
getwelcome
msgcount
mboxsize
server
stat
print
there
are
msgcount
mail
messages
size
mboxsize
msginfo
server
list
print
msginfo
for
i
in
range
msgcount
msgnum
i
msgsize
msginfo
i
split
resp
hdrlines
octets
server
top
msgnum
get
hdrs
only
print
print
d
octets
d
size
s
msgnum
octets
msgsize
for
line
in
hdrlines
print
line
if
input
print
in
y
y
for
line
in
server
retr
msgnum
print
line
if
input
delete
in
y
y
print
deleting
server
dele
msgnum
else
print
skipping
finally
server
quit
input
bye
get
whole
msg
delete
on
srvr
make
sure
we
unlock
mbox
keep
window
up
on
windows
cgi
server
side
script
to
interact
with
a
web
browser
usr
bin
python
import
cgi
form
cgi
fieldstorage
parse
form
data
print
content
type
text
html
n
hdr
plus
blank
line
print
html
print
title
reply
page
title
html
reply
page
print
body
if
not
user
in
form
print
h
who
are
you
h
else
print
h
hello
i
s
i
h
cgi
escape
form
user
value
print
body
html
database
script
to
populate
and
query
a
mysql
database
from
mysqldb
import
connect
appendix
b
solutions
to
end
of
part
exercises
conn
connect
host
localhost
user
root
passwd
darling
curs
conn
cursor
try
curs
execute
drop
database
testpeopledb
except
pass
did
not
exist
curs
execute
create
database
testpeopledb
curs
execute
use
testpeopledb
curs
execute
create
table
people
name
char
job
char
pay
int
curs
execute
insert
people
values
s
s
s
bob
dev
curs
execute
insert
people
values
s
s
s
sue
dev
curs
execute
insert
people
values
s
s
s
ann
mgr
curs
execute
select
from
people
for
row
in
curs
fetchall
print
row
curs
execute
select
from
people
where
name
s
bob
print
curs
description
colnames
desc
for
desc
in
curs
description
while
true
print
row
curs
fetchone
if
not
row
break
for
name
value
in
zip
colnames
row
print
s
s
name
value
conn
commit
save
inserted
records
database
script
to
populate
a
shelve
with
python
objects
see
also
chapter
shelve
and
chapter
pickle
examples
rec
name
first
bob
last
smith
job
dev
mgr
age
rec
name
first
sue
last
jones
job
mgr
age
import
shelve
db
shelve
open
dbfile
db
bob
rec
db
sue
rec
db
close
database
script
to
print
and
update
shelve
created
in
prior
script
import
shelve
db
shelve
open
dbfile
part
vii
exceptions
and
tools
for
key
in
db
print
key
db
key
bob
db
bob
bob
age
db
bob
bob
db
close
appendix
b
solutions
to
end
of
part
exercises
index
symbols
and
equality
operators
repetition
operator
symbol
backslash
backslash
escape
sequences
bitwise
and
operator
bitwise
or
operator
bitwise
xor
operator
colon
curly
braces
dictionaries
and
set
comprehensions
and
sets
and
and
division
operators
see
also
division
double
quotes
and
strings
ellipses
and
equality
operators
hash
bang
hash
character
magnitude
comparison
operators
minus
operator
multiplication
operator
parentheses
functions
and
generator
expressions
and
tuples
and
plus
operator
u
and
u
escapes
remainder
operator
semicolon
and
shift
operators
single
quotes
and
strings
square
brackets
dictionaries
and
list
comprehensions
and
lists
and
underscore
add
method
all
variable
bases
attribute
bool
method
call
method
function
interfaces
and
class
attribute
cmp
method
python
contains
method
del
method
delattr
method
delete
method
dict
attribute
doc
attribute
enter
method
eq
method
exit
method
get
method
getattr
method
computed
attributes
delegation
using
delegation
based
managers
example
interception
of
built
in
attributes
loops
avoiding
in
interception
methods
getattribute
compared
to
getattribute
method
computed
attributes
we
d
like
to
hear
your
suggestions
for
improving
our
indexes
send
email
to
index
oreilly
com
delegation
based
managers
example
interception
of
built
in
operation
attributes
loops
avoiding
in
attribute
interception
getattr
compared
to
getitem
method
index
iteration
membership
gt
method
iadd
method
init
py
files
init
method
iter
method
design
purpose
membership
len
method
lt
method
main
attribute
name
attribute
of
modules
and
main
module
metaclass
variable
python
name
attribute
command
line
arguments
with
unit
tests
ne
method
next
method
radd
method
repr
method
custom
exception
display
using
set
method
setattr
method
setitem
method
slots
attribute
descriptors
and
dict
attribute
and
str
method
custom
exception
display
using
overload
method
for
printing
objects
sub
method
a
abs
function
absolute
imports
abstract
superclasses
example
python
and
accessor
functions
index
activepython
annotation
information
anonymous
functions
anydbm
module
python
append
method
apply
built
in
python
arbitrary
arguments
examples
apply
built
in
python
applying
functions
generically
collecting
arguments
unpacking
arguments
arguments
argument
passing
basics
mutable
argument
changes
avoiding
output
parameters
simulating
shared
references
argument
matching
modes
arbitrary
arguments
examples
available
modes
defaults
keyword
only
arguments
python
keywords
keywords
and
defaults
combined
matching
syntax
ordering
rules
emulating
python
print
in
earlier
versions
keyword
only
arguments
generalized
set
functions
keyword
arguments
min
wakeup
call
three
ways
of
coding
using
max
instead
of
min
arithmeticerror
class
as
extension
for
import
and
from
ascii
character
code
coding
ascii
text
assert
statement
trapping
constraints
example
assertionerror
exception
assignment
import
from
and
def
mutables
in
within
function
classes
assignment
statements
assignment
statement
forms
augmented
assignments
sequence
assignments
extended
sequence
unpacking
in
python
multiple
target
assignments
associative
arrays
as
integer
ratio
method
attribute
fetches
attribute
interception
methods
attribute
tree
construction
attributes
managed
attributes
see
managed
attributes
automatic
memory
management
b
base
indicators
baseexception
class
basic
numeric
literals
basic
statement
form
beginners
mistakes
behavior
methods
binary
files
binary
numeric
literals
binary
mode
files
in
python
bit
length
method
python
blank
lines
block
delimiters
blocks
bom
byte
order
marker
python
handling
in
book
update
websites
xlv
bool
type
boolean
numeric
type
boolean
object
type
boolean
operators
booleans
in
python
bound
methods
other
callable
objects
compared
to
break
statement
bsddb
extension
module
built
in
exception
classes
categories
class
hierarchy
default
printing
and
state
built
in
mathematical
functions
built
in
object
types
additional
core
types
dictionaries
files
issues
to
be
aware
of
assignment
creates
references
cyclic
data
structures
immutable
types
repetition
adds
one
level
deep
lists
numbers
object
classifications
sets
shared
properties
strings
tuples
type
built
in
scope
builtins
module
byte
code
compilation
byte
order
marker
see
bom
bytearray
object
type
using
bytearray
string
type
bytes
bytes
object
data
encoding
in
literals
bytes
string
type
c
c
code
call
expressions
calls
character
encoding
schemes
character
set
encoding
declarations
chmod
command
class
attribute
descriptors
class
decorators
coding
decorators
versus
manager
functions
retaining
multiple
instances
singleton
classes
tracing
object
interfaces
implementation
justification
metaclasses
compared
to
private
attributes
implementing
index
public
attributes
implementing
supporting
multiple
instances
usage
class
methods
counting
instances
counting
per
class
justification
using
class
properties
class
statement
example
general
form
classes
abstract
superclasses
as
attributes
of
modules
built
in
types
extending
embedding
subclassing
class
decorators
class
hierarchies
class
instances
class
method
calls
class
methods
see
class
methods
class
statements
class
trees
classic
classes
coding
behavior
methods
class
statement
composition
delegation
and
embedding
constructors
customizing
databases
storing
objects
in
docstrings
inheritance
introspection
making
instances
methods
modules
versus
namespaces
oop
concepts
embodied
in
operator
overloading
subclassing
dependencies
and
function
design
dictionaries
versus
distinctions
of
exception
classes
see
exception
classes
frameworks
index
function
decorators
gotchas
changing
class
attributes
changing
mutable
class
attributes
delegation
based
classes
python
methods
classes
and
nested
scopes
python
and
before
multiple
inheritance
overwrapping
inheritance
customization
by
instances
generation
of
interception
of
python
operators
justification
metaclasses
as
namespace
objects
naming
conventions
new
style
classes
changes
persistence
and
properties
of
simplest
class
static
and
class
methods
subclasses
and
superclasses
user
defined
classes
classic
division
classmethod
function
classtree
function
close
method
closure
function
code
reuse
modules
and
oop
and
code
reuse
and
code
redundancy
codecs
open
call
python
cohesion
collections
see
lists
colon
command
line
see
interactive
prompt
command
line
arguments
comments
companies
using
python
comparison
methods
comparison
operators
comparisons
in
python
compiled
extensions
complex
numbers
component
integration
composites
composition
stream
processing
with
compound
statements
general
pattern
comprehension
syntax
concatenation
constructor
method
init
constructors
coding
customizing
context
managers
file
and
server
connection
closure
continue
statement
control
flow
statements
conversionflag
copy
module
nested
data
structures
copying
with
copying
versus
referencing
of
objects
core
data
types
count
method
and
tuples
coupling
cpython
cross
file
module
linking
cross
file
name
changes
curly
braces
dictionaries
and
set
comprehensions
and
sets
and
cwd
current
working
directory
cyclic
references
cygwin
cython
d
data
attributes
data
hiding
in
modules
data
structures
database
programming
databases
storing
objects
in
pickles
and
shelves
dbm
module
debuggers
debugging
assert
statement
trapping
constraints
example
outer
try
statements
using
for
decimal
module
decimal
numeric
literals
decimal
numeric
type
decoding
and
encoding
decorators
call
and
instance
management
class
decorators
coding
decorator
arguments
versus
function
annotations
function
decorators
coding
functions
and
classes
managing
open
issues
private
and
public
attributes
justification
nesting
type
testing
with
using
and
defining
def
statement
default
exception
handler
definitions
del
statement
delegation
descriptor
protocol
descriptors
descriptor
methods
method
arguments
read
only
descriptors
delete
method
get
method
set
method
slots
implementation
by
design
patterns
destructor
method
developer
community
development
tools
python
toolset
hierarchy
diamond
pattern
of
multiple
inheritance
trees
dictionaries
basic
operations
changing
in
place
classes
versus
coding
of
common
literals
and
operations
items
method
languages
table
example
pop
method
index
python
comparisons
python
changes
in
dictionary
comprehensions
dictionary
magnitude
comparisons
dictionary
views
dictionary
views
and
sets
sorting
dictionary
keys
use
of
in
method
instead
of
has
key
update
method
usage
notes
missing
key
errors
avoiding
records
using
as
simulating
flexible
lists
sparse
data
structures
using
for
values
method
ways
of
making
dictionaries
dictionary
comprehensions
dictionary
object
type
mapping
operations
missing
keys
and
if
tests
nesting
sorting
keys
and
for
loops
dictionary
view
iterators
dir
function
mix
in
classes
listing
inherited
attributes
of
direct
or
indirect
recursion
disutils
division
python
and
python
compared
docstr
py
docstrings
built
in
docstrings
docstring
standards
user
defined
docstrings
doctest
documentation
dir
function
docstrings
see
docstrings
hash
mark
comments
pydoc
reference
books
standard
manual
set
web
resources
dom
parsing
dotted
path
double
quotes
and
strings
dynamic
typing
index
garbage
collection
objects
versus
variables
polymorphism
and
references
shared
references
variables
e
easter
egg
ebcdic
encoding
eclipse
elementtree
package
elif
else
if
clause
ellipses
else
clause
see
also
for
statement
try
statement
while
statement
emacs
embedded
calls
embedding
contrasted
with
inheritance
empty
strings
encapsulation
encoding
and
decoding
encodings
module
end
of
line
characters
enthought
python
distribution
enumerate
function
env
program
equality
testing
for
error
checking
python
compared
to
c
error
handling
etree
package
eval
function
event
notification
except
clause
see
also
try
statement
empty
clauses
exception
class
built
in
exceptions
and
system
exit
events
exception
classes
advantages
built
in
exception
classes
categories
default
printing
and
state
hierarchies
coding
custom
data
and
behavior
providing
exception
details
providing
exception
methods
custom
print
displays
defining
handler
methods
exception
hierarchies
justification
exceptions
assert
statement
trapping
constraints
example
catching
built
in
exceptions
example
catching
exceptions
class
based
exceptions
see
also
exception
classes
for
closing
files
and
server
connections
default
behavior
default
exception
handlers
design
tips
and
gotchas
handler
specificity
and
class
based
categories
limiting
handler
generality
wrappers
exception
handlers
nested
exception
handlers
in
process
testing
with
justification
nonerror
exceptions
user
defined
exceptions
purposes
raise
statement
raising
exceptions
string
exceptions
deprecation
of
termination
actions
try
statement
see
try
statement
typical
uses
for
user
defined
exceptions
with
as
statement
context
management
protocol
usage
exec
function
loading
modules
from
a
string
exec
statement
python
executable
files
creating
with
python
unix
path
defining
in
comment
executable
scripts
execution
optimization
tools
exercises
xliii
part
i
part
ii
part
iii
part
iv
part
v
part
vi
part
vii
expression
operators
table
of
including
precedence
versions
and
x
differences
expression
statements
in
place
changes
expressions
mixing
operators
parentheses
and
extend
method
extended
slicing
extensions
in
python
versions
and
xxxv
f
factories
justification
factoring
of
code
factory
design
pattern
factory
functions
false
and
true
values
fieldname
file
execution
file
icon
clicks
limitations
file
input
output
python
file
iterators
file
object
methods
and
printing
operations
file
object
type
files
advanced
file
methods
common
operations
examples
of
usage
file
context
managers
packed
binary
data
storing
and
parsing
in
files
storing
and
parsing
of
python
objects
text
and
binary
files
python
file
iterators
mode
string
argument
for
opening
opening
index
pickle
using
filter
filter
function
filter
iterator
finally
clause
see
also
try
statement
find
method
fixed
precision
floating
point
values
floating
point
numbers
floor
division
flush
method
for
loop
iterator
as
an
example
of
line
by
line
iteration
with
next
method
versus
while
and
range
for
statement
examples
extended
sequence
unpacking
in
format
nested
for
loops
tuple
assignment
in
format
function
format
method
formats
py
formatspec
formatting
fraction
number
object
type
fraction
numeric
type
conversions
frameworks
freeze
from
clause
raise
statement
from
statement
as
assignment
equivalence
to
import
from
imports
and
reload
statement
interactive
testing
import
statement
versus
name
copying
without
linking
pitfalls
corruption
of
namespaces
reload
statement
when
used
with
when
import
is
required
variables
and
underscore
prefix
and
all
variable
from
future
statement
index
from
float
method
frozen
binaries
frozenset
built
in
call
function
argument
matching
forms
function
attributes
function
calls
function
decorators
basics
coding
adding
arguments
decorating
class
methods
state
information
retention
timing
calls
tracing
calls
example
function
arguments
validating
generalizing
for
keywords
and
defaults
implementation
details
open
issues
range
tester
for
positional
arguments
implementation
properties
of
managed
attributes
coding
with
supporting
method
decoration
usage
function
introspection
functional
programming
functions
attributes
and
annotations
calls
coding
definitions
dependencies
and
function
design
design
concepts
example
definitions
and
calls
example
intersecting
sequences
local
variables
function
annotations
python
function
attributes
function
instrospection
function
related
statements
and
expressions
global
statement
see
global
statement
gotchas
default
arguments
and
mutable
objects
enclosing
scope
loop
variables
functions
without
returns
static
detection
of
local
names
indirect
function
calls
lambda
expression
see
lambda
expression
local
scope
mapping
over
sequences
nonlocal
statement
see
nonlocal
statement
parentheses
and
polymorphism
purpose
of
recursive
functions
arbitrary
structures
handling
coding
alternatives
loop
statements
versus
summation
return
statement
see
return
statement
simple
functions
yield
statement
see
yield
statement
g
garbage
collection
generator
expressions
generator
functions
examples
generator
expressions
versus
iteration
protocol
and
iteration
tools
coding
a
map
func
coding
zip
and
map
none
emulating
zip
and
map
functions
one
shot
iterations
send
method
and
next
state
suspension
value
generation
in
built
in
types
and
classes
generator
objects
generators
get
method
getrefcount
function
global
scope
access
without
the
global
statement
global
statement
minimize
cross
file
changes
minimize
global
variables
google
s
unladen
swallow
project
guis
graphical
user
interfaces
h
handlers
has
a
relationships
hash
bang
hash
character
hash
tables
hash
mark
comments
hashes
has
key
method
python
x
help
function
helper
functions
hexadecimal
numeric
literals
home
directory
i
ides
idle
see
idle
user
interface
idle
user
interface
getting
support
on
linux
idle
debugger
source
code
creation
and
editing
in
startup
in
windows
and
unix
like
systems
usage
and
pitfalls
if
clause
if
statement
examples
format
multiway
branching
if
else
ternary
expression
immutability
immutable
objects
implementation
of
shared
services
and
data
implementation
related
types
import
hooks
import
statement
py
file
extension
and
as
assignment
cross
file
name
changes
enabling
new
language
features
from
statement
equivalence
to
from
statement
versus
usage
notes
imports
in
expressions
in
membership
expression
in
place
addition
index
in
place
change
operations
incremental
prototyping
indentation
rules
tabs
versus
spaces
index
method
and
tuples
indexing
indexing
expressions
indirect
function
calls
infinite
loops
inheritance
abstract
superclasses
attribute
inheritance
key
ideas
of
attribute
trees
class
interface
techniques
real
world
relationships
modeling
with
simplicity
of
inheritance
model
specializing
inherited
methods
input
function
insert
method
installing
python
instance
methods
instances
making
instances
coding
constructors
incremental
testing
test
code
as
namespace
objects
int
int
function
integer
division
python
versus
integers
python
integrated
development
environments
see
ides
interactive
loops
math
operations
on
user
input
nesting
code
three
levels
deep
simple
example
testing
inputs
try
statements
handling
errors
with
interactive
prompt
exiting
a
session
experimenting
with
code
files
running
from
multiline
statements
entering
testing
code
index
tips
for
using
internet
scripting
interpreters
introspection
introspection
attributes
ironpython
is
operator
is
a
relationships
is
integer
method
items
method
iter
function
iteration
built
in
tools
for
manual
iteration
iteration
protocol
iterators
additional
built
in
iterators
file
iterators
filter
generator
functions
see
generator
functions
map
in
python
range
support
for
multiple
iterators
range
function
timing
iteration
alternatives
other
suggestions
time
module
time
module
alternatives
timing
results
timing
script
zip
iters
py
j
jit
just
in
time
compilation
jump
tables
jython
xlv
k
keys
keys
method
keyword
arguments
keyword
only
arguments
python
justification
ordering
rules
komodo
l
lambda
expression
basics
defining
inline
callback
functions
in
tkinter
justification
for
nested
lambdas
and
scopes
potential
for
code
obfuscation
lambdas
and
nested
scopes
latin
character
encoding
legb
rule
len
function
lexical
scoping
linux
python
command
line
starting
list
comprehension
expressions
list
comprehensions
basics
best
uses
of
extended
syntax
files
using
on
map
function
and
map
function
versus
matrixes
and
tests
and
nested
loops
adding
list
object
type
bounds
checking
nesting
type
specific
operations
list
unpacking
assignment
statements
lister
py
listinstance
class
lists
basic
operations
changing
in
place
deleting
items
or
sections
in
place
index
and
slice
assignments
list
method
calls
coding
of
lists
common
literals
and
operations
indexing
slicing
and
matrixes
iteration
and
comprehensions
literals
local
scope
local
variables
long
integers
python
loop
else
block
loop
statement
versus
recursive
functions
loops
break
continue
pass
and
loop
else
clause
coding
techniques
counter
loops
with
while
and
range
for
statement
general
format
generation
of
offsets
and
items
interactive
loops
see
interactive
loops
loop
else
clause
nonexhaustive
traversals
with
range
and
slices
parallel
traversals
with
zip
and
map
range
function
lists
changing
with
while
statement
m
mac
os
x
python
command
line
starting
makedb
py
managed
attributes
attribute
validations
example
descriptors
validation
properties
validation
getattribute
validation
with
getattr
validation
with
coding
to
run
on
attribute
access
comparison
of
management
techniques
descriptors
computed
attributes
descriptor
methods
example
method
arguments
properties
relation
to
read
only
descriptors
state
information
using
in
justification
properties
computed
attributes
decorators
coding
with
first
example
new
style
object
derivation
requirement
getattr
and
getattribute
avoiding
loops
comparison
computed
attributes
delegation
example
index
interception
of
built
in
attributes
manager
class
manager
functions
manual
iteration
manynames
py
map
function
lambda
expressions
and
list
comprehensions
and
list
comprehensions
versus
map
iterator
matching
algorithm
math
module
example
functions
mathematical
functions
max
and
min
functions
mergdexc
py
metaclass
model
see
also
metaclasses
class
statement
protocol
classes
are
instances
of
type
metaclasses
are
subclasses
of
type
metaclasses
see
also
metaclass
model
adding
methods
to
classes
example
manual
augmentation
metaclass
based
augmentation
applying
decorators
to
methods
example
manual
tracing
tracing
with
metaclasses
and
decorators
with
any
decorators
class
decorators
compared
to
decorator
based
augmentation
managing
instances
instead
of
classes
class
decorators
compared
with
coding
basic
metaclass
customizing
construction
and
initialization
factory
functions
using
instances
versus
inheritance
overloading
class
creation
calls
with
classes
index
overloading
class
creation
calls
with
metaclasses
declaration
issues
around
use
potential
roles
metafunctions
metaprograms
method
call
expression
methods
augmenting
methods
bound
and
unbound
methods
bound
methods
calls
to
methods
class
methods
coding
methods
comparison
methods
destructor
method
example
static
methods
see
also
static
methods
superclass
constructors
calling
min
and
max
functions
mins
py
mix
in
classes
coding
instance
attributes
listing
listing
inherited
attributes
listing
object
attributes
in
class
trees
module
packages
package
imports
import
example
justification
packages
and
search
path
settings
inti
py
package
relative
imports
see
package
relative
imports
modules
as
extension
for
import
and
from
attributes
classes
as
attributes
of
classes
versus
creating
data
hiding
in
design
concepts
exec
running
module
files
with
from
statement
future
language
features
enabling
global
scope
gotchas
from
imports
and
reload
from
statement
from
statement
and
variables
recursive
import
failures
statement
order
in
top
level
code
import
statement
importing
byte
code
compilation
if
required
running
importing
by
name
string
importing
of
modules
locating
imports
and
reloads
metaprograms
mixed
usage
modes
module
extensions
module
namespaces
attribute
name
qualification
generation
from
files
imports
versus
scopes
namespace
nesting
module
search
path
advanced
module
selection
concepts
module
file
selection
search
path
configuration
search
path
variations
sys
path
list
third
party
extensions
module
search
path
changing
namespaces
naming
conventions
naming
of
program
structure
and
reloading
modules
example
roles
of
scope
standard
library
transitive
module
reloads
name
attribute
command
line
arguments
with
unit
tests
monty
python
s
flying
circus
multiline
statements
multiple
inheritance
diamond
pattern
inheritance
trees
mix
in
classes
see
mix
in
classes
multiway
branching
mutable
objects
mutables
in
assignments
mybooks
xml
mydir
py
myfile
py
n
name
attribute
name
mangling
namespace
objects
namespaces
attribute
names
name
assignment
namespace
dictionaries
namespace
links
simple
names
negative
offsets
nested
scopes
abitrary
nesting
examples
factory
functions
lambdas
and
nester
py
net
and
ironpython
netbeans
new
style
classes
changes
class
extensions
class
properties
instance
slots
metaclasses
multiple
slot
lists
in
superclasses
slots
and
generic
code
getattribute
method
diamond
inheritance
change
example
explicit
conflict
resolution
scope
of
search
order
type
model
changes
object
type
objects
type
testing
implications
next
function
next
method
non
ascii
text
coding
encoding
and
decoding
none
object
index
nonlocal
statement
absence
from
python
basics
examples
boundary
cases
justification
for
python
alternatives
normal
integers
python
number
object
type
number
operations
bitwise
operations
comparisons
chained
comparisons
complex
numbers
division
integer
precision
math
module
functions
notation
hexadecimal
octal
and
binary
numeric
display
formats
variables
and
basic
expressions
numeric
display
formats
numeric
extensions
numeric
object
type
built
in
numeric
tools
complexity
ranking
expression
operators
and
precedence
numeric
literals
operator
overloading
and
polymorphism
some
noncore
types
booleans
decimal
type
fraction
types
sets
numeric
precision
setting
globally
numeric
programming
numpy
numeric
programming
extension
o
object
embedding
object
persistence
object
type
categories
mutable
versus
immutable
types
shared
operation
sets
object
types
built
in
object
types
see
built
in
object
types
index
object
oriented
programming
object
oriented
scripting
language
object
attr
expression
object
attribute
expression
object
attribute
notation
objects
comparisons
equality
and
truth
compound
object
types
copying
versus
referencing
databases
storing
objects
in
dynamic
typing
and
iterable
objects
nonbuilt
in
object
types
object
classifications
for
built
in
types
references
versus
copies
truth
and
falsity
bool
type
none
object
type
hierarchies
type
object
type
octal
numeric
literals
oop
object
oriented
programming
as
exemplified
by
coding
of
classes
attribute
inheritance
search
class
method
calls
classes
class
trees
customization
by
inheritance
code
reuse
design
issues
bound
and
unbound
methods
composition
delegation
and
wrapper
classes
generic
object
factories
inheritance
multiple
inheritance
polymorphism
pseudoprivate
class
attributes
design
patterns
important
concepts
instances
object
attribute
expression
open
call
python
open
function
mode
string
argument
operator
overloading
attribute
references
attribute
privacy
boolean
tests
call
expressions
function
interfaces
common
operator
overloading
methods
comparisons
constructors
and
expressions
index
iteration
indexing
and
slicing
python
iterator
objects
multiple
iterators
on
one
object
user
defined
iterators
justification
membership
comparisons
python
object
destruction
overloading
methods
overloading
methods
in
python
overview
right
side
and
in
place
addition
string
representation
operator
precedence
optimization
orms
object
relational
mappers
overflowerror
class
p
package
imports
justification
import
versus
from
root
directory
packages
and
search
path
settings
package
relative
imports
absolute
package
paths
versus
basics
examples
imports
outside
packages
imports
relative
to
cwd
imports
still
relative
to
cwd
imports
within
packages
modules
selecting
with
relative
and
absolute
imports
justification
module
lookup
rules
summary
python
changes
versus
scope
packages
parallel
traversals
parentheses
functions
and
generator
expressions
and
tuples
and
parrot
project
parsing
pass
statement
path
environment
variable
pattern
matching
pdb
debugger
pep
python
enhancement
proposal
protocol
person
class
incremental
testing
subclassing
version
portability
person
py
peters
tim
pickle
module
binary
data
requirement
string
serialization
python
pizzashop
py
polymorphism
dynamic
typing
and
example
overloading
in
python
versus
other
languages
pop
method
portability
portable
python
pow
function
precedence
parentheses
and
precedence
rules
print
function
print
operations
print
and
stdout
print
function
python
print
statement
python
print
stream
redirection
version
neutral
printing
print
statement
python
procedure
profile
module
profilers
program
execution
index
development
implications
python
compared
to
other
languages
program
portability
program
shipping
options
program
structure
imports
program
units
programs
icons
opening
with
launching
additional
launch
options
choosing
a
launch
option
clicking
file
icons
exec
function
from
the
command
line
idle
user
interface
input
function
module
imports
and
reloads
unix
executable
scripts
windows
automatic
file
extensions
running
interactively
experimentation
testing
saving
in
files
structure
windows
saving
under
property
built
in
function
computed
attributes
decorators
first
example
proxy
classes
pseudoprivate
attributes
justification
pseudoprivate
names
psf
python
software
foundation
psyco
just
in
time
compiler
pth
file
extension
pth
path
file
directories
pvm
python
virtual
machine
py
file
extension
py
exe
pyc
file
extension
pychecker
pylint
and
pyunit
pydev
pydoc
help
function
html
reports
pyinstaller
pypy
project
python
command
line
options
index
configuration
dos
variables
in
autoexec
bat
environment
variables
path
files
setting
configuration
options
unix
linux
shell
variables
windows
environment
variable
gui
windows
registry
installing
python
string
module
python
xxxii
backward
compatibility
to
older
versions
xxxii
binary
and
unicode
strings
handling
of
booleans
iteration
method
x
next
nonlocal
statement
alternatives
to
in
operator
overloading
methods
python
print
function
emulating
using
keyword
only
arguments
raw
input
function
reload
function
string
object
types
unicode
and
str
operation
sets
new
style
and
classic
classes
python
xxxii
built
in
attributes
compared
x
versions
xxxv
comparisons
and
sorts
dictionary
changes
dictionary
comparisons
extended
sequence
unpacking
in
for
loops
function
annotations
incompatibility
with
older
versions
xxxii
input
function
new
iterables
new
style
classes
older
version
tools
removed
from
xxxvi
special
character
coding
string
object
types
string
type
changes
in
text
and
binary
files
unicode
and
binary
data
support
unsupported
raise
syntax
python
interpreter
installing
on
linux
on
pdas
on
unix
on
windows
on
windows
vista
website
downloads
link
python
programming
language
xxxi
advantages
of
common
coding
gotchas
compared
to
other
languages
developer
productivity
and
development
tools
documentation
see
documentation
execution
speed
iteration
protocol
manuals
and
resources
old
and
new
versions
xxxii
perl
compared
to
portability
primary
implementations
of
so
called
optional
features
statically
typed
languages
compared
to
string
model
support
technical
strengths
user
base
uses
for
pythonpath
pythonpath
directories
pythonstartup
pythonwin
pywin
q
quizzes
xliii
chapter
a
python
q
a
session
chapter
how
python
runs
programs
chapter
how
you
run
programs
chapter
introducing
python
object
types
chapter
numeric
types
chapter
the
dynamic
typing
interlude
chapter
strings
chapter
lists
and
dictionaries
chapter
tuples
files
and
everything
else
chapter
introducing
python
statements
chapter
assignments
expressions
and
prints
chapter
if
tests
and
syntax
rules
chapter
while
and
for
loops
chapter
iterations
and
comprehensions
part
chapter
the
documentation
interlude
chapter
function
basics
chapter
scopes
chapter
arguments
chapter
advanced
function
topics
chapter
iterations
and
comprehensions
part
chapter
modules
the
big
picture
chapter
module
coding
basics
chapter
module
packages
chapter
advanced
module
topics
chapter
oop
the
big
picture
chapter
class
coding
basics
chapter
a
more
realistic
example
chapter
class
coding
details
chapter
operator
overloading
chapter
designing
with
classes
chapter
advanced
class
topics
chapter
exception
basics
chapter
exception
coding
details
chapter
exception
objects
chapter
designing
with
exceptions
chapter
unicode
and
byte
strings
chapter
managed
attributes
chapter
decorators
chapter
metaclasses
quotes
escaping
strings
and
triple
quotes
r
raise
statement
from
clause
python
exception
chaining
index
nonerror
conditions
signaling
with
random
module
range
versus
for
loops
range
function
range
iterator
support
for
multiple
iterators
rapid
prototyping
rational
number
objects
raw
string
literals
raw
strings
raw
input
function
python
x
re
regular
expression
module
string
handling
in
python
read
method
readline
method
recursive
functions
arbitrary
structures
handling
coding
alternatives
direct
or
indirect
loop
statements
versus
summation
recursive
imports
reduce
reduce
function
reference
counters
references
copies
of
objects
versus
shared
references
equality
in
place
changes
relative
imports
reload
function
example
from
imports
and
interactive
testing
import
and
from
contrasted
with
transitive
module
reloads
usage
notes
version
requirements
reloadall
py
remove
method
repetition
replace
method
repr
function
str
compared
to
return
statement
reverse
method
round
function
index
rstrip
method
s
sax
parsing
scientific
programming
scientificpython
programming
extensions
scipy
programming
extensions
scopes
basics
built
in
scope
defaults
with
loop
variables
versus
example
global
statements
module
files
and
name
resolution
and
the
legb
rule
namespaces
nested
functions
and
nonlocal
rules
script
py
script
py
running
with
an
import
scripts
search
tables
see
dictionaries
self
argument
semicolon
send
method
sequence
assignment
statements
sequence
assignments
sequence
operations
sequences
set
comprehensions
set
numeric
type
dictionaries
compared
to
immutable
constraints
and
frozen
sets
python
python
set
comprehensions
in
python
set
object
type
setsubclass
py
shared
references
equality
in
place
changes
shedskin
c
translator
shelve
module
advantages
and
disadvantages
database
client
database
files
object
storage
in
shelve
databases
shelves
and
dictionaries
updating
a
shelve
s
objects
simple
functions
single
quotes
and
strings
site
module
slice
assignment
in
lists
slice
objects
slicing
example
extended
slicing
loops
usage
in
software
components
sort
method
sorted
function
sorts
in
python
source
code
source
file
character
set
encoding
declarations
spaces
special
characters
split
method
square
brackets
dictionaries
and
list
comprehensions
and
lists
and
square
roots
stack
trace
stackless
python
standard
library
library
directories
standard
manual
set
standard
output
stream
stdout
state
information
state
retention
state
with
classes
statements
assignment
statements
see
assignment
statements
compound
statements
differences
from
other
c
like
languages
end
of
line
expression
statements
in
place
changes
indentation
syntax
multiline
statements
python
statement
set
syntax
block
rule
special
case
colon
indentation
interactive
loops
semicolons
statement
separators
static
methods
alternatives
to
coding
with
decorator
syntax
counting
instances
python
and
using
staticmethod
function
steps
stopiteration
exception
str
repr
compared
to
str
object
type
data
encoding
in
str
string
type
python
operation
set
python
compared
to
x
unicode
and
stream
processors
stream
redirection
strides
string
exceptions
deprecation
of
string
formatting
advanced
expressions
dictionary
based
formatting
expressions
string
formatting
type
codes
string
formatting
method
calls
format
method
formatting
expression
compared
to
justification
for
keys
attributes
and
offsets
string
methods
additional
examples
changing
strings
example
parsing
text
example
python
x
string
module
string
method
calls
to
format
method
string
method
calls
python
string
object
type
coding
special
characters
pattern
matching
raw
string
literals
index
sequence
operations
and
string
literals
common
literals
and
operations
escape
sequences
raw
strings
and
escapes
single
and
double
quoted
strings
string
backslash
characters
triple
quotes
version
changes
versions
and
string
types
string
operations
basic
operations
changing
strings
indexing
slicing
extended
slicing
string
conversions
character
code
conversions
strings
and
bit
unicode
values
coding
of
ascii
text
coding
bytearray
objects
using
bytes
objects
python
method
calls
sequence
operations
bytes
string
type
making
bytes
objects
character
encoding
schemes
and
encoding
conversions
escape
sequence
coding
by
type
examples
of
usage
python
literals
and
basic
properties
mixing
string
types
mutability
or
immutability
of
string
types
non
ascii
text
coding
non
ascii
text
encoding
and
decoding
pickle
object
serialization
module
python
python
string
types
usage
re
pattern
matching
module
python
source
file
character
set
encoding
declarations
string
methods
string
types
index
struct
binary
data
module
python
text
and
binary
files
bom
in
python
file
modes
in
python
type
and
content
mismatches
unicode
in
python
type
conversions
unicode
files
using
reading
and
writing
in
python
unicode
strings
coding
unicode
strings
python
coding
xml
parsing
tools
strong
typing
struct
module
string
handling
python
subclasses
coding
augmenting
methods
inheritance
customization
and
extension
oop
as
illustration
of
polymorphism
sum
function
super
class
superclasses
abstract
superclasses
syntax
rules
indentation
multiline
statements
open
syntactic
pairs
rule
sys
exc
info
sys
exit
statuscode
call
sys
getdefaultencoding
function
sys
modules
table
sys
path
list
system
namespace
partitioning
and
modules
systems
programming
t
termination
actions
testdriver
function
tester
testing
of
code
testmixin
py
testprint
py
text
files
in
python
text
mode
files
text
py
threenames
py
time
module
alternatives
timeit
module
timer
module
keyword
only
arguments
tkinter
getting
support
on
linux
settings
top
level
code
top
level
file
transitive
module
reloads
triple
quotes
true
and
false
true
and
false
boolean
values
true
and
false
values
true
division
truth
tests
try
except
statement
try
statement
see
also
exceptions
debugging
with
except
statement
and
nested
try
statements
python
and
later
try
except
else
try
statement
clause
forms
try
else
clause
try
finally
statement
coding
termination
actions
unified
try
except
finally
example
nesting
finally
and
except
statement
syntax
try
finally
statement
file
and
server
connection
closure
tuple
object
type
tuple
unpacking
assignment
statements
tuples
common
literals
and
operations
conversions
methods
and
immutability
in
for
loops
immutability
and
tuple
contents
lists
compared
to
sorting
supported
sequence
operations
syntax
with
parentheses
and
commas
type
class
type
hierarchies
type
object
type
typesubclass
py
u
unbound
methods
python
status
as
functions
undefined
name
exception
underscore
unicode
strings
coding
of
text
handling
in
versions
and
unicode
files
reading
and
writing
python
decoding
mismatches
file
input
decoding
file
output
encoding
manual
encoding
unicode
string
type
python
unicode
string
type
python
x
unicode
strings
union
function
unit
tests
with
name
attribute
unittest
unix
env
lookup
trick
executable
scripts
python
command
line
starting
unladen
swallow
project
update
method
user
base
of
python
language
user
defined
classes
user
defined
exceptions
utf
encoding
utility
modules
v
values
method
van
rossum
guido
variables
declaration
initialization
local
variables
scope
variable
name
rules
index
w
websites
while
loop
versus
for
loops
while
statement
range
function
and
windows
automatic
file
extensions
executable
files
displaying
output
icon
clicks
for
program
initiation
idle
user
interface
and
program
files
opening
with
icons
python
command
line
starting
in
python
files
running
in
python
standard
manual
set
windows
notepad
file
encoding
specification
with
statement
with
as
extension
with
as
statement
context
management
protocol
usage
wrapper
classes
wrapper
objects
wrappers
catching
exceptions
with
write
method
x
xml
y
yield
expression
yield
operator
yield
statement
usage
in
generators
z
zip
zip
function
dictionary
construction
using
zip
iterator
zodb
object
oriented
database
system
index
about
the
author
mark
lutz
is
the
world
leader
in
python
training
the
author
of
python
s
earliest
and
bestselling
texts
and
a
pioneering
figure
in
the
python
community
mark
is
the
author
of
the
popular
o
reilly
books
learning
python
programming
python
and
python
pocket
reference
all
available
in
third
or
fourth
editions
in
he
has
been
using
and
promoting
python
since
started
writing
python
books
in
and
began
teaching
python
classes
in
as
of
early
mark
has
instructed
python
training
sessions
taught
some
students
and
written
python
books
that
have
sold
roughly
a
quarter
of
a
million
copies
and
been
translated
into
more
than
a
dozen
languages
in
addition
he
holds
b
s
and
m
s
degrees
in
computer
science
from
the
university
of
wisconsin
and
during
the
last
years
he
has
worked
as
a
professional
developer
on
compilers
programming
tools
scripting
applications
and
assorted
client
server
systems
mark
can
be
reached
on
the
web
at
http
www
rmi
net
lutz
colophon
the
animal
on
the
cover
of
learning
python
fourth
edition
is
a
wood
rat
neotoma
muridae
the
wood
rat
lives
in
a
wide
range
of
conditions
mostly
rocky
scrub
and
desert
areas
over
much
of
north
and
central
america
generally
at
some
distance
from
humans
wood
rats
are
good
climbers
nesting
in
trees
or
bushes
up
to
six
meters
off
the
ground
some
species
burrow
underground
or
in
rock
crevices
or
inhabit
other
species
abandoned
holes
these
grayish
beige
medium
size
rodents
are
the
original
pack
rats
they
carry
anything
and
everything
into
their
homes
whether
or
not
it
s
needed
and
are
especially
attracted
to
shiny
objects
such
as
tin
cans
glass
and
silverware
the
cover
image
is
a
th
century
engraving
from
cuvier
s
animals
the
cover
font
is
adobe
itc
garamond
the
text
font
is
linotype
birka
the
heading
font
is
adobe
myriad
condensed
and
the
code
font
is
lucasfont
s
thesansmonocondensed
